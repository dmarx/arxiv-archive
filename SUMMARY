---
File: .github/workflows/convert-markdown.yml
---
# .github/workflows/convert-markdown.yml
name: Convert Papers to Markdown

on:
  schedule:
    - cron: '0 */12 * * *'  # Run every 12 hours
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false
  
jobs:
  test:
    uses: ./.github/workflows/test-python.yml

  convert-markdown:
    needs: test
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y pandoc texlive-base
          pandoc --version  # Verify installation
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers-feed-src/.
      
      - name: Convert to markdown
        run: |
          python -m scripts.asset_manager convert-markdown
          python -m scripts.asset_manager retry-failures
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Convert papers to markdown"
          file_pattern: |
            data/papers/**



---
File: .github/workflows/deploy_frontend.yaml
---
name: Deploy Paper Feed to GitHub Pages

on:
  push:
    paths:
      - 'data/papers/papers.yaml'
      - 'src/scripts/frontend/**'
      - '.github/workflows/deploy_frontend.yaml'
  workflow_dispatch:
  schedule:
    # Run daily at midnight UTC
    - cron: '0 0 * * *'

concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers-feed-src/.

      - name: Generate HTML
        run: |
          python -m scripts.frontend.generate_html \
            --data_path data/papers/papers.yaml \
            --template_path papers-feed-src/src/scripts/frontend/index.template.html \
            --output_path web/index.html

      - name: Ensure presence of .nojekyll file
        run: touch web/.nojekyll

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: web
  
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./web
          force_orphan: true # use only latest commit



---
File: .github/workflows/download-papers.yml
---
# .github/workflows/download-papers.yml
name: Download Paper Files

on:
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false
  
jobs:
  test:
    uses: ./.github/workflows/test-python.yml

  download-files:
    needs: test
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers-feed-src/.
      
      - name: Download PDFs and Source
        run: |
          python -m scripts.asset_manager download-pdfs
          python -m scripts.asset_manager download-source
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Download paper files"
          file_pattern: |
            data/papers/**



---
File: .github/workflows/hard-refresh.yml
---
# .github/workflows/hard-refresh.yml
name: Hard Refresh

on:
  workflow_dispatch:  # Manual trigger only
  
permissions:
  contents: write
  issues: write

jobs:
  # First ensure all tests pass
  test:
    uses: ./.github/workflows/test-python.yml

  refresh:
    needs: test  # Wait for tests to pass
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        submodules: true
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
      
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install PyGithub
        pip install papers-feed-src/. 
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y pandoc texlive-base
    
    - name: Clear data directory and reopen issues
      run: |
        python - <<EOF
        import os
        import shutil
        from github import Github
        
        # Clear data directory
        data_dir = "data"
        if os.path.exists(data_dir):
            print(f"Removing {data_dir} directory...")
            shutil.rmtree(data_dir)
            os.makedirs(data_dir)
        
        # Reopen closed paper/reading issues
        g = Github(os.environ["GITHUB_TOKEN"])
        repo = g.get_repo(os.environ["GITHUB_REPOSITORY"])
        
        for issue in repo.get_issues(state="closed"):
            labels = [label.name for label in issue.labels]
            if "wontfix" in labels:
                continue
            if "paper" in labels or "reading-session" in labels:
                print(f"Reopening issue #{issue.number}")
                issue.edit(state="open")
        EOF
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Process events
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: python -m scripts.process_events
  
    - name: Download PDFs and Source
      run: |
        python -m scripts.asset_manager download-pdfs
        python -m scripts.asset_manager download-source

    - name: Convert to markdown
      run: |
        python -m scripts.asset_manager convert-markdown
        python -m scripts.asset_manager retry-failures
    
    - name: Commit and push if there are changes
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "chore: Hard refresh"
        file_pattern: |
          data/**



---
File: .github/workflows/llamero-summarize.yaml
---
name: Llamero Summarization

on:
  #push:
  workflow_dispatch:

jobs:
  generate-summaries:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install llamero
      run: pip install llamero

    - name: Generate summaries
      run: llamero summarize all



---
File: .github/workflows/ops-misc.yml
---
# .github/workflows/ops-misc.yml
# General purpose utility operator for one-off operations
# Executes misc.sh and clears it after successful run

name: Miscellaneous Operations

on:
  push:
    paths:
      - 'ops/misc.sh'
      - '.github/workflows/ops-misc.yml'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  execute-misc:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Execute and clear misc script
        run: |
          bash ops/misc.sh
          echo '#!/bin/bash' > ops/misc.sh

      - uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: executed miscellaneous operation"



---
File: .github/workflows/ops-remove-files.yml
---
# .github/workflows/remove-files.yml
# Automated file removal workflow triggered by changes to ops/rm.txt
# or to this workflow file itself

name: Remove Files

on:
  push:
    paths:
      - 'ops/rm.txt'
      - '.github/workflows/ops-remove-files.yml'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  remove-files:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Remove files and clear list
        run: |
          if [ -s ops/rm.txt ]; then
            while IFS= read -r pattern; do
              [ -n "$pattern" ] && find . -path "./$pattern" -type f -delete
            done < ops/rm.txt
            : > ops/rm.txt
          fi

      - uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Auto: Remove files listed in ops/rm.txt"



---
File: .github/workflows/process-events.yml
---
# .github/workflows/process-events.yml
name: Process Paper Events
on:
  push:
    paths:
      - ".github/workflows/process-events.yml"
  issues:
    types: [opened]
    labels:
      - 'paper'
      - 'reading-session'
  # schedule:
  #   - cron: '0 * * * *'  # Run every hour
  workflow_call:
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false
  
jobs:
  process-papers:
    runs-on: ubuntu-latest
    permissions:
      actions: write
      contents: write
      issues: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers-feed-src/.
      
      - name: Process Events
        id: process
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          OUTPUT=$(python -m scripts.process_events)
          echo "Debug: Script output: $OUTPUT"
          if [[ "$OUTPUT" == *"Events processed."* ]]; then
            echo "SHOULD_TRIGGER=true" >> "$GITHUB_OUTPUT"
          else
            echo "SHOULD_TRIGGER=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Conditionally trigger frontend deploy
        if: ${{ steps.process.outputs.SHOULD_TRIGGER == 'true' }}
        run: |
          curl -L \
            -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/deploy_frontend.yaml/dispatches \
            -d '{"ref":"${{ github.ref }}"}'



---
File: .github/workflows/test-python.yml
---
name: Test Python Scripts

on:
  push:
  #   branches: [ main ]
    paths:
      - .github/workflows/test-python.yml
  pull_request:
  #   branches: [ main ]
  workflow_dispatch:
  workflow_call:

concurrency:
  group: ${{ github.repository }}-test-python
  cancel-in-progress: true

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        submodules: true

    # - name: Install pandoc
    #   run: |
    #     sudo apt-get update
    #     sudo apt-get install -y pandoc texlive-base
    #     pandoc --version  # Verify installation

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e 'papers-feed-src/.[test]'  # Install package in editable mode with test dependencies
  
    - name: Run tests
      run: |
        pytest tests/ -v --cov=scripts

    - name: Print coverage report
      run: |
        coverage report



---
File: .github/workflows/update-submodule.yml
---
# .github/workflows/update-submodule.yml
name: Update Submodule

on:
  schedule:
    - cron: '0 */6 * * *'
  push:
    paths: "./.github/workflows/update-submodule.yml"
  workflow_dispatch:

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Update submodule
        run: |
          git submodule update --recursive --remote

      - uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: update submodule papers-feed-src"
          file_pattern: 'papers-feed-src'



---
File: extension/background.js
---
// background.js
import { loadSessionConfig, getConfigurationInMs } from './config/session.js';

let githubToken = '';
let githubRepo = '';
let currentPaperData = null;
let currentSession = null;
let activityInterval = null;
let activityTimeout = null;
let sessionConfig = null;

// Load credentials and configuration when extension starts
async function loadCredentials() {
    const items = await chrome.storage.sync.get(['githubToken', 'githubRepo']);
    githubToken = items.githubToken || '';
    githubRepo = items.githubRepo || '';
    console.log('Credentials loaded:', { hasToken: !!githubToken, hasRepo: !!githubRepo });
    
    // Load session configuration
    sessionConfig = getConfigurationInMs(await loadSessionConfig());
    console.log('Session configuration loaded:', sessionConfig);
}

// Listen for credential changes
chrome.storage.onChanged.addListener(async (changes) => {
    console.log('Storage changes detected:', Object.keys(changes));
    if (changes.githubToken) {
        githubToken = changes.githubToken.newValue;
    }
    if (changes.githubRepo) {
        githubRepo = changes.githubRepo.newValue;
    }
    if (changes.sessionConfig) {
        sessionConfig = getConfigurationInMs(changes.sessionConfig.newValue);
        console.log('Session configuration updated:', sessionConfig);
    }
});

// Reading Session class to track individual reading sessions
class ReadingSession {
    constructor(arxivId, config) {
        this.arxivId = arxivId;
        this.startTime = Date.now();
        this.activeTime = 0;
        this.lastActiveTime = Date.now();
        this.isTracking = true;
        this.config = config;
    }

    update() {
        if (this.isTracking) {
            const now = Date.now();
            const timeSinceLastActive = now - this.lastActiveTime;
            
            if (timeSinceLastActive < this.config.idleThreshold) {
                this.activeTime += timeSinceLastActive;
            } else if (this.config.requireContinuousActivity) {
                // Reset active time if continuous activity is required
                this.activeTime = 0;
            }
            
            this.lastActiveTime = now;
        }
    }

    end() {
        this.isTracking = false;
        this.update();
        
        if (this.config.logPartialSessions) {
            return this.activeTime;
        }
        return this.activeTime >= this.config.minSessionDuration ? this.activeTime : 0;
    }
}

// Initialize credentials
loadCredentials();

// Listen for URL changes
chrome.webNavigation.onCompleted.addListener(async (details) => {
    console.log('Navigation detected:', details.url);
    if (details.url.includes('arxiv.org')) {
        console.log('arXiv URL detected, processing...');
        const paperData = await processArxivUrl(details.url);
        if (paperData) {
            console.log('Paper data extracted:', paperData);
            await createGithubIssue(paperData);
        } else {
            console.log('Failed to extract paper data');
        }
    }
}, {
    url: [{
        hostSuffix: 'arxiv.org'
    }]
});

// Message passing between background and popup
chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
    console.log('Message received:', request);
    
    if (request.type === 'getCurrentPaper') {
        console.log('Popup requested current paper:', currentPaperData);
        sendResponse(currentPaperData);
    }
    else if (request.type === 'updateRating') {
        console.log('Rating update requested:', request.rating);
        if (currentPaperData && currentPaperData.issueNumber) {
            updatePaperRating(currentPaperData.issueNumber, request.rating)
                .then(() => {
                    currentPaperData.rating = request.rating;
                    sendResponse({success: true});
                })
                .catch(error => {
                    console.error('Error updating rating:', error);
                    sendResponse({success: false, error: error.message});
                });
            return true; // Will respond asynchronously
        } else {
            sendResponse({success: false, error: 'No current paper or issue number'});
        }
    }
    return true;
});

// Tab and window management
chrome.tabs.onActivated.addListener(async (activeInfo) => {
    const tab = await chrome.tabs.get(activeInfo.tabId);
    handleTabChange(tab);
});

chrome.tabs.onUpdated.addListener((tabId, changeInfo, tab) => {
    if (changeInfo.status === 'complete') {
        handleTabChange(tab);
    }
});

chrome.windows.onFocusChanged.addListener((windowId) => {
    if (windowId === chrome.windows.WINDOW_ID_NONE) {
        endCurrentSession();
    }
});

async function handleTabChange(tab) {
    const isArxiv = tab.url?.includes('arxiv.org/');
    console.log('Tab change detected:', { isArxiv, url: tab.url });
    
    if (!isArxiv) {
        console.log('Not an arXiv page, ending current session');
        await endCurrentSession();
        return;
    }

    // End any existing session before starting a new one
    if (currentSession) {
        console.log('Ending existing session before starting new one');
        await endCurrentSession();
    }

    // Always process the URL and start a new session
    console.log('Processing arXiv URL for new session');
    currentPaperData = await processArxivUrl(tab.url);
    if (currentPaperData) {
        console.log('Starting new session for:', currentPaperData.arxivId);
        currentSession = new ReadingSession(currentPaperData.arxivId, sessionConfig);
        startActivityTracking();
    }
}

async function endCurrentSession() {
    if (currentSession && currentPaperData) {
        console.log('Ending session for:', currentPaperData.arxivId);
        const duration = currentSession.end();
        if (duration > 0) {
            console.log('Creating reading event with duration:', duration);
            await createReadingEvent(currentPaperData, duration);
        }
        currentSession = null;
        currentPaperData = null;
        stopActivityTracking();
    }
}

function startActivityTracking() {
    if (!activityInterval) {
        console.log('Starting activity tracking');
        activityInterval = setInterval(() => {
            if (currentSession) {
                currentSession.update();
            }
        }, sessionConfig.activityUpdateInterval);
    }
}

function stopActivityTracking() {
    if (activityInterval) {
        clearInterval(activityInterval);
        activityInterval = null;
    }
    if (activityTimeout) {
        clearTimeout(activityTimeout);
        activityTimeout = null;
    }
}

async function createReadingEvent(paperData, sessionDuration) {
    if (!githubToken || !githubRepo || !paperData) {
        console.error('Missing required data for creating reading event:', {
            hasToken: !!githubToken,
            hasRepo: !!githubRepo,
            hasPaperData: !!paperData
        });
        return;
    }

    const seconds = Math.round(sessionDuration / 1000);
    if (sessionDuration < sessionConfig.minSessionDuration) {
        console.log('Session too short to log:', seconds, 'seconds');
        return;
    }

    console.log('Creating reading event:', {
        arxivId: paperData.arxivId,
        duration: seconds,
        title: paperData.title
    });

    const eventData = {
        type: 'reading_session',
        arxivId: paperData.arxivId, // TODO: change to arxiv_id throughout
        timestamp: new Date().toISOString(),
        duration_seconds: seconds,
        title: paperData.title,
        authors: paperData.authors,
        abstract: paperData.abstract,
        url: paperData.url,
        session_config: {
            idle_threshold_seconds: sessionConfig.idleThreshold / 1000,
            min_duration_seconds: sessionConfig.minSessionDuration / 1000,
            continuous_activity_required: sessionConfig.requireContinuousActivity,
            partial_sessions_logged: sessionConfig.logPartialSessions
        }
    };

    const issueBody = JSON.stringify(eventData, null, 2);

    try {
        const response = await fetch(`https://api.github.com/repos/${githubRepo}/issues`, {
            method: 'POST',
            headers: {
                'Authorization': `token ${githubToken}`,
                'Accept': 'application/vnd.github.v3+json'
            },
            body: JSON.stringify({
                title: `[Reading] ${paperData.title || paperData.arxivId} (${seconds}s)`,
                body: issueBody,
                labels: ['reading-session']
            })
        });

        if (!response.ok) {
            throw new Error(`GitHub API error: ${response.status}`);
        }

        const issueData = await response.json();
        console.log('Reading event created:', issueData.html_url);
        return issueData;
    } catch (error) {
        console.error('Error creating reading event:', error);
    }
}

// Update parseXMLText function to extract publication date and categories
async function parseXMLText(xmlText) {
    console.log('Parsing XML response...');
    try {
        const getTagContent = (tag, text) => {
            const entryRegex = /<entry>([\s\S]*?)<\/entry>/;
            const entryMatch = text.match(entryRegex);
            
            if (entryMatch) {
                const entryContent = entryMatch[1];
                const regex = new RegExp(`<${tag}[^>]*>(.*?)</${tag}>`, 's');
                const match = entryContent.match(regex);
                return match ? match[1].trim() : '';
            }
            return '';
        };
        
        const getAuthors = (text) => {
            const authors = [];
            const regex = /<author>[^]*?<name>([^]*?)<\/name>[^]*?<\/author>/g;
            let match;
            while (match = regex.exec(text)) {
                authors.push(match[1].trim());
            }
            return authors;
        };

        // Extract categories/tags
        const getCategories = (text) => {
            const categories = new Set();
            
            // Get primary category
            const primaryMatch = text.match(/<arxiv:primary_category[^>]*term="([^"]+)"/);
            if (primaryMatch) {
                categories.add(primaryMatch[1]);
            }
            
            // Get all categories
            const categoryRegex = /<category[^>]*term="([^"]+)"/g;
            let match;
            while (match = categoryRegex.exec(text)) {
                categories.add(match[1]);
            }
            
            return Array.from(categories);
        };

        // Get publication date (first version)
        const getPublishedDate = (text) => {
            const match = text.match(/<published>([^<]+)<\/published>/);
            return match ? match[1].trim() : null;
        };

        const parsed = {
            title: getTagContent('title', xmlText),
            summary: getTagContent('summary', xmlText),
            authors: getAuthors(xmlText),
            published_date: getPublishedDate(xmlText),
            arxiv_tags: getCategories(xmlText)
        };
        
        console.log('Parsed XML:', parsed);
        return parsed;
    } catch (error) {
        console.error('Error parsing XML:', error);
        return null;
    }
}

// Update processArxivUrl function to include new fields
async function processArxivUrl(url) {
    console.log('Processing URL:', url);
    
    const patterns = [
        /arxiv\.org\/abs\/([0-9.]+)/,
        /arxiv\.org\/pdf\/([0-9.]+)\.pdf/,
        /arxiv\.org\/\w+\/([0-9.]+)/
    ];
    
    let arxivId = null;
    for (const pattern of patterns) {
        const match = url.match(pattern);
        if (match) {
            arxivId = match[1];
            break;
        }
    }
    
    if (!arxivId) {
        console.log('No arXiv ID found in URL');
        return null;
    }
    
    console.log('Found arXiv ID:', arxivId);
    
    try {
        const apiUrl = `http://export.arxiv.org/api/query?id_list=${arxivId}`;
        console.log('Fetching from arXiv API:', apiUrl);
        
        const response = await fetch(apiUrl);
        console.log('API response status:', response.status);
        
        const text = await response.text();
        const parsed = await parseXMLText(text);
        
        if (!parsed) {
            console.log('Failed to parse API response');
            return null;
        }
        
        const paperData = {
            arxivId,
            url,
            title: parsed.title,
            authors: parsed.authors.join(", "),
            abstract: parsed.summary,
            timestamp: new Date().toISOString(),
            rating: 'novote',
            published_date: parsed.published_date,
            arxiv_tags: parsed.arxiv_tags
        };
        
        console.log('Paper data processed:', paperData);
        return paperData;
    } catch (error) {
        console.error('Error processing arXiv URL:', error);
        return null;
    }
}

// Update createGithubIssue to add tags to labels
async function createGithubIssue(paperData) {
    if (!githubToken || !githubRepo) {
        console.error('GitHub credentials not set. Please configure extension options.');
        return;
    }

    try {
        console.log('Creating GitHub issue for paper:', paperData.arxivId);
        const issueBody = JSON.stringify(paperData, null, 2);

        // Create issue labels starting with paper and rating
        const issueLabels = ['paper', `rating:${paperData.rating}`];
        
        // // Add arXiv tags as labels if they exist
        // if (paperData.arxiv_tags && paperData.arxiv_tags.length > 0) {
        //     // Add tags in format "arxiv:cs.AI", "arxiv:cs.LG", etc.
        //     issueLabels.push(...paperData.arxiv_tags.map(tag => `arxiv:${tag}`));
        // }

        const response = await fetch(`https://api.github.com/repos/${githubRepo}/issues`, {
            method: 'POST',
            headers: {
                'Authorization': `token ${githubToken}`,
                'Accept': 'application/vnd.github.v3+json'
            },
            body: JSON.stringify({
                title: `[Paper] ${paperData.title || paperData.arxivId}`,
                body: issueBody,
                labels: issueLabels
            })
        });

        if (!response.ok) {
            throw new Error(`GitHub API error: ${response.status}`);
        }

        const issueData = await response.json();
        console.log('GitHub issue created successfully:', issueData.html_url);
        return issueData;
    } catch (error) {
        console.error('Error creating Github issue:', error);
    }
}

async function updatePaperRating(issueNumber, rating) {
    if (!githubToken || !githubRepo) {
        console.error('GitHub credentials not set. Please configure extension options.');
        return;
    }

    try {
        console.log(`Updating rating for issue ${issueNumber} to ${rating}`);
        
        // Update issue labels
        await fetch(`https://api.github.com/repos/${githubRepo}/issues/${issueNumber}/labels`, {
            method: 'PUT',
            headers: {
                'Authorization': `token ${githubToken}`,
                'Accept': 'application/vnd.github.v3+json'
            },
            body: JSON.stringify([
                'paper',
                `rating:${rating}`
            ])
        });

        // Add comment about rating change
        await fetch(`https://api.github.com/repos/${githubRepo}/issues/${issueNumber}/comments`, {
            method: 'POST',
            headers: {
                'Authorization': `token ${githubToken}`,
                'Accept': 'application/vnd.github.v3+json'
            },
            body: JSON.stringify({
                body: `Updated paper rating to: ${rating}`
            })
        });

        console.log('Rating updated successfully');
    } catch (error) {
        console.error('Error updating rating:', error);
        throw error;
    }
}



---
File: extension/config/session.js
---
// extension/config/session.js

// Default configuration values
const DEFAULT_CONFIG = {
    idleThresholdMinutes: 5,
    minSessionDurationSeconds: 30,
    // Adding more granular control
    requireContinuousActivity: true,  // If true, resets timer on idle
    logPartialSessions: false,        // If true, logs sessions even if under minimum duration
    activityUpdateIntervalSeconds: 1  // How often to update active time
};

// Load session configuration from storage
async function loadSessionConfig() {
    const items = await chrome.storage.sync.get('sessionConfig');
    return { ...DEFAULT_CONFIG, ...items.sessionConfig };
}

// Save session configuration to storage
async function saveSessionConfig(config) {
    await chrome.storage.sync.set({
        sessionConfig: {
            idleThresholdMinutes: Number(config.idleThresholdMinutes),
            minSessionDurationSeconds: Number(config.minSessionDurationSeconds),
            requireContinuousActivity: Boolean(config.requireContinuousActivity),
            logPartialSessions: Boolean(config.logPartialSessions),
            activityUpdateIntervalSeconds: Number(config.activityUpdateIntervalSeconds)
        }
    });
}

// Convert configuration to milliseconds for internal use
function getConfigurationInMs(config) {
    return {
        idleThreshold: config.idleThresholdMinutes * 60 * 1000,
        minSessionDuration: config.minSessionDurationSeconds * 1000,
        activityUpdateInterval: config.activityUpdateIntervalSeconds * 1000,
        requireContinuousActivity: config.requireContinuousActivity,
        logPartialSessions: config.logPartialSessions
    };
}

export { loadSessionConfig, saveSessionConfig, getConfigurationInMs, DEFAULT_CONFIG };


---
File: extension/manifest.json
---
{
  "manifest_version": 3,
  "name": "ArXiv Paper Tracker",
  "version": "1.0",
  "description": "Track and rate arXiv papers you read",
  "permissions": [
    "tabs",
    "storage",
    "webNavigation"
  ],
  "host_permissions": [
    "*://arxiv.org/*",
    "*://api.github.com/*"
  ],
  "background": {
    "service_worker": "background.js",
    "type": "module"
  },
  "action": {
    "default_popup": "popup.html"
  },
  "options_ui": {
    "page": "options.html",
    "open_in_tab": false
  }
}


---
File: extension/options.html
---
<!DOCTYPE html>
<html>
<head>
  <title>ArXiv Tracker Settings</title>
  <style>
    body {
      padding: 20px;
      font-family: system-ui, -apple-system, sans-serif;
    }
    .container {
      max-width: 500px;
      margin: 0 auto;
    }
    .field {
      margin-bottom: 20px;
    }
    label {
      display: block;
      margin-bottom: 5px;
      font-weight: 500;
    }
    input[type="text"],
    input[type="password"],
    input[type="number"] {
      width: 100%;
      padding: 8px;
      border: 1px solid #ddd;
      border-radius: 4px;
      font-family: monospace;
    }
    input[type="number"] {
      width: 100px;
    }
    .help-text {
      font-size: 0.9em;
      color: #666;
      margin-top: 4px;
    }
    .status {
      margin-top: 16px;
      padding: 8px;
      border-radius: 4px;
    }
    .success {
      background: #e6ffe6;
      color: #006600;
    }
    .error {
      background: #ffe6e6;
      color: #660000;
    }
    button {
      background: #0366d6;
      color: white;
      border: none;
      padding: 8px 16px;
      border-radius: 4px;
      cursor: pointer;
      margin-top: 16px;
    }
    button:hover {
      background: #0255b3;
    }
    .section {
      margin-bottom: 32px;
    }
    .section-title {
      font-size: 1.2em;
      font-weight: 600;
      margin-bottom: 16px;
      padding-bottom: 8px;
      border-bottom: 1px solid #eee;
    }
    .checkbox-field {
      margin-top: 12px;
    }
    .checkbox-field label {
      display: flex;
      align-items: center;
      font-weight: normal;
    }
    .checkbox-field input[type="checkbox"] {
      margin-right: 8px;
    }
  </style>
</head>
<body>
  <div class="container">
    <h2>ArXiv Tracker Settings</h2>
    
    <div class="section">
      <div class="section-title">GitHub Integration</div>
      <div class="field">
        <label for="repo">GitHub Repository</label>
        <input type="text" id="repo" placeholder="username/repository">
        <div class="help-text">Format: username/repository (e.g., johndoe/arxiv-tracker)</div>
      </div>

      <div class="field">
        <label for="token">GitHub Personal Access Token</label>
        <input type="password" id="token" placeholder="ghp_xxxxxxxxxxxxxxxxxxxx">
        <div class="help-text">
          Token needs 'repo' scope for private repositories.<br>
          Never share this token with anyone.
        </div>
      </div>
    </div>

    <div class="section">
      <div class="section-title">Reading Session Settings</div>
      
      <div class="field">
        <label for="idleThreshold">Idle Threshold (minutes)</label>
        <input type="number" id="idleThreshold" min="1" max="60" value="5">
        <div class="help-text">
          Time of inactivity before session is paused (1-60 minutes).<br>
          Default: 5 minutes
        </div>
      </div>

      <div class="field">
        <label for="minDuration">Minimum Session Duration (seconds)</label>
        <input type="number" id="minDuration" min="10" max="300" value="30">
        <div class="help-text">
          Minimum time required to log a reading session (10-300 seconds).<br>
          Default: 30 seconds
        </div>
      </div>

      <div class="checkbox-field">
        <label>
          <input type="checkbox" id="requireContinuous">
          Require Continuous Activity
        </label>
        <div class="help-text">
          When enabled, resets the session timer if you're idle for too long.<br>
          Default: Enabled
        </div>
      </div>

      <div class="checkbox-field">
        <label>
          <input type="checkbox" id="logPartial">
          Log Partial Sessions
        </label>
        <div class="help-text">
          When enabled, logs sessions even if they're shorter than the minimum duration.<br>
          Default: Disabled
        </div>
      </div>
    </div>

    <button id="save">Save Settings</button>
    <div id="status" class="status"></div>
  </div>
  <script type="module" src="options.js"></script>
</body>
</html>


---
File: extension/options.js
---
// options.js
import { loadSessionConfig, DEFAULT_CONFIG, saveSessionConfig } from './config/session.js';

// Helper to set form field values
function setFormValues(settings) {
  // GitHub settings
  if (settings.githubRepo) {
    document.getElementById('repo').value = settings.githubRepo;
  }
  if (settings.githubToken) {
    // Don't show the actual token, just indicate it's set
    document.getElementById('token').placeholder = '‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢';
  }

  // Session settings
  document.getElementById('idleThreshold').value = settings.sessionConfig?.idleThresholdMinutes ?? DEFAULT_CONFIG.idleThresholdMinutes;
  document.getElementById('minDuration').value = settings.sessionConfig?.minSessionDurationSeconds ?? DEFAULT_CONFIG.minSessionDurationSeconds;
  document.getElementById('requireContinuous').checked = settings.sessionConfig?.requireContinuousActivity ?? DEFAULT_CONFIG.requireContinuousActivity;
  document.getElementById('logPartial').checked = settings.sessionConfig?.logPartialSessions ?? DEFAULT_CONFIG.logPartialSessions;
}

// Helper to get form values
function getFormValues() {
  return {
    githubRepo: document.getElementById('repo').value.trim(),
    githubToken: document.getElementById('token').value.trim(),
    sessionConfig: {
      idleThresholdMinutes: Number(document.getElementById('idleThreshold').value),
      minSessionDurationSeconds: Number(document.getElementById('minDuration').value),
      requireContinuousActivity: document.getElementById('requireContinuous').checked,
      logPartialSessions: document.getElementById('logPartial').checked
    }
  };
}

// Display status message
function showStatus(message, isError = false) {
  const status = document.getElementById('status');
  status.textContent = message;
  status.className = `status ${isError ? 'error' : 'success'}`;

  // Clear status after 3 seconds if it's a success message
  if (!isError) {
    setTimeout(() => {
      status.textContent = '';
      status.className = 'status';
    }, 3000);
  }
}

// Validate settings before saving
async function validateSettings(settings) {
  // Validate repository format
  if (!/^[\w-]+\/[\w-]+$/.test(settings.githubRepo)) {
    throw new Error('Invalid repository format. Use username/repository');
  }

  // Validate the token by making a test API call
  const response = await fetch(`https://api.github.com/repos/${settings.githubRepo}`, {
    headers: {
      'Authorization': `token ${settings.githubToken}`,
      'Accept': 'application/vnd.github.v3+json'
    }
  });

  if (!response.ok) {
    throw new Error('Invalid token or repository. Please check your credentials.');
  }

  // Validate session settings
  const { sessionConfig } = settings;
  if (sessionConfig.idleThresholdMinutes < 1 || sessionConfig.idleThresholdMinutes > 60) {
    throw new Error('Idle threshold must be between 1 and 60 minutes');
  }
  if (sessionConfig.minSessionDurationSeconds < 1 || sessionConfig.minSessionDurationSeconds > 300) {
    throw new Error('Minimum session duration must be between 10 and 300 seconds');
  }
}

// Save settings
async function saveSettings(settings) {
  await chrome.storage.sync.set({
    githubRepo: settings.githubRepo,
    githubToken: settings.githubToken
  });

  await saveSessionConfig(settings.sessionConfig);
}

// Initialize options page
document.addEventListener('DOMContentLoaded', async () => {
  try {
    // Load current settings
    const [storageItems, sessionConfig] = await Promise.all([
      chrome.storage.sync.get(['githubRepo', 'githubToken']),
      loadSessionConfig()
    ]);

    // Combine settings and display them
    setFormValues({
      ...storageItems,
      sessionConfig
    });

    // Add save button handler
    document.getElementById('save').addEventListener('click', async () => {
      try {
        const settings = getFormValues();
        await validateSettings(settings);
        await saveSettings(settings);
        showStatus('Settings saved successfully!');
      } catch (error) {
        showStatus(`Error: ${error.message}`, true);
      }
    });

  } catch (error) {
    showStatus(`Error loading settings: ${error.message}`, true);
  }
});


---
File: extension/popup.html
---
<!DOCTYPE html>
<html>
<head>
  <style>
    body {
      width: 400px;
      padding: 15px;
      font-family: system-ui, -apple-system, sans-serif;
    }
    .paper-info {
      margin-bottom: 15px;
    }
    .paper-title {
      font-weight: bold;
      margin-bottom: 8px;
      font-size: 14px;
      line-height: 1.4;
    }
    .paper-authors {
      font-size: 12px;
      color: #666;
      margin-bottom: 12px;
      line-height: 1.4;
    }
    .rating-buttons {
      display: flex;
      gap: 10px;
      margin-top: 15px;
    }
    button {
      flex: 1;
      padding: 8px;
      border: 1px solid #ddd;
      border-radius: 4px;
      background: #f5f5f5;
      cursor: pointer;
    }
    button:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }
    button:not(:disabled):hover {
      background: #e5e5e5;
    }
    .status {
      margin-top: 10px;
      font-size: 12px;
      color: #666;
      padding: 8px;
      background: #f5f5f5;
      border-radius: 4px;
      text-align: center;
    }
  </style>
</head>
<body>
  <div id="currentPaper" class="paper-info">
    <div id="paperTitle" class="paper-title">Loading...</div>
    <div id="paperAuthors" class="paper-authors"></div>
    <div class="rating-buttons">
      <button id="thumbsUp" disabled>üëç Interesting</button>
      <button id="thumbsDown" disabled>üëé Not Relevant</button>
    </div>
    <div id="status" class="status">Loading paper details...</div>
  </div>
  <script src="popup.js"></script>
</body>
</html>



---
File: extension/popup.js
---
// popup.js
let currentIssueNumber = null;

// Function to get paper data from background script
async function getCurrentPaper() {
  return new Promise((resolve) => {
    chrome.runtime.sendMessage({type: 'getCurrentPaper'}, response => {
      console.log('Got paper data from background:', response);
      resolve(response);
    });
  });
}

// Function to update UI with paper data
function updateUI(paperData) {
  const titleElement = document.getElementById('paperTitle');
  const authorsElement = document.getElementById('paperAuthors');
  const statusElement = document.getElementById('status');

  if (paperData) {
    titleElement.textContent = paperData.title || paperData.arxivId;
    authorsElement.textContent = paperData.authors;
    statusElement.textContent = 'Paper tracked! Issue created on GitHub.';
    
    // Enable rating buttons
    document.getElementById('thumbsUp').disabled = false;
    document.getElementById('thumbsDown').disabled = false;
  } else {
    titleElement.textContent = 'No arXiv paper detected';
    authorsElement.textContent = '';
    statusElement.textContent = 'Visit an arXiv paper to track it';
    
    // Disable rating buttons
    document.getElementById('thumbsUp').disabled = true;
    document.getElementById('thumbsDown').disabled = true;
  }
}

// Initialize popup
document.addEventListener('DOMContentLoaded', async () => {
  console.log('Popup opened');
  
  // Get current tab
  const [tab] = await chrome.tabs.query({ active: true, currentWindow: true });
  console.log('Current tab:', tab.url);
  
  if (tab.url.includes('arxiv.org')) {
    console.log('On arXiv page, getting paper data...');
    // Try multiple times to get paper data, as it might not be ready immediately
    let retries = 3;
    let paperData = null;
    
    while (retries > 0 && !paperData) {
      paperData = await getCurrentPaper();
      if (!paperData) {
        await new Promise(resolve => setTimeout(resolve, 500)); // Wait 500ms before retry
        retries--;
      }
    }
    
    updateUI(paperData);
    
    // Set up rating handlers
    document.getElementById('thumbsUp').addEventListener('click', () => {
      chrome.runtime.sendMessage({
        type: 'updateRating',
        rating: 'thumbsup'
      }, response => {
        if (response && response.success) {
          document.getElementById('status').textContent = 'Rating updated to: thumbs up';
          setTimeout(() => window.close(), 1500);
        }
      });
    });
    
    document.getElementById('thumbsDown').addEventListener('click', () => {
      chrome.runtime.sendMessage({
        type: 'updateRating',
        rating: 'thumbsdown'
      }, response => {
        if (response && response.success) {
          document.getElementById('status').textContent = 'Rating updated to: thumbs down';
          setTimeout(() => window.close(), 1500);
        }
      });
    });
  } else {
    updateUI(null);
  }
});



---
File: ops/rm.txt
---



---
File: pyproject.toml
---
[project]
name = "scripts"
version = "0.1.0"
description = ""
requires-python = ">=3.11"
dependencies = [
   "pyyaml", # todo: deprecate in favor of omegaconf
    "llamero>=0.2.5", # brings along loguru, jinja, tomli, fire, tree-format, omegaconf, pytest
    "aiohttp",
    "pydantic",
    "requests"
]
readme = "README.md"
license = {file = "LICENSE"}


[project.optional-dependencies]
test = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
    "pytest-asyncio"
]

[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"


[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
addopts = "-v --cov=scripts --no-cov-on-fail --asyncio-mode=strict"
markers = ["integration: marks tests as integration tests"]

[tool.readme.tree]
ignore_patterns = [
    "__pycache__",
    "*.pyc",
    ".git",
    ".venv",
    ".pytest_cache",
    ".vscode",
    ".idea",
    "*.egg-info",
    "*.pyc",
    "*.pyo",
    "*.pyd",
    ".Python",
    "*.so",
    ".gitkeep",
    "_version.py"
]

[tool.readme.sections.order]
"introduction.md.j2" = 0
"features.md.j2" = 1
"prerequisites.md.j2" = 2
"setup.md.j2" = 2.1
"installation.md.j2" = 2.2
"usage.md.j2" = 3
"development.md.j2" = 4
"summaries.md.j2" = 5
"site.md.j2" = 6
"structure.md.j2" = 7
"todo.md.j2" = 999

[tool.summary]
max_file_size_kb = 500  # Skip files larger than 1MB

# File patterns to exclude
exclude_patterns = [
    '.git',
    '.gitignore',
    '.pytest_cache',
    '__pycache__',
    'SUMMARY',
    '.coverage',
    '.env',
    '.venv',
    '.idea',
    '.vscode',
    'README.md',
    'README_LLM.md',
    'package-lock.json',
    'REGISTRY.md',
    'research.yaml',
    'registry.yaml',
    'bibliography',
    '.bibtex',
    'metadata.json',
    'events.log',
    'papers.yaml'
]

# File extensions to include
include_extensions = [
    '.py',
    '.md',
    '.txt',
    '.yml',
    '.yaml',
    '.toml',
    '.json',
    '.html',
    '.css',
    '.js',
    '.ts',
    '.tsx',
    '.j2'
]

# Directories to exclude
exclude_directories = [
    '.git',
    '__pycache__',
    '.pytest_cache',
    '.venv',
    '.idea',
    '.vscode',
    'data'
]



---
File: src/scripts/arxiv_client.py
---
# src/scripts/arxiv_client.py
"""Client for interacting with arXiv API and downloading papers."""

import os
import time
import shutil
import tarfile
import tempfile
import requests
from pathlib import Path
from datetime import datetime
from typing import Optional
from loguru import logger

from .models import Paper

class ArxivClient:
    """Client for interacting with arXiv API and downloading papers."""
    
    def __init__(self, papers_dir: str | Path):
        """
        Initialize ArxivClient.
        
        Args:
            papers_dir: Base directory for paper storage
        """
        self.papers_dir = Path(papers_dir)
        self.papers_dir.mkdir(parents=True, exist_ok=True)
        
        # Rate limiting controls
        self.last_request = 0
        self.min_delay = 3  # Seconds between requests
        self.headers = {'User-Agent': 'ArxivPaperTracker/1.0'}
        self.api_base = "http://export.arxiv.org/api/query"
    
    def _wait_for_rate_limit(self):
        """Enforce rate limiting between requests."""
        now = time.time()
        time_since_last = now - self.last_request
        if time_since_last < self.min_delay:
            time.sleep(self.min_delay - time_since_last)
        self.last_request = time.time()
    
    def get_paper_dir(self, arxiv_id: str) -> Path:
        """Get paper's directory, creating if needed."""
        paper_dir = self.papers_dir / arxiv_id
        paper_dir.mkdir(parents=True, exist_ok=True)
        return paper_dir
    
    def get_paper_status(self, arxiv_id: str) -> dict:
        """
        Get current status of paper downloads.
        
        Returns:
            dict with keys:
                - has_pdf: Whether PDF exists
                - has_source: Whether source exists
                - pdf_size: Size of PDF if it exists
                - source_size: Size of source directory if it exists
        """
        paper_dir = self.papers_dir / arxiv_id
        pdf_file = paper_dir / f"{arxiv_id}.pdf"
        source_dir = paper_dir / "source"
        
        return {
            "has_pdf": pdf_file.exists(),
            "has_source": source_dir.exists(),
            "pdf_size": pdf_file.stat().st_size if pdf_file.exists() else 0,
            "source_size": sum(
                f.stat().st_size for f in source_dir.rglob('*') if f.is_file()
            ) if source_dir.exists() else 0
        }
    
    def fetch_metadata(self, arxiv_id: str) -> Paper:
        """
        Fetch paper metadata from arXiv API.
        
        Args:
            arxiv_id: The arXiv identifier
            
        Returns:
            Paper: Constructed Paper object
            
        Raises:
            ValueError: If API response is invalid
            Exception: For network or parsing errors
        """
        self._wait_for_rate_limit()
        
        try:
            url = f"{self.api_base}?id_list={arxiv_id}"
            logger.debug(f"Fetching arXiv metadata: {url}")
            
            response = requests.get(url, headers=self.headers, timeout=30)
            if response.status_code != 200:
                raise ValueError(f"ArXiv API error: {response.status_code}")
            
            return self._parse_arxiv_response(response.text, arxiv_id)
                
        except Exception as e:
            logger.error(f"Error fetching arXiv metadata for {arxiv_id}: {e}")
            raise
        
    def _parse_arxiv_response(self, xml_text: str, arxiv_id: str) -> Paper:
        """Parse ArXiv API response XML into Paper object."""
        import xml.etree.ElementTree as ET
        
        try:
            # Parse XML
            root = ET.fromstring(xml_text)
            
            # ArXiv API uses Atom namespace
            ns = {'atom': 'http://www.w3.org/2005/Atom',
                  'arxiv': 'http://arxiv.org/schemas/atom'}
            
            # Find the entry element
            entry = root.find('.//atom:entry', ns)
            if entry is None:
                raise ValueError(f"No entry found for {arxiv_id}")
    
            # Extract metadata
            title = entry.find('atom:title', ns).text.strip()
            abstract = entry.find('atom:summary', ns).text.strip()
            authors = ", ".join(
                author.text.strip() 
                for author in entry.findall('.//atom:author/atom:name', ns)
            )
    
            # Extract URLs
            urls = {
                link.get('title', ''): link.get('href', '')
                for link in entry.findall('atom:link', ns)
            }
            html_url = urls.get('abs', f"https://arxiv.org/abs/{arxiv_id}")
    
            # Extract published date (for v1)
            published = entry.find('atom:published', ns)
            published_date = published.text if published is not None else None
    
            # Extract arXiv categories/tags
            primary_category = entry.find('arxiv:primary_category', ns)
            categories = [
                term.get('term') 
                for term in entry.findall('atom:category', ns)
            ]
            if primary_category is not None:
                primary = primary_category.get('term')
                if primary and primary not in categories:
                    categories.insert(0, primary)
    
            # Construct Paper object
            return Paper(
                arxivId=arxiv_id,
                title=title,
                authors=authors,
                abstract=abstract,
                url=html_url,
                issue_number=0,
                issue_url="",
                created_at=datetime.utcnow().isoformat(),
                state="open",
                labels=["paper"],
                total_reading_time_seconds=0,
                last_read=None,
                published_date=published_date,
                arxiv_tags=categories
            )
    
        except ET.ParseError as e:
            logger.error(f"XML parsing error for {arxiv_id}: {e}")
            raise ValueError(f"Invalid XML response from arXiv API: {e}")
        except Exception as e:
            logger.error(f"Error parsing arXiv response: {e}")
            raise
    
    def get_pdf_url(self, arxiv_id: str) -> str:
        """Get PDF URL from arXiv ID."""
        return f"https://arxiv.org/pdf/{arxiv_id}.pdf"
    
    def get_source_url(self, arxiv_id: str) -> str:
        """Get source URL from arXiv ID."""
        return f"https://arxiv.org/e-print/{arxiv_id}"

    def download_pdf(self, arxiv_id: str) -> bool:
        """
        Download PDF for a paper.
        
        Args:
            arxiv_id: Paper ID to download
            
        Returns:
            bool: True if successful
        """
        try:
            pdf_url = self.get_pdf_url(arxiv_id)
            paper_dir = self.get_paper_dir(arxiv_id)
            pdf_path = paper_dir / f"{arxiv_id}.pdf"
            
            if pdf_path.exists():
                logger.info(f"PDF already exists for {arxiv_id}")
                return True
            
            self._wait_for_rate_limit()
            logger.info(f"Downloading PDF: {pdf_path}")
            
            response = requests.get(pdf_url, headers=self.headers, timeout=30)
            if response.status_code != 200:
                raise ValueError(f"Failed to download PDF: {response.status_code}")
            
            pdf_path.write_bytes(response.content)
            return True
            
        except Exception as e:
            logger.error(f"Error downloading PDF for {arxiv_id}: {e}")
            return False

    def download_source(self, arxiv_id: str) -> bool:
        """
        Download and extract source files for a paper.
        
        Args:
            arxiv_id: Paper ID to download
            
        Returns:
            bool: True if successful
        """
        try:
            source_url = self.get_source_url(arxiv_id)
            paper_dir = self.get_paper_dir(arxiv_id)
            source_dir = paper_dir / "source"
            
            if source_dir.exists():
                logger.info(f"Source already exists for {arxiv_id}")
                return True
            
            self._wait_for_rate_limit()
            logger.info(f"Downloading source: {source_dir}")
            
            response = requests.get(source_url, headers=self.headers, timeout=30)
            if response.status_code != 200:
                raise ValueError(f"Failed to download source: {response.status_code}")
            
            # Create temporary file for the tar content
            with tempfile.NamedTemporaryFile(suffix='.tar', delete=False) as tmp_file:
                tmp_file.write(response.content)
                tmp_file_path = tmp_file.name
            
            try:
                source_dir.mkdir(exist_ok=True)
                
                # Extract tar file
                try:
                    with tarfile.open(tmp_file_path) as tar:
                        def is_within_directory(directory, target):
                            abs_directory = os.path.abspath(directory)
                            abs_target = os.path.abspath(target)
                            prefix = os.path.commonprefix([abs_directory, abs_target])
                            return prefix == abs_directory

                        def safe_extract(tar, path=".", members=None):
                            for member in tar.getmembers():
                                member_path = os.path.join(path, member.name)
                                if not is_within_directory(path, member_path):
                                    raise Exception("Attempted path traversal in tar file")
                            tar.extractall(path=path, members=members)

                        safe_extract(tar, path=source_dir)
                        
                except tarfile.ReadError:
                    # If not a tar file, just copy it as a single file
                    main_tex = source_dir / "main.tex"
                    main_tex.write_bytes(response.content)
            finally:
                # Clean up temporary file
                if os.path.exists(tmp_file_path):
                    os.unlink(tmp_file_path)
            
            return True
            
        except Exception as e:
            logger.error(f"Error downloading source for {arxiv_id}: {e}")
            if source_dir.exists():
                shutil.rmtree(source_dir)  # Clean up on failure
            return False

    def download_paper(self, arxiv_id: str, skip_existing: bool = True) -> bool:
        """
        Download both PDF and source files for a paper.
        
        Args:
            arxiv_id: Paper ID to download
            skip_existing: Skip downloads if files exist
            
        Returns:
            bool: True if all downloads successful
        """
        status = self.get_paper_status(arxiv_id)
        
        if skip_existing and status["has_pdf"] and status["has_source"]:
            logger.info(f"All files already exist for {arxiv_id}")
            return True
        
        if not status["has_pdf"]:
            if not self.download_pdf(arxiv_id):
                return False
        
        if not status["has_source"]:
            if not self.download_source(arxiv_id):
                return False
        
        return True



---
File: src/scripts/asset_manager.py
---
# src/scripts/asset_manager.py
"""Manage paper assets including downloads, source files, and markdown conversions."""

import time
from pathlib import Path
from loguru import logger
from typing import Optional
import fire

from .arxiv_client import ArxivClient
from .markdown_service import MarkdownService

class PaperAssetManager:
    """Manages paper assets including PDFs, source files, and markdown conversions."""
    
    def __init__(self, papers_dir: str | Path, 
                 arxiv_client: Optional[ArxivClient] = None,
                 markdown_service: Optional[MarkdownService] = None):
        self.papers_dir = Path(papers_dir)
        self.papers_dir.mkdir(parents=True, exist_ok=True)
        self.arxiv = arxiv_client or ArxivClient(papers_dir)
        self.markdown = markdown_service or MarkdownService(papers_dir)
    
    def find_missing_pdfs(self) -> list[str]:
        """Find papers missing PDF downloads."""
        missing = []
        for paper_dir in self.papers_dir.iterdir():
            if not paper_dir.is_dir():
                continue
            arxiv_id = paper_dir.name
            status = self.arxiv.get_paper_status(arxiv_id)
            if not status["has_pdf"]:
                missing.append(arxiv_id)
        return missing
    
    def find_missing_source(self) -> list[str]:
        """Find papers missing source files."""
        missing = []
        for paper_dir in self.papers_dir.iterdir():
            if not paper_dir.is_dir():
                continue
            arxiv_id = paper_dir.name
            status = self.arxiv.get_paper_status(arxiv_id)
            if not status["has_source"]:
                missing.append(arxiv_id)
        return missing
    
    def find_pending_markdown(self) -> list[str]:
        """Find papers with source but no markdown."""
        pending = []
        for paper_dir in self.papers_dir.iterdir():
            if not paper_dir.is_dir():
                continue
            arxiv_id = paper_dir.name
            download_status = self.arxiv.get_paper_status(arxiv_id)
            markdown_status = self.markdown.get_conversion_status(arxiv_id)
            if (download_status["has_source"] and 
                not markdown_status["has_markdown"] and 
                not markdown_status["failed"]):
                pending.append(arxiv_id)
        return pending
    
    def download_pdfs(self, force: bool = False) -> dict[str, bool]:
        """Download PDFs for papers missing them."""
        papers = self.find_missing_pdfs() if not force else [
            p.name for p in self.papers_dir.iterdir() if p.is_dir()
        ]
        results = {}
        for arxiv_id in papers:
            logger.info(f"Downloading PDF for {arxiv_id}")
            success = self.arxiv.download_pdf(arxiv_id)
            results[arxiv_id] = success
        return results
    
    def download_source(self, force: bool = False) -> dict[str, bool]:
        """Download source files for papers missing them."""
        papers = self.find_missing_source() if not force else [
            p.name for p in self.papers_dir.iterdir() if p.is_dir()
        ]
        results = {}
        for arxiv_id in papers:
            logger.info(f"Downloading source for {arxiv_id}")
            success = self.arxiv.download_source(arxiv_id)
            results[arxiv_id] = success
        return results
        
    def convert_markdown(self, force: bool = False) -> dict[str, bool]:
        """Convert papers with source to markdown."""
        # Get candidate papers
        if force:
            # On force, attempt all papers that have source files
            candidates = [
                p.name for p in self.papers_dir.iterdir() 
                if p.is_dir() and self.arxiv.get_paper_status(p.name)["has_source"]
            ]
        else:
            # Get papers with source but no markdown
            candidates = []
            for paper_dir in self.papers_dir.iterdir():
                if not paper_dir.is_dir():
                    continue
                arxiv_id = paper_dir.name
                download_status = self.arxiv.get_paper_status(arxiv_id)
                markdown_status = self.markdown.get_conversion_status(arxiv_id)
                
                if (download_status["has_source"] and not markdown_status["has_markdown"]):
                    candidates.append(arxiv_id)
        
        # Process candidates
        results = {}
        for arxiv_id in candidates:
            logger.info(f"Converting {arxiv_id} to markdown")
            try:
                success = self.markdown.convert_paper(arxiv_id, force=force)
                results[arxiv_id] = success
            except Exception as e:
                logger.error(f"Error converting {arxiv_id}: {e}")
                results[arxiv_id] = False
        
        return results
    
    def ensure_all_assets(self, force: bool = False, retry_failed: bool = True):
        """Ensure all papers have complete assets."""
        if retry_failed:
            self.markdown.retry_failed_conversions(force=force)
        
        download_results = self.download_pdfs(force)
        source_results = self.download_source(force)
        markdown_results = self.convert_markdown(force)
        
        total = len(download_results) + len(source_results) + len(markdown_results)
        success = (
            sum(download_results.values()) + 
            sum(source_results.values()) + 
            sum(markdown_results.values())
        )
        
        if total == 0:
            logger.info("All paper assets are complete")
        else:
            logger.info(f"Successfully processed {success}/{total} items")

def main():
    """Command-line interface."""
    manager = PaperAssetManager(papers_dir="data/papers")
    fire.Fire({
        'ensure': manager.ensure_all_assets,
        'download-pdfs': manager.download_pdfs,
        'download-source': manager.download_source,
        'convert-markdown': manager.convert_markdown,
        'retry-failures': lambda: manager.markdown.retry_failed_conversions(force=True),
        'status': lambda: {
            'missing_pdfs': manager.find_missing_pdfs(),
            'missing_source': manager.find_missing_source(),
            'pending_markdown': manager.find_pending_markdown(),
            'failed_markdown': list(manager.markdown.failed_conversions.keys())
        }
    })

if __name__ == "__main__":
    main()



---
File: src/scripts/frontend/__init__.py
---




---
File: src/scripts/frontend/generate_html.py
---
# src/scripts/frontend/generate_html.py
import yaml
import json
from pathlib import Path
import fire
from typing import Dict, Any
from datetime import datetime

def format_authors(authors: str | list[str]) -> str:
    """Format author list consistently."""
    if isinstance(authors, str):
        author_list = [a.strip() for a in authors.split(',')]
    elif isinstance(authors, list):
        author_list = authors
    else:
        return 'Unknown authors'
    
    if len(author_list) > 4:
        return f"{', '.join(author_list[:3])} and {len(author_list) - 3} others"
    return ', '.join(author_list)

def normalize_datetime(date_str: str | None) -> datetime | None:
    """Parse datetime string to UTC datetime and strip timezone info."""
    if not date_str:
        return None
    try:
        # Replace Z with +00:00 for consistent timezone handling
        dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
        # Convert to UTC if timezone aware
        if dt.tzinfo is not None:
            dt = dt.astimezone().replace(tzinfo=None)
        return dt
    except (ValueError, AttributeError):
        return None

def get_last_visited(paper: Dict[str, Any]) -> str:
    """Compute the most recent interaction time for a paper."""
    last_read = normalize_datetime(paper.get('last_read'))
    last_visited = normalize_datetime(paper.get('last_visited'))
    
    # Compare only if both exist
    if last_read and last_visited:
        latest = max(last_read, last_visited)
    elif last_read:
        latest = last_read
    elif last_visited:
        latest = last_visited
    else:
        return ''
    
    return latest.isoformat()

def preprocess_paper(paper: Dict[str, Any]) -> Dict[str, Any]:
    """Process a single paper entry."""
    return {
        'id': paper.get('arxivId', ''),
        'title': paper.get('title', '').replace('\n', ' '),
        'authors': format_authors(paper.get('authors', [])),
        'abstract': paper.get('abstract', '').replace('\n', ' '),
        'url': paper.get('url', ''),
        'arxivId': paper.get('arxivId', ''),
        'last_visited': get_last_visited(paper),
        'last_read': paper.get('last_read', ''),  # Keep for "Read on" display
        'total_reading_time_seconds': paper.get('total_reading_time_seconds', 0),
        'published_date': paper.get('published_date'),
        'arxiv_tags': paper.get('arxiv_tags', []),
    }

def preprocess_papers(papers: Dict[str, Any]) -> Dict[str, Any]:
    """Process all papers and prepare them for display."""
    # Process all papers that have either last_read or last_visited
    processed_papers = {
        id_: preprocess_paper(paper)
        for id_, paper in papers.items()
        if paper.get('last_read') or paper.get('last_visited')
    }
    
    return processed_papers

def generate_html(
    data_path: str,
    template_path: str,
    output_path: str,
) -> None:
    """Generate HTML page from papers data and template.
    
    Args:
        data_path: Path to papers YAML file
        template_path: Path to HTML template file
        output_path: Path where generated HTML should be written
    """
    # Convert all paths to Path objects
    data_path = Path(data_path)
    template_path = Path(template_path)
    output_path = Path(output_path)

    # Create output directory if it doesn't exist
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Read the papers YAML
    with open(data_path, 'r', encoding='utf-8') as f:
        papers = yaml.safe_load(f)
    
    # Preprocess the papers data
    processed_papers = preprocess_papers(papers)
    
    # Read the template
    with open(template_path, 'r', encoding='utf-8') as f:
        template = f.read()
    
    # Convert processed papers to JSON
    papers_json = json.dumps(
        processed_papers,
        indent=2,
        ensure_ascii=False
    )
    
    # Replace the placeholder in template
    html = template.replace(
        'window.yamlData = {};',
        f'window.yamlData = {papers_json};'
    )
    
    # Write the final HTML
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html)

if __name__ == '__main__':
    fire.Fire(generate_html)



---
File: src/scripts/frontend/index.template.html
---
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Paper Feed</title>
    <style>
        :root {
            /* Controls panel variables */
            --panel-bg: #ffffff;
            --panel-shadow: rgba(0, 0, 0, 0.1);
            --panel-border: #e2e8f0;
            --button-hover: #f8fafc;
            
            --bg-color: #f8fafc;
            --card-bg: #ffffff;
            --text-color: #1e293b;
            --secondary-text: #64748b;
            --border-color: #e2e8f0;
            --accent-bg: #f1f5f9;
            --link-color: #2563eb;
        }

        body {
            font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background: var(--bg-color);
            padding: 2rem 1rem;
            margin: 0;
        }

        .container {
            max-width: 860px;
            margin: 0 auto;
        }

        header {
            margin-bottom: 3rem;
            text-align: center;
        }

        h1 {
            font-size: 2.25rem;
            font-weight: 800;
            margin-bottom: 1rem;
        }

        .header-desc {
            color: var(--secondary-text);
            font-size: 1.125rem;
        }

        a {
            color: var(--link-color);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .day-group {
            margin-bottom: 1.5rem;
        }

        .day-header {
            background: var(--accent-bg);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 1rem 1.5rem;
            margin-bottom: 1rem;
            cursor: pointer;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .day-header:hover {
            background: #e9eef5;
        }

        .papers-container {
            display: grid;
            grid-template-rows: 1fr;
            transition: grid-template-rows 0.3s ease-out;
        }

        .papers-container-inner {
            overflow: hidden;
        }

        .collapsed .papers-container {
            grid-template-rows: 0fr;
        }

        /* Controls Panel Styles */
        .controls-button {
            position: fixed;
            top: 1rem;
            right: 1rem;
            z-index: 1000;
            padding: 0.5rem;
            background: var(--panel-bg);
            border: 1px solid var(--panel-border);
            border-radius: 0.5rem;
            cursor: pointer;
            box-shadow: 0 2px 4px var(--panel-shadow);
            transition: all 0.2s ease;
        }

        .controls-button:hover {
            background: var(--button-hover);
        }

        .controls-panel {
            position: fixed;
            top: 1rem;
            right: 1rem;
            width: 300px;
            background: var(--panel-bg);
            border: 1px solid var(--panel-border);
            border-radius: 0.5rem;
            padding: 1rem;
            box-shadow: 0 4px 6px var(--panel-shadow);
            z-index: 999;
            transform: translateX(120%);
            transition: transform 0.3s ease;
        }

        .controls-panel.expanded {
            transform: translateX(0);
        }

        .controls-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--panel-border);
        }

        .controls-title {
            font-weight: 600;
            color: var(--text-color);
        }

        .close-controls {
            cursor: pointer;
            color: var(--secondary-text);
        }

        .control-group {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .radio-group {
            display: flex;
            align-items: center;
            gap: 1rem;
            margin-bottom: 0.5rem;
        }

        .radio-label {
            font-weight: 500;
            color: var(--text-color);
            white-space: nowrap;
            min-width: 4rem;
        }

        .radio-options {
            display: flex;
            gap: 1rem;
        }

        .radio-option {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--text-color);
            cursor: pointer;
            white-space: nowrap;
        }

        .radio-option input {
            cursor: pointer;
        }

        .control-button {
            width: 100%;
            padding: 0.5rem;
            background: var(--accent-bg);
            border: 1px solid var(--border-color);
            border-radius: 0.25rem;
            color: var(--text-color);
            font-weight: 500;
            cursor: pointer;
            transition: background 0.2s ease;
        }

        .control-button:hover {
            background: var(--button-hover);
        }

        .paper-card {
            background: var(--card-bg);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 0.75rem 1.5rem;
            margin-bottom: 0.5rem;
            cursor: pointer;
        }

        .paper-header {
            display: flex;
            align-items: center;
            gap: 1rem;
        }

        .expand-icon {
            color: var(--secondary-text);
            transition: transform 0.3s ease;
            font-size: 0.75rem;
            min-width: 12px;
        }

        .expanded .expand-icon {
            transform: rotate(90deg);
        }

        .arxiv-id {
            font-family: ui-monospace, SFMono-Regular, Menlo, monospace;
            color: var(--link-color);
            font-size: 0.9rem;
            min-width: 90px;
        }

        .paper-title {
            font-size: 1rem;
            font-weight: 500;
            margin: 0;
            color: var(--text-color);
        }

        .paper-content {
            overflow: hidden;
            display: grid;
            grid-template-rows: 0fr;
            transition: grid-template-rows 0.3s ease-out;
        }

        .paper-content-inner {
            overflow: hidden;
            padding-top: 1rem;
            margin-top: 1rem;
            border-top: 1px solid var(--border-color);
        }

        .expanded .paper-content {
            grid-template-rows: 1fr;
        }

        .paper-meta {
            margin-bottom: 1rem;
            color: var(--secondary-text);
        }

        .meta-divider {
            margin: 0 0.5rem;
        }

        /* Tag filtering styles */
        .filter-container {
            margin-bottom: 2rem;
            padding: 1rem;
            background: var(--card-bg);
            border: 1px solid var(--border-color);
            border-radius: 8px;
        }

        .filter-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
        }

        .filter-mode {
            display: flex;
            gap: 0.5rem;
        }

        .mode-button {
            padding: 0.25rem 0.75rem;
            border: 1px solid var(--border-color);
            border-radius: 1rem;
            background: var(--bg-color);
            cursor: pointer;
            font-size: 0.875rem;
        }

        .mode-button.active {
            background: var(--link-color);
            color: white;
            border-color: var(--link-color);
        }

        .filter-stats {
            font-size: 0.875rem;
            color: var(--secondary-text);
        }

        .tag-cloud {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-bottom: 1rem;
        }

        .filter-actions {
            display: flex;
            gap: 0.5rem;
            justify-content: flex-end;
        }

        .filter-action {
            padding: 0.25rem 0.75rem;
            border: 1px solid var(--border-color);
            border-radius: 0.25rem;
            background: var(--bg-color);
            cursor: pointer;
            font-size: 0.875rem;
        }

        .filter-action:hover {
            background: var(--button-hover);
        }

        .tooltip {
            position: absolute;
            bottom: 100%;
            left: 50%;
            transform: translateX(-50%);
            padding: 0.5rem;
            background: var(--text-color);
            color: white;
            border-radius: 0.25rem;
            font-size: 0.75rem;
            white-space: nowrap;
            opacity: 0;
            pointer-events: none;
            transition: opacity 0.2s ease;
            margin-bottom: 0.5rem;
            z-index: 1000;
        }

        .tag-pill:hover .tooltip {
            opacity: 1;
        }

        /* Hide papers that don't match the filter */
        .paper-card.filtered {
            display: none;
        }

        @media (max-width: 640px) {
            body {
                padding: 1rem;
            }

            .paper-card {
                padding: 0.75rem 1rem;
            }

            .paper-header {
                gap: 0.75rem;
            }
        }

        .coloring-controls {
            margin-top: 1rem;
            padding-top: 1rem;
            border-top: 1px solid var(--panel-border);
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        
        .toggle-switch {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .coloring-type {
            margin-left: 0.5rem;
        }

        .toggle-label {
            font-size: 0.875rem;
            color: var(--text-color);
        }

        .switch {
            position: relative;
            display: inline-block;
            width: 36px;
            height: 20px;
        }

        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }

        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: var(--secondary-text);
            transition: .4s;
            border-radius: 20px;
        }

        .slider:before {
            position: absolute;
            content: "";
            height: 16px;
            width: 16px;
            left: 2px;
            bottom: 2px;
            background-color: white;
            transition: .4s;
            border-radius: 50%;
        }

        input:checked + .slider {
            background-color: var(--link-color);
        }

        input:checked + .slider:before {
            transform: translateX(16px);
        }
    </style>
</head>
<body>
    <button class="controls-button" id="showControls" aria-label="Show controls">‚öôÔ∏è</button>
    
    <div class="controls-panel" id="controlsPanel">
        <div class="controls-header">
            <span class="controls-title">Display Controls</span>
            <span class="close-controls" id="closeControls">√ó</span>
        </div>
        <div class="controls-content">
            <div class="controls-section">
                <div class="controls-subtitle">Display Options</div>
                <div class="control-group">
                    <div class="radio-group">
                        <div class="radio-label">Target:</div>
                        <div class="radio-options">
                            <label class="radio-option">
                                <input type="radio" name="target" value="days" checked>
                                Days
                            </label>
                            <label class="radio-option">
                                <input type="radio" name="target" value="papers">
                                Papers
                            </label>
                        </div>
                    </div>
                    <div class="radio-group">
                        <div class="radio-label">Action:</div>
                        <div class="radio-options">
                            <label class="radio-option">
                                <input type="radio" name="action" value="collapse" checked>
                                Collapse
                            </label>
                            <label class="radio-option">
                                <input type="radio" name="action" value="expand">
                                Expand
                            </label>
                        </div>
                    </div>
                    <div class="coloring-controls">
                        <div class="toggle-switch">
                            <span class="toggle-label">Enable ID coloring</span>
                            <label class="switch">
                                <input type="checkbox" id="coloringToggle" checked>
                                <span class="slider"></span>
                            </label>
                        </div>
                        <div class="radio-group coloring-type">
                            <div class="radio-label">Color by:</div>
                            <div class="radio-options">
                                <label class="radio-option">
                                    <input type="radio" name="colorBy" value="freshness" checked>
                                    Freshness
                                </label>
                                <label class="radio-option">
                                    <input type="radio" name="colorBy" value="readingTime">
                                    Reading Time
                                </label>
                            </div>
                        </div>
                    </div>
                    <button id="executeAction" class="control-button">Apply</button>
                </div>
            </div>
            <div class="controls-section">
                <div class="controls-subtitle">Category Filters</div>
                    <div class="filter-mode">
                        <button class="mode-button active" data-mode="any">ANY</button>
                        <button class="mode-button" data-mode="all">ALL</button>
                        <button class="mode-button" data-mode="none">NONE</button>
                    </div>
                    <div class="filter-stats">
                        Showing <span id="filtered-count">0</span> of <span id="total-count">0</span> papers
                    </div>
                    <div class="tag-cloud" id="tag-cloud">
                        <!-- Tags will be inserted here -->
                    </div>
                    <div class="filter-actions">
                        <button class="filter-action" id="clear-filters">Clear</button>
                        <button class="filter-action" id="select-all">Select All</button>
                    </div>
                </div>
            </div>
    </div>

    <div class="container">
        <header>
            <h1>ArXiv Paper Feed</h1>
            <p class="header-desc">Papers recently visited by <a href="https://bsky.app/profile/digthatdata.bsky.social">@DigThatData</a></p>
        </header>

        <main id="papers-container">
            <!-- Papers will be inserted here -->
        </main>
    </div>

    <script>
        // Styles for tag pills
        const styles = `
            .tag-pill {
                padding: 0.25rem 0.75rem;
                border-radius: 1rem;
                border: 1px solid transparent;
                cursor: pointer;
                font-size: 0.875rem;
                display: flex;
                align-items: center;
                gap: 0.5rem;
                transition: all 0.2s ease;
                position: relative;
            }

            .tag-pill:hover {
                filter: brightness(0.95);
            }

            .tag-pill.active {
                border: 1px solid rgba(0, 0, 0, 0.2);
                filter: brightness(0.9);
            }

            .tag-count {
                background: rgba(0, 0, 0, 0.1);
                padding: 0.125rem 0.375rem;
                border-radius: 1rem;
                font-size: 0.75rem;
            }
        `;

        function formatDate(dateString, format = 'full') {
            const date = new Date(dateString);
            if (format === 'full') {
                return date.toLocaleDateString('en-US', {
                    year: 'numeric',
                    month: 'short',
                    day: 'numeric'
                });
            } else if (format === 'group') {
                return date.toLocaleDateString('en-US', {
                    weekday: 'long',
                    year: 'numeric',
                    month: 'long',
                    day: 'numeric'
                });
            }
        }

        function toggleDayGroup(element) {
            const group = element.closest('.day-group');
            group.classList.toggle('collapsed');
            const date = group.dataset.date;
            const collapsedDays = JSON.parse(localStorage.getItem('collapsedDays') || '{}');
            collapsedDays[date] = group.classList.contains('collapsed');
            localStorage.setItem('collapsedDays', JSON.stringify(collapsedDays));
        }

        function togglePaperCard(element, event) {
            event.stopPropagation();
            const card = element.closest('.paper-card');
            card.classList.toggle('expanded');
            const paperId = card.dataset.paperId;
            const expandedCards = JSON.parse(localStorage.getItem('expandedCards') || '{}');
            expandedCards[paperId] = card.classList.contains('expanded');
            localStorage.setItem('expandedCards', JSON.stringify(expandedCards));
        }

        function getCategoryInfo(tag) {
            // Get the parent category (everything before the dot)
            const parentCategory = tag.split('.')[0];
            
            // Using ColorBrewer Set3 qualitative palette, optimized for colorblind accessibility
            const parentCategoryMap = {
                'cs': { color: '#8dd3c7', category: 'Computer Science' },
                'stat': { color: '#ffffb3', category: 'Statistics' },
                'math': { color: '#bebada', category: 'Mathematics' },
                'physics': { color: '#fb8072', category: 'Physics' },
                'q-bio': { color: '#80b1d3', category: 'Quantitative Biology' },
                'q-fin': { color: '#fdb462', category: 'Quantitative Finance' }
            };
            
            // Map of specific subcategory names
            const subcategoryMap = {
                // Computer Science
                'cs.AI': 'Artificial Intelligence',
                'cs.LG': 'Machine Learning',
                'cs.CL': 'Computation and Language',
                'cs.CV': 'Computer Vision and Pattern Recognition',
                'cs.RO': 'Robotics',
                'cs.NE': 'Neural and Evolutionary Computing',
                'cs.IR': 'Information Retrieval',
                'cs.HC': 'Human-Computer Interaction',
                'cs.SI': 'Social and Information Networks',
                'cs.DB': 'Databases',
                
                // Statistics
                'stat.ML': 'Machine Learning (Statistics)',
                'stat.ME': 'Methodology',
                'stat.TH': 'Statistics Theory',
                
                // Mathematics
                'math.ST': 'Statistics Theory',
                'math.PR': 'Probability',
                'math.OC': 'Optimization',
                
                // Physics
                'physics.data-an': 'Data Analysis',
                'physics.soc-ph': 'Social Physics',
                
                // Quantitative Biology
                'q-bio.NC': 'Neurons and Cognition',
                'q-bio.QM': 'Quantitative Methods',
                
                // Quantitative Finance
                'q-fin.ST': 'Statistical Finance',
                'q-fin.PM': 'Portfolio Management'
            };
            
            const parentInfo = parentCategoryMap[parentCategory] || { color: '#f5f5f5', category: 'Other' };
            const name = subcategoryMap[tag] || tag;
            
            return {
                name: name,
                color: parentInfo.color
            };
        }

        function renderTagCloud() {
            const tags = new Map();
            
            // Collect tags and counts
            Object.values(window.yamlData).forEach(paper => {
                if (paper.arxiv_tags) {
                    paper.arxiv_tags.forEach(tag => {
                        const count = tags.get(tag) || 0;
                        tags.set(tag, count + 1);
                    });
                }
            });

            // Sort tags by count
            const sortedTags = Array.from(tags.entries())
                .sort(([, a], [, b]) => b - a);

            // Render tag cloud
            const tagCloud = document.getElementById('tag-cloud');
            tagCloud.innerHTML = sortedTags.map(([tag, count]) => {
                const { name, color } = getCategoryInfo(tag);
                return `
                    <button class="tag-pill" data-tag="${tag}" style="background-color: ${color}">
                        <span class="tag-name">${tag}</span>
                        <span class="tag-count">${count}</span>
                        <span class="tooltip">${name}</span>
                    </button>
                `;
            }).join('');

            // Re-add click handlers
            document.querySelectorAll('.tag-pill').forEach(pill => {
                pill.addEventListener('click', () => {
                    const tag = pill.dataset.tag;
                    if (window.filterState.activeTags.has(tag)) {
                        window.filterState.activeTags.delete(tag);
                        pill.classList.remove('active');
                    } else {
                        window.filterState.activeTags.add(tag);
                        pill.classList.add('active');
                    }
                    applyFilters();
                });
            });
        }
        
        function calculateColor(paper, coloringEnabled = true) {
            if (!coloringEnabled) return 'rgb(255, 255, 255)';  // White when coloring is disabled
            
            const colorBy = document.querySelector('input[name="colorBy"]:checked').value;
            
            if (colorBy === 'freshness') {
                if (!paper.last_visited || !paper.published_date) return 'rgb(255, 255, 255)';
                
                const visitDate = new Date(paper.last_visited);
                const pubDate = new Date(paper.published_date);
                const diffDays = Math.floor((visitDate - pubDate) / (1000 * 60 * 60 * 24));
                
                const maxAge = 365;
                const freshness = Math.max(0, Math.min(1, 1 - (diffDays / maxAge)));
                const value = Math.round(255 - (freshness * 55));
                return `rgb(${value}, 255, ${value})`; // Green gradient
            } else {
                // Reading time coloring
                const readingTime = paper.total_reading_time_seconds || 0;
                const maxReadingTime = 300; // 5 minutes
                const intensity = Math.max(0, Math.min(1, readingTime / maxReadingTime));
                const value = Math.round(255 - (intensity * 55));
                return `rgb(255, ${value}, ${value})`; // Red gradient
            }
        }
        
        function renderPaperCard(paper, expanded) {
            const readingTime = paper.total_reading_time_seconds 
                ? `${Math.round(paper.total_reading_time_seconds / 60)} min read`
                : '';
        
            // Get freshness toggle state
            const coloringEnabled = document.getElementById('coloringToggle')?.checked ?? true;
            const bgColor = calculateColor(paper, coloringEnabled);
            
            const metaParts = [];
            
            // Add authors
            metaParts.push(`<span>${paper.authors}</span>`);
            
            // Add reading time if available
            if (readingTime) {
                metaParts.push(`<span class="meta-divider">‚Ä¢</span><span>${readingTime}</span>`);
            }
            
            // Add publication date if available
            if (paper.published_date) {
                const pubDate = new Date(paper.published_date).toLocaleDateString();
                metaParts.push(`<span class="meta-divider">‚Ä¢</span><span>Published: ${pubDate}</span>`);
            }
            
            // Add arXiv tags if available
            if (paper.arxiv_tags && paper.arxiv_tags.length > 0) {
                const tags = paper.arxiv_tags.join(', ');
                metaParts.push(`<span class="meta-divider">‚Ä¢</span><span>${tags}</span>`);
            }
            
            return `
                <article class="paper-card ${expanded ? 'expanded' : ''}" data-paper-id="${paper.id}">
                    <div class="paper-header">
                        <span class="expand-icon">‚ñ∂</span>
                        <a href="${paper.url}" class="arxiv-id" onclick="event.stopPropagation()" 
                           style="background-color: ${bgColor}; padding: 4px 8px; border-radius: 4px;">
                            ${paper.arxivId}
                        </a>
                        <span class="paper-title">${paper.title}</span>
                    </div>
                    <div class="paper-content">
                        <div class="paper-content-inner">
                            <div class="paper-meta">
                                ${metaParts.join('')}
                            </div>
                            <div class="paper-abstract">${paper.abstract}</div>
                        </div>
                    </div>
                </article>
            `;
        }
        
        function initializeFilters() {
            // Add the updated styles to the document
            const styleSheet = document.createElement("style");
            styleSheet.textContent = styles;
            document.head.appendChild(styleSheet);

            // Initialize filter state
            window.filterState = {
                mode: 'any',
                activeTags: new Set()
            };

            // Render initial tag cloud
            renderTagCloud();

            // Update total count
            document.getElementById('total-count').textContent = 
                Object.keys(window.yamlData).length;

            // Mode buttons already handled in initializeEventListeners()
        }
        
        function renderPapers() {
            const container = document.getElementById('papers-container');
            container.innerHTML = '';
            const expandedCards = JSON.parse(localStorage.getItem('expandedCards') || '{}');
            const collapsedDays = JSON.parse(localStorage.getItem('collapsedDays') || '{}');
            
            const papersByDay = {};
            Object.entries(window.yamlData)
                .sort(([_, a], [__, b]) => new Date(b.last_visited) - new Date(a.last_visited))
                .forEach(([id, paper]) => {
                    const date = paper.last_visited.split('T')[0];
                    if (!papersByDay[date]) papersByDay[date] = [];
                    papersByDay[date].push({ ...paper, id });
                });
        
            Object.entries(papersByDay).forEach(([date, papers]) => {
                const dayGroup = document.createElement('section');
                dayGroup.className = `day-group ${collapsedDays[date] ? 'collapsed' : ''}`;
                dayGroup.dataset.date = date;
        
                const dayHeader = document.createElement('div');
                dayHeader.className = 'day-header';
                dayHeader.onclick = () => toggleDayGroup(dayHeader);
                dayHeader.innerHTML = `
                    <span class="day-title">${formatDate(date, 'group')}</span>
                    <span class="paper-count">${papers.length} paper${papers.length !== 1 ? 's' : ''}</span>
                `;
        
                const papersContainer = document.createElement('div');
                papersContainer.className = 'papers-container';
        
                const papersContainerInner = document.createElement('div');
                papersContainerInner.className = 'papers-container-inner';
                papersContainerInner.innerHTML = papers
                    .map(paper => renderPaperCard(paper, expandedCards[paper.id]))
                    .join('');
        
                papersContainer.appendChild(papersContainerInner);
                dayGroup.appendChild(dayHeader);
                dayGroup.appendChild(papersContainer);
                container.appendChild(dayGroup);
            });

            // Add click handlers for paper cards
            document.querySelectorAll('.paper-card').forEach(card => {
                card.onclick = (e) => togglePaperCard(card, e);
            });

            // Initialize filters after papers are rendered
            applyFilters();
        }

        function initializeEventListeners() {
            // Add coloring controls listeners
            const coloringToggle = document.getElementById('coloringToggle');
            if (coloringToggle) {
                // Load saved preferences
                const savedColoring = localStorage.getItem('coloringEnabled');
                if (savedColoring !== null) {
                    coloringToggle.checked = savedColoring === 'true';
                }
                
                const savedColorBy = localStorage.getItem('colorBy');
                if (savedColorBy) {
                    const radio = document.querySelector(`input[name="colorBy"][value="${savedColorBy}"]`);
                    if (radio) radio.checked = true;
                }
                
                // Add listeners
                coloringToggle.addEventListener('change', () => {
                    localStorage.setItem('coloringEnabled', coloringToggle.checked);
                    renderPapers();
                });
                
                document.querySelectorAll('input[name="colorBy"]').forEach(radio => {
                    radio.addEventListener('change', () => {
                        localStorage.setItem('colorBy', radio.value);
                        renderPapers();
                    });
                });
            }

            // Mode buttons
            document.querySelectorAll('.mode-button').forEach(button => {
                button.addEventListener('click', () => {
                    document.querySelectorAll('.mode-button').forEach(b => 
                        b.classList.remove('active'));
                    button.classList.add('active');
                    window.filterState.mode = button.dataset.mode;
                    applyFilters();
                });
            });

            // Clear filters
            document.getElementById('clear-filters').addEventListener('click', () => {
                window.filterState.activeTags.clear();
                document.querySelectorAll('.tag-pill').forEach(pill => 
                    pill.classList.remove('active'));
                applyFilters();
            });

            // Select all
            document.getElementById('select-all').addEventListener('click', () => {
                document.querySelectorAll('.tag-pill').forEach(pill => {
                    const tag = pill.dataset.tag;
                    window.filterState.activeTags.add(tag);
                    pill.classList.add('active');
                });
                applyFilters();
            });

            // Controls panel functionality
            const showControls = document.getElementById('showControls');
            const controlsPanel = document.getElementById('controlsPanel');
            const closeControls = document.getElementById('closeControls');

            showControls.addEventListener('click', () => {
                controlsPanel.classList.add('expanded');
                showControls.style.visibility = 'hidden';
            });

            closeControls.addEventListener('click', () => {
                controlsPanel.classList.remove('expanded');
                showControls.style.visibility = 'visible';
            });

            // Close panel when clicking outside
            document.addEventListener('click', (event) => {
                if (!controlsPanel.contains(event.target) && 
                    event.target !== showControls && 
                    controlsPanel.classList.contains('expanded')) {
                    controlsPanel.classList.remove('expanded');
                    showControls.style.visibility = 'visible';
                }
            });

            // Bulk collapse/expand functionality
            document.getElementById('executeAction').addEventListener('click', () => {
                const target = document.querySelector('input[name="target"]:checked').value;
                const action = document.querySelector('input[name="action"]:checked').value;
                const shouldCollapse = action === 'collapse';
                
                if (target === 'days') {
                    toggleAllDays(shouldCollapse);
                } else {
                    toggleAllPapers(shouldCollapse);
                }
            });
        }

        function toggleAllDays(shouldCollapse) {
            const dayGroups = document.querySelectorAll('.day-group');
            const collapsedDays = JSON.parse(localStorage.getItem('collapsedDays') || '{}');
            
            dayGroups.forEach(group => {
                if (shouldCollapse) {
                    group.classList.add('collapsed');
                    collapsedDays[group.dataset.date] = true;
                } else {
                    group.classList.remove('collapsed');
                    delete collapsedDays[group.dataset.date];
                }
            });
            
            localStorage.setItem('collapsedDays', JSON.stringify(collapsedDays));
        }

        function toggleAllPapers(shouldCollapse) {
            const visiblePapers = document.querySelectorAll('.day-group:not(.collapsed) .paper-card');
            const expandedCards = JSON.parse(localStorage.getItem('expandedCards') || '{}');
            
            visiblePapers.forEach(card => {
                if (shouldCollapse) {
                    card.classList.remove('expanded');
                    delete expandedCards[card.dataset.paperId];
                } else {
                    card.classList.add('expanded');
                    expandedCards[card.dataset.paperId] = true;
                }
            });
            
            localStorage.setItem('expandedCards', JSON.stringify(expandedCards));
        }

        function applyFilters() {
            const { mode, activeTags } = window.filterState;
            let visibleCount = 0;

            document.querySelectorAll('.paper-card').forEach(card => {
                const paperId = card.dataset.paperId;
                const paper = window.yamlData[paperId];
                const paperTags = new Set(paper.arxiv_tags || []);

                let visible = true;
                if (activeTags.size > 0) {
                    if (mode === 'any') {
                        visible = Array.from(activeTags).some(tag => 
                            paperTags.has(tag));
                    } else if (mode === 'all') {
                        visible = Array.from(activeTags).every(tag => 
                            paperTags.has(tag));
                    } else if (mode === 'none') {
                        visible = Array.from(activeTags).every(tag => 
                            !paperTags.has(tag));
                    }
                }

                card.classList.toggle('filtered', !visible);
                if (visible) visibleCount++;
            });

            document.getElementById('filtered-count').textContent = visibleCount;
        }

        window.yamlData = {};
        initializeEventListeners();
        initializeFilters();
        renderPapers();
        
    </script>
</body>
</html>



---
File: src/scripts/github_client.py
---
# src/scripts/github_client.py
from typing import List, Dict, Any
import requests
from loguru import logger

def patch_schema_change(issue):
    if 'duration_minutes' in issue:
        issue['duration_seconds'] = issue.pop('duraction_minutes') * 60
    return issue

class GithubClient:
    """Handles GitHub API interactions."""
    def __init__(self, token: str, repo: str):
        self.token = token
        self.repo = repo
        self.headers = {
            "Authorization": f"token {token}",
            "Accept": "application/vnd.github.v3+json"
        }

    def get_open_issues(self) -> List[Dict[str, Any]]:
        """Fetch open issues with paper or reading-session labels."""
        url = f"https://api.github.com/repos/{self.repo}/issues"
        params = {"state": "open", "per_page": 100}
        outv=[]
        response = requests.get(url, headers=self.headers, params=params, timeout=30)
        if response.status_code == 200:
            all_issues = response.json()
            outv = [
                patch_schema_change(issue) for issue in all_issues
                if any(label['name'] in ['paper', 'reading-session'] 
                      for label in issue['labels'])
            ]
        return outv

    def close_issue(self, issue_number: int) -> bool:
        """Close an issue with comment."""
        base_url = f"https://api.github.com/repos/{self.repo}/issues/{issue_number}"
        
        # Add comment
        comment_data = {"body": "‚úÖ Event processed and recorded. Closing this issue."}
        comment_response = requests.post(
            f"{base_url}/comments", 
            headers=self.headers, 
            json=comment_data,
            timeout=30
        )
        if comment_response.status_code != 201:
            logger.error(f"Failed to add comment to issue {issue_number}")
            return False

        # Close issue
        close_data = {"state": "closed"}
        close_response = requests.patch(
            base_url, 
            headers=self.headers, 
            json=close_data,
            timeout=30
        )
        if close_response.status_code != 200:
            logger.error(f"Failed to close issue {issue_number}")
            return False

        return True



---
File: src/scripts/markdown_service.py
---
# src/scripts/markdown_service.py
"""Service for managing markdown conversions of arXiv papers."""

from pathlib import Path
from datetime import datetime, timedelta, timezone
from typing import Optional
from loguru import logger

from .pandoc_utils import PandocConverter, create_default_config
from .tex_utils import find_main_tex_file

class MarkdownService:
    """Manages the conversion of LaTeX papers to Markdown format."""
    
    def __init__(self, papers_dir: str | Path):
        """
        Initialize MarkdownService.
        
        Args:
            papers_dir: Base directory for paper storage
        """
        self.papers_dir = Path(papers_dir)
        self.failed_conversions_file = self.papers_dir / "failed_markdown.json"
        self._load_failed_conversions()
        
    def _load_failed_conversions(self):
        """Load record of failed conversions with timestamps."""
        self.failed_conversions = {}
        if self.failed_conversions_file.exists():
            import json
            try:
                self.failed_conversions = json.loads(
                    self.failed_conversions_file.read_text()
                )
            except Exception as e:
                logger.error(f"Error loading failed conversions: {e}")
    
    def _save_failed_conversions(self):
        """Save record of failed conversions."""
        import json
        try:
            self.failed_conversions_file.write_text(
                json.dumps(self.failed_conversions, indent=2)
            )
        except Exception as e:
            logger.error(f"Error saving failed conversions: {e}")
    
    def _record_failure(self, arxiv_id: str, error: str):
        """Record a conversion failure with timestamp."""
        self.failed_conversions[arxiv_id] = {
            "last_attempt": datetime.now(timezone.utc).isoformat(),
            "error": str(error)
        }
        self._save_failed_conversions()
    
    def _clear_failure(self, arxiv_id: str):
        """Clear a failure record after successful conversion."""
        if arxiv_id in self.failed_conversions:
            del self.failed_conversions[arxiv_id]
            self._save_failed_conversions()
    
    def should_retry_conversion(self, arxiv_id: str, retry_after_hours: int = 24) -> bool:
        """
        Check if we should retry a failed conversion.
        
        Args:
            arxiv_id: Paper ID to check
            retry_after_hours: Hours to wait before retrying
            
        Returns:
            bool: True if enough time has passed to retry
        """
        if arxiv_id not in self.failed_conversions:
            return True
            
        last_attempt = datetime.fromisoformat(
            self.failed_conversions[arxiv_id]["last_attempt"]
        )
        retry_threshold = datetime.now(timezone.utc) - timedelta(hours=retry_after_hours)
        return last_attempt < retry_threshold
    
    def convert_paper(self, arxiv_id: str, force: bool = False, tex_file: Optional[Path] = None) -> bool:
        """
        Convert a paper's LaTeX source to Markdown.
        
        Args:
            arxiv_id: Paper ID to convert
            force: Force conversion even if previously failed
            tex_file: Optional specific tex file to use for conversion
        """
        try:
            # Check if we should skip conversion
            if not force:
                if not self.should_retry_conversion(arxiv_id):
                    logger.info(f"Skipping recent failed conversion for {arxiv_id}")
                    return False
                    
                paper_dir = self.papers_dir / arxiv_id
                markdown_file = paper_dir / f"{arxiv_id}.md"
                if markdown_file.exists() and markdown_file.stat().st_size > 0:
                    logger.info(f"Markdown already exists for {arxiv_id}")
                    self._clear_failure(arxiv_id)
                    return True
            
            paper_dir = self.papers_dir / arxiv_id
            source_dir = paper_dir / "source"
            markdown_file = paper_dir / f"{arxiv_id}.md"
            
            # Verify source exists
            if not source_dir.exists():
                raise FileNotFoundError(f"No source directory for {arxiv_id}")
            
            # Check metadata for main_tex_file first
            metadata_file = paper_dir / "metadata.json"
            if metadata_file.exists():
                import json
                try:
                    metadata = json.loads(metadata_file.read_text())
                    if metadata.get('main_tex_file'):
                        specified_tex = paper_dir / metadata['main_tex_file']
                        if specified_tex.exists():
                            main_tex = specified_tex
                            logger.info(f"Using main_tex_file from metadata: {main_tex}")
                        else:
                            logger.warning(f"Specified main_tex_file does not exist: {specified_tex}")
                except Exception as e:
                    logger.warning(f"Error reading metadata.json: {e}")

            # Fall back to provided tex_file or inference if needed
            if not locals().get('main_tex'):
                if tex_file is not None:
                    if not tex_file.exists():
                        raise FileNotFoundError(f"Specified tex file does not exist: {tex_file}")
                    main_tex = tex_file
                else:
                    # Find main tex file
                    tex_files = list(source_dir.rglob("*.tex"))
                    if not tex_files:
                        raise FileNotFoundError(f"No .tex files found for {arxiv_id}")
                    
                    main_tex = find_main_tex_file(tex_files, arxiv_id)
                    if not main_tex:
                        raise ValueError(f"Could not identify main tex file for {arxiv_id}")
            
            # Set up Pandoc conversion
            config = create_default_config(paper_dir)
            converter = PandocConverter(config)
            
            # Attempt conversion - will raise exception on failure
            converter.convert_tex_to_markdown(main_tex, markdown_file)
            logger.success(f"Successfully converted {arxiv_id} to Markdown")
            self._clear_failure(arxiv_id)
            return True
                
        except Exception as e:
            error_msg = str(e)
            logger.error(f"Error converting {arxiv_id} to Markdown: {error_msg}")
            self._record_failure(arxiv_id, error_msg)
            return False
    
    def retry_failed_conversions(self, force: bool = False):
        """
        Retry converting papers that previously failed.
        
        Args:
            force: Force retry all failed conversions regardless of timing
        """
        for arxiv_id in list(self.failed_conversions.keys()):
            if force or self.should_retry_conversion(arxiv_id):
                logger.info(f"Retrying conversion for {arxiv_id}")
                self.convert_paper(arxiv_id, force=force)

    def get_conversion_status(self, arxiv_id: str) -> dict:
        """
        Get the current conversion status for a paper.
        
        Args:
            arxiv_id: Paper ID to check
            
        Returns:
            dict: Status information including:
                - has_markdown: Whether markdown exists
                - has_source: Whether source exists
                - failed: Whether conversion previously failed
                - last_attempt: Timestamp of last attempt if failed
                - error: Error message if failed
        """
        paper_dir = self.papers_dir / arxiv_id
        return {
            "has_markdown": (paper_dir / f"{arxiv_id}.md").exists(),
            "has_source": (paper_dir / "source").exists(),
            "failed": arxiv_id in self.failed_conversions,
            "last_attempt": self.failed_conversions.get(arxiv_id, {}).get("last_attempt"),
            "error": self.failed_conversions.get(arxiv_id, {}).get("error")
        }



---
File: src/scripts/models.py
---
from pydantic import BaseModel, Field
from datetime import datetime, timezone

class Paper(BaseModel):
    """Schema for paper metadata"""
    arxiv_id: str = Field(..., alias="arxivId")
    title: str
    authors: str
    abstract: str
    url: str
    issue_number: int
    issue_url: str
    created_at: str
    state: str
    labels: list[str]
    total_reading_time_seconds: int = 0
    last_read: str | None = None
    last_visited: str | None = None
    main_tex_file: str | None = None  # Path to main TeX file used for conversion
    
    published_date: str | None = None  # v1 publication date on arXiv
    arxiv_tags: list[str] | None = None 
    
    class Config:
        populate_by_name = True

class ReadingSession(BaseModel):
    """Schema for reading session events"""
    type: str = "reading_session"
    arxiv_id: str = Field(..., alias="arxivId") 
    timestamp: str = Field(..., description="Original timestamp when reading occurred")
    duration_seconds: int
    issue_url: str
    processed_at: str = Field(default_factory=lambda: datetime.now(timezone.utc).isoformat())

class PaperVisitEvent(BaseModel):
    """Schema for paper visit events"""
    type: str = "paper_visit" 
    timestamp: str = Field(..., description="Original timestamp when visit occurred")
    issue_url: str
    arxiv_id: str



---
File: src/scripts/pandoc_utils.py
---
# src/scripts/pandoc_utils.py
"""Utilities for converting LaTeX papers to Markdown using Pandoc."""

import os
import shutil
import subprocess
import tempfile
from pathlib import Path
from typing import Optional
from loguru import logger
from dataclasses import dataclass

@dataclass
class PandocConfig:
    """Configuration for Pandoc conversion."""
    extract_media_dir: Path
    metadata_file: Optional[Path] = None
    css_file: Optional[Path] = None
    bib_file: Optional[Path] = None
    lua_filter: Optional[Path] = None

class PandocConverter:
    """Convert LaTeX papers to Markdown using enhanced Pandoc settings."""
    
    def __init__(self, config: PandocConfig):
        """Initialize converter with configuration."""
        self.config = config
        self._ensure_directories()
        self._create_default_files()
    
    def _ensure_directories(self):
        """Ensure all required directories exist."""
        # Create main media directory
        try:
            self.config.extract_media_dir.mkdir(parents=True, exist_ok=True)
            logger.debug(f"Created media directory: {self.config.extract_media_dir}")
            
            # Create parent directories for all configured paths
            paths_to_check = [
                self.config.metadata_file,
                self.config.css_file,
                self.config.bib_file,
                self.config.lua_filter
            ]
            
            for path in paths_to_check:
                if path is not None:
                    path.parent.mkdir(parents=True, exist_ok=True)
                    logger.debug(f"Created directory for: {path}")
                    
        except Exception as e:
            logger.error(f"Error creating directories: {e}")
            raise
    
    def _write_file(self, path: Path, content: str) -> bool:
        """Write content to file and verify it exists."""
        try:
            path.write_text(content)
            # Verify file was written
            if not path.exists():
                logger.error(f"Failed to create file: {path}")
                return False
            logger.debug(f"Successfully wrote file: {path}")
            return True
        except Exception as e:
            logger.error(f"Error writing file {path}: {e}")
            return False
    
    def _create_default_files(self):
        """Create default supporting files if not provided."""
        # Create and assign paths relative to media directory if not provided
        if not self.config.lua_filter:
            self.config.lua_filter = self.config.extract_media_dir / 'crossref.lua'
        
        if not self.config.metadata_file:
            self.config.metadata_file = self.config.extract_media_dir / 'metadata.yaml'
        
        # Ensure parent directories exist again (in case paths were just assigned)
        self._ensure_directories()
        
        # Create Lua filter
        lua_content = '''
function Math(elem)
    -- Preserve math content
    return elem
end

function Link(elem)
    -- Handle cross-references
    return elem
end

function Image(elem)
    -- Handle figure references
    return elem
end

function Table(elem)
    -- Handle table formatting
    return elem
end
'''
        if not self._write_file(self.config.lua_filter, lua_content):
            raise RuntimeError(f"Failed to create Lua filter: {self.config.lua_filter}")
        
        # Create metadata file
        metadata_content = '''---
reference-section-title: "References"
link-citations: true
citation-style: ieee
header-includes:
  - \\usepackage{amsmath}
  - \\usepackage{amsthm}
---'''
        if not self._write_file(self.config.metadata_file, metadata_content):
            raise RuntimeError(f"Failed to create metadata file: {self.config.metadata_file}")
        
        logger.debug("Successfully created all supporting files")
    
    def _verify_files_exist(self) -> bool:
        """Verify that all required files exist before running pandoc."""
        files_to_check = []
        
        if self.config.metadata_file:
            files_to_check.append(self.config.metadata_file)
        if self.config.lua_filter:
            files_to_check.append(self.config.lua_filter)
        if self.config.css_file:
            files_to_check.append(self.config.css_file)
        if self.config.bib_file:
            files_to_check.append(self.config.bib_file)
            
        for file_path in files_to_check:
            if not file_path.exists():
                logger.error(f"Required file does not exist: {file_path}")
                return False
            logger.debug(f"Verified file exists: {file_path}")
        
        return True
        
    def build_pandoc_command(self, input_file: Path, output_file: Path) -> list[str]:
        """Build Pandoc command with all necessary arguments."""
        cmd = [
            'pandoc',
            # Input/output formats
            '-f', 'latex+raw_tex',
            '-t', 'gfm',
            
            # Math handling
            '--mathjax',
            
            # Table and formatting
            '--columns=1000',
            '--wrap=none',
            
            # Figure handling
            f'--extract-media={self.config.extract_media_dir.resolve()}',
            '--standalone',
            
            # Debug info
            '--verbose',
        ]
        
        # Add optional components with absolute paths
        if self.config.metadata_file and self.config.metadata_file.exists():
            cmd.extend(['--metadata-file', str(self.config.metadata_file.resolve())])
            logger.debug(f"Adding metadata file: {self.config.metadata_file.resolve()}")
        
        if self.config.css_file and self.config.css_file.exists():
            cmd.extend(['--css', str(self.config.css_file.resolve())])
            logger.debug(f"Adding CSS file: {self.config.css_file.resolve()}")
            
        if self.config.bib_file and self.config.bib_file.exists():
            cmd.extend([
                '--citeproc',
                '--bibliography', str(self.config.bib_file.resolve())
            ])
            logger.debug(f"Adding bibliography file: {self.config.bib_file.resolve()}")
            
        if self.config.lua_filter and self.config.lua_filter.exists():
            cmd.extend(['--lua-filter', str(self.config.lua_filter.resolve())])
            logger.debug(f"Adding Lua filter: {self.config.lua_filter.resolve()}")
            
        # Add input/output files with absolute paths
        cmd.extend([
            str(input_file.resolve()),
            '-o', str(output_file.resolve())
        ])
        
        return cmd
        
    def convert_tex_to_markdown(self, tex_file: Path, output_file: Optional[Path] = None) -> bool:
        """
        Convert a LaTeX file to Markdown using Pandoc.
        
        Args:
            tex_file: Path to LaTeX file
            output_file: Optional output path, defaults to same name with .md extension
            
        Returns:
            bool: True if conversion successful
        """
        try:
            if not tex_file.exists():
                raise FileNotFoundError(f"LaTeX file not found: {tex_file}")
                
            if not output_file:
                output_file = tex_file.with_suffix('.md')
                    
            # Verify all required files exist
            if not self._verify_files_exist():
                raise FileNotFoundError("Missing required pandoc configuration files")
                    
            # Create temporary directory for conversion
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_dir = Path(temp_dir)
                
                # Copy LaTeX file to temp directory
                temp_tex = temp_dir / tex_file.name
                shutil.copy2(tex_file, temp_tex)
                if not temp_tex.exists():
                    raise RuntimeError(f"Failed to copy LaTeX file to temp directory: {temp_tex}")
                
                # Build and run Pandoc command
                cmd = self.build_pandoc_command(temp_tex, output_file)
                logger.debug(f"Running Pandoc command: {' '.join(cmd)}")
                
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    cwd=str(temp_dir)
                )
                
                if result.returncode != 0:
                    error_msg = result.stderr.strip() or "Unknown pandoc error"
                    raise RuntimeError(f"Pandoc conversion failed: {error_msg}")
                
                # Verify output file was created and not empty
                if not output_file.exists():
                    raise RuntimeError(f"Output file not created: {output_file}")
                if output_file.stat().st_size == 0:
                    raise RuntimeError(f"Output file is empty: {output_file}")
                    
                logger.success(f"Successfully converted {tex_file} to {output_file}")
                return True
                
        except Exception as e:
            logger.error(f"Error converting {tex_file} to Markdown: {e}")
            raise

def create_default_config(paper_dir: Path) -> PandocConfig:
    """Create default Pandoc configuration for a paper directory."""
    media_dir = paper_dir / "media"
    return PandocConfig(extract_media_dir=media_dir)



---
File: src/scripts/paper_manager.py
---
# src/scripts/paper_manager.py
"""Paper metadata management with automatic hydration of missing fields."""

import json
from pathlib import Path
from loguru import logger
from datetime import datetime, timezone
from typing import Optional

from .models import Paper, ReadingSession, PaperVisitEvent
from .arxiv_client import ArxivClient

class PaperManager:
    """Manages paper metadata and event storage."""
    _event_log_fname = "interactions.log"

    def __init__(self, data_dir: Path, arxiv_client: Optional[ArxivClient] = None):
        """Initialize PaperManager with data directory and optional ArxivClient."""
        self.data_dir = data_dir
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.arxiv_client = arxiv_client or ArxivClient(data_dir)
        self.modified_files: set[str] = set()

    def _needs_hydration(self, paper: Paper) -> bool:
        """Check if paper needs metadata hydration."""
        return (
            paper.published_date is None or 
            paper.arxiv_tags is None or
            not paper.arxiv_tags  # Also hydrate if tags list is empty
        )
    
    def _hydrate_metadata(self, paper: Paper) -> Paper:
        """Fetch missing metadata from arXiv API."""
        try:
            # Get fresh metadata from arXiv
            updated_paper = self.arxiv_client.fetch_metadata(paper.arxiv_id)
            
            # Keep track of fields we want to preserve from the existing paper
            preserve_fields = [
                "issue_number", "issue_url", "state", "labels",
                "total_reading_time_seconds", "last_read", "last_visited",
                "main_tex_file"
            ]
            
            # Update our paper with new metadata while preserving existing fields
            updated_dict = updated_paper.model_dump()
            paper_dict = paper.model_dump()
            
            for field in preserve_fields:
                if paper_dict.get(field) is not None:
                    updated_dict[field] = paper_dict[field]
            
            # Create new paper instance with combined data
            hydrated_paper = Paper.model_validate(updated_dict)
            logger.info(f"Hydrated metadata for {paper.arxiv_id}")
            return hydrated_paper
            
        except Exception as e:
            logger.error(f"Failed to hydrate metadata for {paper.arxiv_id}: {e}")
            return paper  # Return original paper if hydration fails
    
    def get_paper(self, arxiv_id: str) -> Paper:
        """Get paper metadata, hydrating if necessary."""
        paper = self.load_metadata(arxiv_id)
        
        if self._needs_hydration(paper):
            logger.info(f"Missing metadata fields for {arxiv_id}, hydrating...")
            paper = self._hydrate_metadata(paper)
            self.save_metadata(paper)
        
        return paper

    def fetch_new_paper(self, arxiv_id: str) -> Paper:
        """Fetch paper metadata from ArXiv."""
        paper = self.arxiv_client.fetch_metadata(arxiv_id)
        self.create_paper(paper)
        return paper

    def get_or_create_paper(self, arxiv_id: str) -> Paper:
        """Get existing paper or create new one."""
        try:
            return self.get_paper(arxiv_id)
        except FileNotFoundError:
            return self.fetch_new_paper(arxiv_id)

    def create_paper(self, paper: Paper) -> None:
        """Create new paper directory and initialize metadata."""
        paper_dir = self.data_dir / paper.arxiv_id
        if paper_dir.exists():
            raise ValueError(f"Paper directory already exists: {paper.arxiv_id}")

        try:
            # Create directory and save metadata
            paper_dir.mkdir(parents=True)
            
            # Check if we need to hydrate metadata before saving
            if self._needs_hydration(paper):
                paper = self._hydrate_metadata(paper)
            
            self.save_metadata(paper)

            # Record visit event with paper's timestamp
            event = PaperVisitEvent(
                timestamp=paper.created_at,  # Use paper's creation timestamp
                issue_url=paper.issue_url,
                arxiv_id=paper.arxiv_id
            )
            self.append_event(paper.arxiv_id, event)

        except Exception as e:
            logger.error(f"Failed to create paper {paper.arxiv_id}: {e}")
            if paper_dir.exists():
                paper_dir.rmdir()  # Cleanup on failure
            raise

    def save_metadata(self, paper: Paper) -> None:
        """Save paper metadata to file."""
        if self._needs_hydration(paper):
            logger.warning(f"Saving paper {paper.arxiv_id} with missing metadata fields")
            
        paper_dir = self.data_dir / paper.arxiv_id
        metadata_file = paper_dir / "metadata.json"
        paper_dir.mkdir(parents=True, exist_ok=True)
        
        # Convert to dict and store
        data = paper.model_dump(by_alias=True)
        # Ensure relative paths for main_tex_file
        if data.get('main_tex_file'):
            try:
                # Convert to relative path from paper directory
                full_path = Path(data['main_tex_file'])
                rel_path = full_path.relative_to(paper_dir)
                data['main_tex_file'] = str(rel_path)
            except ValueError:
                # If path is already relative or invalid, store as-is
                pass
                
        with metadata_file.open('w') as f:
            json.dump(data, f, indent=2)
        self.modified_files.add(str(metadata_file))

    def load_metadata(self, arxiv_id: str) -> Paper:
        """Load paper metadata from file."""
        paper_dir = self.data_dir / arxiv_id
        metadata_file = paper_dir / "metadata.json"
        if not metadata_file.exists():
            raise FileNotFoundError(f"No metadata found for paper {arxiv_id}")
        
        with metadata_file.open('r') as f:
            data = json.load(f)
            # Convert relative main_tex_file path to absolute if it exists
            if data.get('main_tex_file'):
                data['main_tex_file'] = str(paper_dir / data['main_tex_file'])
            return Paper.model_validate(data)

    def append_event(self, arxiv_id: str, event: PaperVisitEvent | ReadingSession) -> None:
        """Append event to paper's event log."""
        paper_dir = self.data_dir / arxiv_id
        paper_dir.mkdir(parents=True, exist_ok=True)
        
        # Create and write to events file
        events_file = paper_dir / self._event_log_fname
        with events_file.open('a+', encoding='utf-8') as f:
            f.write(f"{event.model_dump_json()}\n")
        self.modified_files.add(str(events_file))

    def update_reading_time(self, arxiv_id: str, duration_seconds: int) -> None:
        """Update paper's total reading time."""
        paper = self.get_or_create_paper(arxiv_id)
        paper.total_reading_time_seconds += duration_seconds
        paper.last_read = datetime.utcnow().isoformat()
        self.save_metadata(paper)

    def get_modified_files(self) -> set[str]:
        """Get set of modified file paths."""
        return self.modified_files.copy()

    def clear_modified_files(self) -> None:
        """Clear set of modified files."""
        self.modified_files.clear()
        
    def update_main_tex_file(self, arxiv_id: str, tex_file: Path) -> None:
        """Update paper's main TeX file path."""
        paper = self.get_paper(arxiv_id)
        paper.main_tex_file = str(tex_file)
        self.save_metadata(paper)
        
        # Check if markdown exists
        paper_dir = self.data_dir / arxiv_id
        markdown_file = paper_dir / f"{arxiv_id}.md"
        
        if not markdown_file.exists() or markdown_file.stat().st_size == 0:
            # Attempt conversion with specified tex file
            from .markdown_service import MarkdownService
            service = MarkdownService(self.data_dir)
            service.convert_paper(arxiv_id, force=True, tex_file=tex_file)



---
File: src/scripts/process_events.py
---
# src/scripts/process_events.py
"""
Event Processing System
======================

This module handles the processing of paper-related events through GitHub issues.

Flow:
1. GitHub issues are fetched
2. Issues are categorized (paper/reading)
3. Events are processed and stored
4. Registry is updated
5. Issues are closed

For new events, see models.py for available event types.
"""

import os
import json
import yaml
from pathlib import Path
from datetime import datetime, timedelta, timezone
from loguru import logger
from typing import Optional, List, Dict, Any

from .models import Paper, ReadingSession, PaperVisitEvent
from .paper_manager import PaperManager
from .github_client import GithubClient
from llamero.utils import commit_and_push

class EventProcessor:
    """Processes GitHub issues into paper events."""

    def __init__(self, papers_dir: str|Path = "data/papers"):
        """Initialize EventProcessor with GitHub credentials and paths."""
        self.github = GithubClient(
            token=os.environ["GITHUB_TOKEN"],
            repo=os.environ["GITHUB_REPOSITORY"]
        )
        self.papers_dir = Path(papers_dir)
        self.papers_dir.mkdir(parents=True, exist_ok=True)
        self.paper_manager = PaperManager(self.papers_dir)
        self.processed_issues: list[int] = []

    def process_paper_issue(self, issue_data: Dict[str, Any]) -> bool:
        """Process paper registration issue."""
        try:
            paper_data = json.loads(issue_data["body"])
            arxiv_id = paper_data.get("arxivId")
            if not arxiv_id:
                raise ValueError("No arXiv ID found in metadata")

            # Create visit event using original timestamp
            timestamp = paper_data.get("timestamp", datetime.now(timezone.utc).isoformat())
            event = PaperVisitEvent(
                arxiv_id=arxiv_id,
                timestamp=timestamp,
                issue_url=issue_data["html_url"]
            )
            
            # Update paper metadata
            paper = self.paper_manager.get_or_create_paper(arxiv_id)
            paper.issue_number = issue_data["number"]
            paper.issue_url = issue_data["html_url"]
            paper.labels = [label["name"] for label in issue_data["labels"]]
            paper.last_visited = timestamp
            
            # Save both metadata and event
            self.paper_manager.save_metadata(paper)
            self.paper_manager.append_event(arxiv_id, event)
            self.processed_issues.append(issue_data["number"])
            return True

        except Exception as e:
            logger.error(f"Error processing paper issue: {e}")
            return False

    def process_reading_issue(self, issue_data: Dict[str, Any]) -> bool:
        """Process reading session issue."""
        try:
            session_data = json.loads(issue_data["body"])
            arxiv_id = session_data.get("arxivId")
            duration_seconds = session_data.get("duration_seconds")
            timestamp = session_data.get("timestamp")
            
            if not all([arxiv_id, duration_seconds, timestamp]):
                raise ValueError("Missing required fields in session data")

            event = ReadingSession(
                arxivId=arxiv_id,
                timestamp=timestamp,  # Use original timestamp from the event
                duration_seconds=duration_seconds,
                issue_url=issue_data["html_url"]
            )
            
            # Calculate visit end time by adding duration to timestamp
            visit_time = datetime.fromisoformat(timestamp)
            visit_end = visit_time + timedelta(seconds=duration_seconds)
            
            paper = self.paper_manager.get_or_create_paper(arxiv_id)
            paper.last_visited = visit_end.isoformat()
            self.paper_manager.save_metadata(paper)
            
            self.paper_manager.update_reading_time(arxiv_id, duration_seconds)
            self.paper_manager.append_event(arxiv_id, event)
            self.processed_issues.append(issue_data["number"])
            return True

        except Exception as e:
            logger.error(f"Error processing reading session: {e}")
            return False

    def update_registry(self) -> None:
        """Update central registry with modified papers."""
        registry_file = self.papers_dir / "papers.yaml"
        registry = {}
        
        if registry_file.exists():
            with registry_file.open('r') as f:
                registry = yaml.safe_load(f) or {}
        
        modified_papers = {
            path.parent.name 
            for path in map(Path, self.paper_manager.get_modified_files())
            if "metadata.json" in str(path)
        }
        
        for arxiv_id in modified_papers:
            try:
                paper = self.paper_manager.load_metadata(arxiv_id)
                registry[arxiv_id] = paper.model_dump(by_alias=True)
            except Exception as e:
                logger.error(f"Error adding {arxiv_id} to registry: {e}")
        
        if modified_papers:
            with registry_file.open('w') as f:
                yaml.safe_dump(registry, f, sort_keys=True, indent=2, allow_unicode=True)
            self.paper_manager.modified_files.add(str(registry_file))

    def process_all_issues(self) -> None:
        """Process all open issues."""
        # Get and process issues
        issues = self.github.get_open_issues()
        for issue in issues:
            labels = [label["name"] for label in issue["labels"]]
            if "reading-session" in labels:
                self.process_reading_issue(issue)
            elif "paper" in labels:
                self.process_paper_issue(issue)

        # Update registry and close issues
        if self.paper_manager.get_modified_files():
            self.update_registry()
            try:
                commit_and_push(list(self.paper_manager.get_modified_files()))
                for issue_number in self.processed_issues:
                    self.github.close_issue(issue_number)
                logger.info("Git operations successful and processed issues closed.")
                # logger.info("Setting EVENTS_PROCESSED variable to trigger deploy-and-publish workflow.")
                # os.environ["EVENTS_PROCESSED"]="true"
                # # with open(os.environ['GITHUB_ENV'], 'a') as f:
                # #     f.write('EVENTS_PROCESSED=true\n')
                print("Events processed.")
            except Exception as e:
                logger.error(f"Failed to commit changes: {e}")
            finally:
                self.paper_manager.clear_modified_files()

def main():
    """Main entry point for processing paper events."""
    processor = EventProcessor()
    processor.process_all_issues()

if __name__ == "__main__":
    main()



---
File: src/scripts/tex_utils.py
---
# scripts/tex_utils.py
"""TeX file utilities for arXiv paper processing."""

import re
from pathlib import Path
from loguru import logger
from dataclasses import dataclass
from typing import Sequence

@dataclass
class TeXFileScore:
    """Score details for a TeX file candidate."""
    path: Path
    score: int
    reasons: list[str]



# Common ML conference and file patterns
ML_MAIN_FILE_NAMES = {
    # Standard names
    'main.tex', 'paper.tex', 'article.tex', 'manuscript.tex',
    'submission.tex', 'arxiv.tex', 'draft.tex', 'final.tex',
    # ML/AI Conference specific
    'neurips.tex', 'neurips_main.tex', 'neurips_camera_ready.tex',
    'iclr.tex', 'iclr_main.tex', 'iclr_conference.tex', 
    'icml.tex', 'icml_final.tex', 'icml_conference.tex',
    'aaai.tex', 'aaai_submission.tex', 'aaai_camera_ready.tex',
    'acl.tex', 'acl_main.tex', 'acl_camera_ready.tex',
    'emnlp.tex', 'emnlp_main.tex', 'emnlp_final.tex',
    'cvpr.tex', 'cvpr_main.tex', 'cvpr_final.tex',
    'iccv.tex', 'iccv_main.tex', 'iccv_camera_ready.tex',
    'eccv.tex', 'eccv_main.tex', 'eccv_submission.tex',
    'mlsys.tex', 'ml4ps.tex', 'ml4md.tex', 'aistats.tex',
}

ML_CONFERENCE_PATTERNS = [
    # Major ML conferences
    r'neurips.*(?:conference|final|main)',
    r'iclr.*(?:conference|final|main)',
    r'icml.*(?:conference|final|main)',
    # NLP conferences
    r'acl.*(?:conference|final|main)',
    r'emnlp.*(?:conference|final|main)',
    r'naacl.*(?:conference|final|main)',
    # Vision conferences
    r'cvpr.*(?:conference|final|main)',
    r'iccv.*(?:conference|final|main)',
    r'eccv.*(?:conference|final|main)',
    # AI conferences
    r'aaai.*(?:conference|final|main)',
    r'ijcai.*(?:conference|final|main)',
    # Systems and specialized
    r'mlsys.*(?:conference|final|main)',
    r'kdd.*(?:conference|final|main)',
    r'aistats.*(?:conference|final|main)',
]

def score_tex_file(tex_file: Path) -> TeXFileScore:
    """Score a single TeX file based on ML-focused heuristics."""
    score = 0
    reasons: list[str] = []
    
    try:
        content = tex_file.read_text(encoding='utf-8', errors='ignore')
        
        # File name scoring
        if tex_file.name.lower() in ML_MAIN_FILE_NAMES:
            score += 3
            reasons.append(f"Main filename match (+3): {tex_file.name}")
        
        # Conference pattern scoring
        for pattern in ML_CONFERENCE_PATTERNS:
            if re.search(pattern, tex_file.name.lower()):
                score += 3
                reasons.append(f"Conference pattern match (+3): {pattern}")
        
        # Document structure
        if r'\documentclass' in content:
            score += 5
            reasons.append("Has documentclass (+5)")
        if r'\begin{document}' in content:
            score += 4
            reasons.append("Has begin{document} (+4)")
        if r'\end{document}' in content:
            score += 4
            reasons.append("Has end{document} (+4)")
        
        # Negative indicators
        input_count = len(re.findall(r'\\input{', content))
        include_count = len(re.findall(r'\\include{', content))
        if input_count + include_count > 0:
            penalty = -2 if input_count + include_count > 2 else -1
            score += penalty
            reasons.append(f"Input/include commands ({penalty})")
        
        # File size scoring
        file_size = len(content)
        size_score = 0
        if file_size > 50000:
            size_score = 4
        elif file_size > 20000:
            size_score = 3
        elif file_size > 10000:
            size_score = 2
        elif file_size > 5000:
            size_score = 1
        if size_score > 0:
            score += size_score
            reasons.append(f"File size {file_size/1000:.1f}KB (+{size_score})")
            
    except Exception as e:
        logger.debug(f"Error processing {tex_file}: {e}")
        return TeXFileScore(tex_file, 0, [f"Error: {str(e)}"])
    
    return TeXFileScore(tex_file, score, reasons)

def find_main_tex_file(tex_files: Sequence[Path], arxiv_id: str = "unknown") -> Path | None:
    """
    Find the most likely main TeX file from a list of candidates.
    
    Args:
        tex_files: List of TeX file paths to evaluate
        arxiv_id: ArXiv ID for logging context
    
    Returns:
        Path to the most likely main TeX file, or None if no valid candidates
    """
    if not tex_files:
        return None
    
    # Score all files
    scored_files = [score_tex_file(f) for f in tex_files]
    
    # Log detailed scoring
    logger.debug(f"\nTeX file scoring for {arxiv_id}:")
    for result in scored_files:
        logger.debug(f"\n{result.path.name}: Total Score = {result.score}")
        for reason in result.reasons:
            logger.debug(f"  {reason}")
    
    # Filter and sort files
    valid_files = [f for f in scored_files if f.score >= 10]  # Minimum score threshold
    if not valid_files:
        return None
        
    valid_files.sort(key=lambda x: x.score, reverse=True)
    return valid_files[0].path



---
File: tests/conftest.py
---
# tests/conftest.py
from datetime import datetime
import pytest
from pathlib import Path
from unittest.mock import Mock, patch
from scripts.models import Paper


@pytest.fixture
def mock_pandoc():
    """Mock pandoc for all tests."""
    def mock_pandoc_run(cmd, capture_output=False, cwd=None, text=True):
        mock_result = Mock()
        mock_result.returncode = 0
        mock_result.stdout = "Success"
        mock_result.stderr = ""
        
        # Handle output file creation
        try:
            output_idx = cmd.index('-o')
            if output_idx + 1 < len(cmd):
                output_file = Path(cmd[output_idx + 1])
                output_file.write_text("# Mock Pandoc Output\n\nConverted content\n")
        except (ValueError, IndexError):
            pass
            
        return mock_result

    with patch('subprocess.run', side_effect=mock_pandoc_run):
        yield

@pytest.fixture
def test_dir(tmp_path):
    """Create a clean test directory."""
    return tmp_path / "papers"

@pytest.fixture
def paper_dir(test_dir):
    """Create a test paper directory."""
    paper_dir = test_dir / "2401.00001"
    paper_dir.mkdir(parents=True)
    return paper_dir

@pytest.fixture
def sample_paper():
    """Create sample Paper object."""
    return Paper(
        arxivId="2401.00001",
        title="Test Paper",
        authors="Test Author",
        abstract="Test Abstract",
        url="https://arxiv.org/abs/2401.00001",
        issue_number=1,
        issue_url="https://github.com/user/repo/issues/1",
        created_at=datetime.utcnow().isoformat(),
        state="open",
        labels=["paper"],
        total_reading_time_seconds=0,
        last_read=None
    )

@pytest.fixture
def source_dir(paper_dir):
    """Create source directory with test TeX content."""
    source_dir = paper_dir / "source"
    source_dir.mkdir()
    
    main_tex = source_dir / "main.tex"
    main_tex.write_text(r"""
\documentclass{article}
\begin{document}
\title{Test Document}
\maketitle
\section{Introduction}
Test content
\end{document}
""")
    
    return source_dir



---
File: tests/test_arxiv_client.py
---
# tests/test_arxiv_client.py
import pytest
from pathlib import Path
from io import StringIO
import tarfile
import tempfile
from unittest.mock import Mock, patch
import xml.etree.ElementTree as ET

from scripts.arxiv_client import ArxivClient
from scripts.models import Paper


@pytest.fixture
def client(test_dir):
    """Create ArxivClient instance with rate limiting disabled."""
    client = ArxivClient(test_dir)
    client.min_delay = 0  # Disable rate limiting for tests
    return client

@pytest.fixture
def arxiv_success_response():
    """Sample successful arXiv API response."""
    return '''<?xml version="1.0" encoding="UTF-8"?>
        <feed xmlns="http://www.w3.org/2005/Atom" 
              xmlns:arxiv="http://arxiv.org/schemas/atom">
            <entry>
                <title>Test Paper Title</title>
                <summary>Test Abstract</summary>
                <author>
                    <name>Test Author One</name>
                </author>
                <author>
                    <name>Test Author Two</name>
                </author>
                <published>2024-01-01T00:00:00Z</published>
                <link href="http://arxiv.org/abs/2401.00001" rel="alternate" type="text/html"/>
                <arxiv:primary_category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
                <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
                <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
            </entry>
        </feed>'''

class TestArxivClient:
    def test_get_paper_dir(self, client):
        """Test paper directory creation."""
        arxiv_id = "2401.00001"
        paper_dir = client.get_paper_dir(arxiv_id)
        
        assert paper_dir.exists()
        assert paper_dir.is_dir()
        assert paper_dir.name == arxiv_id

    def test_get_paper_status_empty(self, client):
        """Test paper status for paper with no files."""
        arxiv_id = "2401.00001"
        client.get_paper_dir(arxiv_id)  # Create directory
        
        status = client.get_paper_status(arxiv_id)
        assert status == {
            "has_pdf": False,
            "has_source": False,
            "pdf_size": 0,
            "source_size": 0
        }

    def test_get_paper_status_with_files(self, client):
        """Test paper status with existing files."""
        arxiv_id = "2401.00001"
        paper_dir = client.get_paper_dir(arxiv_id)
        
        # Create dummy PDF
        pdf_file = paper_dir / f"{arxiv_id}.pdf"
        pdf_file.write_bytes(b"dummy pdf")
        
        # Create dummy source
        source_dir = paper_dir / "source"
        source_dir.mkdir()
        (source_dir / "main.tex").write_text("dummy tex")
        
        status = client.get_paper_status(arxiv_id)
        assert status["has_pdf"]
        assert status["has_source"]
        assert status["pdf_size"] > 0
        assert status["source_size"] > 0
    
    def test_fetch_metadata_success(self, client, arxiv_success_response):
        """Test successful metadata fetch with extended fields."""
        with patch('requests.get') as mock_get:
            mock_get.return_value.status_code = 200
            mock_get.return_value.text = arxiv_success_response
            
            paper = client.fetch_metadata("2401.00001")
            
            assert isinstance(paper, Paper)
            assert paper.arxiv_id == "2401.00001"
            assert paper.title == "Test Paper Title"
            assert paper.authors == "Test Author One, Test Author Two"
            assert paper.abstract == "Test Abstract"
            assert "arxiv.org/abs/2401.00001" in paper.url
            
            # Check new fields
            assert paper.published_date == "2024-01-01T00:00:00Z"
            assert paper.arxiv_tags == ["cs.LG", "cs.AI"]
            
            # Verify API call
            mock_get.assert_called_once()
            args, kwargs = mock_get.call_args
            assert "2401.00001" in args[0]
            assert kwargs["headers"]["User-Agent"].startswith("ArxivPaperTracker")

    def test_fetch_metadata_api_error(self, client):
        """Test handling of API error responses."""
        with patch('requests.get') as mock_get:
            mock_get.return_value.status_code = 404
            
            with pytest.raises(ValueError, match="ArXiv API error: 404"):
                client.fetch_metadata("2401.00001")

    def test_fetch_metadata_invalid_xml(self, client):
        """Test handling of invalid XML responses."""
        with patch('requests.get') as mock_get:
            mock_get.return_value.status_code = 200
            mock_get.return_value.text = "Invalid XML"
            
            with pytest.raises(ValueError, match="Invalid XML response"):
                client.fetch_metadata("2401.00001")

    def test_download_pdf_success(self, client):
        """Test successful PDF download."""
        arxiv_id = "2401.00001"
        pdf_content = b"Test PDF content"
        
        with patch('requests.get') as mock_get:
            mock_get.return_value.status_code = 200
            mock_get.return_value.content = pdf_content
            
            success = client.download_pdf(arxiv_id)
            
            assert success
            paper_dir = client.get_paper_dir(arxiv_id)
            pdf_file = paper_dir / f"{arxiv_id}.pdf"
            assert pdf_file.exists()
            assert pdf_file.read_bytes() == pdf_content

    def test_download_pdf_failure(self, client):
        """Test handling of PDF download failures."""
        with patch('requests.get') as mock_get:
            mock_get.return_value.status_code = 404
            
            success = client.download_pdf("2401.00001")
            assert not success

        def test_download_source_success(self, client):
            """Test successful source download."""
            arxiv_id = "2401.00001"
            
            # Create a test tar file
            with tempfile.NamedTemporaryFile(suffix='.tar') as tmp_file:
                with tarfile.open(tmp_file.name, 'w') as tar:
                    content = b"Test TeX content"
                    info = tarfile.TarInfo(name="main.tex")
                    info.size = len(content)
                    content_io = io.BytesIO(content)
                    tar.addfile(info, content_io)
                
                with patch('requests.get') as mock_get:
                    mock_get.return_value.status_code = 200
                    mock_get.return_value.content = open(tmp_file.name, 'rb').read()
                    
                    success = client.download_source(arxiv_id)
                    
                    assert success
                    source_dir = client.get_paper_dir(arxiv_id) / "source"
                    assert source_dir.exists()
                    assert (source_dir / "main.tex").exists()
                    assert b"Test TeX content" in (source_dir / "main.tex").read_bytes()

    def test_download_source_failure(self, client):
        """Test handling of source download failures."""
        with patch('requests.get') as mock_get:
            mock_get.return_value.status_code = 404
            
            success = client.download_source("2401.00001")
            assert not success

    def test_download_paper_complete(self, client):
        """Test downloading complete paper with PDF and source."""
        arxiv_id = "2401.00001"
        
        with patch.object(client, 'download_pdf') as mock_pdf, \
             patch.object(client, 'download_source') as mock_source:
            
            mock_pdf.return_value = True
            mock_source.return_value = True
            
            success = client.download_paper(arxiv_id)
            
            assert success
            mock_pdf.assert_called_once()
            mock_source.assert_called_once()

    def test_rate_limiting(self, client):
        """Test rate limiting between requests."""
        client.min_delay = 0.1  # Short delay for testing
        
        with patch('requests.get') as mock_get, \
             patch('time.sleep') as mock_sleep:
            
            mock_get.return_value.status_code = 200
            mock_get.return_value.text = '''<?xml version="1.0" encoding="UTF-8"?>
    <feed xmlns="http://www.w3.org/2005/Atom">
        <entry>
            <title>Test</title>
            <summary>Test summary</summary>
        </entry>
    </feed>'''
            
            # Make multiple requests
            for _ in range(3):
                client.fetch_metadata("2401.00001")
            
            assert mock_sleep.call_count == 2  # Called between requests



---
File: tests/test_asset_manager.py
---
# tests/test_asset_manager.py
import pytest
from pathlib import Path
from unittest.mock import patch

from scripts.asset_manager import PaperAssetManager

@pytest.fixture
def manager(test_dir):
    """Create AssetManager with mocked dependencies."""
    with patch('scripts.arxiv_client.ArxivClient') as mock_arxiv, \
         patch('scripts.markdown_service.MarkdownService') as mock_markdown:
        
        # Configure mock ArxivClient
        mock_arxiv.return_value.get_paper_status.return_value = {
            "has_pdf": False,
            "has_source": False,
        }
        mock_arxiv.return_value.download_pdf.return_value = True
        mock_arxiv.return_value.download_source.return_value = True
        
        # Configure mock MarkdownService
        mock_markdown.return_value.get_conversion_status.return_value = {
            "has_markdown": False,
            "has_source": False,
            "failed": False,
        }
        mock_markdown.return_value.convert_paper.return_value = True
        
        yield PaperAssetManager(
            papers_dir=test_dir,
            arxiv_client=mock_arxiv.return_value,
            markdown_service=mock_markdown.return_value
        )

def test_ensure_all_assets(manager):
    """Test processing all papers."""
    # Create test papers
    (manager.papers_dir / "2401.00001").mkdir()
    (manager.papers_dir / "2401.00002").mkdir()
    
    # Set up mock behavior to create conditions for markdown conversion
    def get_paper_status(arxiv_id):
        # After "downloading" source files, report them as present
        call_count = manager.arxiv.download_source.call_count
        return {
            "has_pdf": False,  # Always need PDF
            "has_source": call_count > 0,  # Source exists after download
        }
    
    def get_conversion_status(arxiv_id):
        return {
            "has_markdown": False,  # Always need markdown conversion
            "has_source": True,  # Source files present
            "failed": False,
        }
    
    manager.arxiv.get_paper_status.side_effect = get_paper_status
    manager.markdown.get_conversion_status.side_effect = get_conversion_status
    
    manager.ensure_all_assets()
    
    # Verify all operations were attempted
    assert manager.arxiv.download_pdf.call_count == 2
    assert manager.arxiv.download_source.call_count == 2
    assert manager.markdown.convert_paper.call_count == 2

def test_convert_markdown(manager):
    """Test converting papers to markdown."""
    # Create test papers
    paper_dirs = ["2401.00001", "2401.00002"]
    for name in paper_dirs:
        (manager.papers_dir / name).mkdir()
    
    # Configure mock for papers with source
    manager.arxiv.get_paper_status.return_value = {"has_pdf": True, "has_source": True}
    manager.markdown.get_conversion_status.return_value = {
        "has_markdown": False,
        "has_source": True,
        "failed": False,
    }
    
    results = manager.convert_markdown()
    assert len(results) == 2
    assert all(results.values())
    assert manager.markdown.convert_paper.call_count == 2



---
File: tests/test_github_client.py
---
# tests/test_github_client.py
import pytest
from unittest.mock import Mock, patch
from scripts.github_client import GithubClient

@pytest.fixture
def client():
    """Create GithubClient instance."""
    return GithubClient(token="fake_token", repo="user/repo")

class TestGithubClient:
    def test_get_open_issues(self, client):
        """Test fetching open issues."""
        mock_response = [
            {"labels": [{"name": "paper"}]},
            {"labels": [{"name": "reading-session"}]},
            {"labels": [{"name": "other"}]}
        ]
        
        with patch('requests.get') as mock_get:
            mock_get.return_value.status_code = 200
            mock_get.return_value.json.return_value = mock_response
            
            issues = client.get_open_issues()
            
            assert len(issues) == 2  # Only paper and reading-session issues
            assert all(
                any(label["name"] in ["paper", "reading-session"] 
                    for label in issue["labels"]) 
                for issue in issues
            )
            
            # Verify API call
            mock_get.assert_called_once()
            args, kwargs = mock_get.call_args
            assert "/issues" in args[0]
            assert kwargs["params"]["state"] == "open"

    def test_get_open_issues_error(self, client):
        """Test handling API errors in issue fetching."""
        with patch('requests.get') as mock_get:
            mock_get.return_value.status_code = 404
            
            issues = client.get_open_issues()
            assert issues == []  # Returns empty list on error

    def test_close_issue_success(self, client):
        """Test successful issue closing."""
        with patch('requests.post') as mock_post, \
             patch('requests.patch') as mock_patch:
            
            mock_post.return_value.status_code = 201  # Comment created
            mock_patch.return_value.status_code = 200  # Issue closed
            
            success = client.close_issue(123)
            
            assert success
            mock_post.assert_called_once()  # Comment added
            mock_patch.assert_called_once()  # Issue closed

    def test_close_issue_comment_error(self, client):
        """Test handling comment creation error."""
        with patch('requests.post') as mock_post:
            mock_post.return_value.status_code = 404
            
            success = client.close_issue(123)
            
            assert not success
            mock_post.assert_called_once()

    def test_close_issue_close_error(self, client):
        """Test handling issue closing error."""
        with patch('requests.post') as mock_post, \
             patch('requests.patch') as mock_patch:
            
            mock_post.return_value.status_code = 201
            mock_patch.return_value.status_code = 404
            
            success = client.close_issue(123)
            
            assert not success
            mock_post.assert_called_once()
            mock_patch.assert_called_once()



---
File: tests/test_markdown_service.py
---
# tests/test_markdown_service.py
import pytest
import json
from pathlib import Path
from datetime import datetime, timedelta
from unittest.mock import patch, MagicMock

from scripts.markdown_service import MarkdownService
from scripts.paper_manager import PaperManager

@pytest.fixture
def paper_manager(test_dir):
    """Create PaperManager instance."""
    return PaperManager(test_dir)

@pytest.fixture
def service(test_dir):
    """Create MarkdownService instance."""
    return MarkdownService(test_dir)

@pytest.fixture
def setup_metadata_with_tex(paper_dir):
    """Setup metadata.json with main_tex_file specified."""
    metadata = {
        "arxivId": paper_dir.name,
        "title": "Test Paper",
        "authors": "Test Author",
        "abstract": "Test abstract",
        "url": "https://arxiv.org/abs/test",
        "issue_number": 1,
        "issue_url": "https://github.com/test/issue/1",
        "created_at": "2024-01-01T00:00:00Z",
        "state": "open",
        "labels": [],
        "main_tex_file": "source/main.tex"
    }
    metadata_file = paper_dir / "metadata.json"
    metadata_file.write_text(json.dumps(metadata, indent=2))
    return metadata_file

class TestMarkdownService:
    def test_convert_with_metadata_tex_file(self, service, source_dir, setup_metadata_with_tex, mock_pandoc):
        """Test conversion using main_tex_file from metadata."""
        paper_dir = source_dir.parent
        main_tex = source_dir / "main.tex"
        main_tex.write_text("\\documentclass{article}\n\\begin{document}\nTest\n\\end{document}")
        
        success = service.convert_paper(paper_dir.name)
        assert success
        assert (paper_dir / f"{paper_dir.name}.md").exists()

    def test_convert_with_invalid_metadata_tex_file(self, service, source_dir, setup_metadata_with_tex):
        """Test fallback when metadata specifies non-existent tex file."""
        paper_dir = source_dir.parent
        metadata = json.loads(setup_metadata_with_tex.read_text())
        metadata["main_tex_file"] = "source/nonexistent.tex"
        setup_metadata_with_tex.write_text(json.dumps(metadata, indent=2))
        
        # Should fall back to inference
        success = service.convert_paper(paper_dir.name)
        assert not success
        assert paper_dir.name in service.failed_conversions

    def test_convert_with_paper_manager_update(self, service, source_dir, paper_manager, mock_pandoc):
        """Test conversion after updating main_tex_file via PaperManager."""
        # Get paths from fixtures
        paper_dir = source_dir.parent
        main_tex = source_dir / "main.tex"
        
        # Create initial metadata using the paper directory name from fixture
        from scripts.models import Paper
        paper = Paper(
            arxivId=paper_dir.name,
            title="Test Paper",
            authors="Test Author",
            abstract="Test abstract", 
            url=f"https://arxiv.org/abs/{paper_dir.name}",
            issue_number=1,
            issue_url=f"https://github.com/test/issue/1",
            created_at="2024-01-01T00:00:00Z",
            state="open",
            labels=[]
        )
        
        # Ensure clean state and create paper
        import shutil
        if paper_dir.exists():
            shutil.rmtree(paper_dir)
        paper_manager.create_paper(paper)
        
        # Recreate source directory and tex file
        source_dir.mkdir(parents=True)
        main_tex.write_text(r"""
\documentclass{article}
\begin{document}
\title{Test Document}
\maketitle
\section{Introduction}
Test content
\end{document}
""")
        
        # Update via PaperManager
        paper_manager.update_main_tex_file(paper_dir.name, main_tex)
        
        # Verify conversion uses specified file
        success = service.convert_paper(paper_dir.name)
        assert success
        assert (paper_dir / f"{paper_dir.name}.md").exists()
    def test_convert_paper_success(self, service, source_dir, mock_pandoc):
        """Test successful paper conversion."""
        paper_dir = source_dir.parent
        success = service.convert_paper(paper_dir.name)
        assert success
        assert (paper_dir / f"{paper_dir.name}.md").exists()

    def test_convert_paper_no_source(self, service, paper_dir):
        """Test conversion without source files."""
        success = service.convert_paper(paper_dir.name)
        assert not success
        assert paper_dir.name in service.failed_conversions

    def test_force_reconversion(self, service, source_dir, mock_pandoc):
        """Test forced reconversion."""
        paper_dir = source_dir.parent
        arxiv_id = paper_dir.name
        
        # First conversion
        markdown_file = paper_dir / f"{arxiv_id}.md"
        service.convert_paper(arxiv_id)
        assert markdown_file.exists()
        
        # Force reconversion
        success = service.convert_paper(arxiv_id, force=True)
        assert success
        assert "Mock Pandoc Output" in markdown_file.read_text()

    def test_skip_recent_failure(self, service, paper_dir):
        """Test that recent failures are skipped."""
        service._record_failure(paper_dir.name, "Test error")
        success = service.convert_paper(paper_dir.name)
        assert not success



---
File: tests/test_pandoc_utils.py
---
"""Tests for pandoc utilities and conversion process."""
import os
import subprocess
import tempfile
from pathlib import Path
from unittest.mock import Mock, patch
import pytest
from scripts.pandoc_utils import PandocConverter, PandocConfig, create_default_config

# Register the integration mark to remove warnings
pytest.mark.integration = pytest.mark.integration

@pytest.fixture
def mock_subprocess_run():
    """Mock successful subprocess run."""
    mock = Mock()
    mock.return_value.returncode = 0
    mock.return_value.stdout = "Success"
    mock.return_value.stderr = ""
    return mock

@pytest.fixture
def test_tex_content():
    """Sample LaTeX content for testing."""
    return r"""
\documentclass{article}
\begin{document}
\title{Test Document}
\maketitle
\section{Introduction}
Test content
\end{document}
"""

# @pytest.fixture
# def paper_dir(tmp_path):
#     """Create a paper directory with necessary structure."""
#     paper_dir = tmp_path / "papers/2203.15556"
#     paper_dir.mkdir(parents=True)
#     return paper_dir

@pytest.fixture
def source_dir(paper_dir, test_tex_content):  # Note: now properly using the fixture
    """Create source directory with test TeX file."""
    source_dir = paper_dir / "source"
    source_dir.mkdir()
    tex_file = source_dir / "main.tex"
    tex_file.write_text(test_tex_content)  # Using the fixture value
    return source_dir

@pytest.fixture
def converter(paper_dir):
    """Create PandocConverter instance with test configuration."""
    config = create_default_config(paper_dir)
    return PandocConverter(config)

def test_directory_creation(paper_dir, converter):
    """Test that all necessary directories are created."""
    media_dir = paper_dir / "media"
    assert media_dir.exists(), "Media directory not created"
    assert media_dir.is_dir(), "Media path is not a directory"

def test_supporting_files_creation(paper_dir, converter):
    """Test that all supporting files are created correctly."""
    media_dir = paper_dir / "media"
    
    # Check Lua filter
    lua_filter = media_dir / "crossref.lua"
    assert lua_filter.exists(), "Lua filter not created"
    content = lua_filter.read_text()
    assert "function Math(elem)" in content, "Lua filter content incorrect"
    
    # Check metadata file
    metadata_file = media_dir / "metadata.yaml"
    assert metadata_file.exists(), "Metadata file not created"
    content = metadata_file.read_text()
    assert "reference-section-title" in content, "Metadata content incorrect"

def test_file_verification(paper_dir, converter):
    """Test file verification logic."""
    assert converter._verify_files_exist(), "File verification failed"

def test_pandoc_command_building(paper_dir, converter):
    """Test pandoc command construction."""
    input_file = Path("test.tex")
    output_file = Path("test.md")
    cmd = converter.build_pandoc_command(input_file, output_file)
    
    assert cmd[0] == "pandoc", "Command should start with pandoc"
    assert f"--extract-media={converter.config.extract_media_dir}" in " ".join(cmd), \
        "Media directory not properly configured"
    assert "--metadata-file" in cmd, "Metadata file not included in command"
    assert "--lua-filter" in cmd, "Lua filter not included in command"

@pytest.mark.integration
def test_full_conversion_process(paper_dir, source_dir, converter, mock_subprocess_run):
    """Test the complete conversion process."""
    with patch('subprocess.run', mock_subprocess_run):
        input_file = source_dir / "main.tex"
        output_file = paper_dir / "2203.15556.md"
        
        # Verify input exists
        assert input_file.exists(), "Test TeX file not created"
        
        # Mock should create the output file to simulate pandoc behavior
        def mock_pandoc_effect(*args, **kwargs):
            mock_result = Mock()
            mock_result.returncode = 0
            mock_result.stdout = "Success"
            mock_result.stderr = ""
            
            # Get output file path from command args
            output_path = args[0][args[0].index('-o') + 1]
            # Simulate pandoc creating the output file
            Path(output_path).write_text("# Test Output\nConverted content")
            return mock_result
        
        mock_subprocess_run.side_effect = mock_pandoc_effect
        
        # Run conversion
        try:
            converter.convert_tex_to_markdown(input_file, output_file)
        except Exception as e:
            pytest.fail(f"Conversion failed with error: {e}")

@pytest.mark.integration
def test_real_pandoc_execution(paper_dir, source_dir, converter, test_tex_content):
    """Test with actual pandoc execution."""
    try:
        # Verify pandoc is installed
        result = subprocess.run(["pandoc", "--version"], 
                              capture_output=True, text=True)
        assert result.returncode == 0, "Pandoc not available"
        
        input_file = source_dir / "main.tex"
        output_file = paper_dir / "2203.15556.md"
        
        # Write minimal test content
        input_file.write_text(test_tex_content)
        
        # Run conversion
        success = converter.convert_tex_to_markdown(input_file, output_file)
        
        # Print debug info if conversion fails
        if not success:
            print("\nDebug information:")
            print(f"Input file exists: {input_file.exists()}")
            print(f"Input file content:\n{input_file.read_text()}")
            print(f"Media dir exists: {converter.config.extract_media_dir.exists()}")
            print(f"Metadata file exists: {converter.config.metadata_file.exists()}")
            if converter.config.metadata_file.exists():
                print(f"Metadata content:\n{converter.config.metadata_file.read_text()}")
            print(f"Lua filter exists: {converter.config.lua_filter.exists()}")
            if converter.config.lua_filter.exists():
                print(f"Lua filter content:\n{converter.config.lua_filter.read_text()}")
        
        assert success, "Real pandoc conversion failed"
        assert output_file.exists(), "Output file not created"
        assert output_file.stat().st_size > 0, "Output file is empty"
        
    except FileNotFoundError:
        pytest.skip("Pandoc not installed")

def test_error_handling(paper_dir, converter):
    """Test error handling in various scenarios."""
    
    # Test with non-existent input file
    with pytest.raises(FileNotFoundError, match="LaTeX file not found"):
        converter.convert_tex_to_markdown(Path("nonexistent.tex"))

def test_temporary_directory_cleanup(paper_dir, source_dir, converter):
    """Test that temporary directory is properly cleaned up."""
    temp_dirs_before = set(Path(tempfile.gettempdir()).iterdir())
    
    with patch('subprocess.run') as mock_run:
        # Mock should create the output file
        def mock_success(*args, **kwargs):
            mock_result = Mock()
            mock_result.returncode = 0
            mock_result.stdout = "Success"
            mock_result.stderr = ""
            
            # Get output file path from command args
            output_path = args[0][args[0].index('-o') + 1]
            # Simulate pandoc creating the output file
            Path(output_path).write_text("Mock output")
            return mock_result
            
        mock_run.side_effect = mock_success
        
        try:
            converter.convert_tex_to_markdown(
                source_dir / "main.tex",
                paper_dir / "output.md"
            )
        except Exception as e:
            pytest.fail(f"Conversion failed with error: {e}")
    
    temp_dirs_after = set(Path(tempfile.gettempdir()).iterdir())
    assert temp_dirs_before == temp_dirs_after, "Temporary directory not cleaned up"

@pytest.mark.integration
def test_minimal_pandoc_conversion(tmp_path):
    """Test bare minimum pandoc conversion with real pandoc."""
    try:
        # Verify pandoc is installed
        result = subprocess.run(["pandoc", "--version"], 
                              capture_output=True, text=True)
        if result.returncode != 0:
            pytest.skip("Pandoc not installed")
            
        # Create test directory structure
        paper_dir = tmp_path / "test_paper"
        paper_dir.mkdir()
        
        # Create test LaTeX file
        tex_file = paper_dir / "test.tex"
        tex_file.write_text(r"""
\documentclass{article}
\begin{document}
Test content
\end{document}
""")
        
        # Create output path
        output_file = paper_dir / "test.md"
        
        # Run minimal pandoc command
        cmd = [
            'pandoc',
            '-f', 'latex',
            '-t', 'gfm',
            '--standalone',
            str(tex_file.resolve()),
            '-o', str(output_file.resolve())
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        print(f"\nCommand: {' '.join(cmd)}")
        print(f"Return code: {result.returncode}")
        print(f"Stdout: {result.stdout}")
        print(f"Stderr: {result.stderr}")
        
        assert result.returncode == 0, f"Pandoc failed: {result.stderr}"
        assert output_file.exists(), "Output file not created"
        content = output_file.read_text()
        assert "Test content" in content, "Expected content not found"
        
    except FileNotFoundError:
        pytest.skip("Pandoc not installed")

if __name__ == "__main__":
    pytest.main(["-v", "-s", __file__])



---
File: tests/test_paper_manager.py
---
import json
import pytest
from pathlib import Path
from datetime import datetime
from unittest.mock import Mock, patch

from scripts.paper_manager import PaperManager
from scripts.models import Paper, ReadingSession, PaperVisitEvent
from scripts.arxiv_client import ArxivClient


@pytest.fixture
def manager(test_dir):
    """Create PaperManager instance with test directory."""
    return PaperManager(test_dir)


class TestPaperManager:
    def test_get_paper_not_found(self, manager):
        """Test getting non-existent paper."""
        with pytest.raises(FileNotFoundError):
            manager.get_paper("2401.00001")

    def test_create_and_get_paper(self, manager, sample_paper):
        """Test creating and retrieving a paper."""
        with patch.object(manager, '_needs_hydration', return_value=False):
            manager.create_paper(sample_paper)
            retrieved = manager.get_paper(sample_paper.arxiv_id)
            assert retrieved.arxiv_id == sample_paper.arxiv_id
            assert retrieved.title == sample_paper.title

    def test_get_or_create_paper_existing(self, manager, sample_paper):
        """Test get_or_create with existing paper."""
        with patch.object(manager, '_needs_hydration', return_value=False):
            manager.create_paper(sample_paper)
            paper = manager.get_or_create_paper(sample_paper.arxiv_id)
            assert paper.arxiv_id == sample_paper.arxiv_id
            assert paper.title == sample_paper.title

    def test_get_or_create_paper_new(self, manager):
        """Test get_or_create fetches new paper."""
        arxiv_id = "2401.00001"
        with patch.object(ArxivClient, 'fetch_metadata') as mock_fetch, \
             patch.object(manager, '_needs_hydration', return_value=False):
            mock_fetch.return_value = Paper(
                arxivId=arxiv_id,
                title="New Paper",
                authors="New Author",
                abstract="New Abstract",
                url=f"https://arxiv.org/abs/{arxiv_id}",
                issue_number=1,
                issue_url="https://github.com/user/repo/issues/1",
                created_at=datetime.utcnow().isoformat(),
                state="open",
                labels=[],
                total_reading_time_seconds=0
            )
            
            paper = manager.get_or_create_paper(arxiv_id)
            assert paper.arxiv_id == arxiv_id
            assert paper.title == "New Paper"
            mock_fetch.assert_called_once_with(arxiv_id)

    def test_update_reading_time(self, manager, sample_paper):
        """Test updating paper reading time."""
        manager.create_paper(sample_paper)
        duration = 300  # 5 minutes
        
        manager.update_reading_time(sample_paper.arxiv_id, duration)
        paper = manager.get_paper(sample_paper.arxiv_id)
        
        assert paper.total_reading_time_seconds == duration
        assert paper.last_read is not None

    def test_append_event(self, manager, sample_paper):
        """Test appending reading session event."""
        manager.create_paper(sample_paper)
        
        event = ReadingSession(
            arxivId=sample_paper.arxiv_id,
            timestamp=datetime.utcnow().isoformat(),
            duration_seconds=300,
            issue_url="https://github.com/user/repo/issues/2"
        )
        
        manager.append_event(sample_paper.arxiv_id, event)
        
        # Verify event was written
        events_file = manager.data_dir / sample_paper.arxiv_id / manager._event_log_fname
        assert events_file.exists()
        
        # Read and verify event content
        events = [json.loads(line) for line in events_file.read_text().splitlines() if line.strip()]
        assert len(events) == 2  # Should have registration and reading session events
        
        # Verify visit event
        visit_event = events[0]
        assert visit_event["type"] == "paper_visit"
        assert visit_event["arxiv_id"] == sample_paper.arxiv_id
        
        # Verify reading session event
        session_event = events[1]
        assert session_event["type"] == "reading_session"
        assert session_event["arxiv_id"] == sample_paper.arxiv_id
        assert session_event["duration_seconds"] == 300

    def test_modified_files_tracking(self, manager, sample_paper):
        """Test tracking of modified files."""
        manager.create_paper(sample_paper)
        
        # Check metadata file was tracked
        metadata_path = str(manager.data_dir / sample_paper.arxiv_id / "metadata.json")
        assert metadata_path in manager.get_modified_files()
        
        # Clear and verify
        manager.clear_modified_files()
        assert len(manager.get_modified_files()) == 0
        
        # Update and verify new modification tracked
        manager.update_reading_time(sample_paper.arxiv_id, 300)
        assert metadata_path in manager.get_modified_files()

    def test_save_load_metadata(self, manager, sample_paper):
        """Test metadata serialization."""
        manager.save_metadata(sample_paper)
        loaded = manager.load_metadata(sample_paper.arxiv_id)
        
        assert loaded.model_dump() == sample_paper.model_dump()
    
    def test_concurrent_event_writing(self, manager, sample_paper):
        """Test concurrent writing of multiple events."""
        manager.create_paper(sample_paper)
        
        # Create multiple events
        events = [
            ReadingSession(
                arxivId=sample_paper.arxiv_id,
                timestamp=f"2024-01-01T00:0{i}:00Z",
                duration_seconds=30,
                issue_url=f"https://example.com/{i}"
            ) for i in range(10)
        ]
        
        # Write events rapidly
        for event in events:
            manager.append_event(sample_paper.arxiv_id, event)
        
        # Verify integrity
        events_file = manager.data_dir / sample_paper.arxiv_id / manager._event_log_fname
        lines = events_file.read_text().splitlines()
        assert len(lines) == len(events) + 1  # +1 for initial paper visit event
        
        # Verify each event was written correctly
        for line in lines[1:]:  # Skip initial visit event
            event_data = json.loads(line)
            assert event_data["type"] == "reading_session"
            assert event_data["duration_seconds"] == 30
            assert event_data["arxiv_id"] == sample_paper.arxiv_id



---
File: tests/test_paper_manager_hydration.py
---
# tests/test_paper_manager.py
import json
import pytest
from pathlib import Path
from datetime import datetime
from unittest.mock import Mock, patch

from scripts.models import Paper
from scripts.paper_manager import PaperManager


@pytest.fixture
def manager(test_dir):
    """Create PaperManager instance with test directory."""
    return PaperManager(test_dir)

@pytest.fixture
def paper_with_missing_fields(sample_paper):
    """Create paper missing optional metadata fields."""
    paper_dict = sample_paper.model_dump()
    paper_dict["published_date"] = None
    paper_dict["arxiv_tags"] = None
    return Paper.model_validate(paper_dict)

@pytest.fixture
def complete_paper(sample_paper):
    """Create paper with all metadata fields."""
    paper_dict = sample_paper.model_dump()
    paper_dict["published_date"] = "2024-01-01T00:00:00Z"
    paper_dict["arxiv_tags"] = ["cs.LG", "cs.AI"]
    return Paper.model_validate(paper_dict)

class TestPaperManagerHydration:
    def test_needs_hydration_missing_fields(self, manager, paper_with_missing_fields):
        """Test hydration check with missing fields."""
        assert manager._needs_hydration(paper_with_missing_fields)
        
    def test_needs_hydration_complete(self, manager, complete_paper):
        """Test hydration check with complete metadata."""
        assert not manager._needs_hydration(complete_paper)
        
    def test_needs_hydration_empty_tags(self, manager, complete_paper):
        """Test hydration check with empty tags list."""
        paper_dict = complete_paper.model_dump()
        paper_dict["arxiv_tags"] = []
        paper = Paper.model_validate(paper_dict)
        assert manager._needs_hydration(paper)

    def test_hydrate_metadata_success(self, manager, paper_with_missing_fields, complete_paper):
        """Test successful metadata hydration."""
        with patch.object(manager.arxiv_client, 'fetch_metadata', return_value=complete_paper):
            hydrated = manager._hydrate_metadata(paper_with_missing_fields)
            
            # Check new fields were added
            assert hydrated.published_date == complete_paper.published_date
            assert hydrated.arxiv_tags == complete_paper.arxiv_tags
            
            # Check existing fields were preserved
            assert hydrated.total_reading_time_seconds == paper_with_missing_fields.total_reading_time_seconds
            assert hydrated.issue_number == paper_with_missing_fields.issue_number

    def test_hydrate_metadata_failure(self, manager, paper_with_missing_fields):
        """Test handling of hydration failure."""
        with patch.object(manager.arxiv_client, 'fetch_metadata', side_effect=Exception("API Error")):
            result = manager._hydrate_metadata(paper_with_missing_fields)
            # Should return original paper on failure
            assert result == paper_with_missing_fields

    def test_get_paper_triggers_hydration(self, manager, paper_with_missing_fields):
        """Test that get_paper initiates hydration when needed."""
        # Save paper with missing fields
        manager.save_metadata(paper_with_missing_fields)
        
        # Mock the hydration
        complete = paper_with_missing_fields.model_copy()
        complete.published_date = "2024-01-01T00:00:00Z"
        complete.arxiv_tags = ["cs.LG"]
        
        with patch.object(manager.arxiv_client, 'fetch_metadata', return_value=complete):
            paper = manager.get_paper(paper_with_missing_fields.arxiv_id)
            assert paper.published_date is not None
            assert paper.arxiv_tags is not None
            
            # Verify metadata file was updated
            loaded = manager.load_metadata(paper.arxiv_id)
            assert loaded.published_date == complete.published_date
            assert loaded.arxiv_tags == complete.arxiv_tags

    def test_create_paper_with_hydration(self, manager, paper_with_missing_fields, complete_paper):
        """Test that create_paper performs hydration."""
        with patch.object(manager.arxiv_client, 'fetch_metadata', return_value=complete_paper):
            manager.create_paper(paper_with_missing_fields)
            
            # Load and verify metadata was hydrated
            paper = manager.load_metadata(paper_with_missing_fields.arxiv_id)
            assert paper.published_date == complete_paper.published_date
            assert paper.arxiv_tags == complete_paper.arxiv_tags



---
File: tests/test_process_events.py
---
# tests/test_process_events.py
import json
import yaml
import pytest
from pathlib import Path
from datetime import datetime
from unittest.mock import Mock, patch

from scripts.process_events import EventProcessor
from scripts.models import Paper


@pytest.fixture
def sample_paper_issue(sample_paper):
    """Create sample paper registration issue."""
    return {
        "number": 1,
        "html_url": "https://github.com/user/repo/issues/1",
        "state": "open",
        "labels": [{"name": "paper"}],
        "body": json.dumps({
            "arxivId": sample_paper.arxiv_id,
            "title": sample_paper.title,
            "authors": sample_paper.authors,
            "abstract": sample_paper.abstract,
            "url": sample_paper.url
        })
    }

@pytest.fixture
def event_processor(tmp_path):
    """Create EventProcessor with temp directory."""
    with patch.dict('os.environ', {
        'GITHUB_TOKEN': 'fake_token',
        'GITHUB_REPOSITORY': 'user/repo'
    }):
        processor = EventProcessor()
        processor.papers_dir = tmp_path / "papers"
        processor.papers_dir.mkdir(parents=True)
        return processor

class TestEventProcessor:
    def test_process_paper_issue(self, event_processor, sample_paper_issue, sample_paper):
        """Test processing paper registration issue."""
        with patch('scripts.paper_manager.PaperManager.get_or_create_paper', return_value=sample_paper):
            success = event_processor.process_paper_issue(sample_paper_issue)
            
            assert success
            assert sample_paper_issue["number"] in event_processor.processed_issues

    def test_process_reading_issue(self, event_processor, sample_paper):
        """Test processing reading session issue."""
        issue_data = {
            "number": 2,
            "html_url": "https://github.com/user/repo/issues/2",
            "labels": [{"name": "reading-session"}],
            "body": json.dumps({
                "arxivId": sample_paper.arxiv_id,
                "timestamp": datetime.utcnow().isoformat(),
                "duration_seconds": 30
            })
        }
        
        with patch('scripts.paper_manager.PaperManager.get_or_create_paper', return_value=sample_paper), \
             patch('scripts.paper_manager.PaperManager.update_reading_time'), \
             patch('scripts.paper_manager.PaperManager.append_event'):
            
            success = event_processor.process_reading_issue(issue_data)
            assert success
            assert issue_data["number"] in event_processor.processed_issues

    def test_process_reading_issue_invalid_data(self, event_processor):
        """Test processing invalid reading session data."""
        invalid_issue = {
            "number": 1,
            "html_url": "https://github.com/user/repo/issues/1",
            "labels": [{"name": "reading-session"}],
            "body": "invalid json"
        }
        
        success = event_processor.process_reading_issue(invalid_issue)
        assert not success
        assert 1 not in event_processor.processed_issues

    def test_update_registry(self, event_processor, sample_paper, tmp_path):
        """Test updating registry file."""
        # Setup: create paper and mark as modified
        paper_dir = event_processor.papers_dir / sample_paper.arxiv_id
        paper_dir.mkdir(parents=True)
        event_processor.paper_manager.save_metadata(sample_paper)
        
        event_processor.update_registry()
        
        registry_file = event_processor.papers_dir / "papers.yaml"
        assert registry_file.exists()
        with registry_file.open() as f:
            registry_data = yaml.safe_load(f)
        assert sample_paper.arxiv_id in registry_data

    def test_process_all_issues(self, event_processor, sample_paper_issue):
        """Test processing multiple issue types."""
        with patch('scripts.github_client.GithubClient.get_open_issues') as mock_get_issues, \
             patch('scripts.github_client.GithubClient.close_issue') as mock_close_issue, \
             patch('scripts.paper_manager.PaperManager.get_or_create_paper') as mock_get_paper, \
             patch('scripts.process_events.commit_and_push'):
            
            # Configure mocks
            mock_get_issues.return_value = [sample_paper_issue]
            mock_close_issue.return_value = True
            
            # Parse JSON from issue body
            issue_data = json.loads(sample_paper_issue["body"])
            mock_get_paper.return_value = Paper(
                arxivId=issue_data["arxivId"],
                title=issue_data["title"],
                authors=issue_data["authors"], 
                abstract=issue_data["abstract"],
                url=issue_data["url"],
                issue_number=sample_paper_issue["number"],
                issue_url=sample_paper_issue["html_url"],
                created_at=datetime.utcnow().isoformat(),
                state="open",
                labels=["paper"],
                total_reading_time_seconds=0,
                last_read=None
            )
            
            event_processor.process_all_issues()
            
            assert len(event_processor.processed_issues) == 1
            mock_get_issues.assert_called_once()
            mock_close_issue.assert_called_once()
            mock_get_paper.assert_called_once()

    def test_process_no_issues(self, event_processor):
        """Test behavior when no issues exist."""
        with patch('scripts.github_client.GithubClient.get_open_issues') as mock_get_issues:
            mock_get_issues.return_value = []
            
            event_processor.process_all_issues()
            assert len(event_processor.processed_issues) == 0
            mock_get_issues.assert_called_once()

    def test_github_api_error(self, event_processor):
        """Test handling of GitHub API errors."""
        with patch('scripts.github_client.GithubClient.get_open_issues') as mock_get_issues:
            mock_get_issues.return_value = []  # API error returns empty list
            
            event_processor.process_all_issues()
            assert len(event_processor.processed_issues) == 0



---
File: tests/test_tex_utils.py
---
# tests/test_tex_utils.py
"""Tests for TeX utilities."""

import pytest
from pathlib import Path
from scripts.tex_utils import find_main_tex_file, score_tex_file

@pytest.fixture
def tex_dir(tmp_path):
    """Create a temporary directory with test TeX files."""
    tex_dir = tmp_path / "tex"
    tex_dir.mkdir()
    return tex_dir

def create_tex_file(directory: Path, name: str, content: str) -> Path:
    """Helper to create a TeX file with given content."""
    file_path = directory / name
    file_path.write_text(content)
    return file_path

def test_score_tex_file(tex_dir):
    # Create test file with various indicators
    content = r"""
\documentclass{article}
\begin{document}
\title{Test Paper}
\author{Test Author}
\maketitle
\section{Introduction}
Test content
\end{document}
"""
    tex_file = create_tex_file(tex_dir, "main.tex", content)
    
    result = score_tex_file(tex_file)
    assert result.score > 0
    assert any("documentclass" in r for r in result.reasons)
    assert any("Main filename" in r for r in result.reasons)

def test_find_main_tex_file_simple(tex_dir):
    # Create main file
    main_content = r"""
\documentclass{article}
\begin{document}
\title{Main Paper}
\end{document}
"""
    main_file = create_tex_file(tex_dir, "main.tex", main_content)
    
    # Create supplementary file
    supp_content = r"""
\documentclass{article}
\begin{document}
\section{Appendix}
\end{document}
"""
    supp_file = create_tex_file(tex_dir, "supplement.tex", supp_content)
    
    result = find_main_tex_file([main_file, supp_file])
    assert result == main_file

def test_find_main_tex_file_ml_conference(tex_dir):
    # Create conference submission file
    conf_content = r"""
\documentclass{neurips_2024}
\begin{document}
\title{Deep Learning Paper}
\end{document}
"""
    conf_file = create_tex_file(tex_dir, "neurips_conference.tex", conf_content)
    
    result = find_main_tex_file([conf_file])
    assert result == conf_file

def test_find_main_tex_file_empty_list():
    assert find_main_tex_file([]) is None

def test_score_tex_file_with_inputs(tex_dir):
    # Test file with multiple inputs (should get penalty)
    content = r"""
\documentclass{article}
\begin{document}
\input{intro}
\input{methods}
\input{results}
\end{document}
"""
    tex_file = create_tex_file(tex_dir, "main.tex", content)
    
    result = score_tex_file(tex_file)
    assert any("Input/include commands" in r for r in result.reasons)
    assert any(r.startswith("Input/include commands (-") for r in result.reasons)


