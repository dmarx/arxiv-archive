{
  "arxivId": "2403.12187",
  "title": "Approximation of RKHS Functionals by Neural Networks",
  "authors": "Tian-Yi Zhou, Namjoon Suh, Guang Cheng, Xiaoming Huo",
  "abstract": "Motivated by the abundance of functional data such as time series and images,\nthere has been a growing interest in integrating such data into neural networks\nand learning maps from function spaces to R (i.e., functionals). In this paper,\nwe study the approximation of functionals on reproducing kernel Hilbert spaces\n(RKHS's) using neural networks. We establish the universality of the\napproximation of functionals on the RKHS's. Specifically, we derive explicit\nerror bounds for those induced by inverse multiquadric, Gaussian, and Sobolev\nkernels. Moreover, we apply our findings to functional regression, proving that\nneural networks can accurately approximate the regression maps in generalized\nfunctional linear models. Existing works on functional learning require\nintegration-type basis function expansions with a set of pre-specified basis\nfunctions. By leveraging the interpolating orthogonal projections in RKHS's,\nour proposed network is much simpler in that we use point evaluations to\nreplace basis function expansions.",
  "url": "https://arxiv.org/abs/2403.12187",
  "issue_number": 0,
  "issue_url": "",
  "created_at": "2024-12-30T08:27:40.564686",
  "state": "open",
  "labels": [
    "paper"
  ],
  "total_reading_time_seconds": 10,
  "last_read": "2024-12-30T08:27:40.565450",
  "last_visited": "2024-12-29T11:02:27.587000+00:00",
  "main_tex_file": null,
  "published_date": "2024-03-18T18:58:23Z",
  "arxiv_tags": [
    "stat.ML",
    "cs.LG",
    "math.ST",
    "stat.TH"
  ]
}