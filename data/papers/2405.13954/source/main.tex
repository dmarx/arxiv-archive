\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
%\usepackage{neurips_2024}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
\PassOptionsToPackage{numbers, compress}{natbib}
\usepackage[preprint,nonatbib]{neurips_2024}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{listings}
\usepackage{tabularx}
\usepackage{subcaption}


\definecolor{myred}{HTML}{FF8577}
\definecolor{mygreen}{HTML}{0FA958}
\definecolor{myblue}{HTML}{1982C4}
\definecolor{codegreen}{rgb}{0,0.5,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.07,0,0.53}
\definecolor{codered}{RGB}{189,41,0}
\definecolor{codecomment}{RGB}{153,153,153}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}
\definecolor{royalblue}{rgb}{0.0, 0.14, 0.4}
\definecolor{egyptianblue}{rgb}{0.06, 0.2, 0.65}
\definecolor{royalazure}{rgb}{0.0, 0.22, 0.66}
\definecolor{portlandorange}{rgb}{1.0, 0.35, 0.21}
\definecolor{saddlebrown}{RGB}{139,69,19}
\definecolor{sienna}{RGB}{183,105,68}
\definecolor{saddlebrown}{RGB}{139,69,19}

\hypersetup{
    colorlinks=true,
    linkcolor=sienna,
    % urlcolor=royalblue,
    citecolor=egyptianblue,
}

\lstset{
    language=Python,
    basicstyle=\ttfamily\scriptsize, 
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{codered},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    emph={with},          
    emphstyle=\color{codered},
    numbers=none,
    keepspaces=false,
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,   
    morekeywords={>,<,.,;,-,!,=,~},
    tabsize=2,
}

\newtheorem{lemma}{Lemma}
\newtheorem{assumption}{Assumption}
\newcommand{\sang}[1]{{\color{orange} [Sang: #1]}}
\newcommand{\ie}{\textit{i}.\textit{e}.}
\newcommand{\eg}{\textit{e}.\textit{g}.}
\newcommand{\method}{\textsc{LoGra}}
\newcommand{\software}{\textsc{Logix}}

\title{\textit{What is Your Data Worth to GPT?}\\LLM-Scale Data Valuation with Influence Functions}
 



\author{
  \small{Sang Keun Choe$^1$\hspace{-0.3mm}\thanks{Lead author: \href{mailto:sangkeuc@andrew.cmu.edu}{sangkeuc@andrew.cmu.edu}.$\;\,^\dagger$Main contributors.}  $\;\,$Hwijeen Ahn$^{1\dagger}$ Juhan Bae$^{2\dagger}$ Kewen Zhao$^{1\dagger}$}\\[0.1ex]
  \small{\textbf{Minsoo Kang$^{3}$ Youngseog Chung$^{1}$ Adithya Pratapa$^{1}$ Willie Neiswanger$^{4}$}}\\[0.1ex]
  \small{\textbf{Emma Strubell$^{1}$ Teruko Mitamura$^{1}$ Jeff Schneider$^{1}$ Eduard Hovy$^{1}$ Roger Grosse$^{2}$ Eric Xing$^{1,5}$}}\\[0.1ex]
  %\small{\textbf{ Eduard Hovy$^{1}$ Roger Grosse$^{2}$ Eric Xing$^{1,4}$}}\\[0.5ex]
  \small{$^1\,$Carnegie Mellon University\hspace{0.2cm} $^2\,$University of Toronto\hspace{0.2cm} $^3\,$Georgia Tech\hspace{0.2cm} $^4\,$USC\hspace{0.2cm} $^5\,$MBZUAI}
}


\begin{document}


\maketitle

\begin{abstract}
  Large language models (LLMs) are trained on a vast amount of human-written data, but data providers often remain uncredited. 
  In response to this issue, data valuation (or data attribution\footnote{Noting that the leave-one-out error~\cite{koh2017understanding}, a basis for most data attribution methods, is a \textit{semivalue} \cite{dubey1981value,kwon2021beta,wang2023data}, we use ``data valuation'' as a unified term in this work.}), which quantifies the contribution or value of each data to the model output, has been discussed as a potential solution.
  Nevertheless, applying existing data valuation methods to recent LLMs and their vast training datasets has been largely limited by prohibitive compute and memory costs.
  In this work, we focus on influence functions, a popular gradient-based data valuation method, and significantly improve its scalability with an efficient gradient projection strategy called \method\ that leverages the gradient structure in backpropagation.
  We then provide a theoretical motivation of gradient projection approaches to influence functions to promote trust in the data valuation process.
  Lastly, we lower the barrier to implementing data valuation systems by introducing \software, a software package that can transform existing training code into data valuation code with minimal effort.
  In our data valuation experiments, \method\ achieves competitive accuracy against more expensive baselines while showing up to 6,500$\times$ improvement in throughput and 5$\times$ reduction in GPU memory usage when applied to Llama3-8B-Instruct and the 1B-token dataset (open source project: \href{https://github.com/logix-project/logix}{link}).

  
\end{abstract}


\input{introduction}
\input{background}
\input{method}
\input{experiments}
\input{related}
\input{conclusion}
\input{acknowledgement}


\bibliographystyle{plain}
\bibliography{reference.bib}

\input{appendix}


\end{document}