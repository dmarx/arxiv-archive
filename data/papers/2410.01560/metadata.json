{
  "arxivId": "2410.01560",
  "title": "OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source\n  Instruction Data",
  "authors": "Shubham Toshniwal, Wei Du, Ivan Moshkov, Branislav Kisacanin, Alexan Ayrapetyan, Igor Gitman",
  "abstract": "Mathematical reasoning continues to be a critical challenge in large language\nmodel (LLM) development with significant interest. However, most of the\ncutting-edge progress in mathematical reasoning with LLMs has become\n\\emph{closed-source} due to lack of access to training data. This lack of data\naccess limits researchers from understanding the impact of different choices\nfor synthesizing and utilizing the data. With the goal of creating a\nhigh-quality finetuning (SFT) dataset for math reasoning, we conduct careful\nablation experiments on data synthesis using the recently released\n\\texttt{Llama3.1} family of models. Our experiments show that: (a) solution\nformat matters, with excessively verbose solutions proving detrimental to SFT\nperformance, (b) data generated by a strong teacher outperforms equally-sized\ndata generated by a weak student model, (c) SFT is robust to low-quality\nsolutions, allowing for imprecise data filtering, and (d) question diversity is\ncrucial for achieving data scaling gains. Based on these insights, we create\nthe OpenMathInstruct-2 dataset, which consists of 14M question-solution pairs\n($\\approx$ 600K unique questions), making it nearly eight times larger than the\nprevious largest open-source math reasoning dataset. Finetuning the\n\\texttt{Llama-3.1-8B-Base} using OpenMathInstruct-2 outperforms\n\\texttt{Llama3.1-8B-Instruct} on MATH by an absolute 15.9\\% (51.9\\%\n$\\rightarrow$ 67.8\\%). Finally, to accelerate the open-source efforts, we\nrelease the code, the finetuned models, and the OpenMathInstruct-2 dataset\nunder a commercially permissive license.",
  "url": "https://arxiv.org/abs/2410.01560",
  "issue_number": 666,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/666",
  "created_at": "2024-12-30T19:58:02.330566",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 14,
  "last_read": "2024-12-30T21:06:41.155472",
  "last_visited": "2024-12-30T21:05:25.289Z",
  "main_tex_file": null,
  "published_date": "2024-10-02T14:00:09Z",
  "arxiv_tags": [
    "cs.CL",
    "cs.AI",
    "cs.LG"
  ]
}