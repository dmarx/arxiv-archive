
\section{Miscellaneous}




\subsection{Generating Solution in OpenMath CoT Format}
\label{sec:app_soln_format}

\begin{figure*}[t]
    \centering
    \begin{tcolorbox}[
    colback=pastelblue!40,
    colframe=pastelblue!50,
    coltitle=pastelpink!50!black,
    colbacktitle=pastelpink!50,
    listing options={language=},
    fonttitle=\bfseries,
    fontupper=\ttfamily,
    halign title=center,         %
    title=Instruct Prompt Template,              %
    boxrule=0.5mm, 
    width=13cm,
]
\footnotesize
\begin{verbatim}
<|begin_of_text|><|start_header_id|>user<|end_header_id|>

FEW-SHOT PROMPTS

Question:
{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>

{generation}
\end{verbatim}
\end{tcolorbox}
    \caption{Typical \emph{instruct} prompt template used with \texttt{Llama-Instruct} models.}
    \label{fig:instruct_prompt}
\end{figure*}


\begin{figure*}[t]
    \centering
    \begin{tcolorbox}[
    colback=pastelblue!40,
    colframe=pastelblue!50,
    coltitle=pastelpink!50!black,
    colbacktitle=pastelpink!50,
    listing options={language=},
    fonttitle=\bfseries,
    fontupper=\ttfamily,
    halign title=center,         %
    title=Base Prompt Template,              %
    boxrule=0.5mm, 
    width=8cm,
]
\footnotesize
\begin{verbatim}
<|begin_of_text|>FEW-SHOT PROMPTS 

Question:
{question}

My solution:
{generation}
\end{verbatim}
\end{tcolorbox}
    \caption{\emph{Base} prompt template where we drop the special tokens for marking roles when using the \texttt{Llama-Instruct} models.}
    \label{fig:base_prompt}
\end{figure*}


When we prompt the \texttt{Llama3.1-405B-Instruct} model with few-shot examples in OpenMath CoT format from Appendix~\ref{sec:app_sol_aug_prompt} in tandem with the \emph{instruct prompt}, shown in Figure~\ref{fig:instruct_prompt}, almost 57\% of the generated solutions are in the Llama CoT format on which the model is most likely trained on.\footnote{\url{https://huggingface.co/datasets/meta-llama/Meta-Llama-3.1-8B-Instruct-evals/viewer/Meta-Llama-3.1-8B-Instruct-evals__math__details}}  
We find that dropping the Llama special tokens for marking roles in the prompt, as shown in Figure~\ref{fig:base_prompt}, results in much better adherence to our proposed few-shot prompt with only 0.1\% generations in the Llama CoT format. 














\subsection{Post-Processing}
We remove or modify solutions based on the following criteria:
\begin{itemize}
    \setlength{\itemsep}{0pt} %
    \item Remove solutions with multiple \texttt{\textbackslash boxed} entries.
    \item Remove prefix \texttt{My Solution:} from solutions.
    \item Truncate the solution till the first sentence with   \texttt{\textbackslash boxed}.
    \item Remove incorrect arithmetic calculations.
    \item Split complex arithmetic calculations to step-by-step calculations to make it easier for the model to generate.
    \item Remove solutions longer than 1024 \texttt{Llama3.1} tokens.
    \item Remove solutions with less than 200 characters. 
    
\end{itemize}



\subsection{Composition of \dataset}

\begin{table*}[t]
    \centering
    \caption{Composition of \dataset}
    \label{tab:dataset_composition}
    \begin{tabular}{llcc}
    \toprule
       Dataset  &  Approach & \# of Unique Ques. &  \# of Unique Ques.-Sol. Pairs\\ 
       \midrule 
       
       GSM8K  & Solution Augmentation & \phantom{00}7.4K & \phantom{0}0.46M \\
       GSM8K & Question-Solution Augmentation & \phantom{0}73.6K & \phantom{0}2.11M \\
       MATH & Solution Augmentation & \phantom{00}7.4K & \phantom{0}2.46M\\
       MATH & Question-Solution Augmentation & 519.1K & \phantom{0}8.94M \\ \midrule
       Total &   -   &  607.3K & 13.97M \\
       \bottomrule
       
    \end{tabular}
\end{table*}

Table~\ref{tab:dataset_composition} represents the composition of \dataset. The dataset consists of about 592K new synthetically-generated questions which contribute about 11M new question-solution pairs.  


\subsection{Checkpoint Averaging}
\label{sec:app_ckpt_avging}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.85\linewidth]{plots/ckpt_avging.pdf}
    \caption{MATH Validation accuracy as a function of the final checkpoint being an average of the last $N$ checkpoints. }
    \label{fig:ckpt_avging}
\end{figure}

We have found consistent gains in our setup with checkpoint averaging.  
Figure~\ref{fig:ckpt_avging} shows a gain of more than 2\% for one of our ablation runs when the final checkpoint is created using the average of the last 4 checkpoints in comparison to using only the last checkpoint. 






\input{tex/6_appendix_examples}
