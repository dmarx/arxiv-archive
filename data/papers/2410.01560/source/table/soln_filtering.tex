\begin{table*}[h]
    \centering
    % \footnotesize
    \caption{Performance of the SFT Llama3.1-8B-Base model on the MATH validation set after applying different filtering strategies to remove poor-quality data from two-choice teacher models: 8B-Base and 405B-Instruct. Results for the 405B-Instruct model are averaged over 4 runs, while the 8B-Base results are based on a single run. }
    \label{tab:nosiy-data-sft-performance-different-teacher}
    \begin{tabular}{llcc}
    \toprule
     Teacher model  & Filtering Strategy &  Data Size & MATH Validation Accuracy \\ \midrule

     \multirow{5}{*}{405B-Inst} 
     & Unfiltered    & 128K &  43.6 $\pm$ 1.7 \\
     & LLM-as-a-Judge: Prompt 1  & 113K           &  43.4 $\pm$ 0.1 \\ 
     & LLM-as-a-Judge: Prompt 2  & 116K          &  43.0 $\pm$ 0.8 \\
     & Nemotron-4-340B-Reward: Helpfulness $\ge 3$  & 118K &  43.7 $\pm$ 0.4 \\
     & Nemotron-4-340B-Reward: Correctness $\ge 3$  & 120K &  43.1 $\pm$ 0.4\\
     
     \midrule
     \multirow{5}{*}{8B-Base} 
     & Unfiltered    & 128K & 29.8 \\
     & LLM-as-a-Judge: Prompt 1  & \phantom{1}70K & 30.3   \\ 
     & LLM-as-a-Judge: Prompt 2  & \phantom{1}72K &  29.3 \\
     & Nemotron-4-340B-Reward: Helpfulness $\ge 3$  & \phantom{1}42K &    28.1 \\
     & Nemotron-4-340B-Reward: Correctness $\ge 3$  &  \phantom{1}49K &   30.5 \\
      \bottomrule
    \end{tabular}
\end{table*}
