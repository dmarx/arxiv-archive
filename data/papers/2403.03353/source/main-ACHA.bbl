\begin{thebibliography}{10}

\bibitem{Aronszajn1950theory}
{\sc N.~Aronszajn}, {\em Theory of reproducing kernels}, Transactions of the American mathematical society, 68 (1950), pp.~337--404.

\bibitem{bartolucci2023understanding}
{\sc F.~Bartolucci, E.~D. Vito, L.~Rosasco, and S.~Vigogna}, {\em Understanding neural networks with reproducing kernel {Banach} spaces}, Applied and Computational Harmonic Analysis, 62 (2023), pp.~194--236.

\bibitem{bohn2019representer}
{\sc B.~Bohn, M.~Griebel, and C.~Rieger}, {\em A representer theorem for deep kernel learning}, Journal of Machine Learning Research, 20 (2019), pp.~1--32.

\bibitem{ChengWangXu2023}
{\sc R.~Cheng, R.~Wang, and Y.~Xu}, {\em A duality approach to regularized learning problems in {Banach} spaces}, Journal of Complexity, 81 (2024), p.~101818.

\bibitem{cheng2021minimum}
{\sc R.~Cheng and Y.~Xu}, {\em Minimum norm interpolation in the $\ell_1(\mathbb{N})$ space}, Analysis and Applications, 19 (2021), pp.~21--42.

\bibitem{chung2023barron}
{\sc S.-Y. Chung and Q.~Sun}, {\em Barron space for graph convolution neural networks}, arXiv preprint arXiv:2311.02838,  (2023).

\bibitem{conway2019course}
{\sc J.~B. Conway}, {\em A Course in Functional Analysis. \rm 2nd Edition}, Springer-Verlag, New York, 1990.

\bibitem{cucker2002mathematical}
{\sc F.~Cucker and S.~Smale}, {\em On the mathematical foundations of learning}, Bulletin of the American Mathematical Society, 39 (2002), pp.~1--49.

\bibitem{daubechies2022nonlinear}
{\sc I.~Daubechies, R.~DeVore, S.~Foucart, B.~Hanin, and G.~Petrova}, {\em Nonlinear approximation and (deep) {ReLU} networks}, Constructive Approximation, 55 (2022), pp.~127--172.

\bibitem{folland1999real}
{\sc G.~B. Folland}, {\em Real analysis: modern techniques and their applications.}, vol.~40, John Wiley \& Sons, 1999.

\bibitem{huang2022error}
{\sc J.~Huang, Y.~Jiao, Z.~Li, S.~Liu, Y.~Wang, and Y.~Yang}, {\em An error analysis of generative adversarial networks for learning distributions}, The Journal of Machine Learning Research, 23 (2022), pp.~5047--5089.

\bibitem{kreyszig1991introductory}
{\sc E.~Kreyszig}, {\em Introductory Functional Analysis with Applications}, John Wiley \& Sons, New York, 1978.

\bibitem{li2024two}
{\sc Y.~Li, S.~Lu, P.~Math{\'e}, and S.~V. Pereverzev}, {\em Two-layer networks with the {ReLU}${}^k$ activation function: Barron spaces and derivative approximation}, Numerische Mathematik, 156 (2024), pp.~319--344.

\bibitem{lin2021multi}
{\sc R.~Lin, G.~Song, and H.~Zhang}, {\em Multi-task learning in vector-valued reproducing kernel {Banach} spaces with the $\ell_1$ norm}, Journal of Complexity, 63 (2021), p.~101514.

\bibitem{megginson2012introduction}
{\sc R.~E. Megginson}, {\em An Introduction to {Banach} Space Theory. \rm Graduate Texts in Mathematics}, vol.~183, Springer-Verlag, New York, 1998.

\bibitem{mhaskar2016deep}
{\sc H.~N. Mhaskar and T.~Poggio}, {\em Deep vs. shallow networks: An approximation theory perspective}, Analysis and Applications, 14 (2016), pp.~829--848.

\bibitem{micchelli2006universal}
{\sc C.~A. Micchelli, Y.~Xu, and H.~Zhang}, {\em Universal kernels}, Journal of Machine Learning Research, 7 (2006), pp.~2651--2667.

\bibitem{parhi2021banach}
{\sc R.~Parhi and R.~D. Nowak}, {\em Banach space representer theorems for neural networks and ridge splines}, Journal of Machine Learning Research, 22 (2021), pp.~1960--1999.

\bibitem{scholkopf2001generalized}
{\sc B.~Sch{\"o}lkopf, R.~Herbrich, and A.~J. Smola}, {\em A generalized representer theorem}, in Proceeding of the Fourteenth Annual Conference on Computational Learning Theory and the Fifth European Conference on Computational Learning Theory, Springer-Verlag, London, 2001, pp.~416--426.

\bibitem{shen2022optimal}
{\sc Z.~Shen, H.~Yang, and S.~Zhang}, {\em Optimal approximation rate of {ReLU} networks in terms of width and depth}, Journal de Math{\'e}matiques Pures et Appliqu{\'e}es, 157 (2022), pp.~101--135.

\bibitem{shenouda2023vector}
{\sc J.~Shenouda, R.~Parhi, K.~Lee, and R.~D. Nowak}, {\em Vector-valued variation spaces and width bounds for {DNNs}: insights on weight decay regularization}, arXiv preprint arXiv:2305.16534,  (2023).

\bibitem{unser2019representer}
{\sc M.~Unser}, {\em A representer theorem for deep neural networks}, Journal of Machine Learning Research, 20 (2019), pp.~1--30.

\bibitem{wang2021representer}
{\sc R.~Wang and Y.~Xu}, {\em Representer theorems in {Banach} spaces: minimum norm interpolation, regularized learning and semi-discrete inverse problems}, Journal of Machine Learning Research, 22 (2021), pp.~1--65.

\bibitem{wang2023sparse}
{\sc R.~Wang, Y.~Xu, and M.~Yan}, {\em Sparse representer theorems for learning in reproducing kernel {B}anach spaces}, Journal of Machine Learning Research, 25 (2024), pp.~1--45.

\bibitem{xu2022sparse}
{\sc Y.~Xu}, {\em Sparse machine learning in {Banach} spaces}, Applied Numerical Mathematics, 187 (2023), pp.~138--157.

\bibitem{xu2019generalized}
{\sc Y.~Xu and Q.~Ye}, {\em Generalized {Mercer} kernels and reproducing kernel {Banach} spaces}, Memoirs of the American Mathematical Society, 258 (2019), p.~1243.

\bibitem{xu2022convergence}
{\sc Y.~Xu and H.~Zhang}, {\em Convergence of deep convolutional neural networks}, Neural Networks, 153 (2022), pp.~553--563.

\bibitem{xu2024convergence}
{\sc Y.~Xu and H.~Zhang}, {\em Convergence of deep {ReLU} networks}, Neurocomputing, 571 (2024), p.~127174.

\bibitem{zhang2009reproducing}
{\sc H.~Zhang, Y.~Xu, and J.~Zhang}, {\em Reproducing kernel {Banach} spaces for machine learning.}, Journal of Machine Learning Research, 10 (2009), pp.~2741--2775.

\bibitem{zhang2013vector}
{\sc H.~Zhang and J.~Zhang}, {\em Vector-valued reproducing kernel {Banach} spaces with applications to multi-task learning}, Journal of Complexity, 29 (2013), pp.~195--215.

\bibitem{zhou2020universality}
{\sc D.-X. Zhou}, {\em Universality of deep convolutional neural networks}, Applied and computational harmonic analysis, 48 (2020), pp.~787--794.

\end{thebibliography}
