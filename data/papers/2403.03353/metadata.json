{
  "arxivId": "2403.03353",
  "title": "Hypothesis Spaces for Deep Learning",
  "authors": "Rui Wang, Yuesheng Xu, Mingsong Yan",
  "abstract": "This paper introduces a hypothesis space for deep learning that employs deep\nneural networks (DNNs). By treating a DNN as a function of two variables, the\nphysical variable and parameter variable, we consider the primitive set of the\nDNNs for the parameter variable located in a set of the weight matrices and\nbiases determined by a prescribed depth and widths of the DNNs. We then\ncomplete the linear span of the primitive DNN set in a weak* topology to\nconstruct a Banach space of functions of the physical variable. We prove that\nthe Banach space so constructed is a reproducing kernel Banach space (RKBS) and\nconstruct its reproducing kernel. We investigate two learning models,\nregularized learning and minimum interpolation problem in the resulting RKBS,\nby establishing representer theorems for solutions of the learning models. The\nrepresenter theorems unfold that solutions of these learning models can be\nexpressed as linear combination of a finite number of kernel sessions\ndetermined by given data and the reproducing kernel.",
  "url": "https://arxiv.org/abs/2403.03353",
  "issue_number": 491,
  "issue_url": "https://github.com/dmarx/arxiv-archive/issues/491",
  "created_at": "2024-12-29T11:10:31.934458",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 13,
  "last_read": "2024-12-29T11:10:31.935214",
  "last_visited": "2024-12-29T10:46:53.922Z",
  "main_tex_file": null,
  "published_date": "2024-03-05T22:42:29Z",
  "arxiv_tags": [
    "stat.ML",
    "cs.LG",
    "math.FA"
  ]
}