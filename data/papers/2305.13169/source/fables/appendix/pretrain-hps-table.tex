
\begingroup
\setlength{\tabcolsep}{4pt}

\begin{table*}[ht]
    \centering
    \small
    % \begin{tabular}{>{\raggedright}p{7cm} crll}
    \caption{
    \textbf{Pretraining hyperparameters} We adopt default pretraining hyperparameters from \citet{wang2022language}, who select their parameters to fairly compare across a wide range of T5-based pretraining and architecture experiments.}
    \begin{tabular}{l | r | r}
    \toprule
    \textsc{Parameter} & \textsc{\bigLM} & \textsc{\smalLM} \\
    \midrule
    TPUs & 8x8x8 & 8x8 \\
    Batch Size & 4096 & 4096 \\
    Sequence Length & 512 & 512 \\
    Training Steps & 88,064 & 88,064 \\
    Dropout & 0.0 & 0.0 \\
    \midrule
    Base Learning Rate & \multicolumn{2}{c}{0.5} \\
    Decay Factor & \multicolumn{2}{c}{0.5} \\
    Warmup Steps & \multicolumn{2}{c}{1000} \\
    Steps per Decay & \multicolumn{2}{c}{20000} \\
    \bottomrule
    \end{tabular}
    \label{tab:pretrain-hyperparams}
\end{table*}
\endgroup
