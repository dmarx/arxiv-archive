\section{Distortion and perceptual quality}\label{sec:related}

Distortion and perceptual quality have been studied in many different contexts, and are sometimes referred to by different names. Let us briefly put past works in our context.

\subsection{Distortion (full-reference) measures}

Given a distorted image $\hat{x}$ and a ground-truth reference image $x$, full-reference distortion measures quantify the quality of $\hat{x}$ by its discrepancy to $x$. These measures are often called full reference image quality criteria because of the reasoning that if $\hat{x}$ is similar to $x$ and $x$ is of high quality, then $\hat{x}$ is also of high quality. However, as we show in this paper, this logic is not always correct. We thus prefer to call these measures distortion or dissimilarity criteria.

The most common distortion measure is the MSE, which is quite poorly correlated with semantic similarity between images \cite{wang2009mean}. Many alternative, more perceptual, distortion measures have been proposed over the years, including SSIM \cite{wang2004image}, MS-SSIM \cite{wang2003multiscale}, IFC \cite{sheikh2005information}, VIF \cite{sheikh2006image}, VSNR~\cite{chandler2007vsnr} and FSIM \cite{zhang2011fsim}. Recently, measures based on the $\ell_2$-distance between deep feature maps of a neural-net have been shown to capture more semantic similarities %. These measures were used as loss functions in super-resolution and style transfer applications, leading to reconstructions with high visual quality 
\cite{johnson2016perceptual,ledig2016photo,zhang2018unreasonable}.

\subsection{Perceptual quality} \label{sec:RelatedWorkPerceptualQuality}
The perceptual quality of an image $\hat{x}$ is the degree to which it looks like a natural image, and has nothing to do with its similarity to any reference image. In many image processing domains, perceptual quality has been associated with deviations from natural image statistics.

\subsubsection*{Human opinion based quality assessment}
Perceptual quality is commonly evaluated empirically by the mean opinion score of human subjects \cite{moorthy2011blind,mittal2012no}. Recently, it has become increasingly popular to perform such studies through real vs.~fake questionnaires \cite{isola2016image,zhang2016colorful,salimans2016improved,denton2015deep,dahl2017pixel,iizuka2016let,zhang2017real,guadarrama2017pixcolor}. These test the ability of a human observer to distinguish whether an image is real or the output of some algorithm. The probability of success $p_{\text{success}}$ of the optimal decision rule in this hypothesis testing task is known to be (see Appendix~\ref{ap:real-vs-fake} in the Supplementary Material)
\begin{equation}\label{eq:psuccess}
p_{\text{success}} = \tfrac{1}{2} d_{\text{TV}}(p_X,p_{\hat{X}}) + \tfrac{1}{2} ,
\end{equation}
where $d_{\text{TV}}(p_X,p_{\hat{X}})$ is the total-variation (TV) distance between the distribution $p_{\hat{X}}$ of images produced by the algorithm in question, and the distribution $p_X$ of natural images~\cite{nielsen2013hypothesis}. Note that $p_{\text{success}}$ decreases as the deviation between $p_{\hat{X}}$ and $p_X$ decreases, becoming $\tfrac{1}{2}$ (no better than a coin toss) when $p_{\hat{X}}=p_X$.

\subsubsection*{No-reference quality measures}
Perceptual quality can also be measured by an algorithm. In particular, no-reference measures quantify the perceptual quality $Q(\hat{x})$ of an image $\hat{x}$ \emph{without} depending on a reference image. These measures are commonly based on estimating deviations from natural image statistics. The works \cite{wang2005reduced,wang2006quality,li2009reduced} proposed perceptual quality indices based on the KL divergence between the distribution of the wavelet coefficients of $\hat{x}$ and that of natural scenes. This idea was further extended by the popular methods DIIVINE~\cite{moorthy2011blind}, BRISQUE~\cite{mittal2012no}, BLIINDS-II~\cite{saad2012blind} and NIQE~\cite{mittal2013making}, which quantify perceptual quality by various measures of deviation from natural image statistics in the spatial, wavelet and DCT domains.

\subsubsection*{GAN-based image restoration}
Most recently, GAN-based methods have demonstrated unprecedented perceptual quality in super-resolution \cite{ledig2016photo,sajjadi2017enhancenet,wang2018esrgan,shaham2019singan}, inpainting \cite{pathak2016context,yeh2017semantic,yu2018generative}, compression \cite{rippel2017real,agustsson2018generative,tschannen2018deep}, deblurring \cite{kupyn2018deblurgan} and image-to-image translation \cite{isola2016image,zhu2017unpaired,liu2017unsupervised}. This was accomplished by utilizing an adversarial loss, which minimizes some distance $d(p_X,p_{\hat{X}_{\text{GAN}}})$ between the distribution $p_{\hat{X}_{\text{GAN}}}$ of images produced by the generator and the distribution $p_X$ of images in the training dataset. A large variety of GAN schemes have been proposed, which minimize different distances between distributions. These include the Jensen-Shannon divergence \cite{goodfellow2014generative}, the Wasserstein distance \cite{arjovsky2017wasserstein}, and any $f$-divergence \cite{nowozin2016f}.

\subsubsection*{Single image quality vs. image ensemble quality}
A common measure of quality is the log-likelihood $Q_{\text{LL}}(\hat{x}) = \log (p_X(\hat{x}))$. However, this notion of quality evaluates each image individually, and therefore has shortcomings. As an example, consider a reconstruction algorithm that disregards the input image, and always outputs the same ``good-looking'' natural image that has a high likelihood. While this algorithm would rate very well by the average log-likelihood measure $\E[Q_{\text{LL}}(\hat{X})]$, it is obviously quite useless. An observer examining an \emph{ensemble} of outputs, would easily notice this flawed behavior. Therefore, in this paper we are more interested in ``ensemble quality''. The relation between the average log-likelihood and ``ensemble quality'' can be understood by noting that
\begin{equation}
\E_{\hat{X}\sim p_{\hat{X}}}[Q_{\text{LL}}(\hat{X})]=-d_{\text{KL}}(p_{\hat{X}},p_X) - H(p_{\hat{X}}).
\end{equation}
Here $d_{\text{KL}}$ is the Kullback-Leibler divergence and $H$ denotes entropy. The second term in this decomposition discourages diversity. % (as quantified by entropy).
Choosing to drop it, results in the distributional-divergence based quality measures described above.
