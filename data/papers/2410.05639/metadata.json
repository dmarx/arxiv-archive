{
  "arxivId": "2410.05639",
  "title": "DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing\n  with Language Models",
  "authors": "Ranchi Zhao, Zhen Leng Thai, Yifan Zhang, Shengding Hu, Yunqi Ba, Jie Zhou, Jie Cai, Zhiyuan Liu, Maosong Sun",
  "abstract": "The performance of Large Language Models (LLMs) is substantially influenced\nby the pretraining corpus, which consists of vast quantities of unsupervised\ndata processed by the models. Despite its critical role in model performance,\nensuring the quality of this data is challenging due to its sheer volume and\nthe absence of sample-level quality annotations and enhancements. In this\npaper, we introduce DecorateLM, a data engineering method designed to refine\nthe pretraining corpus through data rating, tagging and editing. Specifically,\nDecorateLM rates texts against quality criteria, tags texts with hierarchical\nlabels, and edits texts into a more formalized format. Due to the massive size\nof the pretraining corpus, adopting an LLM for decorating the entire corpus is\nless efficient. Therefore, to balance performance with efficiency, we curate a\nmeticulously annotated training corpus for DecorateLM using a large language\nmodel and distill data engineering expertise into a compact 1.2 billion\nparameter small language model (SLM). We then apply DecorateLM to enhance 100\nbillion tokens of the training corpus, selecting 45 billion tokens that\nexemplify high quality and diversity for the further training of another 1.2\nbillion parameter LLM. Our results demonstrate that employing such high-quality\ndata can significantly boost model performance, showcasing a powerful approach\nto enhance the quality of the pretraining corpus.",
  "url": "https://arxiv.org/abs/2410.05639",
  "issue_number": 683,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/683",
  "created_at": "2024-12-30T20:04:18.817314",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 16,
  "last_read": "2024-12-30T20:04:18.842488",
  "last_visited": "2024-12-30T21:19:21.741Z",
  "main_tex_file": null,
  "published_date": "2024-10-08T02:42:56Z",
  "arxiv_tags": [
    "cs.CL"
  ]
}