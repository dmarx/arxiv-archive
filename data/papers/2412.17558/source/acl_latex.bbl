\begin{thebibliography}{92}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Ali et~al.(2024)Ali, Daftardar, Waheed, Qin, and Wang}]{MQA-KEAL}
Muhammad~Asif Ali, Nawal Daftardar, Mutayyaba Waheed, Jianbin Qin, and Di~Wang.
  2024.
\newblock \href {https://arxiv.org/abs/2409.12257} {Mqa-keal: Multi-hop
  question answering under knowledge editing for arabic language}.
\newblock \emph{Preprint}, arXiv:2409.12257.

\bibitem[{Anonymous(2024)}]{RuleRAG}
Anonymous. 2024.
\newblock \href {https://openreview.net/forum?id=zl3nFqY8l1} {Rule{RAG}:
  Rule-guided retrieval-augmented generation with language models for question
  answering}.
\newblock In \emph{Submitted to The Thirteenth International Conference on
  Learning Representations}.
\newblock Under review.

\bibitem[{Azad and Deepak(2019)}]{query_expansion_survey1}
Hiteshwar~Kumar Azad and Akshay Deepak. 2019.
\newblock \href {https://doi.org/10.1016/J.IPM.2019.05.009} {Query expansion
  techniques for information retrieval: {A} survey}.
\newblock \emph{Inf. Process. Manag.}, 56(5):1698--1735.

\bibitem[{Baek et~al.(2024)Baek, Lee, Yang, and Lee}]{Crafting-the-Path}
Ingeol Baek, Jimin Lee, Joonho Yang, and Hwanhee Lee. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2407.12529} {Crafting the path:
  Robust query rewriting for information retrieval}.
\newblock \emph{CoRR}, abs/2407.12529.

\bibitem[{Bai et~al.(2024)Bai, Xiao, He, Wang, Zhang, Brox, and Shou}]{GQE}
Zechen Bai, Tianjun Xiao, Tong He, Pichao Wang, Zheng Zhang, Thomas Brox, and
  Mike~Zheng Shou. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2408.07249} {{GQE:} generalized
  query expansion for enhanced text-video retrieval}.
\newblock \emph{CoRR}, abs/2408.07249.

\bibitem[{Cai et~al.(2024)Cai, Guo, Pei, Bian, and Zheng}]{SimGRAG}
Yuzheng Cai, Zhenyue Guo, Yiwen Pei, Wanrui Bian, and Weiguo Zheng. 2024.
\newblock \href {https://arxiv.org/abs/2412.15272} {Simgrag: Leveraging similar
  subgraphs for knowledge graphs driven retrieval-augmented generation}.
\newblock \emph{Preprint}, arXiv:2412.15272.

\bibitem[{Chan et~al.(2024)Chan, Xu, Yuan, Luo, Xue, Guo, and Fu}]{RQ-RAG}
Chi-Min Chan, Chunpu Xu, Ruibin Yuan, Hongyin Luo, Wei Xue, Yike Guo, and Jie
  Fu. 2024.
\newblock Rq-{RAG}: Learning to {Refine} {Queries} for {Retrieval} {Augmented}
  {Generation}.
\newblock \emph{arXiv}, abs/2404.00610.

\bibitem[{Chen et~al.(2024)Chen, Zhao, Zhu, Zhang, Li, Raj, and Yao}]{AutoPRM}
Zhaorun Chen, Zhuokai Zhao, Zhihong Zhu, Ruiqi Zhang, Xiang Li, Bhiksha Raj,
  and Huaxiu Yao. 2024.
\newblock \href {https://doi.org/10.18653/V1/2024.NAACL-LONG.73} {Autoprm:
  Automating procedural supervision for multi-step reasoning via controllable
  question decomposition}.
\newblock In \emph{Proceedings of the 2024 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (Volume 1: Long Papers), {NAACL} 2024, Mexico City, Mexico, June
  16-21, 2024}, pages 1346--1362. Association for Computational Linguistics.

\bibitem[{Chuang et~al.(2023)Chuang, Fang, Li, Yih, and Glass}]{EAR}
Yung{-}Sung Chuang, Wei Fang, Shang{-}Wen Li, Wen{-}tau Yih, and James~R.
  Glass. 2023.
\newblock \href {https://doi.org/10.18653/V1/2023.FINDINGS-ACL.768} {Expand,
  rerank, and retrieve: Query reranking for open-domain question answering}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  {ACL} 2023, Toronto, Canada, July 9-14, 2023}, pages 12131--12147.
  Association for Computational Linguistics.

\bibitem[{Cong et~al.(2024)Cong, Wang, Akash, and Chang}]{ERRR}
Youan Cong, Cheng Wang, Pritom~Saha Akash, and Kevin Chen-Chuan Chang. 2024.
\newblock \href {https://arxiv.org/abs/2411.07820} {Query optimization for
  parametric knowledge refinement in retrieval-augmented large language
  models}.
\newblock \emph{Preprint}, arXiv:2411.07820.

\bibitem[{Dai et~al.(2023)Dai, Zhao, Ma, Luan, Ni, Lu, Bakalov, Guu, Hall, and
  Chang}]{Promptagator}
Zhuyun Dai, Vincent~Y. Zhao, Ji~Ma, Yi~Luan, Jianmo Ni, Jing Lu, Anton Bakalov,
  Kelvin Guu, Keith~B. Hall, and Ming{-}Wei Chang. 2023.
\newblock \href {https://openreview.net/forum?id=gmL46YMpu2J} {Promptagator:
  Few-shot dense retrieval from 8 examples}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net.

\bibitem[{Dehghan et~al.(2024)Dehghan, Alomrani, Bagga, Alfonso{-}Hermelo,
  Bibi, Ghaddar, Zhang, Li, Hao, Liu, Lin, Chen, Parthasarathi, Biparva, and
  Rezagholizadeh}]{EWEK-QA}
Mohammad Dehghan, Mohammad~Ali Alomrani, Sunyam Bagga, David Alfonso{-}Hermelo,
  Khalil Bibi, Abbas Ghaddar, Yingxue Zhang, Xiaoguang Li, Jianye Hao, Qun Liu,
  Jimmy Lin, Boxing Chen, Prasanna Parthasarathi, Mahdi Biparva, and Mehdi
  Rezagholizadeh. 2024.
\newblock \href {https://doi.org/10.18653/V1/2024.ACL-LONG.764} {{EWEK-QA} :
  Enhanced web and efficient knowledge graph retrieval for citation-based
  question answering systems}.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok,
  Thailand, August 11-16, 2024}, pages 14169--14187. Association for
  Computational Linguistics.

\bibitem[{Dhole and Agichtein(2024)}]{GenQREnsemble}
Kaustubh~D. Dhole and Eugene Agichtein. 2024.
\newblock \href {https://doi.org/10.1007/978-3-031-56063-7\_24} {Genqrensemble:
  Zero-shot {LLM} ensemble prompting for generative query reformulation}.
\newblock In \emph{Advances in Information Retrieval - 46th European Conference
  on Information Retrieval, {ECIR} 2024, Glasgow, UK, March 24-28, 2024,
  Proceedings, Part {III}}, volume 14610 of \emph{Lecture Notes in Computer
  Science}, pages 326--335. Springer.

\bibitem[{Fan et~al.(2024)Fan, Ding, Ning, Wang, Li, Yin, Chua, and
  Li}]{survey8}
Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin,
  Tat{-}Seng Chua, and Qing Li. 2024.
\newblock \href {https://doi.org/10.1145/3637528.3671470} {A survey on {RAG}
  meeting llms: Towards retrieval-augmented large language models}.
\newblock In \emph{Proceedings of the 30th {ACM} {SIGKDD} Conference on
  Knowledge Discovery and Data Mining, {KDD} 2024, Barcelona, Spain, August
  25-29, 2024}, pages 6491--6501. {ACM}.

\bibitem[{Feng et~al.(2024)Feng, Tao, Geng, Shen, Xu, Long, Zhao, and
  Jiang}]{InteR}
Jiazhan Feng, Chongyang Tao, Xiubo Geng, Tao Shen, Can Xu, Guodong Long,
  Dongyan Zhao, and Daxin Jiang. 2024.
\newblock \href {https://doi.org/10.18653/V1/2024.ACL-LONG.517} {Synergistic
  interplay between search and large language models for information
  retrieval}.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok,
  Thailand, August 11-16, 2024}, pages 9571--9583. Association for
  Computational Linguistics.

\bibitem[{Gao et~al.(2023{\natexlab{a}})Gao, Ma, Lin, and Callan}]{HyDE}
Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan. 2023{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/V1/2023.ACL-LONG.99} {Precise
  zero-shot dense retrieval without relevance labels}.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto,
  Canada, July 9-14, 2023}, pages 1762--1777. Association for Computational
  Linguistics.

\bibitem[{Gao et~al.(2024)Gao, Dwivedi-Yu, Yu, Tan, Pasunuru, Golovneva, Sinha,
  Celikyilmaz, Bosselut, and Wang}]{CoA}
Silin Gao, Jane Dwivedi-Yu, Ping Yu, Xiaoqing~Ellen Tan, Ramakanth Pasunuru,
  Olga Golovneva, Koustuv Sinha, Asli Celikyilmaz, Antoine Bosselut, and Tianlu
  Wang. 2024.
\newblock \href {https://arxiv.org/abs/2401.17464} {Efficient tool use with
  chain-of-abstraction reasoning}.
\newblock \emph{Preprint}, arXiv:2401.17464.

\bibitem[{Gao et~al.(2023{\natexlab{b}})Gao, Xiong, Gao, Jia, Pan, Bi, Dai,
  Sun, Guo, Wang, and Wang}]{survey2}
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi~Dai,
  Jiawei Sun, Qianyu Guo, Meng Wang, and Haofen Wang. 2023{\natexlab{b}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2312.10997}
  {Retrieval-augmented generation for large language models: {A} survey}.
\newblock \emph{CoRR}, abs/2312.10997.

\bibitem[{Gupta et~al.(2024)Gupta, Ranjan, and Singh}]{survey11}
Shailja Gupta, Rajesh Ranjan, and Surya~Narayan Singh. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2410.12837} {A comprehensive
  survey of retrieval-augmented generation {(RAG):} evolution, current
  landscape and future directions}.
\newblock \emph{CoRR}, abs/2410.12837.

\bibitem[{Han et~al.(2024)Han, Zhang, Qi, Xu, Wang, Liu, Wang, Min, and
  Castelli}]{rag_benchmark_3}
Rujun Han, Yuhao Zhang, Peng Qi, Yumo Xu, Jenyuan Wang, Lan Liu, William~Yang
  Wang, Bonan Min, and Vittorio Castelli. 2024.
\newblock \href {https://aclanthology.org/2024.emnlp-main.249} {{RAG-QA} arena:
  Evaluating domain robustness for long-form retrieval augmented question
  answering}.
\newblock In \emph{Proceedings of the 2024 Conference on Empirical Methods in
  Natural Language Processing, {EMNLP} 2024, Miami, FL, USA, November 12-16,
  2024}, pages 4354--4374. Association for Computational Linguistics.

\bibitem[{He et~al.(2024)He, Chen, He, Yan, Wei, Luo, and Ling}]{CoV-RAG}
Bolei He, Nuo Chen, Xinran He, Lingyong Yan, Zhenkai Wei, Jinchang Luo, and
  Zhen-Hua Ling. 2024.
\newblock \href {https://arxiv.org/abs/2410.05801} {Retrieving, rethinking and
  revising: The chain-of-verification can improve retrieval augmented
  generation}.
\newblock \emph{Preprint}, arXiv:2410.05801.

\bibitem[{Hei et~al.(2024)Hei, Liu, Ou, Qiao, Jiao, Song, Tian, and
  Lin}]{DR-RAG}
Zijian Hei, Weiling Liu, Wenjie Ou, Juyi Qiao, Junming Jiao, Guowen Song, Ting
  Tian, and Yi~Lin. 2024.
\newblock \href {https://arxiv.org/abs/2406.07348} {Dr-rag: Applying dynamic
  document relevance to retrieval-augmented generation for question-answering}.
\newblock \emph{Preprint}, arXiv:2406.07348.

\bibitem[{Hong et~al.(2024)Hong, Zhang, Pan, Yu, and Zhang}]{AoT}
Ruixin Hong, Hongming Zhang, Xiaoman Pan, Dong Yu, and Changshui Zhang. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2406.12442}
  {Abstraction-of-thought makes language models better reasoners}.
\newblock \emph{CoRR}, abs/2406.12442.

\bibitem[{Hu and Lu(2024)}]{survey7}
Yucheng Hu and Yuxing Lu. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2404.19543} {{RAG} and {RAU:}
  {A} survey on retrieval-augmented language model in natural language
  processing}.
\newblock \emph{CoRR}, abs/2404.19543.

\bibitem[{Huang and Huang(2024)}]{survey4}
Yizheng Huang and Jimmy Huang. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2404.10981} {A survey on
  retrieval-augmented text generation for large language models}.
\newblock \emph{CoRR}, abs/2404.10981.

\bibitem[{Jagerman et~al.(2023)Jagerman, Zhuang, Qin, Wang, and
  Bendersky}]{Query2Expand}
Rolf Jagerman, Honglei Zhuang, Zhen Qin, Xuanhui Wang, and Michael Bendersky.
  2023.
\newblock \href {https://doi.org/10.48550/ARXIV.2305.03653} {Query expansion by
  prompting large language models}.
\newblock \emph{CoRR}, abs/2305.03653.

\bibitem[{Jia et~al.(2024)Jia, Liu, Zhao, Li, Hao, Wang, and Yin}]{MILL}
Pengyue Jia, Yiding Liu, Xiangyu Zhao, Xiaopeng Li, Changying Hao, Shuaiqiang
  Wang, and Dawei Yin. 2024.
\newblock \href {https://doi.org/10.18653/V1/2024.NAACL-LONG.138} {{MILL:}
  mutual verification with large language models for zero-shot query
  expansion}.
\newblock In \emph{Proceedings of the 2024 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (Volume 1: Long Papers), {NAACL} 2024, Mexico City, Mexico, June
  16-21, 2024}, pages 2498--2518. Association for Computational Linguistics.

\bibitem[{Jiang et~al.(2024)Jiang, Chen, Li, Ren, Wang, Zhao, Song, and
  Zhang}]{RAG-Star}
Jinhao Jiang, Jiayi Chen, Junyi Li, Ruiyang Ren, Shijie Wang, Wayne~Xin Zhao,
  Yang Song, and Tao Zhang. 2024.
\newblock \href {https://arxiv.org/abs/2412.12881} {Rag-star: Enhancing
  deliberative reasoning with retrieval augmented verification and refinement}.
\newblock \emph{Preprint}, arXiv:2412.12881.

\bibitem[{Jiang et~al.(2023)Jiang, Xu, Gao, Sun, Liu, Dwivedi{-}Yu, Yang,
  Callan, and Neubig}]{FLARE}
Zhengbao Jiang, Frank~F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane
  Dwivedi{-}Yu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023.
\newblock \href {https://doi.org/10.18653/V1/2023.EMNLP-MAIN.495} {Active
  retrieval augmented generation}.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in
  Natural Language Processing, {EMNLP} 2023, Singapore, December 6-10, 2023},
  pages 7969--7992. Association for Computational Linguistics.

\bibitem[{Joshi et~al.(2024)Joshi, Sarwar, Varshney, Nag, Agrawal, and
  Naik}]{REAPER}
Ashutosh Joshi, Sheikh~Muhammad Sarwar, Samarth Varshney, Sreyashi Nag,
  Shrivats Agrawal, and Juhi Naik. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2407.18553} {{REAPER:}
  reasoning based retrieval planning for complex {RAG} systems}.
\newblock \emph{CoRR}, abs/2407.18553.

\bibitem[{Kandpal et~al.(2023)Kandpal, Deng, Roberts, Wallace, and
  Raffel}]{survey1}
Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel.
  2023.
\newblock \href {https://proceedings.mlr.press/v202/kandpal23a.html} {Large
  language models struggle to learn long-tail knowledge}.
\newblock In \emph{International Conference on Machine Learning, {ICML} 2023,
  23-29 July 2023, Honolulu, Hawaii, {USA}}, volume 202 of \emph{Proceedings of
  Machine Learning Research}, pages 15696--15707. {PMLR}.

\bibitem[{Khattab et~al.(2022)Khattab, Santhanam, Li, Hall, Liang, Potts, and
  Zaharia}]{Demonstrate-Search-Predict}
Omar Khattab, Keshav Santhanam, Xiang~Lisa Li, David Hall, Percy Liang,
  Christopher Potts, and Matei Zaharia. 2022.
\newblock \href {https://doi.org/10.48550/ARXIV.2212.14024}
  {Demonstrate-search-predict: Composing retrieval and language models for
  knowledge-intensive {NLP}}.
\newblock \emph{CoRR}, abs/2212.14024.

\bibitem[{Khot et~al.(2023)Khot, Trivedi, Finlayson, Fu, Richardson, Clark, and
  Sabharwal}]{DecomP}
Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter
  Clark, and Ashish Sabharwal. 2023.
\newblock \href {https://openreview.net/forum?id=\_nGgzQjzaRy} {Decomposed
  prompting: {A} modular approach for solving complex tasks}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net.

\bibitem[{Kim et~al.(2023)Kim, Kim, Jeon, Park, and Kang}]{ToC}
Gangwoo Kim, Sungdong Kim, Byeongguk Jeon, Joonsuk Park, and Jaewoo Kang. 2023.
\newblock \href {https://doi.org/10.18653/V1/2023.EMNLP-MAIN.63} {Tree of
  clarifications: Answering ambiguous questions with retrieval-augmented large
  language models}.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in
  Natural Language Processing, {EMNLP} 2023, Singapore, December 6-10, 2023},
  pages 996--1009. Association for Computational Linguistics.

\bibitem[{Korikov et~al.(2024)Korikov, Saad, Baron, Khan, Shah, and
  Sanner}]{MA-RIR}
Anton Korikov, George Saad, Ethan Baron, Mustafa Khan, Manav Shah, and Scott
  Sanner. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2408.00878} {Multi-aspect
  reviewed-item retrieval via {LLM} query decomposition and aspect fusion}.
\newblock \emph{CoRR}, abs/2408.00878.

\bibitem[{Kuo et~al.(2024)Kuo, Liao, Hsieh, Chang, Hsu, and
  Shiu}]{rag_benchmark_1}
Tzu{-}Lin Kuo, Feng{-}Ting Liao, Mu{-}Wei Hsieh, Fu{-}Chieh Chang, Po{-}Chun
  Hsu, and Da{-}Shan Shiu. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2409.12558} {Rad-bench:
  Evaluating large language models capabilities in retrieval augmented
  dialogues}.
\newblock \emph{CoRR}, abs/2409.12558.

\bibitem[{Lei et~al.(2024)Lei, Cao, Zhou, Shen, and Yates}]{CSQE}
Yibin Lei, Yu~Cao, Tianyi Zhou, Tao Shen, and Andrew Yates. 2024.
\newblock \href {https://aclanthology.org/2024.eacl-short.34} {Corpus-steered
  query expansion with large language models}.
\newblock In \emph{Proceedings of the 18th Conference of the European Chapter
  of the Association for Computational Linguistics, {EACL} 2024 - Volume 2:
  Short Papers, St. Julian's, Malta, March 17-22, 2024}, pages 393--401.
  Association for Computational Linguistics.

\bibitem[{Lewis et~al.(2020)Lewis, Perez, Piktus, Petroni, Karpukhin, Goyal,
  K{\"{u}}ttler, Lewis, Yih, Rockt{\"{a}}schel, Riedel, and Kiela}]{2020rag}
Patrick S.~H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
  Karpukhin, Naman Goyal, Heinrich K{\"{u}}ttler, Mike Lewis, Wen{-}tau Yih,
  Tim Rockt{\"{a}}schel, Sebastian Riedel, and Douwe Kiela. 2020.
\newblock \href {https://arxiv.org/abs/2005.11401} {Retrieval-augmented
  generation for knowledge-intensive {NLP} tasks}.
\newblock \emph{CoRR}, abs/2005.11401.

\bibitem[{Li et~al.(2024)Li, Zhao, Chia, Ding, Joty, Poria, and Bing}]{CoK}
Xingxuan Li, Ruochen Zhao, Yew~Ken Chia, Bosheng Ding, Shafiq Joty, Soujanya
  Poria, and Lidong Bing. 2024.
\newblock \href {https://openreview.net/forum?id=cPgh4gWZlz}
  {Chain-of-knowledge: Grounding large language models via dynamic knowledge
  adapting over heterogeneous sources}.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations, {ICLR} 2024, Vienna, Austria, May 7-11, 2024}.
  OpenReview.net.

\bibitem[{Ling et~al.(2023)Ling, Fang, Li, Huang, Lee, Memisevic, and
  Su}]{Natural-Program}
Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, Mingu Lee, Roland Memisevic,
  and Hao Su. 2023.
\newblock \href
  {http://papers.nips.cc/paper\_files/paper/2023/hash/72393bd47a35f5b3bee4c609e7bba733-Abstract-Conference.html}
  {Deductive verification of chain-of-thought reasoning}.
\newblock In \emph{Advances in Neural Information Processing Systems 36: Annual
  Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New
  Orleans, LA, USA, December 10 - 16, 2023}.

\bibitem[{Liu et~al.(2024)Liu, Peng, Zhang, Liu, Yin, Cao, and Du}]{RA-ISF}
Yanming Liu, Xinyue Peng, Xuhong Zhang, Weihao Liu, Jianwei Yin, Jiannan Cao,
  and Tianyu Du. 2024.
\newblock \href {https://doi.org/10.18653/V1/2024.FINDINGS-ACL.281} {{RA-ISF:}
  learning to answer and understand from retrieval augmentation via iterative
  self-feedback}.
\newblock In \emph{Findings of the Association for Computational Linguistics,
  {ACL} 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024}, pages
  4730--4749. Association for Computational Linguistics.

\bibitem[{Ma et~al.(2023{\natexlab{a}})Ma, Zhou, Liu, Yuan, Liu, You, and
  Yang}]{prms_1}
Qianli Ma, Haotian Zhou, Tingkai Liu, Jianbo Yuan, Pengfei Liu, Yang You, and
  Hongxia Yang. 2023{\natexlab{a}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2310.10080} {Let's reward step
  by step: Step-level reward model as the navigators for reasoning}.
\newblock \emph{CoRR}, abs/2310.10080.

\bibitem[{Ma et~al.(2023{\natexlab{b}})Ma, Gong, He, Zhao, and
  Duan}]{Rewrite-Retrieve-Read}
Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, and Nan Duan.
  2023{\natexlab{b}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2305.14283} {Query rewriting
  for retrieval-augmented large language models}.
\newblock \emph{CoRR}, abs/2305.14283.

\bibitem[{Mao et~al.(2024)Mao, Jiang, Chen, Li, Wang, Wang, Xie, Huang, Chen,
  and Zhang}]{RaFe}
Shengyu Mao, Yong Jiang, Boli Chen, Xiao Li, Peng Wang, Xinyu Wang, Pengjun
  Xie, Fei Huang, Huajun Chen, and Ningyu Zhang. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2405.14431} {Rafe: Ranking
  feedback improves query rewriting for {RAG}}.
\newblock \emph{CoRR}, abs/2405.14431.

\bibitem[{Mekala et~al.(2024)Mekala, Razeghi, and Singh}]{EchoPrompt}
Raja Sekhar~Reddy Mekala, Yasaman Razeghi, and Sameer Singh. 2024.
\newblock \href {https://doi.org/10.18653/V1/2024.NAACL-SHORT.35} {Echoprompt:
  Instructing the model to rephrase queries for improved in-context learning}.
\newblock In \emph{Proceedings of the 2024 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies: Short Papers, {NAACL} 2024, Mexico City, Mexico, June 16-21,
  2024}, pages 399--432. Association for Computational Linguistics.

\bibitem[{Mo et~al.(2024)Mo, Ghaddar, Mao, Rezagholizadeh, Chen, Liu, and
  Nie}]{CHIQ}
Fengran Mo, Abbas Ghaddar, Kelong Mao, Mehdi Rezagholizadeh, Boxing Chen, Qun
  Liu, and Jian{-}Yun Nie. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2406.05013} {{CHIQ:} contextual
  history enhancement for improving query rewriting in conversational search}.
\newblock \emph{CoRR}, abs/2406.05013.

\bibitem[{Park and Lee(2024)}]{GuideCQR}
Jeonghyun Park and Hwanhee Lee. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2407.12363} {Conversational
  query reformulation with the guidance of retrieved documents}.
\newblock \emph{CoRR}, abs/2407.12363.

\bibitem[{Peng et~al.(2024{\natexlab{a}})Peng, Zhu, Liu, Bo, Shi, Hong, Zhang,
  and Tang}]{survey10}
Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao Hong, Yan
  Zhang, and Siliang Tang. 2024{\natexlab{a}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2408.08921} {Graph
  retrieval-augmented generation: {A} survey}.
\newblock \emph{CoRR}, abs/2408.08921.

\bibitem[{Peng et~al.(2024{\natexlab{b}})Peng, Li, Jiang, Wang, Ou, Zeng, Xu,
  Xu, and Chen}]{BEQUE}
Wenjun Peng, Guiyang Li, Yue Jiang, Zilong Wang, Dan Ou, Xiaoyi Zeng, Derong
  Xu, Tong Xu, and Enhong Chen. 2024{\natexlab{b}}.
\newblock \href {https://doi.org/10.1145/3589335.3648298} {Large language model
  based long-tail query rewriting in taobao search}.
\newblock In \emph{Companion Proceedings of the {ACM} on Web Conference 2024,
  {WWW} 2024, Singapore, Singapore, May 13-17, 2024}, pages 20--28. {ACM}.

\bibitem[{Press et~al.(2023)Press, Zhang, Min, Schmidt, Smith, and
  Lewis}]{Self-Ask}
Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah~A. Smith, and Mike
  Lewis. 2023.
\newblock \href {https://doi.org/10.18653/V1/2023.FINDINGS-EMNLP.378}
  {Measuring and narrowing the compositionality gap in language models}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  {EMNLP} 2023, Singapore, December 6-10, 2023}, pages 5687--5711. Association
  for Computational Linguistics.

\bibitem[{Qi et~al.(2024)Qi, Ma, Xu, Zhang, Yang, and Yang}]{rStar}
Zhenting Qi, Mingyuan Ma, Jiahang Xu, Li~Lyna Zhang, Fan Yang, and Mao Yang.
  2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2408.06195} {Mutual reasoning
  makes smaller llms stronger problem-solvers}.
\newblock \emph{CoRR}, abs/2408.06195.

\bibitem[{Roy et~al.(2024)Roy, Akash, Chang, and Popa}]{ConTReGen}
Kashob~Kumar Roy, Pritom~Saha Akash, Kevin Chen-Chuan Chang, and Lucian Popa.
  2024.
\newblock \href {https://arxiv.org/abs/2410.15511} {Contregen: Context-driven
  tree-structured retrieval for open-domain long-form text generation}.
\newblock \emph{Preprint}, arXiv:2410.15511.

\bibitem[{Setlur et~al.(2024)Setlur, Nagpal, Fisch, Geng, Eisenstein, Agarwal,
  Agarwal, Berant, and Kumar}]{prms_2}
Amrith Setlur, Chirag Nagpal, Adam Fisch, Xinyang Geng, Jacob Eisenstein,
  Rishabh Agarwal, Alekh Agarwal, Jonathan Berant, and Aviral Kumar. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2410.08146} {Rewarding
  progress: Scaling automated process verifiers for {LLM} reasoning}.
\newblock \emph{CoRR}, abs/2410.08146.

\bibitem[{Shen et~al.(2024{\natexlab{a}})Shen, Long, Geng, Tao, Lei, Zhou,
  Blumenstein, and Jiang}]{LameR}
Tao Shen, Guodong Long, Xiubo Geng, Chongyang Tao, Yibin Lei, Tianyi Zhou,
  Michael Blumenstein, and Daxin Jiang. 2024{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/V1/2024.FINDINGS-ACL.943}
  {Retrieval-augmented retrieval: Large language models are strong zero-shot
  retriever}.
\newblock In \emph{Findings of the Association for Computational Linguistics,
  {ACL} 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024}, pages
  15933--15946. Association for Computational Linguistics.

\bibitem[{Shen et~al.(2024{\natexlab{b}})Shen, Jiang, Qu, and
  Zhao}]{Think-then-Act}
Yige Shen, Hao Jiang, Hua Qu, and Jihong Zhao. 2024{\natexlab{b}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2406.13050} {Think-then-act:
  {A} dual-angle evaluated retrieval-augmented generation}.
\newblock \emph{CoRR}, abs/2406.13050.

\bibitem[{Su et~al.(2024)Su, Tang, Ai, Wu, and Liu}]{DRAGIN}
Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, and Yiqun Liu. 2024.
\newblock \href {https://doi.org/10.18653/V1/2024.ACL-LONG.702} {{DRAGIN:}
  dynamic retrieval augmented generation based on the real-time information
  needs of large language models}.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok,
  Thailand, August 11-16, 2024}, pages 12991--13013. Association for
  Computational Linguistics.

\bibitem[{Tonmoy et~al.(2024)Tonmoy, Zaman, Jain, Rani, Rawte, Chadha, and
  Das}]{hallucination2}
S.~M. Towhidul~Islam Tonmoy, S.~M.~Mehedi Zaman, Vinija Jain, Anku Rani, Vipula
  Rawte, Aman Chadha, and Amitava Das. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2401.01313} {A comprehensive
  survey of hallucination mitigation techniques in large language models}.
\newblock \emph{CoRR}, abs/2401.01313.

\bibitem[{V et~al.(2023)V, Bhattacharya, and Anand}]{ICAT}
Venktesh V, Sourangshu Bhattacharya, and Avishek Anand. 2023.
\newblock \href {https://doi.org/10.48550/ARXIV.2310.18371} {In-context ability
  transfer for question decomposition in complex {QA}}.
\newblock \emph{CoRR}, abs/2310.18371.

\bibitem[{Verma et~al.(2024)Verma, Midigeshi, Sinha, Solin, Natarajan, and
  Sharma}]{plantimesrag}
Prakhar Verma, Sukruta~Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan
  Natarajan, and Amit Sharma. 2024.
\newblock \href {https://arxiv.org/abs/2410.20753} {Plan$\times$rag:
  Planning-guided retrieval augmented generation}.
\newblock \emph{Preprint}, arXiv:2410.20753.

\bibitem[{Verma(2024)}]{survey5}
Sourav Verma. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2409.13385} {Contextual
  compression in retrieval-augmented generation for large language models: {A}
  survey}.
\newblock \emph{CoRR}, abs/2409.13385.

\bibitem[{Wang et~al.(2024{\natexlab{a}})Wang, Zhao, and Gao}]{BlendFilter}
Haoyu Wang, Tuo Zhao, and Jing Gao. 2024{\natexlab{a}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2402.11129} {Blendfilter:
  Advancing retrieval-augmented large language models via query generation
  blending and knowledge filtering}.
\newblock \emph{CoRR}, abs/2402.11129.

\bibitem[{Wang et~al.(2024{\natexlab{b}})Wang, Chen, Hu, Yang, Liu, Shen, Wei,
  Zhang, Gu, Zhou, Pan, Zhang, and Chen}]{LPKG}
Junjie Wang, Mingyang Chen, Binbin Hu, Dan Yang, Ziqi Liu, Yue Shen, Peng Wei,
  Zhiqiang Zhang, Jinjie Gu, Jun Zhou, Jeff~Z. Pan, Wen Zhang, and Huajun Chen.
  2024{\natexlab{b}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2406.14282} {Learning to plan
  for retrieval-augmented large language models from knowledge graphs}.
\newblock \emph{CoRR}, abs/2406.14282.

\bibitem[{Wang et~al.(2023{\natexlab{a}})Wang, Xu, Lan, Hu, Lan, Lee, and
  Lim}]{Plan-and-Solve}
Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy~Ka{-}Wei Lee, and
  Ee{-}Peng Lim. 2023{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/V1/2023.ACL-LONG.147} {Plan-and-solve
  prompting: Improving zero-shot chain-of-thought reasoning by large language
  models}.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto,
  Canada, July 9-14, 2023}, pages 2609--2634. Association for Computational
  Linguistics.

\bibitem[{Wang et~al.(2023{\natexlab{b}})Wang, Yang, and Wei}]{Query2doc}
Liang Wang, Nan Yang, and Furu Wei. 2023{\natexlab{b}}.
\newblock \href {https://doi.org/10.18653/V1/2023.EMNLP-MAIN.585} {Query2doc:
  Query expansion with large language models}.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in
  Natural Language Processing, {EMNLP} 2023, Singapore, December 6-10, 2023},
  pages 9414--9423. Association for Computational Linguistics.

\bibitem[{Wang et~al.(2024{\natexlab{c}})Wang, Yu, Wang, Chen, Zhu, and
  Dou}]{RichRAG}
Shuting Wang, Xin Yu, Mang Wang, Weipeng Chen, Yutao Zhu, and Zhicheng Dou.
  2024{\natexlab{c}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2406.12566} {Richrag: Crafting
  rich responses for multi-faceted queries in retrieval-augmented generation}.
\newblock \emph{CoRR}, abs/2406.12566.

\bibitem[{Wang et~al.(2023{\natexlab{c}})Wang, Yang, Qiu, Liang, He, Gu, Xiao,
  and Wang}]{KnowledGPT}
Xintao Wang, Qianwen Yang, Yongting Qiu, Jiaqing Liang, Qianyu He, Zhouhong Gu,
  Yanghua Xiao, and Wei Wang. 2023{\natexlab{c}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2308.11761} {Knowledgpt:
  Enhancing large language models with retrieval and storage access on
  knowledge bases}.
\newblock \emph{CoRR}, abs/2308.11761.

\bibitem[{Wang et~al.(2024{\natexlab{d}})Wang, Zhang, Zhang, Yang, and
  Wang}]{Meta-Reasoning}
Yiming Wang, Zhuosheng Zhang, Pei Zhang, Baosong Yang, and Rui Wang.
  2024{\natexlab{d}}.
\newblock \href {https://doi.org/10.18653/V1/2024.FINDINGS-ACL.34}
  {Meta-reasoning: Semantics-symbol deconstruction for large language models}.
\newblock In \emph{Findings of the Association for Computational Linguistics,
  {ACL} 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024}, pages
  622--643. Association for Computational Linguistics.

\bibitem[{Wang et~al.(2024{\natexlab{e}})Wang, Zhang, Pang, Guo, Zheng, and
  Zheng}]{MaFeRw}
Yujing Wang, Hainan Zhang, Liang Pang, Binghui Guo, Hongwei Zheng, and Zhiming
  Zheng. 2024{\natexlab{e}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2408.17072} {Maferw: Query
  rewriting with multi-aspect feedbacks for retrieval-augmented large language
  models}.
\newblock \emph{CoRR}, abs/2408.17072.

\bibitem[{Wang et~al.(2024{\natexlab{f}})Wang, Fan, Zong, Zhang, Choi, Fang,
  Liu, Song, Wong, and See}]{AbsInstruct}
Zhaowei Wang, Wei Fan, Qing Zong, Hongming Zhang, Sehyun Choi, Tianqing Fang,
  Xin Liu, Yangqiu Song, Ginny~Y. Wong, and Simon See. 2024{\natexlab{f}}.
\newblock \href {https://doi.org/10.18653/V1/2024.ACL-LONG.55} {Absinstruct:
  Eliciting abstraction ability from llms through explanation tuning with
  plausibility estimation}.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok,
  Thailand, August 11-16, 2024}, pages 973--994. Association for Computational
  Linguistics.

\bibitem[{Wang et~al.(2024{\natexlab{g}})Wang, Shi, Wang, Fang, Zhang, Choi,
  Liu, and Song}]{AbsPyramid}
Zhaowei Wang, Haochen Shi, Weiqi Wang, Tianqing Fang, Hongming Zhang, Sehyun
  Choi, Xin Liu, and Yangqiu Song. 2024{\natexlab{g}}.
\newblock \href {https://doi.org/10.18653/V1/2024.FINDINGS-NAACL.252}
  {Abspyramid: Benchmarking the abstraction ability of language models with a
  unified entailment graph}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  {NAACL} 2024, Mexico City, Mexico, June 16-21, 2024}, pages 3991--4010.
  Association for Computational Linguistics.

\bibitem[{Weller et~al.(2024)Weller, Lo, Wadden, Lawrie, Durme, Cohan, and
  Soldaini}]{query_expansion_survey2}
Orion Weller, Kyle Lo, David Wadden, Dawn~J. Lawrie, Benjamin~Van Durme, Arman
  Cohan, and Luca Soldaini. 2024.
\newblock \href {https://aclanthology.org/2024.findings-eacl.134} {When do
  generative query and document expansions fail? {A} comprehensive study across
  methods, retrievers, and datasets}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  {EACL} 2024, St. Julian's, Malta, March 17-22, 2024}, pages 1987--2003.
  Association for Computational Linguistics.

\bibitem[{Wu et~al.(2024)Wu, Xiong, Cui, Wu, Chen, Yuan, Huang, Liu, Kuo, Guan,
  and Xue}]{survey9}
Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye~Yuan, Lianming
  Huang, Xue Liu, Tei{-}Wei Kuo, Nan Guan, and Chun~Jason Xue. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2407.13193}
  {Retrieval-augmented generation for natural language processing: {A} survey}.
\newblock \emph{CoRR}, abs/2407.13193.

\bibitem[{Xie et~al.(2024)Xie, Laban, Choubey, Xiong, and Wu}]{rag_benchmark_2}
Kaige Xie, Philippe Laban, Prafulla~Kumar Choubey, Caiming Xiong, and
  Chien{-}Sheng Wu. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2410.15531} {Do {RAG} systems
  cover what matters? evaluating and optimizing responses with sub-question
  coverage}.
\newblock \emph{CoRR}, abs/2410.15531.

\bibitem[{Yang et~al.(2024)Yang, Rao, Chen, Guo, Zhang, Yang, and
  Zhang}]{IM-RAG}
Diji Yang, Jinmeng Rao, Kezhen Chen, Xiaoyuan Guo, Yawen Zhang, Jie Yang, and
  Yi~Zhang. 2024.
\newblock \href {https://doi.org/10.1145/3626772.3657760} {{IM-RAG:}
  multi-round retrieval-augmented generation through learning inner
  monologues}.
\newblock In \emph{Proceedings of the 47th International {ACM} {SIGIR}
  Conference on Research and Development in Information Retrieval, {SIGIR}
  2024, Washington DC, USA, July 14-18, 2024}, pages 730--740. {ACM}.

\bibitem[{Yao et~al.(2023)Yao, Zhao, Yu, Du, Shafran, Narasimhan, and
  Cao}]{ReAct}
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik~R.
  Narasimhan, and Yuan Cao. 2023.
\newblock \href {https://openreview.net/forum?id=WE\_vluYUL-X} {React:
  Synergizing reasoning and acting in language models}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net.

\bibitem[{Ye et~al.(2023)Ye, Fang, Li, and Yilmaz}]{InfoCQR}
Fanghua Ye, Meng Fang, Shenghui Li, and Emine Yilmaz. 2023.
\newblock \href {https://doi.org/10.18653/V1/2023.FINDINGS-EMNLP.398}
  {Enhancing conversational search: Large language model-aided informative
  query rewriting}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  {EMNLP} 2023, Singapore, December 6-10, 2023}, pages 5985--6006. Association
  for Computational Linguistics.

\bibitem[{Yu et~al.(2023{\natexlab{a}})Yu, Iter, Wang, Xu, Ju, Sanyal, Zhu,
  Zeng, and Jiang}]{GenRead}
Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal,
  Chenguang Zhu, Michael Zeng, and Meng Jiang. 2023{\natexlab{a}}.
\newblock \href {https://openreview.net/forum?id=fB0hRu9GZUS} {Generate rather
  than retrieve: Large language models are strong context generators}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net.

\bibitem[{Yu et~al.(2023{\natexlab{b}})Yu, Zhang, Liang, Jiang, and
  Sabharwal}]{ReFeed}
Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, and Ashish Sabharwal.
  2023{\natexlab{b}}.
\newblock \href {https://arxiv.org/abs/2305.14002} {Improving language models
  via plug-and-play retrieval feedback}.
\newblock \emph{Preprint}, arXiv:2305.14002.

\bibitem[{Yue et~al.(2024)Yue, Zeng, Lu, Shang, Zhang, and Wang}]{RARG}
Zhenrui Yue, Huimin Zeng, Yimeng Lu, Lanyu Shang, Yang Zhang, and Dong Wang.
  2024.
\newblock \href {https://doi.org/10.18653/V1/2024.NAACL-LONG.313}
  {Evidence-driven retrieval augmented response generation for online
  misinformation}.
\newblock In \emph{Proceedings of the 2024 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (Volume 1: Long Papers), {NAACL} 2024, Mexico City, Mexico, June
  16-21, 2024}, pages 5628--5643. Association for Computational Linguistics.

\bibitem[{Zhang et~al.(2024{\natexlab{a}})Zhang, Ma, and Yang}]{ALTER}
Han Zhang, Yuheng Ma, and Hanfang Yang. 2024{\natexlab{a}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2407.03061} {{ALTER:}
  augmentation for large-table-based reasoning}.
\newblock \emph{CoRR}, abs/2407.03061.

\bibitem[{Zhang et~al.(2024{\natexlab{b}})Zhang, Wu, Yang, and Nie}]{MUGI}
Le~Zhang, Yihong Wu, Qian Yang, and Jian-Yun Nie. 2024{\natexlab{b}}.
\newblock \href {https://arxiv.org/abs/2401.06311} {Exploring the best
  practices of query expansion with large language models}.
\newblock \emph{Preprint}, arXiv:2401.06311.

\bibitem[{Zhang et~al.(2024{\natexlab{c}})Zhang, Li, Luo, Wu, Glass, and
  Meng}]{AdaQR}
Tianhua Zhang, Kun Li, Hongyin Luo, Xixin Wu, James~R. Glass, and Helen Meng.
  2024{\natexlab{c}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2406.10991} {Adaptive query
  rewriting: Aligning rewriters through marginal probability of conversational
  answers}.
\newblock \emph{CoRR}, abs/2406.10991.

\bibitem[{Zhang et~al.(2024{\natexlab{d}})Zhang, Wang, Yang, Wang, Feng, and
  Zhang}]{HiRAG}
Xiaoming Zhang, Ming Wang, Xiaocui Yang, Daling Wang, Shi Feng, and Yifei
  Zhang. 2024{\natexlab{d}}.
\newblock \href {https://arxiv.org/abs/2408.11875} {Hierarchical
  retrieval-augmented generation model with rethink for multi-hop question
  answering}.
\newblock \emph{Preprint}, arXiv:2408.11875.

\bibitem[{Zhang et~al.(2023{\natexlab{a}})Zhang, Cui, Zhang, Bai, Zhang, Ma,
  Chen, and Zhou}]{EQE}
Yanan Zhang, Weijie Cui, Yangfan Zhang, Xiaoling Bai, Zhe Zhang, Jin Ma, Xiang
  Chen, and Tianhua Zhou. 2023{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/V1/2023.ACL-INDUSTRY.45}
  {Event-centric query expansion in web search}.
\newblock In \emph{Proceedings of the The 61st Annual Meeting of the
  Association for Computational Linguistics: Industry Track, {ACL} 2023,
  Toronto, Canada, July 9-14, 2023}, pages 464--475. Association for
  Computational Linguistics.

\bibitem[{Zhang et~al.(2023{\natexlab{b}})Zhang, Li, Cui, Cai, Liu, Fu, Huang,
  Zhao, Zhang, Chen, Wang, Luu, Bi, Shi, and Shi}]{hallucination1}
Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting
  Huang, Enbo Zhao, Yu~Zhang, Yulong Chen, Longyue Wang, Anh~Tuan Luu, Wei Bi,
  Freda Shi, and Shuming Shi. 2023{\natexlab{b}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2309.01219} {Siren's song in
  the {AI} ocean: {A} survey on hallucination in large language models}.
\newblock \emph{CoRR}, abs/2309.01219.

\bibitem[{Zhao et~al.(2024)Zhao, Yang, Wang, He, Qiu, and Qiu}]{survey6}
Siyun Zhao, Yuqing Yang, Zilong Wang, Zhiyuan He, Luna Qiu, and Lili Qiu. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2409.14924} {Retrieval
  augmented generation {(RAG)} and beyond: {A} comprehensive survey on how to
  make your llms use external data more wisely}.
\newblock \emph{CoRR}, abs/2409.14924.

\bibitem[{Zhao et~al.(2023)Zhao, Zhou, Li, Tang, Wang, Hou, Min, Zhang, Zhang,
  Dong, Du, Yang, Chen, Chen, Jiang, Ren, Li, Tang, Liu, Liu, Nie, and
  Wen}]{llm_survey}
Wayne~Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou,
  Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang,
  Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang,
  Zikang Liu, Peiyu Liu, Jian{-}Yun Nie, and Ji{-}Rong Wen. 2023.
\newblock \href {https://doi.org/10.48550/ARXIV.2303.18223} {A survey of large
  language models}.
\newblock \emph{CoRR}, abs/2303.18223.

\bibitem[{Zheng et~al.(2024)Zheng, Mishra, Chen, Cheng, Chi, Le, and
  Zhou}]{StepBack}
Huaixiu~Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed~H. Chi,
  Quoc~V Le, and Denny Zhou. 2024.
\newblock Take a {Step} {Back}: Evoking {Reasoning} via {Abstraction} in
  {Large} {Language} {Models}.
\newblock In \emph{The {Twelfth} {International} {Conference} on {Learning}
  {Representations}}, volume abs/2310.06117.

\bibitem[{Zhou et~al.(2024)Zhou, Zhang, Chen, Yu, Wang, Peng, Roth, and
  Yu}]{Conceptualization-Abstraction}
Ben Zhou, Hongming Zhang, Sihao Chen, Dian Yu, Hongwei Wang, Baolin Peng, Dan
  Roth, and Dong Yu. 2024.
\newblock \href {https://doi.org/10.48550/ARXIV.2404.00205} {Conceptual and
  unbiased reasoning in language models}.
\newblock \emph{CoRR}, abs/2404.00205.

\bibitem[{Zhou et~al.(2023)Zhou, Sch{\"{a}}rli, Hou, Wei, Scales, Wang,
  Schuurmans, Cui, Bousquet, Le, and Chi}]{Least-to-Most}
Denny Zhou, Nathanael Sch{\"{a}}rli, Le~Hou, Jason Wei, Nathan Scales, Xuezhi
  Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc~V. Le, and Ed~H.
  Chi. 2023.
\newblock \href {https://openreview.net/forum?id=WZH7099tgfM} {Least-to-most
  prompting enables complex reasoning in large language models}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net.

\bibitem[{Zhu et~al.(2023{\natexlab{a}})Zhu, Thomason, and Jia}]{QDMR}
Wang Zhu, Jesse Thomason, and Robin Jia. 2023{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/V1/2023.EMNLP-MAIN.547}
  {Chain-of-questions training with latent answers for robust multistep
  question answering}.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in
  Natural Language Processing, {EMNLP} 2023, Singapore, December 6-10, 2023},
  pages 8845--8860. Association for Computational Linguistics.

\bibitem[{Zhu et~al.(2023{\natexlab{b}})Zhu, Yuan, Wang, Liu, Liu, Deng, Dou,
  and Wen}]{survey3}
Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng,
  Zhicheng Dou, and Ji{-}Rong Wen. 2023{\natexlab{b}}.
\newblock \href {https://doi.org/10.48550/ARXIV.2308.07107} {Large language
  models for information retrieval: {A} survey}.
\newblock \emph{CoRR}, abs/2308.07107.

\end{thebibliography}
