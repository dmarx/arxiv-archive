\documentclass{article} %
\usepackage[preprint]{neurips_2024}

\usepackage{xcolor}
\usepackage{times}
\usepackage{mkolar_definitions}
\input{notation}
\usepackage{hyperref}
\usepackage{url}
\usepackage{xcolor}
\usepackage{booktabs}       %
\usepackage{amsfonts}       %
\usepackage{nicefrac}       %
\usepackage{microtype}      %
\usepackage{xspace}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{mkolar_definitions}
\usepackage{algorithmic}
\usepackage{color}
\usepackage{color, colortbl}
\usepackage{enumitem}
\usepackage{comment}
\usepackage{bm}
\usepackage{subcaption}
\usepackage{thmtools}
\newtheorem{myexp}{Example}

\usepackage{url}
\usepackage{csquotes}
\usepackage{tikz}


\newenvironment{packed_enum}{
  \begin{enumerate}
    \setlength{\itemsep}{1pt}
    \setlength{\parskip}{-1pt}
    \setlength{\parsep}{0pt}
}{\end{enumerate}}

\usepackage{centernot}
\newcommand{\bigCI}{\mathrel{\text{\scalebox{1.07}{$\perp\mkern-10mu\perp$}}}}
\newcommand{\nbigCI}{\centernot{\bigCI}}

\newcount\Comments  %
\Comments=1 %
\definecolor{darkgreen}{rgb}{0,0.5,0}
\definecolor{darkred}{rgb}{0.7,0,0}

\definecolor{teal}{rgb}{0.3,0.8,0.8}
\definecolor{orange}{rgb}{1.0,0.5,0.0}
\definecolor{purple}{rgb}{0.8,0.0,0.8}
\newcommand{\kibitz}[2]{\ifnum\Comments=1{\textcolor{#1}{\textsf{\footnotesize #2}}}\fi}
\usetikzlibrary{positioning}
\newcommand{\masa}[1]{\noindent{\textcolor{purple}{\{{\bf Masa:} \em #1\}}}}
\newcommand{\xiner}[1]{\noindent{\textcolor{red}{\{{\bf Xiner:} \em #1\}}}}


\title{
Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding}



\author{%
\textbf{Xiner Li} $^{1}$\thanks{Work mainly done during an internship at Genentech} \quad \textbf{Yulai Zhao} $^{2}$ \quad \textbf{Chenyu Wang} $^{3}$ \quad \textbf{Gabriele Scalia}  $^4$   \\ 
\textbf{Gokcen Eraslan} $^4$ \textbf{Surag Nair} $^4$\,\,\textbf{Tommaso Biancalani} $^4$ \quad  \textbf{Shuiwang Ji}  $^1$ \\
\textbf{Aviv Regev} $^{4\dagger}$ \quad \textbf{Sergey Levine} $^{5\dagger}$ \quad \textbf{Masatoshi Uehara} $^{4}$\thanks{Corresponding authors: \texttt{regev.aviv@gene.com},\,\texttt{svlevine@eecs.berkeley.edu} \\ \texttt{uehara.masatoshi@gene.com}} \\   
$^1$Texas A\&M University\quad $^2$Princeton University \quad $^3$MIT  \quad $^4$Genentech \quad $^5$UC Berkeley
}



\begin{document}


\maketitle

\begin{abstract}
Diffusion models excel at capturing the natural design spaces of images, molecules, and biological sequences of DNA, RNA, and proteins. However, for many applications from biological research to biotherapeutic discovery, rather than merely generating designs that are natural, we aim to optimize downstream reward functions while preserving the naturalness of these design spaces. Existing methods for achieving this goal often require ``differentiable'' proxy models (\textit{e.g.}, classifier guidance) or computationally-expensive fine-tuning of diffusion models (\textit{e.g.}, classifier-free guidance, RL-based fine-tuning). Here, we propose a new method, \textbf{S}oft \text{V}alue-based \textbf{D}ecoding in \textbf{D}iffusion models ({\alg}), to address these challenges. {\alg} is an iterative sampling method that integrates soft value functions, which looks ahead to how intermediate noisy states lead to high rewards in the future, into the standard inference procedure of pre-trained diffusion models. Notably, {\alg} avoids fine-tuning generative models and eliminates the need to construct differentiable models. This enables us to (1) directly utilize non-differentiable features/reward feedback, commonly used in many scientific domains, and (2) apply our method to recent discrete diffusion models in a principled way. Finally, we demonstrate the effectiveness of {\alg} across several domains, including image generation, molecule generation (optimization of docking scores, QED, SA), and DNA/RNA generation (optimization of activity levels).
The code is available at \href{https://github.com/masa-ue/SVDD}{https://github.com/masa-ue/SVDD}. 
\end{abstract}


\input{main_intro}

\input{main_pre}

\input{main_alg}

\input{main_experiments}

\input{main_conclusion}


\onecolumn  
\clearpage



\bibliographystyle{chicago}
\bibliography{rl}


\appendix

\input{main_extension}



\end{document}
