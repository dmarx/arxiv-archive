\section{Conclusion}
\label{section:conclusion}
In many ways, the development of high-quality foundation models is still in its infancy.
Our experience in developing Llama 3 suggests that substantial further improvements of these models are on the horizon.
Throughout the development of the Llama 3 model family, we found that a strong focus on high-quality data, scale, and simplicity consistently yielded the best results.
In preliminary experiments, we explored more complex model architectures and training recipes but did not find the benefits of such approaches to outweigh the additional complexity they introduce in model development.

Developing a flagship foundation model such as Llama 3 involves overcoming a plethora of deep technical problems but also requires clever organizational decisions.
For example, to ensure Llama 3 is not accidentally overfitted on commonly used benchmarks, our pre-training data was procured and processed by a separate team that was strongly incentivized to prevent contamination of that pre-training data with external benchmarks. 
As another example, we ensure that our human evaluations remain trustworthy by allowing only a small set of researchers who do not contribute to model development to perform and access these evaluations.
While such organizational decisions are rarely discussed in technical papers, we found them to be pivotal to the successful development of the Llama 3 family of models.

We shared the details of our development process because we believe this will: \textbf{(1)} help the larger research community understand the key factors of foundation model development and \textbf{(2)} contribute to a more informed debate about the future of foundation models in the general public.
We also shared preliminary experiments with integrating multimodal capabilities into Llama 3.
While these models are still under active development and not yet ready for release, we hope sharing our results early will accelerate research in this direction.

Following the positive outcomes of the detailed safety analyses presented in this paper, we publicly release our Llama 3 language models in order to accelerate the development of AI systems for a plethora of societally relevant use cases and enable the research community to scrutinize our models and identify ways to make these models better and safer.
We believe that the public release of foundation models plays a key role in the responsible development of such models, and we hope that the release of Llama 3 encourages the industry to embrace the open, responsible development of AGI.
