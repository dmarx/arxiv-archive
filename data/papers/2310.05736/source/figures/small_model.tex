\begin{table}[htb]
    \centering
	\setlength{\tabcolsep}{0.5mm}
	\scalebox{0.8}{
    \begin{tabular}{lccc}
    \toprule
         & EM & Tokens & $1/\tau$ \\
         \midrule
        \textbf{Ours} with GPT2 in 1-shot constraint & 77.02 & 447 & 5x \\
        \textbf{Ours} with GPT2 in half-shot constraint & 76.42 & 173 & 14x \\
        \textbf{Ours} with GPT2 in quarter-shot constraint & 76.27 & 128 & 18x \\
        \bottomrule
    \end{tabular}
    }
    \caption{Our method on GSM8K with GPT2-Alpaca as the small language model.}
    \label{tab:small_model}
\end{table}