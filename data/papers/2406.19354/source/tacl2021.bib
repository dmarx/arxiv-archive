@article{kassner2020pretrained,
	title        = {Are Pretrained Language Models Symbolic Reasoners Over Knowledge?},
	author       = {Kassner, Nora and Krojer, Benno and Sch{\"u}tze, Hinrich},
	year         = 2020,
	journal      = {CoNLL},
	url          = {https://aclanthology.org/2020.conll-1.45.pdf}
}
@article{kassner2019negated,
	title        = {Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly},
	author       = {Kassner, Nora and Sch{\"u}tze, Hinrich},
	year         = 2019,
	journal      = {ACL},
	url          = {https://aclanthology.org/2020.acl-main.698.pdf}
}
@inproceedings{talmor2020leap,
	title        = {Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge},
	author       = {Talmor, Alon and Tafjord, Oyvind and Clark, Peter and Goldberg, Yoav and Berant, Jonathan},
	year         = 2020,
	booktitle    = {NeurIPS},
	url          = {http://128.84.4.27/pdf/2006.06609}
}
@inproceedings{loshchilov_decoupled_2017,
	title        = {Decoupled Weight Decay Regularization},
	author       = {Ilya Loshchilov and Frank Hutter},
	year         = 2019,
	booktitle    = {ICLR},
	url          = {https://arxiv.org/pdf/1711.05101.pdf},
	eprint       = {arXiv:1711.05101}
}
@inproceedings{petroni-etal-2019-language,
	title        = {Language Models as Knowledge Bases?},
	author       = {Petroni, Fabio  and Rockt{\"a}schel, Tim  and Riedel, Sebastian  and Lewis, Patrick  and Bakhtin, Anton  and Wu, Yuxiang  and Miller, Alexander},
	year         = 2019,
	month        = nov,
	booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Hong Kong, China},
	pages        = {2463--2473},
	doi          = {10.18653/v1/D19-1250},
	url          = {https://aclanthology.org/D19-1250}
}
@article{geiger2023causal,
	title        = {Causal abstraction for faithful model interpretation},
	author       = {Geiger, Atticus and Potts, Chris and Icard, Thomas},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2301.04709}
}
@article{jacovi2021aligning,
	title        = {Aligning faithful interpretations with their social attribution},
	author       = {Jacovi, Alon and Goldberg, Yoav},
	year         = 2021,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	volume       = 9,
	pages        = {294--310},
	url          = {https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00367/98620/Aligning}
}
@article{miller2019explanation,
	title        = {Explanation in artificial intelligence: Insights from the social sciences},
	author       = {Tim Miller},
	year         = 2019,
	journal      = {Artif. Intell.},
	volume       = 267,
	pages        = {1--38},
	doi          = {10.1016/j.artint.2018.07.007},
	url          = {https://doi.org/10.1016/j.artint.2018.07.007},
	timestamp    = {Fri, 25 Dec 2020 01:14:07 +0100},
	biburl       = {https://dblp.org/rec/journals/ai/Miller19.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{li2023inference,
	title        = {Inference-Time Intervention: Eliciting Truthful Answers from a Language Model},
	author       = {Li, Kenneth and Patel, Oam and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2306.03341}
}
@inproceedings{heinzerling-inui-2021-language,
	title        = {Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries},
	author       = {Heinzerling, Benjamin  and Inui, Kentaro},
	year         = 2021,
	month        = apr,
	booktitle    = {Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {1772--1791},
	url          = {https://aclanthology.org/2021.eacl-main.153}
}
@article{wang2021kepler,
	title        = {KEPLER: A unified model for knowledge embedding and pre-trained language representation},
	author       = {Wang, Xiaozhi and Gao, Tianyu and Zhu, Zhaocheng and Zhang, Zhengyan and Liu, Zhiyuan and Li, Juanzi and Tang, Jian},
	year         = 2021,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	volume       = 9,
	pages        = {176--194},
	url          = {https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00360/98089/KEPLER-A-Unified-Model-for-Knowledge-Embedding-and}
}
@inproceedings{elsahar-etal-2018-rex,
	title        = {{T}-{RE}x: A Large Scale Alignment of Natural Language with Knowledge Base Triples},
	author       = {Elsahar, Hady  and Vougiouklis, Pavlos  and Remaci, Arslen  and Gravier, Christophe  and Hare, Jonathon  and Laforest, Frederique  and Simperl, Elena},
	year         = 2018,
	month        = may,
	booktitle    = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)},
	publisher    = {European Language Resources Association (ELRA)},
	address      = {Miyazaki, Japan},
	url          = {https://aclanthology.org/L18-1544}
}
@article{elazar2021measuring,
	title        = {Measuring and improving consistency in pretrained language models},
	author       = {Elazar, Yanai and Kassner, Nora and Ravfogel, Shauli and Ravichander, Abhilasha and Hovy, Eduard and Sch{\"u}tze, Hinrich and Goldberg, Yoav},
	year         = 2021,
	journal      = {Transactions of the Association for Computational Linguistics},
	volume       = 9,
	pages        = {1012--1031},
	url          = {https://arxiv.org/pdf/2102.01017.pdf}
}
@article{jiang2020can,
	title        = {How can we know what language models know?},
	author       = {Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
	year         = 2020,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	volume       = 8,
	pages        = {423--438},
	url          = {https://arxiv.org/pdf/2212.14315.pdf}
}
@inproceedings{hewitt2019designing,
	title        = {Designing and interpreting probes with control tasks},
	author       = {Hewitt, John and Liang, Percy},
	year         = 2019,
	booktitle    = {EMNLP},
	url          = {https://arxiv.org/pdf/1909.03368.pdf}
}
@inproceedings{voita2020information,
	title        = {Information-theoretic probing with minimum description length},
	author       = {Voita, Elena and Titov, Ivan},
	year         = 2020,
	booktitle    = {EMNLP},
	url          = {https://aclanthology.org/2020.emnlp-main.14.pdf}
}
@article{giannakidou2020linguistic,
	title        = {A linguistic framework for knowledge, belief, and veridicality judgement},
	author       = {Giannakidou, Anastasia and Mari, Alda},
	year         = 2020,
	journal      = {HAL},
	url          = {https://halshs.archives-ouvertes.fr/halshs-03088697/document}
}
@article{safavi2021relational,
	title        = {Relational world knowledge representation in contextual language models: A review},
	author       = {Safavi, Tara and Koutra, Danai},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2104.05837},
	url          = {https://arxiv.org/pdf/2104.05837.pdf}
}
@inproceedings{dai2021knowledge,
	title        = {Knowledge neurons in pretrained transformers},
	author       = {Dai, Damai and Dong, Li and Hao, Yaru and Sui, Zhifang and Wei, Furu},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2104.08696},
	url          = {https://arxiv.org/pdf/2104.08696.pdf}
}
@inproceedings{de2021editing,
	title        = {Editing Factual Knowledge in Language Models},
	author       = {De Cao, Nicola  and Aziz, Wilker  and Titov, Ivan},
	year         = 2021,
	month        = nov,
	booktitle    = {EMNLP},
	publisher    = {Association for Computational Linguistics},
	pages        = {6491--6506},
	url          = {https://aclanthology.org/2021.emnlp-main.522}
}
@inproceedings{sinitsin2020editable,
	title        = {Editable Neural Networks},
	author       = {Sinitsin, Anton and Plokhotnyuk, Vsevolod and Pyrkin, Dmitriy and Popov, Sergei and Babenko, Artem},
	year         = 2020,
	booktitle    = {ICLR},
	url          = {https://openreview.net/pdf?id=HJedXaEtvS}
}
@inproceedings{wong2021leveraging,
	title        = {Leveraging Sparse Linear Layers for Debuggable Deep Networks},
	author       = {Wong, Eric and Santurkar, Shibani and Madry, Aleksander},
	year         = 2021,
	month        = {18--24 Jul},
	booktitle    = {ICML},
	publisher    = {PMLR},
	series       = {Proceedings of Machine Learning Research},
	volume       = 139,
	pages        = {11205--11216},
	url          = {http://proceedings.mlr.press/v139/wong21b.html},
	editor       = {Meila, Marina and Zhang, Tong},
	pdf          = {http://proceedings.mlr.press/v139/wong21b/wong21b.pdf}
}
@inproceedings{lazaridou2021pitfalls,
	title        = {Mind the Gap: Assessing Temporal Generalization in Neural Language Models},
	author       = {Lazaridou, Angeliki and Kuncoro, Adhiguna and Gribovskaya, Elena and Agrawal, Devang and Liska, Adam and Terzi, Tayfun and Gimenez, Mai and d'Autume, Cyprien de Masson and Ruder, Sebastian and Yogatama, Dani and others},
	year         = 2021,
	booktitle    = {NeurIPS},
	url          = {https://arxiv.org/pdf/2102.01951.pdf}
}
@article{dennett1995animals,
	title        = {Do animals have beliefs?},
	author       = {Dennett, Daniel},
	year         = 1995,
	journal      = {Comparative approaches to cognitive science},
	publisher    = {MIT press Cambridge, MA},
	volume       = 111,
	url          = {https://dl.tufts.edu/concern/pdfs/rj430g708}
}
@article{newen2020ascribe,
	title        = {How to ascribe beliefs to animals},
	author       = {Newen, Albert and Starzak, Tobias},
	year         = 2020,
	journal      = {Mind \& Language},
	publisher    = {Wiley Online Library},
	url          = {https://onlinelibrary.wiley.com/doi/full/10.1111/mila.12302}
}
@article{lertvittayakumjorn2021explanation,
	title        = {Explanation-Based Human Debugging of NLP Models: A Survey},
	author       = {Lertvittayakumjorn, Piyawat and Toni, Francesca},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2104.15135},
	url          = {https://arxiv.org/pdf/2104.15135.pdf}
}
@article{saha2021explagraphs,
	title        = {ExplaGraphs: An Explanation Graph Generation Task for Structured Commonsense Reasoning},
	author       = {Saha, Swarnadeep and Yadav, Prateek and Bauer, Lisa and Bansal, Mohit},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2104.07644},
	url          = {https://arxiv.org/pdf/2104.07644.pdf}
}
@inproceedings{dagan2005pascal,
	title        = {The pascal recognising textual entailment challenge},
	author       = {Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
	year         = 2005,
	booktitle    = {Machine Learning Challenges Workshop},
	pages        = {177--190},
	url          = {https://link.springer.com/chapter/10.1007/11736790_9},
	organization = {Springer}
}
@article{manning2006,
	title        = {LOCAL TEXTUAL INFERENCE: IT’S HARD TO CIRCUMSCRIBE, BUT YOU KNOW IT WHEN YOU SEE IT – AND NLP NEEDS IT},
	author       = {Manning, Christopher D.},
	url          = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.510.4207&rep=rep1&type=pdf}
}
@article{pavlick2019inherent,
	title        = {Inherent disagreements in human textual inferences},
	author       = {Pavlick, Ellie and Kwiatkowski, Tom},
	year         = 2019,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	volume       = 7,
	pages        = {677--694},
	url          = {https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00293/43531/Inherent-Disagreements-in-Human-Textual-Inferences}
}
@article{bommasani2021opportunities,
	title        = {On the Opportunities and Risks of Foundation Models},
	author       = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2108.07258}
}
@article{wallat2021bertnesia,
	title        = {BERTnesia: Investigating the capture and forgetting of knowledge in BERT},
	author       = {Wallat, Jonas and Singh, Jaspreet and Anand, Avishek},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2106.02902},
	url          = {https://arxiv.org/abs/2010.09313}
}
@inproceedings{wang2021k,
	title        = {K-adapter: Infusing knowledge into pre-trained models with adapters},
	author       = {Wang, Ruize and Tang, Duyu and Duan, Nan and Wei, Zhongyu and Huang, Xuanjing and Cao, Guihong and Jiang, Daxin and Zhou, Ming and others},
	year         = 2021,
	booktitle    = {Findings of ACL},
	url          = {https://aclanthology.org/2021.findings-acl.121.pdf}
}
@article{mitchell2021fast,
	title        = {Fast Model Editing at Scale},
	author       = {Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Finn, Chelsea and Manning, Christopher D},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2110.11309},
	url          = {https://arxiv.org/pdf/2110.11309.pdf}
}
@inproceedings{gehman2020realtoxicityprompts,
	title        = {Realtoxicityprompts: Evaluating neural toxic degeneration in language models},
	author       = {Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A},
	year         = 2020,
	booktitle    = {Findings of EMNLP},
	url          = {https://arxiv.org/pdf/2009.11462.pdf}
}
@inproceedings{bender2021dangers,
	title        = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
	author       = {Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
	pages        = {610--623},
	url          = {https://dl.acm.org/doi/10.1145/3442188.3445922}
}
@article{lin2021truthfulqa,
	title        = {TruthfulQA: Measuring How Models Mimic Human Falsehoods},
	author       = {Lin, Stephanie and Hilton, Jacob and Evans, Owain},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2109.07958},
	url          = {https://arxiv.org/pdf/2109.07958.pdf}
}
@article{zhu2020modifying,
	title        = {Modifying Memories in Transformer Models},
	author       = {Zhu, Chen and Rawat, Ankit Singh and Zaheer, Manzil and Bhojanapalli, Srinadh and Li, Daliang and Yu, Felix and Kumar, Sanjiv},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2012.00363},
	url          = {https://arxiv.org/pdf/2012.00363.pdf}
}
@article{rogers-etal-2020-primer,
	title        = {A Primer in {BERT}ology: What We Know About How {BERT} Works},
	author       = {Rogers, Anna  and Kovaleva, Olga  and Rumshisky, Anna},
	year         = 2020,
	journal      = {Transactions of the Association for Computational Linguistics},
	volume       = 8,
	pages        = {842--866},
	doi          = {10.1162/tacl_a_00349},
	url          = {https://aclanthology.org/2020.tacl-1.54},
	abstract     = {Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue, and approaches to compression. We then outline directions for future research.}
}
@inproceedings{roberts-etal-2020-much,
	title        = {How Much Knowledge Can You Pack Into the Parameters of a Language Model?},
	author       = {Roberts, Adam  and Raffel, Colin  and Shazeer, Noam},
	year         = 2020,
	month        = nov,
	booktitle    = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {5418--5426},
	doi          = {10.18653/v1/2020.emnlp-main.437},
	url          = {https://aclanthology.org/2020.emnlp-main.437}
}
@article{kassner2021beliefbank,
	title        = {BeliefBank: Adding Memory to a Pre-Trained Language Model for a Systematic Notion of Belief},
	author       = {Kassner, Nora and Tafjord, Oyvind and Sch{\"u}tze, Hinrich and Clark, Peter},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2109.14723},
	url          = {https://arxiv.org/pdf/2109.14723.pdf}
}
@article{west2021symbolic,
	title        = {Symbolic Knowledge Distillation: from General Language Models to Commonsense Models},
	author       = {West, Peter and Bhagavatula, Chandra and Hessel, Jack and Hwang, Jena D and Jiang, Liwei and Bras, Ronan Le and Lu, Ximing and Welleck, Sean and Choi, Yejin},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2110.07178},
	url          = {https://arxiv.org/pdf/2110.07178.pdf}
}
@inproceedings{lewis2020retrieval,
	title        = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
	author       = {Patrick S. H. Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich K{\"{u}}ttler and Mike Lewis and Wen{-}tau Yih and Tim Rockt{\"{a}}schel and Sebastian Riedel and Douwe Kiela},
	year         = 2020,
	booktitle    = {NeurIPS},
	url          = {https://arxiv.org/abs/2005.11401},
	editor       = {Hugo Larochelle and Marc'Aurelio Ranzato and Raia Hadsell and Maria{-}Florina Balcan and Hsuan{-}Tien Lin},
	timestamp    = {Fri, 04 Dec 2020 15:22:44 +0100},
	biburl       = {https://dblp.org/rec/conf/nips/LewisPPPKGKLYR020.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{hase2021can,
	title        = {When can models learn from explanations? a formal framework for understanding the roles of explanation data},
	author       = {Hase, Peter and Bansal, Mohit},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2102.02201},
	url          = {https://arxiv.org/pdf/2102.02201.pdf}
}
@article{ying2023adaptive,
	title        = {Adaptive Contextual Perception: How to Generalize to New Backgrounds and Ambiguous Objects},
	author       = {Ying, Zhuofan and Hase, Peter and Bansal, Mohit},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2306.05963},
	url          = {https://arxiv.org/pdf/2306.05963.pdf}
}
@article{saha2022summarization,
	title        = {Summarization programs: Interpretable abstractive summarization with neural modular trees},
	author       = {Saha, Swarnadeep and Zhang, Shiyue and Hase, Peter and Bansal, Mohit},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2209.10492},
	url          = {https://arxiv.org/pdf/2209.10492.pdf}
}
@article{ying2022visfis,
	title        = {VisFIS: Visual Feature Importance Supervision with Right-for-the-Right-Reason Objectives},
	author       = {Ying, Zhuofan and Hase, Peter and Bansal, Mohit},
	year         = 2022,
	journal      = {Advances in Neural Information Processing Systems},
	booktitle    = {NeurIPS},
	volume       = 35,
	pages        = {17057--17072},
	url          = {https://arxiv.org/pdf/2206.11212.pdf}
}
@article{saha2023can,
	title        = {Can Language Models Teach Weaker Agents? Teacher Explanations Improve Students via Theory of Mind},
	author       = {Saha, Swarnadeep and Hase, Peter and Bansal, Mohit},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2306.09299},
	url          = {https://arxiv.org/pdf/2306.09299.pdf}
}
@article{saha2022hard,
	title        = {Are hard examples also harder to explain? a study with human and model-generated explanations},
	author       = {Saha, Swarnadeep and Hase, Peter and Rajani, Nazneen and Bansal, Mohit},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2211.07517},
	url          = {https://arxiv.org/pdf/2211.07517.pdf}
}
@article{patil2023can,
	title        = {Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks},
	author       = {Patil, Vaidehi and Hase, Peter and Bansal, Mohit},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2309.17410},
	url          = {https://arxiv.org/pdf/2309.17410.pdf}
}
@inproceedings{andrychowicz2016learning,
	title        = {Learning to learn by gradient descent by gradient descent},
	author       = {Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W and Pfau, David and Schaul, Tom and Shillingford, Brendan and De Freitas, Nando},
	year         = 2016,
	booktitle    = {NeurIPS},
	pages        = {3981--3989},
	url          = {https://proceedings.neurips.cc/paper/2016/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf}
}
@inproceedings{finn2017model,
	title        = {Model-agnostic meta-learning for fast adaptation of deep networks},
	author       = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
	year         = 2017,
	booktitle    = {ICML},
	pages        = {1126--1135},
	url          = {https://arxiv.org/pdf/1703.03400.pdf},
	organization = {PMLR}
}
@inproceedings{thorne-etal-2018-fever,
	title        = {{FEVER}: a Large-scale Dataset for Fact Extraction and {VER}ification},
	author       = {Thorne, James  and Vlachos, Andreas  and Christodoulopoulos, Christos  and Mittal, Arpit},
	year         = 2018,
	month        = jun,
	booktitle    = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {New Orleans, Louisiana},
	pages        = {809--819},
	doi          = {10.18653/v1/N18-1074},
	url          = {https://www.aclweb.org/anthology/N18-1074}
}
@inproceedings{levy-etal-2017-zero,
	title        = {Zero-Shot Relation Extraction via Reading Comprehension},
	author       = {Levy, Omer  and Seo, Minjoon  and Choi, Eunsol  and Zettlemoyer, Luke},
	year         = 2017,
	month        = aug,
	booktitle    = {Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)},
	publisher    = {Association for Computational Linguistics},
	address      = {Vancouver, Canada},
	pages        = {333--342},
	doi          = {10.18653/v1/K17-1034},
	url          = {https://aclanthology.org/K17-1034}
}
@inproceedings{card-etal-2020-little,
	title        = {With Little Power Comes Great Responsibility},
	author       = {Card, Dallas  and Henderson, Peter  and Khandelwal, Urvashi  and Jia, Robin  and Mahowald, Kyle  and Jurafsky, Dan},
	year         = 2020,
	month        = nov,
	booktitle    = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {9263--9274},
	doi          = {10.18653/v1/2020.emnlp-main.745},
	url          = {https://aclanthology.org/2020.emnlp-main.745}
}
@incollection{sep-belief,
	title        = {{Belief}},
	author       = {Schwitzgebel, Eric},
	year         = 2019,
	booktitle    = {The {Stanford} Encyclopedia of Philosophy},
	publisher    = {Metaphysics Research Lab, Stanford University},
	url          = {https://plato.stanford.edu/entries/belief/},
	editor       = {Edward N. Zalta},
	howpublished = {\url{https://plato.stanford.edu/archives/fall2019/entries/belief/}},
	edition      = {{F}all 2019}
}
@article{clarkcognizer,
	title        = {The Cognizer's Innards: A Psychological and Philosophical Perspective on the Development of Thought.},
	author       = {Clark, Andy and Karmiloff-Smith, Annette},
	year         = 1993,
	journal      = {Mind \& Language, 8(4)},
	pages        = {487–519},
	url          = {https://psycnet.apa.org/record/1994-39837-001}
}
@article{parisi2019continual,
	title        = {Continual lifelong learning with neural networks: A review},
	author       = {Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
	year         = 2019,
	journal      = {Neural Networks},
	publisher    = {Elsevier},
	volume       = 113,
	pages        = {54--71},
	url          = {https://www.sciencedirect.com/science/article/pii/S0893608019300231}
}
@inproceedings{petroni-etal-2021-kilt,
	title        = {{KILT}: a Benchmark for Knowledge Intensive Language Tasks},
	author       = {Petroni, Fabio  and Piktus, Aleksandra  and Fan, Angela  and Lewis, Patrick  and Yazdani, Majid  and De Cao, Nicola  and Thorne, James  and Jernite, Yacine  and Karpukhin, Vladimir  and Maillard, Jean  and Plachouras, Vassilis  and Rockt{\"a}schel, Tim  and Riedel, Sebastian},
	year         = 2021,
	month        = jun,
	booktitle    = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {2523--2544},
	doi          = {10.18653/v1/2021.naacl-main.200},
	url          = {https://aclanthology.org/2021.naacl-main.200}
}
@inproceedings{meng2022locating,
	title        = {Locating and editing factual knowledge in gpt},
	author       = {Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2202.05262},
	booktitle    = {NeurIPS 2022},
	url          = {https://arxiv.org/pdf/2202.05262.pdf}
}
@article{meng2022mass,
	title        = {Mass-Editing Memory in a Transformer},
	author       = {Meng, Kevin and Sharma, Arnab Sen and Andonian, Alex and Belinkov, Yonatan and Bau, David},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2210.07229},
	url          = {https://arxiv.org/pdf/2210.07229.pdf}
}
@article{chowdhery2022palm,
	title        = {PaLM: Scaling language modeling with pathways},
	author       = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2204.02311},
	url          = {https://arxiv.org/pdf/2204.02311.pdf}
}
@inproceedings{geva2020transformer,
	title        = {Transformer feed-forward layers are key-value memories},
	author       = {Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
	year         = 2021,
	booktitle    = {EMNLP},
	url          = {https://arxiv.org/pdf/2012.14913.pdf}
}
@article{geva2022transformer,
	title        = {Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space},
	author       = {Geva, Mor and Caciularu, Avi and Wang, Kevin Ro and Goldberg, Yoav},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2203.14680},
	url          = {https://arxiv.org/pdf/2203.14680.pdf}
}
@inproceedings{zhao2021non,
	title        = {Of non-linearity and commutativity in bert},
	author       = {Zhao, Sumu and Pascual, Dami{\'a}n and Brunner, Gino and Wattenhofer, Roger},
	year         = 2021,
	booktitle    = {2021 International Joint Conference on Neural Networks (IJCNN)},
	pages        = {1--8},
	url          = {https://arxiv.org/pdf/2101.04547.pdf},
	organization = {IEEE}
}
@misc{gpt-j,
	title        = {{GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model}},
	author       = {Wang, Ben and Komatsuzaki, Aran},
	year         = 2021,
	month        = May,
	howpublished = {\url{https://github.com/kingoflolz/mesh-transformer-jax}}
}
@article{hase2021language,
	title        = {Do language models have beliefs? methods for detecting, updating, and visualizing model beliefs},
	author       = {Hase, Peter and Diab, Mona and Celikyilmaz, Asli and Li, Xian and Kozareva, Zornitsa and Stoyanov, Veselin and Bansal, Mohit and Iyer, Srinivasan},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2111.13654},
	url          = {https://arxiv.org/pdf/2111.13654.pdf}
}
@inproceedings{kim2018tcav,
	title        = {Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors ({TCAV})},
	author       = {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and sayres, Rory},
	year         = 2018,
	month        = {10--15 Jul},
	booktitle    = {Proceedings of the 35th International Conference on Machine Learning},
	publisher    = {PMLR},
	series       = {Proceedings of Machine Learning Research},
	volume       = 80,
	pages        = {2668--2677},
	url          = {https://proceedings.mlr.press/v80/kim18d.html},
	editor       = {Dy, Jennifer and Krause, Andreas},
	pdf          = {http://proceedings.mlr.press/v80/kim18d/kim18d.pdf},
	abstract     = {The interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classifiers, operate on low-level features rather than high-level concepts. To address these challenges, we introduce Concept Activation Vectors (CAVs), which provide an interpretation of a neural net’s internal state in terms of human-friendly concepts. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result–for example, how sensitive a prediction of “zebra” is to the presence of stripes. Using the domain of image classification as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classification network as well as a medical application.}
}
@article{olah2018the,
	title        = {The Building Blocks of Interpretability},
	author       = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
	year         = 2018,
	journal      = {Distill},
	doi          = {10.23915/distill.00010},
	note         = {https://distill.pub/2018/building-blocks}
}
@article{mu2020compositional,
	title        = {Compositional explanations of neurons},
	author       = {Mu, Jesse and Andreas, Jacob},
	year         = 2020,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 33,
	pages        = {17153--17163},
	url          = {https://proceedings.neurips.cc/paper/2020/file/c74956ffb38ba48ed6ce977af6727275-Paper.pdf}
}
@inproceedings{schneider2021explaining,
	title        = {Explaining neural networks by decoding layer activations},
	author       = {Schneider, Johannes and Vlachos, Michalis},
	year         = 2021,
	booktitle    = {International Symposium on Intelligent Data Analysis},
	pages        = {63--75},
	url          = {https://arxiv.org/pdf/2005.13630.pdf},
	organization = {Springer}
}
@article{vig2020causal,
	title        = {Causal mediation analysis for interpreting neural nlp: The case of gender bias},
	author       = {Vig, Jesse and Gehrmann, Sebastian and Belinkov, Yonatan and Qian, Sharon and Nevo, Daniel and Sakenis, Simas and Huang, Jason and Singer, Yaron and Shieber, Stuart},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2004.12265},
	url          = {https://arxiv.org/pdf/2004.12265.pdf}
}
@inproceedings{andreas-etal-2017-translating,
	title        = {Translating Neuralese},
	author       = {Andreas, Jacob  and Dragan, Anca  and Klein, Dan},
	year         = 2017,
	month        = jul,
	booktitle    = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Vancouver, Canada},
	pages        = {232--242},
	doi          = {10.18653/v1/P17-1022},
	url          = {https://aclanthology.org/P17-1022},
	abstract     = {Several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel. While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge. Here we propose to interpret agents{'} messages by translating them. Unlike in typical machine translation problems, we have no parallel data to learn from. Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener. We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmatics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language.}
}
@article{bau2020understanding,
	title        = {Understanding the role of individual units in a deep neural network},
	author       = {Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
	year         = 2020,
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Acad Sciences},
	volume       = 117,
	number       = 48,
	pages        = {30071--30078},
	url          = {https://www.pnas.org/doi/pdf/10.1073/pnas.1907375117}
}
@article{rogers2020primer,
	title        = {A primer in bertology: What we know about how bert works},
	author       = {Rogers, Anna and Kovaleva, Olga and Rumshisky, Anna},
	year         = 2020,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	volume       = 8,
	pages        = {842--866},
	url          = {https://arxiv.org/pdf/2002.12327.pdf}
}
@inproceedings{hernandez2022natural,
	title        = {Natural Language Descriptions of Deep Visual Features},
	author       = {Hernandez, Evan and Schwettmann, Sarah and Bau, David and Bagashvili, Teona and Torralba, Antonio and Andreas, Jacob},
	year         = 2022,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/pdf?id=NudBMY-tzDr}
}
@article{radford2017learning,
	title        = {Learning to generate reviews and discovering sentiment},
	author       = {Radford, Alec and Jozefowicz, Rafal and Sutskever, Ilya},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1704.01444},
	url          = {https://arxiv.org/pdf/1704.01444.pdf}
}
@inproceedings{casper2022graphical,
	title        = {Graphical Clusterability and Local Specialization in Deep Neural Networks},
	author       = {Casper, Stephen and Hod, Shlomi and Filan, Daniel and Wild, Cody and Critch, Andrew and Russell, Stuart},
	year         = 2022,
	booktitle    = {ICLR 2022 Workshop on PAIR},
	url          = {https://arxiv.org/pdf/2110.08058v2.pdf}
}
@article{csordas2020neural,
	title        = {Are neural nets modular? inspecting functional modularity through differentiable weight masks},
	author       = {Csord{\'a}s, R{\'o}bert and van Steenkiste, Sjoerd and Schmidhuber, J{\"u}rgen},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2010.02066},
	url          = {https://arxiv.org/pdf/2010.02066.pdf}
}
@article{casper2023open,
	title        = {Open problems and fundamental limitations of reinforcement learning from human feedback},
	author       = {Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, J{\'e}r{\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and others},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2307.15217},
	url          = {https://arxiv.org/pdf/2307.15217.pdf}
}
@article{prasad2022grips,
	title        = {Grips: Gradient-free, edit-based instruction search for prompting large language models},
	author       = {Prasad, Archiki and Hase, Peter and Zhou, Xiang and Bansal, Mohit},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2203.07281},
	url          = {https://arxiv.org/pdf/2203.07281.pdf}
}
@inproceedings{de2021sparse,
	title        = {Sparse Interventions in Language Models with Differentiable Masking},
	author       = {De Cao, Nicola and Schmid, Leon and Hupkes, Dieuwke and Titov, Ivan},
	year         = 2021,
	booktitle    = {EMNLP BlackboxNLP Workshop},
	url          = {https://arxiv.org/pdf/2112.06837.pdf}
}
@article{bolukbasi2021interpretability,
	title        = {An interpretability illusion for bert},
	author       = {Bolukbasi, Tolga and Pearce, Adam and Yuan, Ann and Coenen, Andy and Reif, Emily and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2104.07143},
	url          = {https://arxiv.org/pdf/2104.07143.pdf}
}
@article{elhage2021mathematical,
	title        = {A Mathematical Framework for Transformer Circuits},
	author       = {Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
	year         = 2021,
	journal      = {Transformer Circuits Thread},
	note         = {https://transformer-circuits.pub/2021/framework/index.html}
}
@article{elhage2022superposition,
	title        = {Toy Models of Superposition},
	author       = {Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and Grosse, Roger and McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Wattenberg, Martin and Olah, Christopher},
	year         = 2022,
	journal      = {Transformer Circuits Thread},
	note         = {https://transformer-circuits.pub/2022/toy_model/index.html}
}
@inproceedings{mikolov2013efficient,
	title        = {Efficient estimation of word representations in vector space},
	author       = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	year         = 2013,
	booktitle    = {arXiv preprint arXiv:1301.3781},
	url          = {https://arxiv.org/pdf/1301.3781.pdf}
}
@inproceedings{santurkar2021editing,
	title        = {Editing a classifier by rewriting its prediction rules},
	author       = {Santurkar, Shibani and Tsipras, Dimitris and Elango, Mahalaxmi and Bau, David and Torralba, Antonio and Madry, Aleksander},
	year         = 2021,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 34,
	pages        = {23359--23373},
	url          = {https://proceedings.neurips.cc/paper/2021/file/c46489a2d5a9a9ecfc53b17610926ddd-Paper.pdf},
	editor       = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan}
}
@inproceedings{bau2020rewriting,
	title        = {Rewriting a deep generative model},
	author       = {Bau, David and Liu, Steven and Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio},
	year         = 2020,
	booktitle    = {European conference on computer vision},
	pages        = {351--369},
	url          = {https://arxiv.org/pdf/2007.15646.pdf},
	organization = {Springer}
}
@article{wang2022finding,
	title        = {Finding Skill Neurons in Pre-trained Transformer-based Language Models},
	author       = {Wang, Xiaozhi and Wen, Kaiyue and Zhang, Zhengyan and Hou, Lei and Liu, Zhiyuan and Li, Juanzi},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2211.07349},
	url          = {https://arxiv.org/pdf/2211.07349.pdf}
}
@inproceedings{lakretz2019emergence,
	title        = {The emergence of number and syntax units in LSTM language models},
	author       = {Lakretz, Yair and Kruszewski, German and Desbordes, Theo and Hupkes, Dieuwke and Dehaene, Stanislas and Baroni, Marco},
	year         = 2019,
	booktitle    = {NAACL-HLT},
	url          = {https://arxiv.org/pdf/1903.07435.pdf}
}
@article{lakretz2021mechanisms,
	title        = {Mechanisms for handling nested dependencies in neural-network language models and humans},
	author       = {Lakretz, Yair and Hupkes, Dieuwke and Vergallito, Alessandra and Marelli, Marco and Baroni, Marco and Dehaene, Stanislas},
	year         = 2021,
	month        = {04},
	journal      = {Cognition},
	volume       = 213,
	pages        = 104699,
	doi          = {10.1016/j.cognition.2021.104699},
	url          = {https://arxiv.org/ftp/arxiv/papers/2006/2006.11098.pdf}
}
@article{cui2022local,
	title        = {Local Relighting of Real Scenes},
	author       = {Cui, Audrey and Jahanian, Ali and Lapedriza, Agata and Torralba, Antonio and Mahdizadehaghdam, Shahin and Kumar, Rohit and Bau, David},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2207.02774},
	url          = {https://arxiv.org/pdf/2207.02774.pdf}
}
@article{radford2019language,
	title        = {Language models are unsupervised multitask learners},
	author       = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
	year         = 2019,
	journal      = {OpenAI blog},
	volume       = 1,
	number       = 8,
	pages        = 9,
	url          = {https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf}
}
@article{chormai2022disentangled,
	title        = {Disentangled Explanations of Neural Network Predictions by Finding Relevant Subspaces},
	author       = {Chormai, Pattarawat and Herrmann, Jan and M{\"u}ller, Klaus-Robert and Montavon, Gr{\'e}goire},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2212.14855},
	url          = {https://arxiv.org/pdf/2212.14855.pdf}
}
@inproceedings{zhou2018interpretable,
	title        = {Interpretable basis decomposition for visual explanation},
	author       = {Zhou, Bolei and Sun, Yiyou and Bau, David and Torralba, Antonio},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)},
	pages        = {119--134},
	url          = {https://people.csail.mit.edu/bzhou/publication/eccv18-IBD}
}
@article{ghorbani2019towards,
	title        = {Towards automatic concept-based explanations},
	author       = {Ghorbani, Amirata and Wexler, James and Zou, James Y and Kim, Been},
	year         = 2019,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 32,
	url          = {https://arxiv.org/pdf/1902.03129.pdf}
}
@inproceedings{zhang2021invertible,
	title        = {Invertible concept-based explanations for cnn models with non-negative concept activation vectors},
	author       = {Zhang, Ruihan and Madumal, Prashan and Miller, Tim and Ehinger, Krista A and Rubinstein, Benjamin IP},
	year         = 2021,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	url          = {https://arxiv.org/pdf/2006.15417.pdf}
}
@article{zhou2018interpreting,
	title        = {Interpreting deep visual representations via network dissection},
	author       = {Zhou, Bolei and Bau, David and Oliva, Aude and Torralba, Antonio},
	year         = 2018,
	journal      = {IEEE transactions on pattern analysis and machine intelligence},
	publisher    = {IEEE},
	volume       = 41,
	number       = 9,
	pages        = {2131--2145},
	url          = {https://arxiv.org/pdf/1711.05611.pdf}
}
@inproceedings{zeiler2014visualizing,
	title        = {Visualizing and understanding convolutional networks},
	author       = {Zeiler, Matthew D and Fergus, Rob},
	year         = 2014,
	booktitle    = {European conference on computer vision},
	pages        = {818--833},
	url          = {https://arxiv.org/pdf/1311.2901.pdf},
	organization = {Springer}
}
@article{hase2023does,
	title        = {Does Localization Inform Editing? Surprising Differences in Causality-Based Localization vs. Knowledge Editing in Language Models},
	author       = {Hase, Peter and Bansal, Mohit and Kim, Been and Ghandeharioun, Asma},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2301.04213},
	url          = {https://arxiv.org/pdf/2301.04213.pdf}
}
@misc{hase2020evaluating,
	title        = {Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?},
	author       = {Peter Hase and Mohit Bansal},
	year         = 2020,
	journal      = {ACL},
	url          = {https://arxiv.org/pdf/2005.01831.pdf},
	eprint       = {2005.01831},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{hase2020leakageadjusted,
	title        = {Leakage-Adjusted Simulatability: Can Models Generate Non-Trivial Explanations of Their Behavior in Natural Language?},
	author       = {Peter Hase and Shiyue Zhang and Harry Xie and Mohit Bansal},
	year         = 2020,
	url          = {https://arxiv.org/pdf/2010.04119.pdf},
	eprint       = {2010.04119},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{hase2021out,
	title        = {The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations},
	author       = {Hase, Peter and Xie, Harry and Bansal, Mohit},
	year         = 2021,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 34,
	pages        = {3650--3666},
	url          = {https://proceedings.neurips.cc/paper_files/paper/2021/file/1def1713ebf17722cbe300cfc1c88558-Paper.pdf},
	editor       = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan}
}
@article{lample_neural_2016,
	title        = {Neural {Architectures} for {Named} {Entity} {Recognition}},
	author       = {Lample, Guillaume and Ballesteros, Miguel and Subramanian, Sandeep and Kawakami, Kazuya and Dyer, Chris},
	year         = 2016,
	month        = mar,
	journal      = {arXiv:1603.01360 [cs]},
	url          = {http://arxiv.org/abs/1603.01360},
	urldate      = {2019-06-27},
	note         = {arXiv: 1603.01360},
	abstract     = {State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.},
	language     = {en},
	keywords     = {Computer Science - Computation and Language},
	annote       = {Comment: Proceedings of NAACL 2016},
	file         = {Lample et al. - 2016 - Neural Architectures for Named Entity Recognition.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\KK9FCMN7\\Lample et al. - 2016 - Neural Architectures for Named Entity Recognition.pdf:application/pdf}
}
@inproceedings{mai_empirical_2018,
	title        = {An {Empirical} {Study} on {Fine}-{Grained} {Named} {Entity} {Recognition}},
	author       = {Mai, Khai and Pham, Thai-Hoang and Nguyen, Minh Trung and Nguyen, Tuan Duc and Bollegala, Danushka and Sasano, Ryohei and Sekine, Satoshi},
	year         = 2018,
	month        = aug,
	booktitle    = {Proceedings of the 27th {International} {Conference} on {Computational} {Linguistics}},
	publisher    = {Association for Computational Linguistics},
	address      = {Santa Fe, New Mexico, USA},
	pages        = {711--722},
	url          = {https://www.aclweb.org/anthology/C18-1060},
	urldate      = {2019-06-27},
	abstract     = {Named entity recognition (NER) has attracted a substantial amount of research. Recently, several neural network-based models have been proposed and achieved high performance. However, there is little research on fine-grained NER (FG-NER), in which hundreds of named entity categories must be recognized, especially for non-English languages. It is still an open question whether there is a model that is robust across various settings or the proper model varies depending on the language, the number of named entity categories, and the size of training datasets. This paper first presents an empirical comparison of FG-NER models for English and Japanese and demonstrates that LSTM+CNN+CRF (Ma and Hovy, 2016), one of the state-of-the-art methods for English NER, also works well for English FG-NER but does not work well for Japanese, a language that has a large number of character types. To tackle this problem, we propose a method to improve the neural network-based Japanese FG-NER performance by removing the CNN layer and utilizing dictionary and category embeddings. Experiment results show that the proposed method improves Japanese FG-NER F-score from 66.76\% to 75.18\%.},
	annote       = {notes FG-NER human annotated data 19800 english sentences 19500 japanese sentences 200 categories data not public!!! test data is, but not the rest. they release the API for tagging. is that helpful?},
	file         = {Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\RHEVDRJF\\Mai et al. - 2018 - An Empirical Study on Fine-Grained Named Entity Re.pdf:application/pdf}
}
@inproceedings{akbik_contextual_2018,
	title        = {Contextual {String} {Embeddings} for {Sequence} {Labeling}},
	author       = {Akbik, Alan and Blythe, Duncan and Vollgraf, Roland},
	year         = 2018,
	month        = aug,
	booktitle    = {Proceedings of the 27th {International} {Conference} on {Computational} {Linguistics}},
	publisher    = {Association for Computational Linguistics},
	address      = {Santa Fe, New Mexico, USA},
	pages        = {1638--1649},
	url          = {https://www.aclweb.org/anthology/C18-1139},
	urldate      = {2019-06-27},
	abstract     = {Recent advances in language modeling using recurrent neural networks have made it viable to model language as distributions over characters. By learning to predict the next character on the basis of previous characters, such models have been shown to automatically internalize linguistic concepts such as words, sentences, subclauses and even sentiment. In this paper, we propose to leverage the internal states of a trained character language model to produce a novel type of word embedding which we refer to as contextual string embeddings. Our proposed embeddings have the distinct properties that they (a) are trained without any explicit notion of words and thus fundamentally model words as sequences of characters, and (b) are contextualized by their surrounding text, meaning that the same word will have different embeddings depending on its contextual use. We conduct a comparative evaluation against previous embeddings and find that our embeddings are highly useful for downstream tasks: across four classic sequence labeling tasks we consistently outperform the previous state-of-the-art. In particular, we significantly outperform previous work on English and German named entity recognition (NER), allowing us to report new state-of-the-art F1-scores on the CoNLL03 shared task. We release all code and pre-trained language models in a simple-to-use framework to the research community, to enable reproduction of these experiments and application of our proposed embeddings to other tasks: https://github.com/zalandoresearch/flair},
	annote       = {notes SOTA 2018 on ConLL 03 use bidirectional character level LM to produce representations that are used in a BiLSTM-CRF model they do an interesting nearest neighbors analysis for use cases of the word Washington. not great though},
	file         = {Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\JEE3DKD2\\Akbik et al. - 2018 - Contextual String Embeddings for Sequence Labeling.pdf:application/pdf}
}
@article{pham_multi-task_2019,
	title        = {Multi-{Task} {Learning} with {Contextualized} {Word} {Representations} for {Extented} {Named} {Entity} {Recognition}},
	author       = {Pham, Thai-Hoang and Mai, Khai and Trung, Nguyen Minh and Duc, Nguyen Tuan and Bolegala, Danushka and Sasano, Ryohei and Sekine, Satoshi},
	year         = 2019,
	month        = feb,
	journal      = {arXiv:1902.10118 [cs]},
	url          = {http://arxiv.org/abs/1902.10118},
	urldate      = {2019-06-27},
	note         = {arXiv: 1902.10118},
	abstract     = {Fine-Grained Named Entity Recognition (FG-NER) is critical for many NLP applications. While classical named entity recognition (NER) has attracted a substantial amount of research, FG-NER is still an open research domain. The current state-of-the-art (SOTA) model for FG-NER relies heavily on manual efforts for building a dictionary and designing hand-crafted features. The end-to-end framework which achieved the SOTA result for NER did not get the competitive result compared to SOTA model for FG-NER. In this paper, we investigate how effective multi-task learning approaches are in an end-to-end framework for FG-NER in different aspects. Our experiments show that using multi-task learning approaches with contextualized word representation can help an end-to-end neural network model achieve SOTA results without using any additional manual effort for creating data and designing features.},
	keywords     = {Computer Science - Computation and Language},
	annote       = {Comment: 7 pages, 2 figures, 4 tables},
	file         = {arXiv\:1902.10118 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\AZQYFWCA\\Pham et al. - 2019 - Multi-Task Learning with Contextualized Word Repre.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\364ZTK24\\1902.html:text/html}
}
@incollection{hutchison_fine-grained_2006,
	title        = {Fine-{Grained} {Named} {Entity} {Recognition} {Using} {Conditional} {Random} {Fields} for {Question} {Answering}},
	author       = {Lee, Changki and Hwang, Yi-Gyu and Oh, Hyo-Jung and Lim, Soojong and Heo, Jeong and Lee, Chung-Hee and Kim, Hyeon-Jin and Wang, Ji-Hyun and Jang, Myung-Gil},
	year         = 2006,
	booktitle    = {Information {Retrieval} {Technology}},
	publisher    = {Springer Berlin Heidelberg},
	address      = {Berlin, Heidelberg},
	volume       = 4182,
	pages        = {581--587},
	doi          = {10.1007/11880592_49},
	isbn         = {978-3-540-45780-0 978-3-540-46237-8},
	url          = {http://link.springer.com/10.1007/11880592_49},
	urldate      = {2019-06-27},
	abstract     = {In many QA systems, fine-grained named entities are extracted by coarse-grained named entity recognizer and fine-grained named entity dictionary. In this paper, we describe a fine-grained Named Entity Recognition using Conditional Random Fields (CRFs) for question answering. We used CRFs to detect boundary of named entities and Maximum Entropy (ME) to classify named entity classes. Using the proposed approach, we could achieve an 83.2\% precision, a 74.5\% recall, and a 78.6\% F1 for 147 fined-grained named entity types. Moreover, we reduced the training time to 27\% without loss of performance compared to a baseline model. In the question answering, The QA system with passage retrieval and AIU archived about 26\% improvement over QA with passage retrieval. The result demonstrated that our approach is effective for QA.},
	language     = {en},
	editor       = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Ng, Hwee Tou and Leong, Mun-Kew and Kan, Min-Yen and Ji, Donghong},
	annote       = {notes example of downstream task with FGNER},
	file         = {Lee et al. - 2006 - Fine-Grained Named Entity Recognition Using Condit.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\X2RMVSLY\\Lee et al. - 2006 - Fine-Grained Named Entity Recognition Using Condit.pdf:application/pdf}
}
@article{ekbal_assessing_nodate,
	title        = {Assessing the challenge of fine-grained named entity recognition and classification},
	author       = {Ekbal, Asif and Sourjikova, Eva and Frank, Anette and Ponzetto, Simone Paolo},
	pages        = 9,
	abstract     = {Named Entity Recognition and Classiﬁcation (NERC) is a well-studied NLP task typically focused on coarse-grained named entity (NE) classes. NERC for more ﬁne-grained semantic NE classes has not been systematically studied. This paper quantiﬁes the difﬁculty of ﬁne-grained NERC (FG-NERC) when performed at large scale on the people domain. We apply unsupervised acquisition methods to construct a gold standard dataset for FG-NERC. This dataset is used to benchmark methods for classifying NEs at various levels of ﬁne-grainedness using classical NERC techniques and global contextual information inspired from Word Sense Disambiguation approaches. Our results indicate high difﬁculty of the task and provide a ‘strong’ baseline for future research.},
	language     = {en},
	annote       = {notes 2010 early work on FGNER extend conll 03 data (by unsupervised method!)},
	file         = {Ekbal et al. - Assessing the challenge of fine-grained named enti.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\4Z96BW2Q\\Ekbal et al. - Assessing the challenge of fine-grained named enti.pdf:application/pdf}
}
@misc{noauthor_ling_nodate,
	title        = {Ling},
	url          = {https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5152/5124},
	urldate      = {2019-06-27},
	annote       = {notes 2012 work on FGER. unsupervised data collection as well FIGER dataset. created by distant supervision annotation 112 classes},
	file         = {Ling:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\5M6RU42Z\\5124.html:text/html}
}
@inproceedings{yosef_hyena:_2012,
	title        = {{HYENA}: {Hierarchical} {Type} {Classification} for {Entity} {Names}},
	shorttitle   = {{HYENA}},
	author       = {Yosef, Mohamed Amir and Bauer, Sandro and Hoffart, Johannes and Spaniol, Marc and Weikum, Gerhard},
	year         = 2012,
	month        = dec,
	booktitle    = {Proceedings of {COLING} 2012: {Posters}},
	publisher    = {The COLING 2012 Organizing Committee},
	address      = {Mumbai, India},
	pages        = {1361--1370},
	url          = {https://www.aclweb.org/anthology/C12-2133},
	urldate      = {2019-06-27},
	annote       = {notes 2013 FGER approach augmented data from FIGER barely beats FIGER on FIGER-Gold},
	file         = {Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\N2XFX3ZX\\Yosef et al. - 2012 - HYENA Hierarchical Type Classification for Entity.pdf:application/pdf}
}
@article{shimaoka_neural_2016,
	title        = {Neural {Architectures} for {Fine}-grained {Entity} {Type} {Classification}},
	author       = {Shimaoka, Sonse and Stenetorp, Pontus and Inui, Kentaro and Riedel, Sebastian},
	year         = 2016,
	month        = jun,
	journal      = {arXiv:1606.01341 [cs]},
	url          = {http://arxiv.org/abs/1606.01341},
	urldate      = {2019-06-27},
	note         = {arXiv: 1606.01341},
	abstract     = {In this work, we investigate several neural network architectures for fine-grained entity type classification. Particularly, we consider extensions to a recently proposed attentive neural architecture and make three key contributions. Previous work on attentive neural architectures do not consider hand-crafted features, we combine learnt and hand-crafted features and observe that they complement each other. Additionally, through quantitative analysis we establish that the attention mechanism is capable of learning to attend over syntactic heads and the phrase containing the mention, where both are known strong hand-crafted features for our task. We enable parameter sharing through a hierarchical label encoding method, that in low-dimensional projections show clear clusters for each type hierarchy. Lastly, despite using the same evaluation dataset, the literature frequently compare models trained using different data. We establish that the choice of training data has a drastic impact on performance, with decreases by as much as 9.85\% loose micro F1 score for a previously proposed method. Despite this, our best model achieves state-of-the-art results with 75.36\% loose micro F1 score on the well- established FIGER (GOLD) dataset.},
	keywords     = {Computer Science - Computation and Language},
	annote       = {Comment: 10 pages, 3 figures, accepted at EACL2017 conference},
	file         = {arXiv\:1606.01341 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\G47J3EYR\\Shimaoka et al. - 2016 - Neural Architectures for Fine-grained Entity Type .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\BJKI629C\\1606.html:text/html}
}
@inproceedings{ren_label_2016,
	title        = {Label {Noise} {Reduction} in {Entity} {Typing} by {Heterogeneous} {Partial}-{Label} {Embedding}},
	author       = {Ren, Xiang and He, Wenqi and Qu, Meng and Voss, Clare R. and Ji, Heng and Han, Jiawei},
	year         = 2016,
	booktitle    = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} - {KDD} '16},
	publisher    = {ACM Press},
	address      = {San Francisco, California, USA},
	pages        = {1825--1834},
	doi          = {10.1145/2939672.2939822},
	isbn         = {978-1-4503-4232-2},
	url          = {http://dl.acm.org/citation.cfm?doid=2939672.2939822},
	urldate      = {2019-06-27},
	abstract     = {Current systems of ﬁne-grained entity typing use distant supervision in conjunction with existing knowledge bases to assign categories (type labels) to entity mentions. However, the type labels so obtained from knowledge bases are often noisy (i.e., incorrect for the entity mention’s local context). We deﬁne a new task, Label Noise Reduction in Entity Typing (LNR), to be the automatic identiﬁcation of correct type labels (type-paths) for training examples, given the set of candidate type labels obtained by distant supervision with a given type hierarchy. The unknown type labels for individual entity mentions and the semantic similarity between entity types pose unique challenges for solving the LNR task. We propose a general framework, called PLE, to jointly embed entity mentions, text features and entity types into the same low-dimensional space where, in that space, objects whose types are semantically close have similar representations. Then we estimate the type-path for each training example in a top-down manner using the learned embeddings. We formulate a global objective for learning the embeddings from text corpora and knowledge bases, which adopts a novel margin-based loss that is robust to noisy labels and faithfully models type correlation derived from knowledge bases. Our experiments on three public typing datasets demonstrate the eﬀectiveness and robustness of PLE, with an average of 25\% improvement in accuracy compared to next best method.},
	language     = {en},
	annote       = {notes gives data used in shimaoka 2017},
	file         = {Ren et al. - 2016 - Label Noise Reduction in Entity Typing by Heteroge.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\4RDG3TDX\\Ren et al. - 2016 - Label Noise Reduction in Entity Typing by Heteroge.pdf:application/pdf}
}
@inproceedings{abhishek_fine-grained_2017,
	title        = {Fine-{Grained} {Entity} {Type} {Classification} by {Jointly} {Learning} {Representations} and {Label} {Embeddings}},
	author       = {Abhishek, Abhishek and Anand, Ashish and Awekar, Amit},
	year         = 2017,
	month        = apr,
	booktitle    = {Proceedings of the 15th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Volume} 1, {Long} {Papers}},
	publisher    = {Association for Computational Linguistics},
	address      = {Valencia, Spain},
	pages        = {797--807},
	url          = {https://www.aclweb.org/anthology/E17-1075},
	urldate      = {2019-06-27}
}
@article{murty_hierarchical_nodate,
	title        = {Hierarchical {Losses} and {New} {Resources} for {Fine}-grained {Entity} {Typing} and {Linking}},
	author       = {Murty, Shikhar and Verga, Patrick and Vilnis, Luke and Radovanovic, Irena and McCallum, Andrew},
	pages        = 13,
	abstract     = {Extraction from raw text to a knowledge base of entities and ﬁne-grained types is often cast as prediction into a ﬂat set of entity and type labels, neglecting the rich hierarchies over types and entities contained in curated ontologies. Previous attempts to incorporate hierarchical structure have yielded little beneﬁt and are restricted to shallow ontologies. This paper presents new methods using real and complex bilinear mappings for integrating hierarchical information, yielding substantial improvement over ﬂat predictions in entity linking and ﬁne-grained entity typing, and achieving new state-of-the-art results for end-to-end models on the benchmark FIGER dataset. We also present two new human-annotated datasets containing wide and deep hierarchies which we will release to the community to encourage further research in this direction: MedMentions, a collection of PubMed abstracts in which 246k mentions have been mapped to the massive UMLS ontology; and TypeNet, which aligns Freebase types with the WordNet hierarchy to obtain nearly 2k entity types. In experiments on all three datasets we show substantial gains from hierarchy-aware training.},
	language     = {en},
	annote       = {notes make the hierarchy deeper! better for such datasets? SOTA over simaokoa on FIGER...barely but with no handcrafted features},
	file         = {Murty et al. - Hierarchical Losses and New Resources for Fine-gra.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\MSTGD464\\Murty et al. - Hierarchical Losses and New Resources for Fine-gra.pdf:application/pdf}
}
@article{murty_finer_nodate,
	title        = {Finer {Grained} {Entity} {Typing} with {TypeNet}},
	author       = {Murty, Shikhar and Verga, Patrick and Vilnis, Luke and McCallum, Andrew},
	pages        = 7,
	abstract     = {We consider the challenging problem of entity typing over an extremely ﬁne grained set of types, wherein a single mention or entity can have many simultaneous and often hierarchically-structured types. Despite the importance of the problem, there is a relative lack of resources in the form of ﬁne-grained, deep type hierarchies aligned to existing knowledge bases. In response, we introduce TypeNet, a dataset of entity types consisting of over 1941 types organized in a hierarchy, obtained by manually annotating a mapping from 1081 Freebase types to WordNet. We also experiment with several models comparable to state-of-the-art systems and explore techniques to incorporate a structure loss on the hierarchy with the standard mention typing loss, as a ﬁrst step towards future research on this dataset.},
	language     = {en},
	annote       = {notes TypeNet paper},
	file         = {Murty et al. - Finer Grained Entity Typing with TypeNet.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\SBSQ4J4K\\Murty et al. - Finer Grained Entity Typing with TypeNet.pdf:application/pdf}
}
@article{lei_interpretable_nodate,
	title        = {Interpretable {Neural} {Models} for {Natural} {Language} {Processing}},
	author       = {Lei, Tao},
	pages        = 119,
	abstract     = {The success of neural network models often comes at a cost of interpretability. This thesis addresses the problem by providing justifications behind the model’s structure and predictions.},
	language     = {en},
	annote       = {notes "From this perspective, ourrationales are simply subsets of the words from the input text that satisfy two keyproperties. First, the selected words represent short and coherent pieces of text (e.g.,phrases) and, second, the selected words must alone suffice for prediction as a substitute of the original text. In most practical applications, rationale generation mustbe learned entirely in an unsupervised manner." identify important words from the input that are sufficient for the classification},
	file         = {Lei - Interpretable Neural Models for Natural Language P.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\T8MG4T2A\\Lei - Interpretable Neural Models for Natural Language P.pdf:application/pdf}
}
@inproceedings{li_visualizing_2016,
	title        = {Visualizing and {Understanding} {Neural} {Models} in {NLP}},
	author       = {Li, Jiwei and Chen, Xinlei and Hovy, Eduard and Jurafsky, Dan},
	year         = 2016,
	month        = jun,
	booktitle    = {Proceedings of the 2016 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher    = {Association for Computational Linguistics},
	pages        = {681--691},
	doi          = {10.18653/v1/N16-1082},
	url          = {https://www.aclweb.org/anthology/N16-1082},
	urldate      = {2019-06-27}
}
@inproceedings{wallace_interpreting_2018,
	title        = {Interpreting {Neural} {Networks} with {Nearest} {Neighbors}},
	author       = {Wallace, Eric and Feng, Shi and Boyd-Graber, Jordan},
	year         = 2018,
	month        = nov,
	booktitle    = {Proceedings of the 2018 {EMNLP} {Workshop} {BlackboxNLP}: {Analyzing} and {Interpreting} {Neural} {Networks} for {NLP}},
	publisher    = {Association for Computational Linguistics},
	address      = {Brussels, Belgium},
	pages        = {136--144},
	url          = {https://www.aclweb.org/anthology/W18-5416},
	urldate      = {2019-06-27},
	abstract     = {Local model interpretation methods explain individual predictions by},
	annote       = {
		notes important paper! a number of NLP tasks, but not entity recognition key idea: systematically manipulate the input and check changes in the classification, which works better when using a notion of conformity among representations than when checking for changes in the classification confidence three methods for interpreting importance of pieces of the input (still saliency, more or less?)

		conformity confidence gradient

		they use a d-KNN method and adjust the input systematically: remove a word in the input and measure change in conformity/confidence/gradient. this gives notion of importance (and valence) of that word to the classification conformity score is based on representations at every layer in the model, and therefore a prediction only receives high conformity if it largely agrees with neighboring examples at all representation levels; this helps defend against adversarial attacks they characterize the approach has higher precision lower recall than confidence approach

		interpretability metrics mostly qualitative illustrations of reasonable of model performance based on saliency maps

		this paper relies on the interpretability of the saliency map to assert the "interpretability' of its method. it is an instance of trust in the saliency method; these methods locate interpretability in logit gradients. this is sensible. it indicates that the class is literally changing as the input changes. in Tinbergen language however, these models are not locating explanations at the conceptual level, but at the logit level what are the problems with sailence approaches? they can fail the Kim tests
	},
	file         = {Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\A73QYTKN\\Wallace et al. - 2018 - Interpreting Neural Networks with Nearest Neighbor.pdf:application/pdf}
}
@article{doshi-velez_towards_2017,
	title        = {Towards {A} {Rigorous} {Science} of {Interpretable} {Machine} {Learning}},
	author       = {Doshi-Velez, Finale and Kim, Been},
	year         = 2017,
	month        = feb,
	journal      = {arXiv:1702.08608 [cs, stat]},
	url          = {http://arxiv.org/abs/1702.08608},
	urldate      = {2019-07-22},
	note         = {arXiv: 1702.08608},
	abstract     = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.},
	keywords     = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote       = {
		2017 def. Interpret means to explain or to present in understandable terms

		confirming other desiderata 1. fairness 2. robustness 3. causlity 4. usable 5. trusted incompleteness (of problem formulation) 1. scientific understanding 2. safety 3. ethics 4. mismatched objectives 5. multi-objective tradeoffs taxonomy 1. application grounded 2. human-grounded 3. functionally-grounded experiments (human grounded) 1. pick which of two explanations for a prediction is better 2. forward simulation: predict the prediction given input and explanation 3. counterfactual simulation: humans are presented with explanation, input, and output, and must identify the changes necessary to adjust the model output task-related dimensions of interpretability 1. global vs. local 2. area, severity of incompleteness 3. time constraints 4. user expertise method-related dimensions of interpretability 1. form of cognitive chunks 2. number of cognitive chunks 3. level of compositionality 4. monotonicity and interactions between chunks 5. uncertainty and stochasticity design questions 1. how is the problem formulation incomplete 2. at what level is the evaluation being performed? 3. what are task-related relevant factors 4. what are method-related relevant factors?
	},
	file         = {arXiv\:1702.08608 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\RSJ3VKN7\\Doshi-Velez and Kim - 2017 - Towards A Rigorous Science of Interpretable Machin.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\6SGWLXPE\\1702.html:text/html}
}
@article{lage_evaluation_2019,
	title        = {An {Evaluation} of the {Human}-{Interpretability} of {Explanation}},
	author       = {Lage, Isaac and Chen, Emily and He, Jeffrey and Narayanan, Menaka and Kim, Been and Gershman, Sam and Doshi-Velez, Finale},
	year         = 2019,
	month        = jan,
	journal      = {arXiv:1902.00006 [cs, stat]},
	url          = {http://arxiv.org/abs/1902.00006},
	urldate      = {2019-07-22},
	note         = {arXiv: 1902.00006},
	abstract     = {Recent years have seen a boom in interest in machine learning systems that can provide a human-understandable rationale for their predictions or decisions. However, exactly what kinds of explanation are truly human-interpretable remains poorly understood. This work advances our understanding of what makes explanations interpretable under three specific tasks that users may perform with machine learning systems: simulation of the response, verification of a suggested response, and determining whether the correctness of a suggested response changes under a change to the inputs. Through carefully controlled human-subject experiments, we identify regularizers that can be used to optimize for the interpretability of machine learning systems. Our results show that the type of complexity matters: cognitive chunks (newly defined concepts) affect performance more than variable repetitions, and these trends are consistent across tasks and domains. This suggests that there may exist some common design principles for explanation systems.},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote       = {2019 empirical study of important factors in interpretability use framework for Towards a Rigorous Science simulation; verification; counterfactual verification - people given the input, explanation, and output, and asked to verify that the output is correct given the input and explanation counterfactual - judge if a change to the input would change the model prediction conditions 1. explanation size 2. cognitive chunks 3. repeated terms in explanations results about what you'd expect. the more complex the explanation, the longer the response time, and the less humans are satisfied with the results. however human trust exhibits a sweet spot wrt explanation complexity},
	file         = {arXiv\:1902.00006 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\9FLJ6QRF\\Lage et al. - 2019 - An Evaluation of the Human-Interpretability of Exp.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\TXS2B3GT\\1902.html:text/html}
}
@article{ribeiro_why_2016,
	title        = {"{Why} {Should} {I} {Trust} {You}?": {Explaining} the {Predictions} of {Any} {Classifier}},
	shorttitle   = {"{Why} {Should} {I} {Trust} {You}?},
	author       = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	year         = 2016,
	month        = feb,
	journal      = {Knowledge Discovery and Data Mining (KDD)},
	url          = {http://arxiv.org/abs/1602.04938},
	urldate      = {2019-07-22},
	keywords     = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning}
}
@article{plumb_model_2018,
	title        = {Model {Agnostic} {Supervised} {Local} {Explanations}},
	author       = {Plumb, Gregory and Molitor, Denali and Talwalkar, Ameet},
	year         = 2018,
	month        = jul,
	journal      = {arXiv:1807.02910 [cs, stat]},
	url          = {http://arxiv.org/abs/1807.02910},
	urldate      = {2019-07-22},
	note         = {arXiv: 1807.02910},
	abstract     = {Model interpretability is an increasingly important component of practical machine learning. Some of the most common forms of interpretability systems are example-based, local, and global explanations. One of the main challenges in interpretability is designing explanation systems that can capture aspects of each of these explanation types, in order to develop a more thorough understanding of the model. We address this challenge in a novel model called MAPLE that uses local linear modeling techniques along with a dual interpretation of random forests (both as a supervised neighborhood approach and as a feature selection method). MAPLE has two fundamental advantages over existing interpretability systems. First, while it is effective as a black-box explanation system, MAPLE itself is a highly accurate predictive model that provides faithful self explanations, and thus sidesteps the typical accuracy-interpretability trade-off. Specifically, we demonstrate, on several UCI datasets, that MAPLE is at least as accurate as random forests and that it produces more faithful local explanations than LIME, a popular interpretability system. Second, MAPLE provides both example-based and local explanations and can detect global patterns, which allows it to diagnose limitations in its local explanations.},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote       = {2019 MAPLE -- claims to beat LIME taxonomy example-based: knn or prototypes local: sparse linear models in a neighborhod global: rule lists experiments so they test a bunch of accuracy metrics, while apparently taking their method to be at least as interpretable as LIME!},
	file         = {arXiv\:1807.02910 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\77TLUKQ3\\Plumb et al. - 2018 - Model Agnostic Supervised Local Explanations.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\LDYH7T5R\\1807.html:text/html}
}
@article{lipton_mythos_2016,
	title        = {The {Mythos} of {Model} {Interpretability}},
	author       = {Lipton, Zachary C.},
	year         = 2016,
	month        = jun,
	journal      = {2016 ICML Workshop on Human Interpretability in Machine Learning},
	url          = {http://arxiv.org/abs/1606.03490},
	urldate      = {2019-07-22},
	keywords     = {Computer Science - Neural and Evolutionary Computing, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote       = {came out dates after Towards a Rigorous Science, presents a very similar message i think we want causal explanations not of nature but of the model itself},
	file         = {arXiv\:1606.03490 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\RWY42QWW\\Lipton - 2016 - The Mythos of Model Interpretability.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\9L84UZX2\\1606.html:text/html}
}
@article{gilpin_explaining_2018,
	title        = {Explaining {Explanations}: {An} {Overview} of {Interpretability} of {Machine} {Learning}},
	shorttitle   = {Explaining {Explanations}},
	author       = {Gilpin, Leilani H. and Bau, David and Yuan, Ben Z. and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
	year         = 2018,
	month        = may,
	journal      = {The 5th IEEE International Conference on Data Science and Advanced Analytics (DSAA 2018)},
	url          = {http://arxiv.org/abs/1806.00069},
	urldate      = {2019-07-22},
	keywords     = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote       = {Comment: The 5th IEEE International Conference on Data Science and Advanced Analytics (DSAA 2018). [Research Track]},
	file         = {arXiv\:1806.00069 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\ERVAN7XJ\\Gilpin et al. - 2018 - Explaining Explanations An Overview of Interpreta.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\BH8HGEII\\1806.html:text/html}
}
@inproceedings{poerner_interpretable_2018,
	title        = {Interpretable {Textual} {Neuron} {Representations} for {NLP}},
	author       = {Poerner, Nina and Roth, Benjamin and Schütze, Hinrich},
	year         = 2018,
	month        = nov,
	booktitle    = {Proceedings of the 2018 {EMNLP} {Workshop} {BlackboxNLP}: {Analyzing} and {Interpreting} {Neural} {Networks} for {NLP}},
	publisher    = {Association for Computational Linguistics},
	address      = {Brussels, Belgium},
	pages        = {325--327},
	url          = {https://www.aclweb.org/anthology/W18-5437},
	urldate      = {2019-07-22},
	abstract     = {Input optimization methods, such as Google Deep Dream, create interpretable representations of neurons for computer vision DNNs. We propose and evaluate ways of transferring this technology to NLP. Our results suggest that gradient ascent with a gumbel softmax layer produces n-gram representations that outperform naive corpus search in terms of target neuron activation. The representations highlight differences in syntax awareness between the language and visual models of the Imaginet architecture.},
	annote       = {2018 translation of neuron activiation maximization to NLP for purposes of figuring out what activates neurons},
	file         = {Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\8QJ5I5M3\\Poerner et al. - 2018 - Interpretable Textual Neuron Representations for N.pdf:application/pdf}
}
@inproceedings{harbecke_learning_2018,
	title        = {Learning {Explanations} from {Language} {Data}},
	author       = {Harbecke, David and Schwarzenberg, Robert and Alt, Christoph},
	year         = 2018,
	month        = nov,
	booktitle    = {Proceedings of the 2018 {EMNLP} {Workshop} {BlackboxNLP}: {Analyzing} and {Interpreting} {Neural} {Networks} for {NLP}},
	publisher    = {Association for Computational Linguistics},
	address      = {Brussels, Belgium},
	pages        = {316--318},
	url          = {https://www.aclweb.org/anthology/W18-5434},
	urldate      = {2019-07-22},
	abstract     = {PatternAttribution is a recent method, introduced in the vision domain, that explains classifications of deep neural networks. We demonstrate that it also generates meaningful interpretations in the language domain.},
	annote       = {2018 saliency but for bigrams, adapted from vision for NLP},
	file         = {Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\E3T5SPY8\\Harbecke et al. - 2018 - Learning Explanations from Language Data.pdf:application/pdf}
}
@article{guidotti_survey_2018,
	title        = {A {Survey} {Of} {Methods} {For} {Explaining} {Black} {Box} {Models}},
	author       = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Pedreschi, Dino and Giannotti, Fosca},
	year         = 2018,
	month        = feb,
	journal      = {arXiv:1802.01933 [cs]},
	url          = {http://arxiv.org/abs/1802.01933},
	urldate      = {2019-07-23},
	note         = {arXiv: 1802.01933},
	abstract     = {In the last years many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness sometimes at the cost of scarifying accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, delineating explicitly or implicitly its own definition of interpretability and explanation. The aim of this paper is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
	keywords     = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computers and Society},
	annote       = {2018 big survey. lists a variety of interpretation methods,including prototype selection. this explanator consists in returning an example very similar to a new classified record, along with the outcome},
	file         = {arXiv\:1802.01933 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\YPD9Q8YY\\Guidotti et al. - 2018 - A Survey Of Methods For Explaining Black Box Model.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\QPNF3FZG\\1802.html:text/html}
}
@inproceedings{gpt3,
	title        = {Language Models are Few-Shot Learners},
	author       = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert{-}Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
	year         = 2020,
	booktitle    = {NeurIPS},
	url          = {https://arxiv.org/abs/2005.14165},
	editor       = {Hugo Larochelle and Marc'Aurelio Ranzato and Raia Hadsell and Maria{-}Florina Balcan and Hsuan{-}Tien Lin},
	timestamp    = {Fri, 04 Dec 2020 15:22:44 +0100},
	biburl       = {https://dblp.org/rec/conf/nips/BrownMRSKDNSSAA20.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{guo2020fastif,
	title        = {Fastif: Scalable influence functions for efficient model interpretation and debugging},
	author       = {Guo, Han and Rajani, Nazneen Fatema and Hase, Peter and Bansal, Mohit and Xiong, Caiming},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2012.15781},
	url          = {https://arxiv.org/pdf/2012.15781.pdf}
}
@article{yadav2021low,
	title        = {{INSPIRE}: Incorporating Diverse Feature Preferences in Recourse},
	author       = {Yadav, Prateek and Hase, Peter and Bansal, Mohit},
	year         = 2021,
	journal      = {arxiv},
	url          = {https://openreview.net/pdf?id=6yzIuqKGnq}
}
@article{zou2023representation,
	title        = {Representation Engineering: A Top-Down Approach to AI Transparency},
	author       = {Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2310.01405},
	url          = {https://arxiv.org/pdf/2310.01405.pdf}
}
@article{ling_fine-grained_nodate,
	title        = {Fine-{Grained} {Entity} {Recognition}},
	author       = {Ling, Xiao and Weld, Daniel S},
	pages        = 7,
	abstract     = {Entity Recognition (ER) is a key component of relation extraction systems and many other natural-language processing applications. Unfortunately, most ER systems are restricted to produce labels from to a small set of entity classes, e.g., person, organization, location or miscellaneous. In order to intelligently understand text and extract a wide range of information, it is useful to more precisely determine the semantic classes of entities mentioned in unstructured text. This paper deﬁnes a ﬁne-grained set of 112 tags, formulates the tagging problem as multi-class, multi-label classiﬁcation, describes an unsupervised method for collecting training data, and presents the FIGER implementation. Experiments show that the system accurately predicts the tags for entities. Moreover, it provides useful information for a relation extraction system, increasing the F1 score by 93\%. We make FIGER and its data available as a resource for future work.},
	language     = {en},
	annote       = {2012 early work on fine-grained ER},
	file         = {Ling and Weld - Fine-Grained Entity Recognition.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\52T2XMKU\\Ling and Weld - Fine-Grained Entity Recognition.pdf:application/pdf}
}
@inproceedings{shimaoka_attentive_2016,
	title        = {An {Attentive} {Neural} {Architecture} for {Fine}-grained {Entity} {Type} {Classification}},
	author       = {Shimaoka, Sonse and Stenetorp, Pontus and Inui, Kentaro and Riedel, Sebastian},
	year         = 2016,
	month        = jun,
	booktitle    = {Proceedings of the 5th {Workshop} on {Automated} {Knowledge} {Base} {Construction}},
	publisher    = {Association for Computational Linguistics},
	pages        = {69--74},
	doi          = {10.18653/v1/W16-1313},
	url          = {https://www.aclweb.org/anthology/W16-1313},
	urldate      = {2019-07-23},
	annote       = {2016 2016 version of Shimaoka 2017},
	file         = {Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\C4VA8RPZ\\Shimaoka et al. - 2016 - An Attentive Neural Architecture for Fine-grained .pdf:application/pdf}
}
@article{peters_deep_2018,
	title        = {Deep contextualized word representations},
	author       = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
	year         = 2018,
	month        = feb,
	journal      = {arXiv:1802.05365 [cs]},
	url          = {http://arxiv.org/abs/1802.05365},
	urldate      = {2019-07-23},
	note         = {arXiv: 1802.05365},
	abstract     = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.},
	keywords     = {Computer Science - Computation and Language},
	annote       = {2018 previous SOTA for NER on ConLL, beat by Akbik does something with ELMO},
	file         = {arXiv\:1802.05365 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\NN9ZB3DT\\Peters et al. - 2018 - Deep contextualized word representations.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\XH3U4PF4\\1802.html:text/html}
}
@inproceedings{akbik_pooled_2019,
	title        = {Pooled {Contextualized} {Embeddings} for {Named} {Entity} {Recognition}},
	author       = {Akbik, Alan and Bergmann, Tanja and Vollgraf, Roland},
	year         = 2019,
	month        = jun,
	booktitle    = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} and {Short} {Papers})},
	publisher    = {Association for Computational Linguistics},
	address      = {Minneapolis, Minnesota},
	pages        = {724--728},
	url          = {https://www.aclweb.org/anthology/N19-1078},
	urldate      = {2019-07-30},
	abstract     = {Contextual string embeddings are a recent type of contextualized word embedding that were shown to yield state-of-the-art results when utilized in a range of sequence labeling tasks. They are based on character-level language models which treat text as distributions over characters and are capable of generating embeddings for any string of characters within any textual context. However, such purely character-based approaches struggle to produce meaningful embeddings if a rare string is used in a underspecified context. To address this drawback, we propose a method in which we dynamically aggregate contextualized embeddings of each unique string that we encounter. We then use a pooling operation to distill a ”global” word representation from all contextualized instances. We evaluate these ”pooled contextualized embeddings” on common named entity recognition (NER) tasks such as CoNLL-03 and WNUT and show that our approach significantly improves the state-of-the-art for NER. We make all code and pre-trained models available to the research community for use and reproduction.},
	annote       = {June 2019 Akbik improves on Akbik. On CoNLL},
	file         = {Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\5GM5A7FD\\Akbik et al. - 2019 - Pooled Contextualized Embeddings for Named Entity .pdf:application/pdf}
}
@article{ma_end--end_2016,
	title        = {End-to-end {Sequence} {Labeling} via {Bi}-directional {LSTM}-{CNNs}-{CRF}},
	author       = {Ma, Xuezhe and Hovy, Eduard},
	year         = 2016,
	month        = mar,
	journal      = {arXiv:1603.01354 [cs, stat]},
	url          = {http://arxiv.org/abs/1603.01354},
	urldate      = {2019-08-05},
	note         = {arXiv: 1603.01354},
	abstract     = {State-of-the-art sequence labeling systems traditionally require large amounts of task-specific knowledge in the form of hand-crafted features and data pre-processing. In this paper, we introduce a novel neutral network architecture that benefits from both word- and character-level representations automatically, by using combination of bidirectional LSTM, CNN and CRF. Our system is truly end-to-end, requiring no feature engineering or data pre-processing, thus making it applicable to a wide range of sequence labeling tasks. We evaluate our system on two data sets for two sequence labeling tasks --- Penn Treebank WSJ corpus for part-of-speech (POS) tagging and CoNLL 2003 corpus for named entity recognition (NER). We obtain state-of-the-art performance on both the two data --- 97.55{\textbackslash}\% accuracy for POS tagging and 91.21{\textbackslash}\% F1 for NER.},
	keywords     = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote       = {Comment: 10 pages, 3 figures. To appear on ACL 2016},
	file         = {arXiv\:1603.01354 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\3K9PTNU3\\Ma and Hovy - 2016 - End-to-end Sequence Labeling via Bi-directional LS.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\BBRFB855\\1603.html:text/html}
}
@article{chernodub_targer:_nodate,
	title        = {{TARGER}: {Neural} {Argument} {Mining} at {Your} {Fingertips}},
	author       = {Chernodub, Artem and Oliynyk, Oleksiy and Heidenreich, Philipp and Bondarenko, Alexander and Hagen, Matthias and Biemann, Chris and Panchenko, Alexander},
	year         = 2019,
	journal      = {ACL System Demonstrations}
}
@article{serrano_is_2019,
	title        = {Is {Attention} {Interpretable}?},
	author       = {Serrano, Sofia and Smith, Noah A.},
	year         = 2019,
	month        = jun,
	journal      = {arXiv:1906.03731 [cs]},
	url          = {http://arxiv.org/abs/1906.03731},
	urldate      = {2019-08-05},
	note         = {arXiv: 1906.03731},
	abstract     = {Attention mechanisms have recently boosted performance on a range of NLP tasks. Because attention layers explicitly weight input components' representations, it is also often assumed that attention can be used to identify information that models found important (e.g., specific contextualized word tokens). We test whether that assumption holds by manipulating attention weights in already-trained text classification models and analyzing the resulting differences in their predictions. While we observe some ways in which higher attention weights correlate with greater impact on model predictions, we also find many ways in which this does not hold, i.e., where gradient-based rankings of attention weights better predict their effects than their magnitudes. We conclude that while attention noisily predicts input components' overall importance to a model, it is by no means a fail-safe indicator.},
	keywords     = {Computer Science - Computation and Language},
	annote       = {Comment: To appear at ACL 2019},
	file         = {arXiv\:1906.03731 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\XFSSHQJW\\Serrano and Smith - 2019 - Is Attention Interpretable.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\2YKJJIBA\\1906.html:text/html}
}
@article{gehrmann_gltr:_2019,
	title        = {{GLTR}: {Statistical} {Detection} and {Visualization} of {Generated} {Text}},
	shorttitle   = {{GLTR}},
	author       = {Gehrmann, Sebastian and Strobelt, Hendrik and Rush, Alexander M.},
	year         = 2019,
	month        = jun,
	journal      = {arXiv:1906.04043 [cs]},
	url          = {http://arxiv.org/abs/1906.04043},
	urldate      = {2019-08-05},
	note         = {arXiv: 1906.04043},
	abstract     = {The rapid improvement of language models has raised the specter of abuse of text generation systems. This progress motivates the development of simple methods for detecting generated text that can be used by and explained to non-experts. We develop GLTR, a tool to support humans in detecting whether a text was generated by a model. GLTR applies a suite of baseline statistical methods that can detect generation artifacts across common sampling schemes. In a human-subjects study, we show that the annotation scheme provided by GLTR improves the human detection-rate of fake text from 54\% to 72\% without any prior training. GLTR is open-source and publicly deployed, and has already been widely used to detect generated outputs},
	keywords     = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Human-Computer Interaction},
	annote       = {2019 create tool for detecting + generating explanations for a text being machine-generated rather than human-generated the premise is that models oversample from a portion of the training distribution on which they are very confident method. unsupervised. three metrics of (over)confidence. - probability of next wod - absolute rank of next word in distribution - entropy of sequence including the word how do they avoid giving away the answer on their test? well the method is unsupervised, so there is no class output to give away but they check to see how a log reg would discriminate real/fake given the first two features (or derivatives thereof given the whole text). so it's like, maybe it turns out that lots of low-prob words means real, and you tell people this with the method. so humans performed much better with the interface. brief explanation and an example of two texts were presented. i bet they learn the rule "not-green means fake" and simulated the log reg},
	file         = {arXiv\:1906.04043 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\Q3WCFE2L\\Gehrmann et al. - 2019 - GLTR Statistical Detection and Visualization of G.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\586CVX83\\1906.html:text/html}
}
@incollection{frasincar_what_2017,
	title        = {“{What} {Does} {My} {Classifier} {Learn}?” {A} {Visual} {Approach} to {Understanding} {Natural} {Language} {Text} {Classifiers}},
	shorttitle   = {“{What} {Does} {My} {Classifier} {Learn}?},
	author       = {Winkler, Jonas Paul and Vogelsang, Andreas},
	year         = 2017,
	booktitle    = {Natural {Language} {Processing} and {Information} {Systems}},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	volume       = 10260,
	pages        = {468--479},
	doi          = {10.1007/978-3-319-59569-6_55},
	isbn         = {978-3-319-59568-9 978-3-319-59569-6},
	url          = {http://link.springer.com/10.1007/978-3-319-59569-6_55},
	urldate      = {2019-08-20},
	abstract     = {Neural Networks have been utilized to solve various tasks such as image recognition, text classiﬁcation, and machine translation and have achieved exceptional results in many of these tasks. However, understanding the inner workings of neural networks and explaining why a certain output is produced are no trivial tasks. Especially when dealing with text classiﬁcation problems, an approach to explain network decisions may greatly increase the acceptance of neural network supported tools. In this paper, we present an approach to visualize reasons why a classiﬁcation outcome is produced by convolutional neural networks by tracing back decisions made by the network. The approach is applied to various text classiﬁcation problems, including our own requirements engineering related classiﬁcation problem. We argue that by providing these explanations in neural network supported tools, users will use such tools with more conﬁdence and also may allow the tool to do certain tasks automatically.},
	language     = {en},
	editor       = {Frasincar, Flavius and Ittoo, Ashwin and Nguyen, Le Minh and Métais, Elisabeth},
	annote       = {2017 applied interpretability example with class activation maps highlighting words 3 datasets The Requirements dataset contains natural language requirements written in German andtaken from multiple requirement specification documents describing automotive components and systems, such as wiper control, outside lighting, etc. Italso contains an equal number of Information objects (e.g. examples, informaldescriptions, and references). More information on this dataset is given in Sect. 5.The Question dataset1 contains short natural language questions asking fordifferent kinds of answers, such as locations, numeric answers (dates, numbers),persons, entities, descriptions, and abbreviations. The task is to detect whatkind of information a question asks for.The Movie Reviews dataset2 consists of single line movie reviews. These areeither positive or negative.},
	file         = {Winkler and Vogelsang - 2017 - “What Does My Classifier Learn” A Visual Approach.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\G9BUSYA7\\Winkler and Vogelsang - 2017 - “What Does My Classifier Learn” A Visual Approach.pdf:application/pdf}
}
@article{jawahar_what_nodate,
	title        = {What {Does} {BERT} {Learn} about the {Structure} of {Language}?},
	author       = {Jawahar, Ganesh and Sagot, Benoît and Seddah, Djamé},
	pages        = 7,
	abstract     = {BERT is a recent language representation model that has surprisingly performed well in diverse language understanding benchmarks. This result indicates the possibility that BERT networks capture structural information about language. In this work, we provide novel support for this claim by performing a series of experiments to unpack the elements of English language structure learned by BERT. We ﬁrst show that BERT’s phrasal representation captures phrase-level information in the lower layers. We also show that BERT’s intermediate layers encode a rich hierarchy of linguistic information, with surface features at the bottom, syntactic features in the middle and semantic features at the top. BERT turns out to require deeper layers when long-distance dependency information is required, e.g. to track subjectverb agreement. Finally, we show that BERT representations capture linguistic information in a compositional way that mimics classical, tree-like structures.},
	language     = {en},
	annote       = {2019 bert learns phase info (np, vp, pp) in early layers and the info is diluted in later layers use probes, models on intermediate bert layers trained on auxiliary tasks, to assess where information is best represented BERT embeds a rich hierarchy of linguistic signals: surface information atthe bottom, syntactic information in the middle,semantic information at the top.},
	file         = {Jawahar et al. - What Does BERT Learn about the Structure of Langua.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\GBM2SFJZ\\Jawahar et al. - What Does BERT Learn about the Structure of Langua.pdf:application/pdf}
}
@article{sydorova_interpretable_2019,
	title        = {Interpretable {Question} {Answering} on {Knowledge} {Bases} and {Text}},
	author       = {Sydorova, Alona and Poerner, Nina and Roth, Benjamin},
	year         = 2019,
	month        = jun,
	journal      = {arXiv:1906.10924 [cs]},
	url          = {http://arxiv.org/abs/1906.10924},
	urldate      = {2019-08-21},
	note         = {arXiv: 1906.10924},
	abstract     = {Interpretability of machine learning (ML) models becomes more relevant with their increasing adoption. In this work, we address the interpretability of ML based question answering (QA) models on a combination of knowledge bases (KB) and text documents. We adapt post hoc explanation methods such as LIME and input perturbation (IP) and compare them with the self-explanatory attention mechanism of the model. For this purpose, we propose an automatic evaluation paradigm for explanation methods in the context of QA. We also conduct a study with human annotators to evaluate whether explanations help them identify better QA models. Our results suggest that IP provides better explanations than LIME or attention, according to both automatic and human evaluation. We obtain the same ranking of methods in both experiments, which supports the validity of our automatic evaluation paradigm.},
	language     = {en},
	keywords     = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote       = {2019 human subjects experiment: which set of facts is more relevant to answering this QA question? set of facts delivered by model},
	file         = {Sydorova et al. - 2019 - Interpretable Question Answering on Knowledge Base.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\9U9T6PI8\\Sydorova et al. - 2019 - Interpretable Question Answering on Knowledge Base.pdf:application/pdf}
}
@incollection{zhang_character-level_2015,
	title        = {Character-level {Convolutional} {Networks} for {Text} {Classification}},
	author       = {Zhang, Xiang and Zhao, Junbo and LeCun, Yann},
	year         = 2015,
	booktitle    = {Advances in {Neural} {Information} {Processing} {Systems} 28},
	publisher    = {Curran Associates, Inc.},
	pages        = {649--657},
	url          = {http://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf},
	urldate      = {2019-08-26},
	editor       = {Cortes, C. and Lawrence, N. D. and Lee, D. D. and Sugiyama, M. and Garnett, R.},
	annote       = {2015 text classification with character level CNNs datasets Dataset Classes Train Samples Test Samples Epoch SizeAG’s News 4 120,000 7,600 5,000Sogou News 5 450,000 60,000 5,000DBPedia 14 560,000 70,000 5,000Yelp Review Polarity 2 560,000 38,000 5,000Yelp Review Full 5 650,000 50,000 5,000Yahoo! Answers 10 1,400,000 60,000 10,000Amazon Review Full 5 3,000,000 650,000 30,000Amazon Review Polarity 2 3,600,000 400,000 30,000},
	file         = {NIPS Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\8HQ9HAL5\\Zhang et al. - 2015 - Character-level Convolutional Networks for Text Cl.pdf:application/pdf;NIPS Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\DXVDYLQP\\5782-character-level-convolutional-networks-for-text-classification.html:text/html}
}
@inproceedings{xu_neural_2018,
	title        = {Neural {Fine}-{Grained} {Entity} {Type} {Classification} with {Hierarchy}-{Aware} {Loss}},
	author       = {Xu, Peng and Barbosa, Denilson},
	year         = 2018,
	month        = jun,
	booktitle    = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher    = {Association for Computational Linguistics},
	pages        = {16--25},
	doi          = {10.18653/v1/N18-1002},
	url          = {https://www.aclweb.org/anthology/N18-1002},
	urldate      = {2019-08-26},
	abstract     = {The task of Fine-grained Entity Type Classification (FETC) consists of assigning types from a hierarchy to entity mentions in text. Existing methods rely on distant supervision and are thus susceptible to noisy labels that can be out-of-context or overly-specific for the training sentence. Previous methods that attempt to address these issues do so with heuristics or with the help of hand-crafted features. Instead, we propose an end-to-end solution with a neural network model that uses a variant of cross-entropy loss function to handle out-of-context labels, and hierarchical loss normalization to cope with overly-specific ones. Also, previous work solve FETC a multi-label classification followed by ad-hoc post-processing. In contrast, our solution is more elegant: we use public word embeddings to train a single-label that jointly learns representations for entity mentions and their context. We show experimentally that our approach is robust against noise and consistently outperforms the state-of-the-art on established benchmarks for the task.},
	annote       = 2018,
	file         = {Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\6RZWSHJ8\\Xu and Barbosa - 2018 - Neural Fine-Grained Entity Type Classification wit.pdf:application/pdf}
}
@inproceedings{zhang_fine-grained_2018,
	title        = {Fine-grained {Entity} {Typing} through {Increased} {Discourse} {Context} and {Adaptive} {Classification} {Thresholds}},
	author       = {Zhang, Sheng and Duh, Kevin and Van Durme, Benjamin},
	year         = 2018,
	month        = jun,
	booktitle    = {Proceedings of the {Seventh} {Joint} {Conference} on {Lexical} and {Computational} {Semantics}},
	publisher    = {Association for Computational Linguistics},
	pages        = {173--179},
	doi          = {10.18653/v1/S18-2022},
	url          = {https://www.aclweb.org/anthology/S18-2022},
	urldate      = {2019-08-26},
	abstract     = {Fine-grained entity typing is the task of assigning fine-grained semantic types to entity mentions. We propose a neural architecture which learns a distributional semantic representation that leverages a greater amount of semantic context – both document and sentence level information – than prior work. We find that additional context improves performance, with further improvements gained by utilizing adaptive classification thresholds. Experiments show that our approach without reliance on hand-crafted features achieves the state-of-the-art results on three benchmark datasets.},
	annote       = {
		2018 entity; sentence; and document level context no document context for FIGER

		entity encoder: average of embeddings sentence encoder: BiLSTM + Attention
	},
	file         = {Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\MQDTLE3M\\Zhang et al. - 2018 - Fine-grained Entity Typing through Increased Disco.pdf:application/pdf}
}
@article{rudin_stop_2019,
	title        = {Stop {Explaining} {Black} {Box} {Machine} {Learning} {Models} for {High} {Stakes} {Decisions} and {Use} {Interpretable} {Models} {Instead}},
	author       = {Rudin, Cynthia},
	year         = 2019,
	month        = may,
	journal      = {Nature Machine Intelligence},
	volume       = 1,
	pages        = {206--215},
	url          = {https://www.nature.com/articles/s42256-019-0048-x}
}
@article{rudin_stop_2019-1,
	title        = {Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
	author       = {Rudin, Cynthia},
	year         = 2019,
	month        = may,
	journal      = {Nature Machine Intelligence},
	volume       = 1,
	number       = 5,
	pages        = {206--215},
	doi          = {10.1038/s42256-019-0048-x},
	issn         = {2522-5839},
	url          = {https://www.nature.com/articles/s42256-019-0048-x},
	urldate      = {2019-08-28},
	copyright    = {2019 Springer Nature Limited},
	abstract     = {Black box machine learning models are currently being used for high-stakes decision making throughout society, causing problems in healthcare, criminal justice and other domains. Some people hope that creating methods for explaining these black box models will alleviate some of the problems, but trying to explain black box models, rather than creating models that are interpretable in the first place, is likely to perpetuate bad practice and can potentially cause great harm to society. The way forward is to design models that are inherently interpretable. This Perspective clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare and computer vision.},
	language     = {en},
	annote       = {2019 explanations are post-hoc descriptions of the model computations interpretability must be domain-specific can incllude some common features (in intro) in vision, it was to build a part identifying model "we know the model computations" -- true for prototype layer, but not the representation learner},
	file         = {Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\JP5CYFWS\\s42256-019-0048-x.html:text/html}
}
@inproceedings{chen_this_2018,
	title        = {This {Looks} {Like} {That}: {Deep} {Learning} for {Interpretable} {Image} {Recognition}},
	shorttitle   = {This {Looks} {Like} {That}},
	author       = {Chen, Chaofan and Li, Oscar and Tao, Chaofan and Barnett, Alina Jade and Su, Jonathan and Rudin, Cynthia},
	year         = 2019,
	month        = jun,
	booktitle    = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
	url          = {http://arxiv.org/abs/1806.10574},
	urldate      = {2019-08-29},
	keywords     = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote       = {Comment: Chaofan Chen and Oscar Li contributed equally to this work},
	file         = {arXiv\:1806.10574 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\AICRK55P\\Chen et al. - 2018 - This Looks Like That Deep Learning for Interpreta.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\K72X9JDN\\1806.html:text/html}
}
@inproceedings{adebayo_sanity_2018,
	title        = {Sanity Checks for Saliency Maps},
	author       = {Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
	year         = 2018,
	booktitle    = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
	url          = {https://arxiv.org/abs/1810.03292}
}
@inproceedings{hase_interpretable_2019,
	title        = {Interpretable {Image} {Recognition} with {Hierarchical} {Prototypes}},
	author       = {Hase, Peter and Chen, Chaofan and Li, Oscar and Rudin, Cynthia},
	year         = 2019,
	month        = jun,
	booktitle    = {Proceedings of the Seventh AAAI Conference on Human Computation and Crowdsourcing (HCOMP-19)},
	pages        = {32--40},
	url          = {http://arxiv.org/abs/1906.10651},
	urldate      = {2019-08-29},
	keywords     = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing}
}
@article{chen_this_2018-1,
	title        = {This {Looks} {Like} {That}: {Deep} {Learning} for {Interpretable} {Image} {Recognition}},
	shorttitle   = {This {Looks} {Like} {That}},
	author       = {Chen, Chaofan and Li, Oscar and Tao, Chaofan and Barnett, Alina Jade and Su, Jonathan and Rudin, Cynthia},
	year         = 2018,
	month        = jun,
	journal      = {arXiv:1806.10574 [cs, stat]},
	url          = {http://arxiv.org/abs/1806.10574},
	urldate      = {2019-08-31},
	note         = {arXiv: 1806.10574},
	abstract     = {When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The model thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, geologists, architects, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training, meaning that there are no labels for parts of images. We demonstrate our method on the CUB-200-2011 dataset and the CBIS-DDSM dataset. Our experiments show that our interpretable network can achieve comparable accuracy with its analogous standard non-interpretable counterpart as well as other interpretable deep models.},
	keywords     = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote       = {Comment: Chaofan Chen and Oscar Li contributed equally to this work},
	file         = {arXiv\:1806.10574 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\FU5LEN3R\\Chen et al. - 2018 - This Looks Like That Deep Learning for Interpreta.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\J8SJ8R5C\\1806.html:text/html}
}
@inproceedings{ribeiro_anchors_2018,
	title        = {Anchors: High-Precision Model-Agnostic Explanations},
	author       = {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
	year         = 2018,
	booktitle    = {AAAI Conference on Artificial Intelligence},
	url          = {https://homes.cs.washington.edu/~marcotcr/aaai18.pdf}
}
@article{gillick_context-dependent_2014,
	title        = {Context-{Dependent} {Fine}-{Grained} {Entity} {Type} {Tagging}},
	author       = {Gillick, Dan and Lazic, Nevena and Ganchev, Kuzman and Kirchner, Jesse and Huynh, David},
	year         = 2014,
	month        = dec,
	journal      = {arXiv:1412.1820 [cs]},
	url          = {http://arxiv.org/abs/1412.1820},
	urldate      = {2019-08-26},
	note         = {arXiv: 1412.1820},
	abstract     = {Entity type tagging is the task of assigning category labels to each mention of an entity in a document. While standard systems focus on a small set of types, recent work (Ling and Weld, 2012) suggests that using a large fine-grained label set can lead to dramatic improvements in downstream tasks. In the absence of labeled training data, existing fine-grained tagging systems obtain examples automatically, using resolved entities and their types extracted from a knowledge base. However, since the appropriate type often depends on context (e.g. Washington could be tagged either as city or government), this procedure can result in spurious labels, leading to poorer generalization. We propose the task of context-dependent fine type tagging, where the set of acceptable labels for a mention is restricted to only those deducible from the local context (e.g. sentence or document). We introduce new resources for this task: 12,017 mentions annotated with their context-dependent fine types, and we provide baseline experimental results on this data.},
	keywords     = {Computer Science - Computation and Language},
	annote       = {2016 ontonotes paper},
	file         = {arXiv\:1412.1820 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\5Q3EKYRE\\Gillick et al. - 2014 - Context-Dependent Fine-Grained Entity Type Tagging.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\C7TUBS7Y\\1412.html:text/html}
}
@inproceedings{hutton_crowdsourcing_nodate,
	title        = {Crowdsourcing {Evaluations} of {Classifier} {Interpretability}},
	author       = {Hutton, Amanda and Liu, Alexander and Martin, Cheryl},
	year         = 2012,
	booktitle    = {AAAI Spring Symposium: Wisdom of the Crowd},
	pages        = {21--26},
	language     = {en}
}
@inproceedings{yang_hierarchical_2016,
	title        = {Hierarchical {Attention} {Networks} for {Document} {Classification}},
	author       = {Yang, Zichao and Yang, Diyi and Dyer, Chris and He, Xiaodong and Smola, Alex and Hovy, Eduard},
	year         = 2016,
	month        = jun,
	booktitle    = {Proceedings of the 2016 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher    = {Association for Computational Linguistics},
	pages        = {1480--1489},
	doi          = {10.18653/v1/N16-1174},
	url          = {https://www.aclweb.org/anthology/N16-1174},
	urldate      = {2019-09-06},
	annote       = {2016 word-level attention for sentiment analysis give avg. sentence count for various sentiment datasets},
	file         = {Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\BMPM3AV4\\Yang et al. - 2016 - Hierarchical Attention Networks for Document Class.pdf:application/pdf}
}
@inproceedings{pang_thumbs_2002,
	title        = {Thumbs up?: sentiment classification using machine learning techniques},
	shorttitle   = {Thumbs up?},
	author       = {Pang, Bo and Lee, Lillian and Vaithyanathan, Shivakumar},
	year         = 2002,
	booktitle    = {Proceedings of the {ACL}-02 conference on {Empirical} methods in natural language processing  - {EMNLP} '02},
	publisher    = {Association for Computational Linguistics},
	volume       = 10,
	pages        = {79--86},
	doi          = {10.3115/1118693.1118704},
	url          = {http://portal.acm.org/citation.cfm?doid=1118693.1118704},
	urldate      = {2019-09-06},
	abstract     = {We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we ﬁnd that standard machine learning techniques deﬁnitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classiﬁcation, and support vector machines) do not perform as well on sentiment classiﬁcation as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classiﬁcation problem more challenging.},
	language     = {en},
	annote       = {2002 movie review data source},
	file         = {Pang et al. - 2002 - Thumbs up sentiment classification using machine.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\JGF3JRH9\\Pang et al. - 2002 - Thumbs up sentiment classification using machine.pdf:application/pdf}
}
@inproceedings{bowman_generating_2016,
	title        = {Generating {Sentences} from a {Continuous} {Space}},
	author       = {Bowman, Samuel R. and Vilnis, Luke and Vinyals, Oriol and Dai, Andrew and Jozefowicz, Rafal and Bengio, Samy},
	year         = 2016,
	month        = aug,
	journal      = {arXiv:1511.06349 [cs]},
	booktitle    = {Proceedings of {The} 20th {SIGNLL} {Conference} on {Computational} {Natural} {Language} {Learning}},
	publisher    = {Association for Computational Linguistics},
	address      = {Berlin, Germany},
	pages        = {10--21},
	doi          = {10.18653/v1/K16-1002},
	url          = {https://www.aclweb.org/anthology/K16-1002},
	urldate      = {2019-09-06},
	note         = {arXiv: 1511.06349},
	annote       = {2016 could use this for interpreting prototypes or constructing counterfactual tests.},
	file         = {Full Text PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\N8HDXL3Q\\Bowman et al. - 2016 - Generating Sentences from a Continuous Space.pdf:application/pdf},
	abstract     = {The standard recurrent neural network language model (RNNLM) generates sentences one word at a time and does not work from an explicit global sentence representation. In this work, we introduce and study an RNN-based variational autoencoder generative model that incorporates distributed latent representations of entire sentences. This factorization allows it to explicitly model holistic properties of sentences such as style, topic, and high-level syntactic features. Samples from the prior over these sentence representations remarkably produce diverse and well-formed sentences through simple deterministic decoding. By examining paths through this latent space, we are able to generate coherent novel sentences that interpolate between known sentences. We present techniques for solving the difficult learning problem presented by this model, demonstrate its effectiveness in imputing missing words, explore many interesting properties of the model's latent sentence space, and present negative results on the use of the model in language modeling.},
	keywords     = {Computer Science - Machine Learning, Computer Science - Computation and Language}
}
@inproceedings{simonyan_deep_2013,
	title        = {Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps},
	author       = {Karen Simonyan and Andrea Vedaldi and Andrew Zisserman},
	year         = 2014,
	booktitle    = {Workshop at International Conference on Learning Representations},
	url          = {https://arxiv.org/abs/1312.6034}
}
@article{smilkov_smoothgrad:_2017,
	title        = {{SmoothGrad}: removing noise by adding noise},
	shorttitle   = {{SmoothGrad}},
	author       = {Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Viégas, Fernanda and Wattenberg, Martin},
	year         = 2017,
	month        = jun,
	journal      = {arXiv:1706.03825 [cs, stat]},
	url          = {http://arxiv.org/abs/1706.03825},
	urldate      = {2019-09-28},
	note         = {arXiv: 1706.03825},
	abstract     = {Explaining the output of a deep network remains a challenge. In the case of an image classifier, one type of explanation is to identify pixels that strongly influence the final decision. A starting point for this strategy is the gradient of the class score function with respect to the input image. This gradient can be interpreted as a sensitivity map, and there are several techniques that elaborate on this basic idea. This paper makes two contributions: it introduces SmoothGrad, a simple method that can help visually sharpen gradient-based sensitivity maps, and it discusses lessons in the visualization of these maps. We publish the code for our experiments and a website with our results.},
	keywords     = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote       = {2017 commentary on visualizing gradients and whether or not to take abs value},
	file         = {arXiv\:1706.03825 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\87WJRK3I\\Smilkov et al. - 2017 - SmoothGrad removing noise by adding noise.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\4E6TBM3W\\1706.html:text/html}
}
@misc{Dua:2019,
	title        = {{UCI} Machine Learning Repository},
	author       = {Dua, Dheeru and Graff, Casey},
	year         = 2017,
	url          = {http://archive.ics.uci.edu/ml},
	institution  = {University of California, Irvine, School of Information and Computer Sciences}
}
@inproceedings{nguyen_comparing_2018,
	title        = {Comparing {Automatic} and {Human} {Evaluation} of {Local} {Explanations} for {Text} {Classification}},
	author       = {Nguyen, Dong},
	year         = 2018,
	month        = jun,
	booktitle    = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} {Papers})},
	pages        = {1069--1078},
	doi          = {10.18653/v1/N18-1097},
	url          = {https://www.aclweb.org/anthology/N18-1097.pdf},
	abstract     = {Text classification models are becoming increasingly complex and opaque, however for many applications it is essential that the models are interpretable. Recently, a variety of approaches have been proposed for generating local explanations. While robust evaluations are needed to drive further progress, so far it is unclear which evaluation approaches are suitable. This paper is a first step towards more robust evaluations of local explanations. We evaluate a variety of local explanation approaches using automatic measures based on word deletion. Furthermore, we show that an evaluation using a crowdsourcing experiment correlates moderately with these automatic measures and that a variety of other factors also impact the human judgements.},
	file         = {Full Text PDF:C\:\\Users\\Peter Hase\\OneDrive\\Documents\\Research\\Zotero\\storage\\P2CE8776\\Nguyen - 2018 - Comparing Automatic and Human Evaluation of Local .pdf:application/pdf}
}
@article{li_understanding_2017,
	title        = {Understanding {Neural} {Networks} through {Representation} {Erasure}},
	author       = {Li, Jiwei and Monroe, Will and Jurafsky, Dan},
	year         = 2017,
	month        = jan,
	journal      = {arXiv:1612.08220 [cs]},
	url          = {http://arxiv.org/abs/1612.08220},
	urldate      = {2019-11-04},
	note         = {arXiv: 1612.08220},
	abstract     = {While neural networks have been successfully applied to many natural language processing tasks, they come at the cost of interpretability. In this paper, we propose a general methodology to analyze and interpret decisions from a neural model by observing the effects on the model of erasing various parts of the representation, such as input word-vector dimensions, intermediate hidden units, or input words. We present several approaches to analyzing the effects of such erasure, from computing the relative difference in evaluation metrics, to using reinforcement learning to erase the minimum set of input words in order to flip a neural model's decision. In a comprehensive analysis of multiple NLP tasks, including linguistic feature classification, sentence-level sentiment analysis, and document level sentiment aspect prediction, we show that the proposed methodology not only offers clear explanations about neural model decisions, but also provides a way to conduct error analysis on neural models.},
	keywords     = {Computer Science - Computation and Language},
	file         = {arXiv Fulltext PDF:C\:\\Users\\Peter Hase\\OneDrive\\Documents\\Research\\Zotero\\storage\\8LE3ZL6J\\Li et al. - 2017 - Understanding Neural Networks through Representati.pdf:application/pdf}
}
@article{joshi_xgems:_2018,
	title        = {{xGEMs}: {Generating} {Examplars} to {Explain} {Black}-{Box} {Models}},
	shorttitle   = {{xGEMs}},
	author       = {Joshi, Shalmali and Koyejo, Oluwasanmi and Kim, Been and Ghosh, Joydeep},
	year         = 2018,
	month        = jun,
	journal      = {arXiv:1806.08867 [cs, stat]},
	url          = {http://arxiv.org/abs/1806.08867},
	urldate      = {2019-11-05},
	note         = {arXiv: 1806.08867},
	abstract     = {This work proposes xGEMs or manifold guided exemplars, a framework to understand black-box classifier behavior by exploring the landscape of the underlying data manifold as data points cross decision boundaries. To do so, we train an unsupervised implicit generative model -- treated as a proxy to the data manifold. We summarize black-box model behavior quantitatively by perturbing data samples along the manifold. We demonstrate xGEMs' ability to detect and quantify bias in model learning and also for understanding the changes in model behavior as training progresses.},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv Fulltext PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\2532LZDX\\Joshi et al. - 2018 - xGEMs Generating Examplars to Explain Black-Box M.pdf:application/pdf}
}
@incollection{samangouei_explaingan:_2018,
	title        = {{ExplainGAN}: {Model} {Explanation} via {Decision} {Boundary} {Crossing} {Transformations}},
	shorttitle   = {{ExplainGAN}},
	author       = {Samangouei, Pouya and Saeedi, Ardavan and Nakagawa, Liam and Silberman, Nathan},
	year         = 2018,
	booktitle    = {{ECCV} 2018},
	publisher    = {Springer International Publishing},
	doi          = {10.1007/978-3-030-01249-6_41},
	isbn         = {978-3-030-01248-9 978-3-030-01249-6},
	url          = {http://link.springer.com/10.1007/978-3-030-01249-6_41},
	urldate      = {2019-11-05},
	language     = {en},
	file         = {Samangouei et al. - 2018 - ExplainGAN Model Explanation via Decision Boundar.pdf:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\2HEJIYMT\\Samangouei et al. - 2018 - ExplainGAN Model Explanation via Decision Boundar.pdf:application/pdf}
}
@article{papernot_deep_2018,
	title        = {Deep k-{Nearest} {Neighbors}: {Towards} {Confident}, {Interpretable} and {Robust} {Deep} {Learning}},
	shorttitle   = {Deep k-{Nearest} {Neighbors}},
	author       = {Papernot, Nicolas and McDaniel, Patrick},
	year         = 2018,
	month        = mar,
	journal      = {arXiv:1803.04765 [cs, stat]},
	url          = {http://arxiv.org/abs/1803.04765},
	urldate      = {2019-11-05},
	note         = {arXiv: 1803.04765},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\KT92H8DH\\1803.html:text/html}
}
@article{bang_explaining_2019,
	title        = {Explaining a black-box using {Deep} {Variational} {Information} {Bottleneck} {Approach}},
	author       = {Bang, Seojin and Xie, Pengtao and Lee, Heewook and Wu, Wei and Xing, Eric},
	year         = 2019,
	month        = feb,
	journal      = {arXiv:1902.06918 [cs, stat]},
	volume       = {abs/1902.06918},
	url          = {http://arxiv.org/abs/1902.06918},
	urldate      = {2019-10-06},
	note         = {arXiv: 1902.06918},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv\:1902.06918 PDF:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\I2RH9NWR\\Bang et al. - 2019 - Explaining a black-box using Deep Variational Info.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\OneDrive\\Documents\\Research\\Zotero\\storage\\PLDCGFV4\\1902.html:text/html}
}
@inproceedings{kim_interpretability_2018,
	title        = {Interpretability {Beyond} {Feature} {Attribution}: {Quantitative} {Testing} with {Concept} {Activation} {Vectors} ({TCAV})},
	shorttitle   = {Interpretability {Beyond} {Feature} {Attribution}},
	author       = {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and Sayres, Rory},
	year         = 2018,
	month        = jun,
	journal      = {arXiv:1711.11279 [stat]},
	booktitle    = {Proceedings of the 35\textsuperscript{th} International Conference on Machine Learning},
	pages        = {2668--2677},
	url          = {http://arxiv.org/abs/1711.11279},
	urldate      = {2019-11-29},
	note         = {arXiv: 1711.11279},
	keywords     = {Statistics - Machine Learning},
	file         = {arXiv Fulltext PDF:C\:\\Users\\Peter Hase\\OneDrive\\Documents\\Research\\Zotero\\storage\\4W2XTV9Z\\Kim et al. - 2018 - Interpretability Beyond Feature Attribution Quant.pdf:application/pdf},
	organization = {PMLR}
}
@inproceedings{sundararajan_axiomatic_2017,
	title        = {Axiomatic {Attribution} for {Deep} {Networks}},
	author       = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	year         = 2017,
	month        = jun,
	journal      = {arXiv:1703.01365 [cs]},
	booktitle    = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
	url          = {http://arxiv.org/abs/1703.01365},
	urldate      = {2019-11-25},
	note         = {arXiv: 1703.01365},
	keywords     = {Computer Science - Machine Learning},
	abstract     = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms---Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
	file         = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\675B2QF2\\Sundararajan et al. - 2017 - Axiomatic Attribution for Deep Networks.pdf:application/pdf}
}
@inproceedings{lundberg_unified_2017,
	title        = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	author       = {Lundberg, Scott M and Lee, Su-In},
	year         = 2017,
	booktitle    = {Advances in {Neural} {Information} {Processing} {Systems} 30},
	pages        = {4765--4774},
	url          = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf},
	urldate      = {2019-11-07},
	editor       = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	file         = {NIPS Full Text PDF:C\:\\Users\\Peter Hase\\OneDrive\\Documents\\Research\\Zotero\\storage\\M5IXFEEC\\Lundberg and Lee - 2017 - A Unified Approach to Interpreting Model Predictio.pdf:application/pdf}
}
% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@book{Aho:72,
	title        = {The Theory of Parsing, Translation and Compiling},
	author       = {Alfred V. Aho and Jeffrey D. Ullman},
	year         = 1972,
	publisher    = {Prentice-Hall},
	address      = {Englewood Cliffs, NJ},
	volume       = 1
}
@book{APA:83,
	title        = {Publications Manual},
	author       = {{American Psychological Association}},
	year         = 1983,
	publisher    = {American Psychological Association},
	address      = {Washington, DC}
}
@article{Chandra:81,
	title        = {Alternation},
	author       = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year         = 1981,
	journal      = {Journal of the Association for Computing Machinery},
	volume       = 28,
	number       = 1,
	pages        = {114--133},
	doi          = {10.1145/322234.322243}
}
@inproceedings{andrew2007scalable,
	title        = {Scalable training of {L1}-regularized log-linear models},
	author       = {Andrew, Galen and Gao, Jianfeng},
	year         = 2007,
	booktitle    = {Proceedings of the 24th International Conference on Machine Learning},
	pages        = {33--40}
}
@book{Gusfield:97,
	title        = {Algorithms on Strings, Trees and Sequences},
	author       = {Dan Gusfield},
	year         = 1997,
	publisher    = {Cambridge University Press},
	address      = {Cambridge, UK}
}
@article{rasooli-tetrault-2015,
	title        = {Yara Parser: {A} Fast and Accurate Dependency Parser},
	author       = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
	year         = 2015,
	journal      = {Computing Research Repository},
	volume       = {arXiv:1503.06733},
	url          = {http://arxiv.org/abs/1503.06733},
	note         = {version 2}
}
@article{Ando2005,
	title        = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	author       = {Ando, Rie Kubota and Zhang, Tong},
	year         = 2005,
	month        = dec,
	journal      = {Journal of Machine Learning Research},
	publisher    = {JMLR.org},
	volume       = 6,
	pages        = {1817--1853},
	issn         = {1532-4435},
	acmid        = 1194905,
	issue_date   = {12/1/2005},
	numpages     = 37
}
@incollection{Bengio+chapter2007,
	title        = {Scaling Learning Algorithms Towards {AI}},
	author       = {Bengio, Yoshua and LeCun, Yann},
	year         = 2007,
	booktitle    = {Large Scale Kernel Machines},
	publisher    = {MIT Press}
}
@article{Hinton06,
	title        = {A Fast Learning Algorithm for Deep Belief Nets},
	author       = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
	year         = 2006,
	journal      = {Neural Computation},
	volume       = 18,
	pages        = {1527--1554}
}
@book{goodfellow2016deep,
	title        = {Deep learning},
	author       = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
	year         = 2016,
	publisher    = {MIT Press},
	volume       = 1
}
@inproceedings{rajani_explain_2019,
	title        = {Explain Yourself! Leveraging Language Models for Commonsense Reasoning},
	author       = {Nazneen Fatema Rajani and Bryan McCann and Caiming Xiong and Richard Socher},
	year         = 2019,
	booktitle    = {ACL 2019},
	url          = {https://arxiv.org/pdf/1906.02361.pdf}
}
@inproceedings{zhang_bridging_2019,
	title        = {Bridging the Gap between Training and Inference for Neural Machine Translation},
	author       = {Wen Zhang and Yang Feng and Fandong Meng and Di You and Qun Liu},
	year         = 2019,
	booktitle    = {ACL},
	url          = {https://arxiv.org/pdf/1906.02448.pdf}
}
@inproceedings{pennington_glove:_2014,
	title        = {Glove: Global Vectors for Word Representation},
	author       = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
	year         = 2014,
	booktitle    = {EMNLP},
	url          = {https://www-nlp.stanford.edu/pubs/glove.pdf}
}
@inproceedings{andreas_translating_2017,
	title        = {Translating Neuralese},
	author       = {Jacob Andreas and Anca D. Dragan and Dan Klein},
	year         = 2017,
	booktitle    = {ACL},
	url          = {https://arxiv.org/abs/1704.06960}
}
@article{collobert_natural_nodate,
	title        = {Natural Language Processing (Almost) from Scratch},
	author       = {Ronan Collobert and Jason Weston and L{\'e}on Bottou and Michael Karlen and Koray Kavukcuoglu and Pavel P. Kuksa},
	year         = 2011,
	journal      = {J. Mach. Learn. Res.},
	volume       = 12,
	pages        = {2493--2537},
	url          = {https://arxiv.org/pdf/1103.0398.pdf}
}
@inproceedings{li_paraphrase_2018,
	title        = {Paraphrase Generation with Deep Reinforcement Learning},
	author       = {Zichao Li and Xin Jiang and Lifeng Shang and Huang Li},
	year         = 2018,
	booktitle    = {EMNLP},
	url          = {https://arxiv.org/pdf/1711.00279.pdf}
}
@article{kaiser_fast_2018,
	title        = {Fast Decoding in Sequence Models using Discrete Latent Variables},
	author       = {Łukasz Kaiser and Aurko Roy and Ashish Vaswani and Niki Parmar and Samy Bengio and Jakob Uszkoreit and Noam Shazeer},
	year         = 2018,
	journal      = {ArXiv},
	volume       = {abs/1803.03382},
	url          = {https://arxiv.org/pdf/1803.03382.pdf}
}
@inproceedings{talmor_commonsenseqa_2019,
	title        = {CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge},
	author       = {Alon Talmor and Jonathan Herzig and Nicholas Lourie and Jonathan Berant},
	year         = 2019,
	booktitle    = {NAACL-HLT 2019},
	url          = {https://arxiv.org/pdf/1811.00937.pdf}
}
@inproceedings{dai_transformer-xl_2019,
	title        = {Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context},
	author       = {Zihang Dai and Zhilin Yang and Yiming Yang and Jaime G. Carbonell and Quoc V. Le and Ruslan Salakhutdinov},
	year         = 2019,
	booktitle    = {ACL},
	url          = {https://arxiv.org/pdf/1901.02860.pdf}
}
@inproceedings{radford_language_2019,
	title        = {Language Models are Unsupervised Multitask Learners},
	author       = {Alec Radford and Jeffrey Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
	year         = 2019,
	booktitle    = {OpenAI Technical Report},
	url          = {https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf}
}
@inproceedings{wang_does_2019,
	title        = {Does It Make Sense? And Why? A Pilot Study for Sense Making and Explanation},
	author       = {Cunxiang Wang and Shuailong Liang and Yue Zhang and Xiaonan Li and Tian Gao},
	year         = 2019,
	booktitle    = {ACL 2019},
	url          = {https://arxiv.org/pdf/1906.00363.pdf}
}
@inproceedings{liu_generating_2018,
	title        = {Generating Wikipedia by Summarizing Long Sequences},
	author       = {Peter J. Liu and Mohammad Saleh and Etienne Pot and Ben Goodrich and Ryan Sepassi and Lukasz Kaiser and Noam Shazeer},
	year         = 2018,
	booktitle    = {ICLR},
	url          = {https://arxiv.org/pdf/1801.10198.pdf}
}
@inproceedings{zhang_explicit_2019,
	title        = {Explicit Contextual Semantics for Text Comprehension},
	author       = {Zhuosheng Zhang and Yuwei Wu and Zuchao Li and Hai Zhao},
	year         = 2018,
	booktitle    = {PACLIC 33},
	url          = {https://arxiv.org/pdf/1809.02794.pdf}
}
@inproceedings{oord_neural_2018,
	title        = {Neural Discrete Representation Learning},
	author       = {A{\"a}ron van den Oord and Oriol Vinyals and Koray Kavukcuoglu},
	year         = 2017,
	booktitle    = {NIPS},
	url          = {https://arxiv.org/pdf/1711.00937.pdf}
}
@inproceedings{devlin_bert_2019,
	title        = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	author       = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
	year         = 2019,
	booktitle    = {ACL 2019},
	url          = {https://arxiv.org/pdf/1810.04805.pdf}
}
@inproceedings{strout_human_2019,
	title        = {Do Human Rationales Improve Machine Explanations?},
	author       = {Julia Strout and Ye Zhang and Raymond J. Mooney},
	year         = 2019,
	booktitle    = {ACL},
	url          = {https://arxiv.org/pdf/1905.13714.pdf}
}
@inproceedings{deyoung_eraser_2019,
	title        = {ERASER: A Benchmark to Evaluate Rationalized NLP Models},
	author       = {Jay DeYoung and Sarthak Jain and Nazneen Fatema Rajani and Eric Lehman and Caiming Xiong and Richard Socher and Byron C. Wallace},
	year         = 2020,
	booktitle    = {ACL 2020},
	volume       = {abs/1911.03429},
	url          = {https://arxiv.org/pdf/1911.03429.pdf},
	eprint       = {arXiv:1911.03429}
}
@inproceedings{bhagavatula_abductive_2019,
	title        = {Abductive Commonsense Reasoning},
	author       = {Chandra Bhagavatula and Ronan Le Bras and Chaitanya Malaviya and Keisuke Sakaguchi and Ari Holtzman and Hannah Rashkin and Doug Downey and Scott Yih and Yejin Choi},
	year         = 2020,
	booktitle    = {ICLR},
	url          = {https://arxiv.org/pdf/1908.05739.pdf}
}
@article{ye_align_2019,
	title        = {Align, Mask and Select: A Simple Method for Incorporating Commonsense Knowledge into Language Representation Models},
	author       = {Zhi-Xiu Ye and Qian Chen and Wen Wang and Zhen-Hua Ling},
	year         = 2019,
	journal      = {ArXiv},
	volume       = {abs/1908.06725},
	url          = {https://arxiv.org/pdf/1908.06725.pdf}
}
@inproceedings{hancock_training_2018,
	title        = {Training Classifiers with Natural Language Explanations},
	author       = {Braden Hancock and Paroma Varma and Stephanie Wang and Martin Bringmann and Percy Liang and Christopher R{\'e}},
	year         = 2018,
	booktitle    = {ACL},
	url          = {https://pubmed.ncbi.nlm.nih.gov/31130772/}
}
@inproceedings{lei_rationalizing_2016,
	title        = {Rationalizing Neural Predictions},
	author       = {Tao Lei and Regina Barzilay and Tommi S. Jaakkola},
	year         = 2016,
	booktitle    = {EMNLP},
	url          = {https://arxiv.org/pdf/1606.04155.pdf}
}
@article{liu_roberta_2019,
	title        = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
	author       = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
	year         = 2019,
	journal      = {ArXiv},
	volume       = {abs/1907.11692},
	url          = {https://arxiv.org/pdf/1907.11692.pdf}
}
@article{talmor_olmpics_2019,
	title        = {oLMpics - On what Language Model Pre-training Captures},
	author       = {Alon Talmor and Yanai Elazar and Yoav Goldberg and Jonathan Berant},
	year         = 2019,
	journal      = {ArXiv},
	volume       = {abs/1912.13283},
	url          = {https://arxiv.org/pdf/1912.13283.pdf}
}
@article{lecun_deep_2015,
	title        = {Deep learning},
	author       = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	year         = 2015,
	month        = may,
	journal      = {Nature},
	volume       = 521,
	number       = 7553,
	pages        = {436--444},
	doi          = {10.1038/nature14539},
	issn         = {0028-0836, 1476-4687},
	url          = {http://www.nature.com/articles/nature14539},
	urldate      = {2020-01-02},
	language     = {en}
}
@inproceedings{chandrasekaran_explanations_2018,
	title        = {Do explanations make VQA models more predictable to a human?},
	author       = {Arjun Chandrasekaran and Viraj Prabhu and Deshraj Yadav and Prithvijit Chattopadhyay and Devi Parikh},
	year         = 2018,
	month        = oct # {-} # nov,
	booktitle    = {EMNLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Brussels, Belgium},
	pages        = {1036--1042},
	doi          = {10.18653/v1/D18-1128},
	url          = {https://arxiv.org/pdf/1810.12366.pdf},
	abstract     = {A rich line of research attempts to make deep neural networks more transparent by generating human-interpretable {`}explanations{'} of their decision process, especially for interactive tasks like Visual Question Answering (VQA). In this work, we analyze if existing explanations indeed make a VQA model {---} its responses as well as failures {---} more predictable to a human. Surprisingly, we find that they do not. On the other hand, we find that human-in-the-loop approaches that treat the model as a black-box do.}
}
@article{lin_kagnet_2019,
	title        = {{KagNet}: {Knowledge}-{Aware} {Graph} {Networks} for {Commonsense} {Reasoning}},
	shorttitle   = {{KagNet}},
	author       = {Lin, Bill Yuchen and Chen, Xinyue and Chen, Jamin and Ren, Xiang},
	year         = 2019,
	month        = sep,
	journal      = {arXiv:1909.02151 [cs]},
	url          = {http://arxiv.org/abs/1909.02151},
	urldate      = {2020-01-02},
	note         = {arXiv: 1909.02151},
	abstract     = {Commonsense reasoning aims to empower machines with the human ability to make presumptions about ordinary situations in our daily life. In this paper, we propose a textual inference framework for answering commonsense questions, which effectively utilizes external, structured commonsense knowledge graphs to perform explainable inferences. The framework first grounds a question-answer pair from the semantic space to the knowledge-based symbolic space as a schema graph, a related sub-graph of external knowledge graphs. It represents schema graphs with a novel knowledge-aware graph network module named KagNet, and finally scores answers with graph representations. Our model is based on graph convolutional networks and LSTMs, with a hierarchical path-based attention mechanism. The intermediate attention scores make it transparent and interpretable, which thus produce trustworthy inferences. Using ConceptNet as the only external resource for Bert-based models, we achieved state-of-the-art performance on the CommonsenseQA, a large-scale dataset for commonsense reasoning.},
	keywords     = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file         = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\KL4LDW7S\\1909.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\8U96MH4D\\Lin et al. - 2019 - KagNet Knowledge-Aware Graph Networks for Commons.pdf:application/pdf}
}
@inproceedings{zellers_recognition_nodate,
	title        = {From Recognition to Cognition: Visual Commonsense Reasoning},
	author       = {Rowan Zellers and Yonatan Bisk and Ali Farhadi and Yejin Choi},
	year         = 2019,
	booktitle    = {IEEE/CVF 2019},
	url          = {https://ieeexplore.ieee.org/document/8953217}
}
@inproceedings{zhang_rationale-augmented_2016,
	title        = {Rationale-{Augmented} {Convolutional} {Neural} {Networks} for {Text} {Classification}},
	author       = {Zhang, Ye and Marshall, Iain and Wallace, Byron C.},
	year         = 2016,
	month        = nov,
	booktitle    = {Proceedings of the 2016 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher    = {Association for Computational Linguistics},
	address      = {Austin, Texas},
	pages        = {795--804},
	doi          = {10.18653/v1/D16-1076},
	url          = {https://www.aclweb.org/anthology/D16-1076},
	urldate      = {2020-01-02},
	file         = {Full Text PDF:C\:\\Users\\peter\\Zotero\\storage\\TFKD4A5M\\Zhang et al. - 2016 - Rationale-Augmented Convolutional Neural Networks .pdf:application/pdf}
}
@inproceedings{zaidan_using_2007,
	title        = {Using “{Annotator} {Rationales}” to {Improve} {Machine} {Learning} for {Text} {Categorization}},
	author       = {Zaidan, Omar and Eisner, Jason and Piatko, Christine},
	year         = 2007,
	month        = apr,
	booktitle    = {Human {Language} {Technologies} 2007: {The} {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}; {Proceedings} of the {Main} {Conference}},
	publisher    = {Association for Computational Linguistics},
	address      = {Rochester, New York},
	pages        = {260--267},
	url          = {https://www.aclweb.org/anthology/N07-1033},
	urldate      = {2020-01-02},
	file         = {Full Text PDF:C\:\\Users\\peter\\Zotero\\storage\\748D6T6P\\Zaidan et al. - 2007 - Using “Annotator Rationales” to Improve Machine Le.pdf:application/pdf}
}
@inproceedings{ling_program_2017,
	title        = {Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems},
	author       = {Wang Ling and Dani Yogatama and Chris Dyer and Phil Blunsom},
	year         = 2017,
	booktitle    = {ACL 2017},
	url          = {https://arxiv.org/pdf/1705.04146.pdf}
}
@inproceedings{hendricks_generating_2016,
	title        = {Generating Visual Explanations},
	author       = {Lisa Anne Hendricks and Zeynep Akata and Marcus Rohrbach and Jeff Donahue and Bernt Schiele and Trevor Darrell},
	year         = 2016,
	booktitle    = {ECCV 2016},
	url          = {https://arxiv.org/pdf/1603.08507.pdf}
}
@inproceedings{kim_textual_2018,
	title        = {Textual Explanations for Self-Driving Vehicles},
	author       = {Jinkyu Kim and Anna Rohrbach and Trevor Darrell and John F. Canny and Zeynep Akata},
	year         = 2018,
	booktitle    = {ECCV 2018},
	url          = {https://arxiv.org/pdf/1807.11546.pdf}
}
@article{park_multimodal_2018,
	title        = {Multimodal Explanations: Justifying Decisions and Pointing to the Evidence},
	author       = {Dong Huk Park and Lisa Anne Hendricks and Zeynep Akata and Anna Rohrbach and Bernt Schiele and Trevor Darrell and Marcus Rohrbach},
	year         = 2018,
	journal      = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {8779--8788},
	url          = {https://ieeexplore.ieee.org/document/8579013/}
}
@article{camburu_can_2019,
	title        = {Can {I} {Trust} the {Explainer}? {Verifying} {Post}-hoc {Explanatory} {Methods}},
	shorttitle   = {Can {I} {Trust} the {Explainer}?},
	author       = {Camburu, Oana-Maria and Giunchiglia, Eleonora and Foerster, Jakob and Lukasiewicz, Thomas and Blunsom, Phil},
	year         = 2019,
	month        = dec,
	journal      = {arXiv:1910.02065 [cs]},
	url          = {http://arxiv.org/abs/1910.02065},
	urldate      = {2019-12-29},
	note         = {arXiv: 1910.02065},
	keywords     = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file         = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\D3G8HBRP\\1910.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\54ELX4E6\\Camburu et al. - 2019 - Can I Trust the Explainer Verifying Post-hoc Expl.pdf:application/pdf},
	abstract     = {For AI systems to garner widespread public acceptance, we must develop methods capable of explaining the decisions of black-box models such as neural networks. In this work, we identify two issues of current explanatory methods. First, we show that two prevalent perspectives on explanations --- feature-additivity and feature-selection --- lead to fundamentally different instance-wise explanations. In the literature, explainers from different perspectives are currently being directly compared, despite their distinct explanation goals. The second issue is that current post-hoc explainers are either validated under simplistic scenarios (on simple models such as linear regression, or on models trained on syntactic datasets), or, when applied to real-world neural networks, explainers are commonly validated under the assumption that the learned models behave reasonably. However, neural networks often rely on unreasonable correlations, even when producing correct decisions. We introduce a verification framework for explanatory methods under the feature-selection perspective. Our framework is based on a non-trivial neural network architecture trained on a real-world task, and for which we are able to provide guarantees on its inner workings. We validate the efficacy of our evaluation by showing the failure modes of current explainers. We aim for this framework to provide a publicly available, off-the-shelf evaluation when the feature-selection perspective on explanations is needed.}
}
@article{camburu_make_2019,
	title        = {Make Up Your Mind! Adversarial Generation of Inconsistent Natural Language Explanations},
	author       = {Oana-Maria Camburu and Brendan Shillingford and Pasquale Minervini and Thomas Lukasiewicz and Phil Blunsom},
	year         = 2019,
	journal      = {ArXiv},
	volume       = {abs/1910.03065},
	url          = {https://arxiv.org/abs/1910.03065}
}
@inproceedings{camburu_e-snli:_2018,
	title        = {e-SNLI: Natural Language Inference with Natural Language Explanations},
	author       = {Oana-Maria Camburu and Tim Rockt{\"a}schel and Thomas Lukasiewicz and Phil Blunsom},
	year         = 2018,
	booktitle    = {NeurIPS 2018},
	url          = {https://arxiv.org/pdf/1812.01193.pdf}
}
@article{alvarez-melis_causal_2017,
	title        = {A causal framework for explaining the predictions of black-box sequence-to-sequence models},
	author       = {Alvarez-Melis, David and Jaakkola, Tommi S.},
	year         = 2017,
	month        = nov,
	journal      = {arXiv:1707.01943 [cs]},
	url          = {http://arxiv.org/abs/1707.01943},
	urldate      = {2019-12-29},
	note         = {arXiv: 1707.01943},
	abstract     = {We interpret the predictions of any black-box structured input-structured output model around a specific input-output pair. Our method returns an "explanation" consisting of groups of input-output tokens that are causally related. These dependencies are inferred by querying the black-box model with perturbed inputs, generating a graph over tokens from the responses, and solving a partitioning problem to select the most relevant components. We focus the general approach on sequence-to-sequence problems, adopting a variational autoencoder to yield meaningful input perturbations. We test our method across several NLP sequence generation tasks.},
	keywords     = {Computer Science - Machine Learning},
	file         = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\QFYZF6LC\\1707.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\KQIJU8LU\\Alvarez-Melis and Jaakkola - 2017 - A causal framework for explaining the predictions .pdf:application/pdf}
}
@article{roy_unsupervised_2019,
	title        = {Unsupervised {Paraphrasing} without {Translation}},
	author       = {Roy, Aurko and Grangier, David},
	year         = 2019,
	month        = may,
	journal      = {arXiv:1905.12752 [cs, stat]},
	url          = {http://arxiv.org/abs/1905.12752},
	urldate      = {2019-12-29},
	note         = {arXiv: 1905.12752},
	abstract     = {Paraphrasing exemplifies the ability to abstract semantic content from surface forms. Recent work on automatic paraphrasing is dominated by methods leveraging Machine Translation (MT) as an intermediate step. This contrasts with humans, who can paraphrase without being bilingual. This work proposes to learn paraphrasing models from an unlabeled monolingual corpus only. To that end, we propose a residual variant of vector-quantized variational auto-encoder. We compare with MT-based approaches on paraphrase identification, generation, and training augmentation. Monolingual paraphrasing outperforms unsupervised translation in all settings. Comparisons with supervised translation are more mixed: monolingual paraphrasing is interesting for identification and augmentation; supervised translation is superior for generation.},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
	file         = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\BICBWA6M\\1905.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\KGLXVDSA\\Roy and Grangier - 2019 - Unsupervised Paraphrasing without Translation.pdf:application/pdf}
}
@article{perez_finding_2019,
	title        = {Finding {Generalizable} {Evidence} by {Learning} to {Convince} {Q}\&{A} {Models}},
	author       = {Perez, Ethan and Karamcheti, Siddharth and Fergus, Rob and Weston, Jason and Kiela, Douwe and Cho, Kyunghyun},
	year         = 2019,
	month        = sep,
	journal      = {arXiv:1909.05863 [cs]},
	url          = {http://arxiv.org/abs/1909.05863},
	urldate      = {2019-12-21},
	note         = {arXiv: 1909.05863},
	abstract     = {We propose a system that finds the strongest supporting evidence for a given answer to a question, using passage-based question-answering (QA) as a testbed. We train evidence agents to select the passage sentences that most convince a pretrained QA model of a given answer, if the QA model received those sentences instead of the full passage. Rather than finding evidence that convinces one model alone, we find that agents select evidence that generalizes; agent-chosen evidence increases the plausibility of the supported answer, as judged by other QA models and humans. Given its general nature, this approach improves QA in a robust manner: using agent-selected evidence (i) humans can correctly answer questions with only {\textasciitilde}20\% of the full passage and (ii) QA models can generalize to longer passages and harder questions.},
	keywords     = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Multiagent Systems},
	file         = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\HYZ4R67B\\1909.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\E452P2H3\\Perez et al. - 2019 - Finding Generalizable Evidence by Learning to Conv.pdf:application/pdf}
}
@article{irving_ai_2018,
	title        = {{AI} safety via debate},
	author       = {Irving, Geoffrey and Christiano, Paul and Amodei, Dario},
	year         = 2018,
	month        = oct,
	journal      = {arXiv:1805.00899 [cs, stat]},
	url          = {http://arxiv.org/abs/1805.00899},
	urldate      = {2019-12-19},
	note         = {arXiv: 1805.00899},
	abstract     = {To make AI systems broadly useful for challenging real-world tasks, we need them to learn complex human goals and preferences. One approach to specifying complex goals asks humans to judge during training which agent behaviors are safe and useful, but this approach can fail if the task is too complicated for a human to directly judge. To help address this concern, we propose training agents via self play on a zero sum debate game. Given a question or proposed action, two agents take turns making short statements up to a limit, then a human judges which of the agents gave the most true, useful information. In an analogy to complexity theory, debate with optimal play can answer any question in PSPACE given polynomial time judges (direct judging answers only NP questions). In practice, whether debate works involves empirical questions about humans and the tasks we want AIs to perform, plus theoretical questions about the meaning of AI alignment. We report results on an initial MNIST experiment where agents compete to convince a sparse classifier, boosting the classifier's accuracy from 59.4\% to 88.9\% given 6 pixels and from 48.2\% to 85.2\% given 4 pixels. Finally, we discuss theoretical and practical aspects of the debate model, focusing on potential weaknesses as the model scales up, and we propose future human and computer experiments to test these properties.},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\CK3CT6N6\\1805.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\QV3T5EQ2\\Irving et al. - 2018 - AI safety via debate.pdf:application/pdf}
}
@article{srinivas_full-gradient_2019,
	title        = {Full-{Gradient} {Representation} for {Neural} {Network} {Visualization}},
	author       = {Srinivas, Suraj and Fleuret, Francois},
	year         = 2019,
	month        = dec,
	journal      = {arXiv:1905.00780 [cs, stat]},
	url          = {http://arxiv.org/abs/1905.00780},
	urldate      = {2019-12-11},
	note         = {arXiv: 1905.00780},
	abstract     = {We introduce a new tool for interpreting neural net responses, namely full-gradients, which decomposes the neural net response into input sensitivity and per-neuron sensitivity components. This is the first proposed representation which satisfies two key properties: completeness and weak dependence, which provably cannot be satisfied by any saliency map-based interpretability method. For convolutional nets, we also propose an approximate saliency map representation, called FullGrad, obtained by aggregating the full-gradient components. We experimentally evaluate the usefulness of FullGrad in explaining model behaviour with two quantitative tests: pixel perturbation and remove-and-retrain. Our experiments reveal that our method explains model behaviour correctly, and more comprehensively than other methods in the literature. Visual inspection also reveals that our saliency maps are sharper and more tightly confined to object regions than other methods.},
	keywords     = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\4AMXYYWU\\1905.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\8Y9YDAXM\\Srinivas and Fleuret - 2019 - Full-Gradient Representation for Neural Network Vi.pdf:application/pdf}
}
@article{grathwohl_your_2019,
	title        = {Your {Classifier} is {Secretly} an {Energy} {Based} {Model} and {You} {Should} {Treat} it {Like} {One}},
	author       = {Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, Jörn-Henrik and Duvenaud, David and Norouzi, Mohammad and Swersky, Kevin},
	year         = 2019,
	month        = dec,
	journal      = {arXiv:1912.03263 [cs, stat]},
	url          = {http://arxiv.org/abs/1912.03263},
	urldate      = {2019-12-10},
	note         = {arXiv: 1912.03263},
	keywords     = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\E6MCNJ5D\\1912.html:text/html;arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\KLW3IQAE\\Grathwohl et al. - 2019 - Your Classifier is Secretly an Energy Based Model .pdf:application/pdf},
	abstract     = {We propose to reinterpret a standard discriminative classifier of p(y{\textbar}x) as an energy based model for the joint distribution p(x,y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x{\textbar}y). Within this framework, standard discriminative architectures may beused and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, andout-of-distribution detection while also enabling our models to generate samplesrivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and presentan approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-artin both generative and discriminative learning within one hybrid model.}
}
@article{nie_adversarial_2019,
	title        = {Adversarial {NLI}: {A} {New} {Benchmark} for {Natural} {Language} {Understanding}},
	shorttitle   = {Adversarial {NLI}},
	author       = {Nie, Yixin and Williams, Adina and Dinan, Emily and Bansal, Mohit and Weston, Jason and Kiela, Douwe},
	year         = 2019,
	month        = oct,
	journal      = {arXiv:1910.14599 [cs]},
	url          = {http://arxiv.org/abs/1910.14599},
	urldate      = {2019-11-11},
	note         = {arXiv: 1910.14599},
	abstract     = {We introduce a new large-scale NLI benchmark dataset, collected via an iterative, adversarial human-and-model-in-the-loop procedure. We show that training models on this new dataset leads to state-of-the-art performance on a variety of popular NLI benchmarks, while posing a more difficult challenge with its new test set. Our analysis sheds light on the shortcomings of current state-of-the-art models, and shows that non-expert annotators are successful at finding their weaknesses. The data collection method can be applied in a never-ending learning scenario, becoming a moving target for NLU, rather than a static benchmark that will quickly saturate.},
	keywords     = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file         = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\U5KQCW35\\Nie et al. - 2019 - Adversarial NLI A New Benchmark for Natural Langu.pdf:application/pdf}
}
@article{holtzman_curious_2019,
	title        = {The {Curious} {Case} of {Neural} {Text} {Degeneration}},
	author       = {Holtzman, Ari and Buys, Jan and Forbes, Maxwell and Choi, Yejin},
	year         = 2019,
	month        = apr,
	journal      = {arXiv:1904.09751 [cs]},
	url          = {http://arxiv.org/abs/1904.09751},
	urldate      = {2019-09-18},
	note         = {arXiv: 1904.09751},
	abstract     = {Despite considerable advancements with deep neural language models, the enigma of neural text degeneration persists when these models are tested as text generators. The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks, using likelihood as a decoding objective leads to text that is bland and strangely repetitive. In this paper, we reveal surprising distributional differences between human text and machine text. In addition, we find that decoding strategies alone can dramatically effect the quality of machine text, even when generated from exactly the same neural language model. Our findings motivate Nucleus Sampling, a simple but effective method to draw the best out of neural generation. By sampling text from the dynamic nucleus of the probability distribution, which allows for diversity while effectively truncating the less reliable tail of the distribution, the resulting text better demonstrates the quality of human text, yielding enhanced diversity without sacrificing fluency and coherence.},
	keywords     = {Computer Science - Computation and Language},
	file         = {arXiv\:1904.09751 PDF:C\:\\Users\\peter\\Zotero\\storage\\IC3YHFSP\\Holtzman et al. - 2019 - The Curious Case of Neural Text Degeneration.pdf:application/pdf}
}
@article{raffel_exploring_2019,
	title        = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
	author       = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
	year         = 2019,
	journal      = {ArXiv},
	volume       = {abs/1910.10683},
	url          = {https://arxiv.org/pdf/1910.10683.pdf}
}
@article{dodge_fine-tuning_2020,
	title        = {Fine-{Tuning} {Pretrained} {Language} {Models}: {Weight} {Initializations}, {Data} {Orders}, and {Early} {Stopping}},
	shorttitle   = {Fine-{Tuning} {Pretrained} {Language} {Models}},
	author       = {Dodge, Jesse and Ilharco, Gabriel and Schwartz, Roy and Farhadi, Ali and Hajishirzi, Hannaneh and Smith, Noah},
	year         = 2020,
	month        = feb,
	journal      = {arXiv:2002.06305 [cs]},
	url          = {http://arxiv.org/abs/2002.06305},
	urldate      = {2020-02-18},
	note         = {arXiv: 2002.06305},
	abstract     = {Fine-tuning pretrained contextual word embedding models to supervised downstream tasks has become commonplace in natural language processing. This process, however, is often brittle: even with the same hyperparameter values, distinct random seeds can lead to substantially different results. To better understand this phenomenon, we experiment with four datasets from the GLUE benchmark, fine-tuning BERT hundreds of times on each while varying only the random seeds. We find substantial performance increases compared to previously reported results, and we quantify how the performance of the best-found model varies as a function of the number of fine-tuning trials. Further, we examine two factors influenced by the choice of random seed: weight initialization and training data order. We find that both contribute comparably to the variance of out-of-sample performance, and that some weight initializations perform well across all tasks explored. On small datasets, we observe that many fine-tuning trials diverge part of the way through training, and we offer best practices for practitioners to stop training less promising runs early. We publicly release all of our experimental data, including training and validation scores for 2,100 trials, to encourage further analysis of training dynamics during fine-tuning.},
	keywords     = {Computer Science - Computation and Language},
	file         = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\NX5EY93K\\Dodge et al. - 2020 - Fine-Tuning Pretrained Language Models Weight Ini.pdf:application/pdf}
}
@article{he_lagging_2019,
	title        = {Lagging {Inference} {Networks} and {Posterior} {Collapse} in {Variational} {Autoencoders}},
	author       = {He, Junxian and Spokoyny, Daniel and Neubig, Graham and Berg-Kirkpatrick, Taylor},
	year         = 2019,
	month        = jan,
	journal      = {arXiv:1901.05534 [cs, stat]},
	url          = {http://arxiv.org/abs/1901.05534},
	urldate      = {2020-02-18},
	note         = {arXiv: 1901.05534},
	abstract     = {The variational autoencoder (VAE) is a popular combination of deep latent variable model and accompanying variational learning technique. By using a neural inference network to approximate the model's posterior on latent variables, VAEs efficiently parameterize a lower bound on marginal data likelihood that can be optimized directly via gradient methods. In practice, however, VAE training often results in a degenerate local optimum known as "posterior collapse" where the model learns to ignore the latent variable and the approximate posterior mimics the prior. In this paper, we investigate posterior collapse from the perspective of training dynamics. We find that during the initial stages of training the inference network fails to approximate the model's true posterior, which is a moving target. As a result, the model is encouraged to ignore the latent encoding and posterior collapse occurs. Based on this observation, we propose an extremely simple modification to VAE training to reduce inference lag: depending on the model's current mutual information between latent variable and observation, we aggressively optimize the inference network before performing each model update. Despite introducing neither new model components nor significant complexity over basic VAE, our approach is able to avoid the problem of collapse that has plagued a large amount of previous work. Empirically, our approach outperforms strong autoregressive baselines on text and image benchmarks in terms of held-out likelihood, and is competitive with more complex techniques for avoiding collapse while being substantially faster.},
	keywords     = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\WTPNDDLI\\He et al. - 2019 - Lagging Inference Networks and Posterior Collapse .pdf:application/pdf}
}
@article{liu_towards_2019,
	title        = {Towards {Explainable} {NLP}: {A} {Generative} {Explanation} {Framework} for {Text} {Classification}},
	shorttitle   = {Towards {Explainable} {NLP}},
	author       = {Liu, Hui and Yin, Qingyu and Wang, William Yang},
	year         = 2019,
	month        = jun,
	journal      = {arXiv:1811.00196 [cs]},
	url          = {http://arxiv.org/abs/1811.00196},
	urldate      = {2020-02-19},
	note         = {arXiv: 1811.00196},
	abstract     = {Building explainable systems is a critical problem in the field of Natural Language Processing (NLP), since most machine learning models provide no explanations for the predictions. Existing approaches for explainable machine learning systems tend to focus on interpreting the outputs or the connections between inputs and outputs. However, the fine-grained information is often ignored, and the systems do not explicitly generate the human-readable explanations. To better alleviate this problem, we propose a novel generative explanation framework that learns to make classification decisions and generate fine-grained explanations at the same time. More specifically, we introduce the explainable factor and the minimum risk training approach that learn to generate more reasonable explanations. We construct two new datasets that contain summaries, rating scores, and fine-grained reasons. We conduct experiments on both datasets, comparing with several strong neural network baseline systems. Experimental results show that our method surpasses all baselines on both datasets, and is able to generate concise explanations at the same time.},
	keywords     = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	file         = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\C3G84CBU\\Liu et al. - 2019 - Towards Explainable NLP A Generative Explanation .pdf:application/pdf}
}
@inproceedings{bowman_large_2015,
	title        = {A large annotated corpus for learning natural language inference},
	author       = {Samuel R. Bowman and Gabor Angeli and Christopher Potts and Christopher D. Manning},
	year         = 2015,
	booktitle    = {EMNLP 2015},
	url          = {https://arxiv.org/abs/1508.05326}
}
@article{olah_building_2018,
	title        = {The {Building} {Blocks} of {Interpretability}},
	author       = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
	year         = 2018,
	month        = mar,
	journal      = {Distill},
	volume       = 3,
	number       = 3,
	pages        = {e10},
	doi          = {10.23915/distill.00010},
	issn         = {2476-0757},
	url          = {https://distill.pub/2018/building-blocks},
	urldate      = {2020-03-18},
	abstract     = {Interpretability techniques are normally studied in isolation. We explore the powerful interfaces that arise when you combine them -- and the rich structure of this combinatorial space.},
	language     = {en}
}
@article{jansen_worldtree_2018,
	title        = {{WorldTree}: {A} {Corpus} of {Explanation} {Graphs} for {Elementary} {Science} {Questions} supporting {Multi}-{Hop} {Inference}},
	shorttitle   = {{WorldTree}},
	author       = {Jansen, Peter A. and Wainwright, Elizabeth and Marmorstein, Steven and Morrison, Clayton T.},
	year         = 2018,
	month        = feb,
	journal      = {arXiv:1802.03052 [cs]},
	url          = {http://arxiv.org/abs/1802.03052},
	urldate      = {2020-03-27},
	note         = {arXiv: 1802.03052},
	abstract     = {Developing methods of automated inference that are able to provide users with compelling human-readable justifications for why the answer to a question is correct is critical for domains such as science and medicine, where user trust and detecting costly errors are limiting factors to adoption. One of the central barriers to training question answering models on explainable inference tasks is the lack of gold explanations to serve as training data. In this paper we present a corpus of explanations for standardized science exams, a recent challenge task for question answering. We manually construct a corpus of detailed explanations for nearly all publicly available standardized elementary science question (approximately 1,680 3rd through 5th grade questions) and represent these as "explanation graphs" -- sets of lexically overlapping sentences that describe how to arrive at the correct answer to a question through a combination of domain and world knowledge. We also provide an explanation-centered tablestore, a collection of semi-structured tables that contain the knowledge to construct these elementary science explanations. Together, these two knowledge resources map out a substantial portion of the knowledge required for answering and explaining elementary science exams, and provide both structured and free-text training data for the explainable inference task.},
	keywords     = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file         = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\CZJ4FG3J\\Jansen et al. - 2018 - WorldTree A Corpus of Explanation Graphs for Elem.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\3YD4BNXT\\1802.html:text/html}
}
@article{lazaridou_towards_2016,
	title        = {Towards {Multi}-{Agent} {Communication}-{Based} {Language} {Learning}},
	author       = {Lazaridou, Angeliki and Pham, Nghia The and Baroni, Marco},
	year         = 2016,
	month        = may,
	journal      = {arXiv:1605.07133 [cs]},
	url          = {http://arxiv.org/abs/1605.07133},
	urldate      = {2020-03-27},
	note         = {arXiv: 1605.07133},
	abstract     = {We propose an interactive multimodal framework for language learning. Instead of being passively exposed to large amounts of natural text, our learners (implemented as feed-forward neural networks) engage in cooperative referential games starting from a tabula rasa setup, and thus develop their own language from the need to communicate in order to succeed at the game. Preliminary experiments provide promising results, but also suggest that it is important to ensure that agents trained in this way do not develop an adhoc communication code only effective for the game they are playing},
	keywords     = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Computation and Language},
	file         = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\JT4Y8ES2\\Lazaridou et al. - 2016 - Towards Multi-Agent Communication-Based Language L.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\X9MCYSW5\\1605.html:text/html}
}
@inproceedings{lazaridou_multi-agent_2017,
	title        = {Multi-Agent Cooperation and the Emergence of (Natural) Language},
	author       = {Angeliki Lazaridou and Alexander Peysakhovich and Marco Baroni},
	year         = 2017,
	booktitle    = {ICLR 2017},
	url          = {https://arxiv.org/pdf/1612.07182.pdf}
}
@inproceedings{das_tarmac_nodate,
	title        = {TarMAC: Targeted Multi-Agent Communication},
	author       = {Abhishek Das and Th{\'e}ophile Gervet and Joshua Romoff and Dhruv Batra and Devi Parikh and Michael G. Rabbat and Joelle Pineau},
	year         = 2018,
	booktitle    = {ICML 2018},
	url          = {https://arxiv.org/abs/1810.11187}
}
@article{kottur_natural_2017,
	title        = {Natural {Language} {Does} {Not} {Emerge} '{Naturally}' in {Multi}-{Agent} {Dialog}},
	author       = {Kottur, Satwik and Moura, José M. F. and Lee, Stefan and Batra, Dhruv},
	year         = 2017,
	month        = aug,
	journal      = {arXiv:1706.08502 [cs]},
	url          = {http://arxiv.org/abs/1706.08502},
	urldate      = {2020-03-27},
	note         = {arXiv: 1706.08502},
	abstract     = {A number of recent works have proposed techniques for end-to-end learning of communication protocols among cooperative multi-agent populations, and have simultaneously found the emergence of grounded human-interpretable language in the protocols developed by the agents, all learned without any human supervision! In this paper, using a Task and Tell reference game between two agents as a testbed, we present a sequence of 'negative' results culminating in a 'positive' one -- showing that while most agent-invented languages are effective (i.e. achieve near-perfect task rewards), they are decidedly not interpretable or compositional. In essence, we find that natural language does not emerge 'naturally', despite the semblance of ease of natural-language-emergence that one may gather from recent literature. We discuss how it is possible to coax the invented languages to become more and more human-like and compositional by increasing restrictions on how two agents may communicate.},
	keywords     = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
	file         = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\AHEMUD72\\Kottur et al. - 2017 - Natural Language Does Not Emerge 'Naturally' in Mu.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\A8PNEIQG\\1706.html:text/html}
}
@inproceedings{mordatch_emergence_nodate,
	title        = {Emergence of Grounded Compositional Language in Multi-Agent Populations},
	author       = {Igor Mordatch and Pieter Abbeel},
	year         = 2017,
	booktitle    = {AAAI 2017},
	url          = {https://arxiv.org/pdf/1703.04908.pdf}
}
@incollection{sukhbaatar_learning_2016,
	title        = {Learning {Multiagent} {Communication} with {Backpropagation}},
	author       = {Sukhbaatar, Sainbayar and szlam, arthur and Fergus, Rob},
	year         = 2016,
	booktitle    = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher    = {Curran Associates, Inc.},
	pages        = {2244--2252},
	url          = {http://papers.nips.cc/paper/6398-learning-multiagent-communication-with-backpropagation.pdf},
	urldate      = {2020-03-31},
	editor       = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	file         = {NIPS Full Text PDF:C\:\\Users\\peter\\Zotero\\storage\\AHSF47XW\\Sukhbaatar et al. - 2016 - Learning Multiagent Communication with Backpropaga.pdf:application/pdf;NIPS Snapshot:C\:\\Users\\peter\\Zotero\\storage\\YPZNF4UQ\\6398-learning-multiagent-communication-with-backpropagation.html:text/html}
}
@article{lewis_bart_2019,
	title        = {{BART}: {Denoising} {Sequence}-to-{Sequence} {Pre}-training for {Natural} {Language} {Generation}, {Translation}, and {Comprehension}},
	shorttitle   = {{BART}},
	author       = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
	year         = 2019,
	month        = oct,
	journal      = {arXiv:1910.13461 [cs, stat]},
	url          = {http://arxiv.org/abs/1910.13461},
	urldate      = {2020-04-06},
	note         = {arXiv: 1910.13461},
	abstract     = {We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and many other more recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of the original sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa with comparable training resources on GLUE and SQuAD, achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 6 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also report ablation experiments that replicate other pretraining schemes within the BART framework, to better measure which factors most influence end-task performance.},
	keywords     = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	file         = {arXiv Fulltext PDF:C\:\\Users\\peter\\Zotero\\storage\\ZL9C68Q2\\Lewis et al. - 2019 - BART Denoising Sequence-to-Sequence Pre-training .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\peter\\Zotero\\storage\\XQ79FHPY\\1910.html:text/html}
}
@misc{atcinnik_explaining_2020,
	title        = {Explaining Question Answering Models through Text Generation},
	author       = {Veronica Latcinnik and Jonathan Berant},
	year         = 2020,
	eprint       = {arXiv:2004.05569}
}
@inproceedings{hendricks2018grounding,
	title        = {Grounding Visual Explanations},
	author       = {Lisa Anne Hendricks and Ronghang Hu and Trevor Darrell and Zeynep Akata},
	year         = 2018,
	booktitle    = {ECCV 2018},
	url          = {https://arxiv.org/pdf/1807.09685.pdf}
}
@article{narang_wt5?!_2020,
	title        = {W{T}5?! Training Text-to-Text Models to Explain their Predictions},
	author       = {Sharan Narang and Colin Raffel and Katherine J. Lee and Adam Roberts and Noah Fiedel and Karishma Malkan},
	year         = 2020,
	journal      = {ArXiv},
	volume       = {abs/2004.14546},
	url          = {https://arxiv.org/pdf/2004.14546.pdf}
}
@article{treviso_towards_2020,
	title        = {Towards Prediction Explainability through Sparse Communication},
	author       = {Marcos Vin{\'i}cius Treviso and Andr{\'e} F. T. Martins},
	year         = 2020,
	journal      = {ArXiv},
	volume       = {abs/2004.13876},
	url          = {https://arxiv.org/pdf/2004.13876.pdf}
}
@inproceedings{hase_evaluating_2020,
	title        = {Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?},
	author       = {Peter Hase and Mohit Bansal},
	year         = 2020,
	booktitle    = {ACL 2020},
	url          = {https://arxiv.org/pdf/2005.01831.pdf}
}
@inproceedings{papineni2002bleu,
	title        = {Bleu: a Method for Automatic Evaluation of Machine Translation},
	author       = {Kishore Papineni and Salim Roukos and Todd Ward and Wei-Jing Zhu},
	year         = 2002,
	booktitle    = {ACL 2002},
	url          = {https://www.aclweb.org/anthology/P02-1040.pdf}
}
@inproceedings{maddison_concrete_2016,
	title        = {The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables},
	author       = {Chris J. Maddison and Andriy Mnih and Yee Whye Teh},
	year         = 2017,
	booktitle    = {ICLR 2017},
	url          = {https://arxiv.org/abs/1611.00712}
}
@article{williams_simple_1992,
	title        = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
	author       = {Ronald J. Williams},
	year         = 1992,
	journal      = {Machine Learning},
	volume       = 8,
	pages        = {229--256},
	url          = {https://link.springer.com/article/10.1023/A:1022672621406}
}
@article{pearl_causal_2009,
	title        = {Causal Inference in Statistics: {An} Overview},
	shorttitle   = {Causal Inference in Statistics},
	author       = {Pearl, Judea},
	year         = 2009,
	journal      = {Statistics Surveys},
	volume       = 3,
	number       = {0},
	pages        = {96--146},
	doi          = {10.1214/09-SS057},
	issn         = {1935-7516},
	url          = {http://projecteuclid.org/euclid.ssu/1255440554},
	urldate      = {2020-05-23},
	language     = {en},
	file         = {Pearl - 2009 - Causal inference in statistics An overview.pdf:C\:\\Users\\Peter Hase\\Zotero\\storage\\FDL9H6S6\\Pearl - 2009 - Causal inference in statistics An overview.pdf:application/pdf}
}
@inproceedings{kumar_NILE_2020,
	title        = {NILE : Natural Language Inference with Faithful Natural Language Explanations},
	author       = {Sawan Kumar and Partha Talukdar},
	year         = 2020,
	booktitle    = {ACL 2020},
	url          = {https://arxiv.org/abs/2005.12116}
}
@article{li_understanding_2016,
	title        = {Understanding {Neural} {Networks} through {Representation} {Erasure}},
	author       = {Li, Jiwei and Monroe, Will and Jurafsky, Dan},
	year         = 2016,
	journal      = {arXiv:1612.08220 [cs]},
	url          = {http://arxiv.org/abs/1612.08220},
	urldate      = {2019-11-04},
	note         = {arXiv: 1612.08220},
	keywords     = {Computer Science - Computation and Language}
}
@article{platt,
	title        = {Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods},
	author       = {Platt, John},
	year         = 2000,
	month        = {06},
	journal      = {Adv. Large Margin Classif.},
	volume       = 10,
	pages        = {}
}
@inproceedings{hooker_benchmark_2019,
	title        = {A Benchmark for Interpretability Methods in Deep Neural Networks},
	author       = {Sara Hooker and Dumitru Erhan and Pieter-Jan Kindermans and Been Kim},
	year         = 2019,
	booktitle    = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
	url          = {https://arxiv.org/abs/1806.10758},
	eprint       = {arXiv:1806.10758}
}
@inproceedings{lowe_pitfalls_2019,
	title        = {On the Pitfalls of Measuring Emergent Communication},
	author       = {Ryan Lowe and Jakob N. Foerster and Y-Lan Boureau and Joelle Pineau and Yann Dauphin},
	year         = 2019,
	booktitle    = {AAMAS 2019},
	url          = {https://arxiv.org/pdf/1903.05168.pdf}
}
@book{efron1994introduction,
	title        = {An Introduction to the Bootstrap},
	author       = {Efron, Bradley and Tibshirani, Robert J},
	year         = 1994,
	publisher    = {CRC press}
}
@inproceedings{jacovi2020towards,
	title        = {Towards Faithfully Interpretable NLP Systems: How should we define and evaluate faithfulness?},
	author       = {Alon Jacovi and Yoav Goldberg},
	year         = 2020,
	booktitle    = {ACL 2020},
	url          = {https://www.aclweb.org/anthology/2020.acl-main.386.pdf}
}
@book{cohen1988,
	title        = {Statistical Power Analysis for the Behavioral Sciences},
	author       = {Cohen, Jacob},
	year         = 1988,
	publisher    = {Routledge},
	isbn         = 9780805802832,
	added-at     = {2017-03-30T21:37:25.000+0200},
	biburl       = {https://www.bibsonomy.org/bibtex/2a06021817e224b8dca50df7c138c128d/sveng},
	interhash    = {ab4b29867f1552a9ab20b69edf9df19d},
	intrahash    = {a06021817e224b8dca50df7c138c128d},
	keywords     = {- / Analysis, General, Mathematics Methodology, Multivariate Probabilities, Probability Probability, Psychology Research Science Social Statistical Statistics Statistics, \& analysis, methods, power sciences sciences, sciences/ statistic Когнитивна Статистически анализ наука,},
	timestamp    = {2017-04-01T10:50:30.000+0200}
}
@article{pavlick2019,
	title        = {Inherent Disagreements in Human Textual Inferences},
	author       = {Pavlick, Ellie and Kwiatkowski, Tom},
	year         = 2019,
	journal      = {Transactions of the Association for Computational Linguistics},
	volume       = 7,
	number       = {},
	pages        = {677--694},
	doi          = {10.1162/tacl\_a\_00293},
	url          = {https://doi.org/10.1162/tacl_a_00293},
	eprint       = {https://doi.org/10.1162/tacl_a_00293}
}
@inproceedings{lazaridou2020,
	title        = {Multi-agent Communication meets Natural Language: Synergies between Functional and Structural Language Learning},
	author       = {Angeliki Lazaridou and Anna Potapenko and Olivier Tieleman},
	year         = 2020,
	booktitle    = {ACL 2020},
	publisher    = {Association for Computational Linguistics},
	pages        = {7663--7674},
	url          = {https://www.aclweb.org/anthology/2020.acl-main.685/},
	timestamp    = {Wed, 24 Jun 2020 17:15:07 +0200},
	biburl       = {https://dblp.org/rec/conf/acl/LazaridouPT20.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{bastings-2019-interpretable,
	title        = {Interpretable Neural Predictions with Differentiable Binary Variables},
	author       = {Bastings, Jasmijn  and Aziz, Wilker  and Titov, Ivan},
	year         = 2019,
	month        = jul,
	booktitle    = {ACL 2019},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {2963--2977},
	doi          = {10.18653/v1/P19-1284},
	url          = {https://www.aclweb.org/anthology/P19-1284}
}
@inproceedings{jain2020,
	title        = {Learning to Faithfully Rationalize by Construction},
	author       = {Jain, Sarthak  and Wiegreffe, Sarah  and Pinter, Yuval  and Wallace, Byron C.},
	year         = 2020,
	month        = jul,
	booktitle    = {ACL 2020},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {4459--4473},
	doi          = {10.18653/v1/2020.acl-main.409},
	url          = {https://www.aclweb.org/anthology/2020.acl-main.409}
}
@article{dodge2020,
	title        = {Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping},
	author       = {Jesse Dodge and Gabriel Ilharco and Roy Schwartz and Ali Farhadi and Hannaneh Hajishirzi and Noah A. Smith},
	year         = 2020,
	journal      = {CoRR},
	volume       = {abs/2002.06305},
	url          = {https://arxiv.org/abs/2002.06305},
	archiveprefix = {arXiv},
	eprint       = {2002.06305},
	timestamp    = {Mon, 02 Mar 2020 16:46:06 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2002-06305.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{post2018call,
	title        = {A Call for Clarity in Reporting BLEU Scores},
	author       = {Post, Matt},
	year         = 2018,
	booktitle    = {Proceedings of the Third Conference on Machine Translation: Research Papers},
	pages        = {186--191}
}
@inproceedings{talmor2020teaching,
	title        = {Leap-Of-Thought: Teaching Pre-Trained Models to Systematically Reason Over Implicit Knowledge},
	author       = {Alon Talmor and Oyvind Tafjord and Peter Clark and Yoav Goldberg and Jonathan Berant},
	year         = 2020,
	booktitle    = {NeurIPS 2020},
	url          = {https://arxiv.org/abs/2006.06609},
	archiveprefix = {arXiv},
	eprint       = {2006.06609},
	timestamp    = {Sat, 13 Jun 2020 18:28:13 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2006-06609.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{Co-Reyes2019Guiding,
	title        = {Guiding Policies with Language via Meta-Learning},
	author       = {John D. Co{-}Reyes and Abhishek Gupta and Suvansh Sanjeev and Nick Altieri and Jacob Andreas and John DeNero and Pieter Abbeel and Sergey Levine},
	year         = 2019,
	booktitle    = {{ICLR} 2019},
	url          = {https://openreview.net/forum?id=HkgSEnA5KQ},
	timestamp    = {Thu, 25 Jul 2019 14:25:52 +0200},
	biburl       = {https://dblp.org/rec/conf/iclr/Co-ReyesGSAADAL19.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{rupprecht2018guide,
	title        = {Guide Me: Interacting with Deep Networks},
	author       = {Rupprecht, Christian and Laina, Iro and Navab, Nassir and Harger, Gregory D. and Tombari, Federico},
	year         = 2018,
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, {CVPR 2018}},
	url          = {https://arxiv.org/abs/1803.11544}
}
@inproceedings{ba2016using,
	title        = {Using Fast Weights to Attend to the Recent Past},
	author       = {Jimmy Ba and Geoffrey E. Hinton and Volodymyr Mnih and Joel Z. Leibo and Catalin Ionescu},
	year         = 2016,
	booktitle    = {NeurIPS 2016},
	url          = {http://papers.nips.cc/paper/6057-using-fast-weights-to-attend-to-the-recent-past},
	editor       = {Daniel D. Lee and Masashi Sugiyama and Ulrike von Luxburg and Isabelle Guyon and Roman Garnett},
	timestamp    = {Fri, 06 Mar 2020 17:00:15 +0100},
	biburl       = {https://dblp.org/rec/conf/nips/BaHMLI16.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{Munkhdalai2019Metalearned,
	title        = {Metalearned Neural Memory},
	author       = {Tsendsuren Munkhdalai and Alessandro Sordoni and Tong Wang and Adam Trischler},
	year         = 2019,
	booktitle    = {NeurIPS 2019},
	pages        = {13310--13321},
	url          = {http://papers.nips.cc/paper/9488-metalearned-neural-memory},
	editor       = {Hanna M. Wallach and Hugo Larochelle and Alina Beygelzimer and Florence d'Alch{\'{e}}{-}Buc and Emily B. Fox and Roman Garnett},
	timestamp    = {Fri, 06 Mar 2020 16:59:09 +0100},
	biburl       = {https://dblp.org/rec/conf/nips/MunkhdalaiSWT19.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{Srivastava2018LearningCF,
	title        = {Learning Classifiers from Declarative Language},
	author       = {Shashank Srivastava and I. Labutov and T. Mitchell},
	year         = 2017,
	booktitle    = {NeurIPS 2017},
	url          = {http://www.cs.cmu.edu/~shashans/papers/srivastava17-lldworkshop.pdf}
}
@inproceedings{awasthi2020learning,
	title        = {Learning from Rules Generalizing Labeled Exemplars},
	author       = {Abhijeet Awasthi and Sabyasachi Ghosh and Rasna Goyal and Sunita Sarawagi},
	year         = 2020,
	booktitle    = {ICLR 2020},
	url          = {https://arxiv.org/pdf/2004.06025.pdf},
	timestamp    = {Thu, 07 May 2020 17:11:48 +0200},
	biburl       = {https://dblp.org/rec/conf/iclr/AwasthiGGS20.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{huang2020counterfactually,
	title        = {Counterfactually-Augmented {SNLI} Training Data Does Not Yield Better Generalization Than Unaugmented Data},
	author       = {William Huang and Haokun Liu and Samuel R. Bowman},
	year         = 2020,
	journal      = {CoRR},
	volume       = {abs/2010.04762},
	url          = {https://arxiv.org/abs/2010.04762},
	archiveprefix = {arXiv},
	eprint       = {2010.04762},
	timestamp    = {Tue, 20 Oct 2020 15:08:10 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2010-04762.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{kaushik2020learning,
	title        = {Learning The Difference That Makes {A} Difference With Counterfactually-Augmented Data},
	author       = {Divyansh Kaushik and Eduard H. Hovy and Zachary Chase Lipton},
	year         = 2020,
	booktitle    = {ICLR 2020},
	url          = {https://arxiv.org/abs/1909.12434},
	timestamp    = {Thu, 07 May 2020 17:11:48 +0200},
	biburl       = {https://dblp.org/rec/conf/iclr/KaushikHL20.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{andreas2018learning,
	title        = {Learning with Latent Language},
	author       = {Jacob Andreas and Dan Klein and Sergey Levine},
	year         = 2018,
	booktitle    = {NAACL-HLT 2018},
	doi          = {10.18653/v1/n18-1197},
	url          = {https://doi.org/10.18653/v1/n18-1197},
	editor       = {Marilyn A. Walker and Heng Ji and Amanda Stent},
	timestamp    = {Tue, 28 Jan 2020 10:30:21 +0100},
	biburl       = {https://dblp.org/rec/conf/naacl/AndreasKL18.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{garnelo2018conditional,
	title        = {Conditional Neural Processes},
	author       = {Marta Garnelo and Dan Rosenbaum and Christopher Maddison and Tiago Ramalho and David Saxton and Murray Shanahan and Yee Whye Teh and Danilo Jimenez Rezende and S. M. Ali Eslami},
	year         = 2018,
	booktitle    = {ICML 2018},
	url          = {http://proceedings.mlr.press/v80/garnelo18a.html},
	editor       = {Jennifer G. Dy and Andreas Krause},
	timestamp    = {Wed, 03 Apr 2019 18:17:30 +0200},
	biburl       = {https://dblp.org/rec/conf/icml/GarneloRMRSSTRE18.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{requeima2019fast,
	title        = {Fast and Flexible Multi-Task Classification using Conditional Neural Adaptive Processes},
	author       = {James Requeima and Jonathan Gordon and John Bronskill and Sebastian Nowozin and Richard E. Turner},
	year         = 2019,
	booktitle    = {NeurIPS 2019},
	url          = {http://papers.nips.cc/paper/9009-fast-and-flexible-multi-task-classification-using-conditional-neural-adaptive-processes},
	editor       = {Hanna M. Wallach and Hugo Larochelle and Alina Beygelzimer and Florence d'Alch{\'{e}}{-}Buc and Emily B. Fox and Roman Garnett},
	timestamp    = {Fri, 06 Mar 2020 16:59:09 +0100},
	biburl       = {https://dblp.org/rec/conf/nips/Requeima0BNT19.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{kim2019attentive,
	title        = {Attentive Neural Processes},
	author       = {Hyunjik Kim and Andriy Mnih and Jonathan Schwarz and Marta Garnelo and S. M. Ali Eslami and Dan Rosenbaum and Oriol Vinyals and Yee Whye Teh},
	year         = 2019,
	booktitle    = {ICLR 2019},
	url          = {https://openreview.net/forum?id=SkE6PjC9KX},
	timestamp    = {Thu, 25 Jul 2019 14:25:41 +0200},
	biburl       = {https://dblp.org/rec/conf/iclr/KimMSGERVT19.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{hinton1987using,
	title        = {Using fast weights to deblur old memories},
	author       = {Hinton, Geoffrey E and Plaut, David C},
	year         = 1987,
	booktitle    = {Proceedings of the ninth annual conference of the Cognitive Science Society},
	url          = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.1011}
}
@inproceedings{srivastava2018zero,
	title        = {Zero-shot Learning of Classifiers from Natural Language Quantification},
	author       = {Srivastava, Shashank  and Labutov, Igor  and Mitchell, Tom},
	year         = 2018,
	month        = jul,
	booktitle    = {ACL 2018},
	doi          = {10.18653/v1/P18-1029},
	url          = {https://www.aclweb.org/anthology/P18-1029}
}
@article{sikka2020deep,
	title        = {Deep Adaptive Semantic Logic (DASL): Compiling Declarative Knowledge into Deep Neural Networks},
	author       = {Sikka, Karan and Silberfarb, Andrew and Byrnes, John and Sur, Indranil and Chow, Ed and Divakaran, Ajay and Rohwer, Richard},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2003.07344},
	url          = {https://arxiv.org/pdf/2003.07344.pdf}
}
@inproceedings{nie-etal-2020-adversarial,
	title        = {Adversarial {NLI}: A New Benchmark for Natural Language Understanding},
	author       = {Nie, Yixin  and Williams, Adina  and Dinan, Emily  and Bansal, Mohit  and Weston, Jason  and Kiela, Douwe},
	year         = 2020,
	month        = jul,
	booktitle    = {ACL 2020},
	url          = {https://www.aclweb.org/anthology/2020.acl-main.441}
}
@inproceedings{koh2017understanding,
	title        = {Understanding black-box predictions via influence functions},
	author       = {Koh, Pang Wei and Liang, Percy},
	year         = 2017,
	booktitle    = {ICML 2017},
	pages        = {1885--1894},
	url          = {https://arxiv.org/pdf/1703.04730.pdf},
	organization = {JMLR. org}
}
@inproceedings{perez2018film,
	title        = {FiLM: Visual Reasoning with a General Conditioning Layer},
	author       = {Ethan Perez and Florian Strub and Harm de Vries and Vincent Dumoulin and Aaron C. Courville},
	year         = 2018,
	booktitle    = {AAAI},
	url          = {https://arxiv.org/pdf/1709.07871.pdf}
}
@inproceedings{ha2016hypernetworks,
	title        = {Hypernetworks},
	author       = {Ha, David and Dai, Andrew and Le, Quoc V},
	year         = 2017,
	booktitle    = {ICLR 2017},
	url          = {https://openreview.net/pdf?id=rkpACe1lx}
}
@inproceedings{hase2020leakage,
	title        = {Leakage-Adjusted Simulatability: Can Models Generate Non-Trivial Explanations of Their Behavior in Natural Language?},
	author       = {Peter Hase and Shiyue Zhang and Harry Xie and Mohit Bansal},
	year         = 2020,
	booktitle    = {Findings of EMNLP},
	url          = {https://arxiv.org/abs/2010.04119}
}
@inproceedings{lipton2017,
	title        = {The Mythos of Model Interpretability},
	author       = {Zachary C. Lipton},
	year         = 2016,
	booktitle    = {2016 ICML Workshop on Human Interpretability in Machine Learning},
	eprint       = {arXiv:1606.03490}
}
@inproceedings{gilpin2019,
	title        = {Explaining Explanations: An Overview of Interpretability of Machine Learning},
	author       = {L. H. {Gilpin} and D. {Bau} and B. Z. {Yuan} and A. {Bajwa} and M. {Specter} and L. {Kagal}},
	year         = 2018,
	booktitle    = {2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA)},
	volume       = {},
	number       = {},
	pages        = {80--89}
}
@inproceedings{han2020explaining,
	title        = {Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions},
	author       = {Xiaochuang Han and Byron C. Wallace and Yulia Tsvetkov},
	year         = 2020,
	booktitle    = {ACL},
	eprint       = {arXiv:2005.06676}
}
@article{olah2020an,
	title        = {An Overview of Early Vision in InceptionV1},
	author       = {Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
	year         = 2020,
	journal      = {Distill},
	doi          = {10.23915/distill.00024.002},
	note         = {https://distill.pub/2020/circuits/early-vision}
}
@article{cook1977detection,
	title        = {Detection of influential observation in linear regression},
	author       = {Cook, R Dennis},
	year         = 1977,
	journal      = {Technometrics},
	publisher    = {Taylor \& Francis Group},
	volume       = 19,
	number       = 1,
	pages        = {15--18}
}
@article{cook1986assessment,
	title        = {Assessment of local influence},
	author       = {Cook, R Dennis},
	year         = 1986,
	journal      = {Journal of the Royal Statistical Society: Series B (Methodological)},
	publisher    = {Wiley Online Library},
	volume       = 48,
	number       = 2,
	pages        = {133--155}
}
@article{cook1980characterizations,
	title        = {Characterizations of an empirical influence function for detecting influential cases in regression},
	author       = {Cook, R Dennis and Weisberg, Sanford},
	year         = 1980,
	journal      = {Technometrics},
	publisher    = {Taylor \& Francis},
	volume       = 22,
	number       = 4,
	pages        = {495--508}
}
@book{cook1982residuals,
	title        = {Residuals and influence in regression},
	author       = {Cook, R Dennis and Weisberg, Sanford},
	year         = 1982,
	publisher    = {New York: Chapman and Hall}
}
@article{chatterjee1986influential,
	title        = {Influential observations, high leverage points, and outliers in linear regression},
	author       = {Chatterjee, Samprit and Hadi, Ali S and others},
	year         = 1986,
	journal      = {Statistical science},
	publisher    = {Institute of Mathematical Statistics},
	volume       = 1,
	number       = 3,
	pages        = {379--393}
}
@article{thomas1990assessing,
	title        = {Assessing influence on predictions from generalized linear models},
	author       = {Thomas, William and Cook, R Dennis},
	year         = 1990,
	journal      = {Technometrics},
	publisher    = {Taylor \& Francis},
	volume       = 32,
	number       = 1,
	pages        = {59--65}
}
@article{wei1998generalized,
	title        = {Generalized leverage and its applications},
	author       = {Wei, Bo-Cheng and Hu, Yue-Qing and Fung, Wing-Kam},
	year         = 1998,
	journal      = {Scandinavian Journal of statistics},
	publisher    = {Wiley Online Library},
	volume       = 25,
	number       = 1,
	pages        = {25--37}
}
@book{faraway2016extending,
	title        = {Extending the linear model with R: generalized linear, mixed effects and nonparametric regression models},
	author       = {Faraway, Julian J},
	year         = 2016,
	publisher    = {CRC press}
}
@article{christmann2004robustness,
	title        = {On robustness properties of convex risk minimization methods for pattern recognition},
	author       = {Christmann, Andreas and Steinwart, Ingo},
	year         = 2004,
	journal      = {Journal of Machine Learning Research},
	volume       = 5,
	number       = {Aug},
	pages        = {1007--1034}
}
@article{debruyne2008model,
	title        = {Model selection in kernel based regression using the influence function},
	author       = {Debruyne, Michiel and Hubert, Mia and Suykens, Johan AK},
	year         = 2008,
	journal      = {Journal of Machine Learning Research},
	volume       = 9,
	number       = {Oct},
	pages        = {2377--2400}
}
@inproceedings{liu2014efficient,
	title        = {Efficient approximation of cross-validation for kernel methods using Bouligand influence function},
	author       = {Liu, Yong and Jiang, Shali and Liao, Shizhong},
	year         = 2014,
	booktitle    = {International Conference on Machine Learning},
	pages        = {324--332}
}
@article{basu2020influence,
	title        = {Influence functions in deep learning are fragile},
	author       = {Basu, Samyadeep and Pope, Philip and Feizi, Soheil},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.14651}
}
@inproceedings{koh2019accuracy,
	title        = {On the accuracy of influence functions for measuring group effects},
	author       = {Koh, Pang Wei W and Ang, Kai-Siang and Teo, Hubert and Liang, Percy S},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {5254--5264}
}
@inproceedings{yang2020g,
	title        = {G-DAUG: Generative Data Augmentation for Commonsense Reasoning},
	author       = {Yang, Yiben and Malaviya, Chaitanya and Fernandez, Jared and Swayamdipta, Swabha and Bras, Ronan Le and Wang, Ji-Ping and Bhagavatula, Chandra and Choi, Yejin and Downey, Doug},
	year         = 2020,
	booktitle    = {Findings of EMNLP}
}
@inproceedings{ghorbani2019data,
	title        = {Data Shapley: Equitable Valuation of Data for Machine Learning},
	author       = {Ghorbani, Amirata and Zou, James},
	year         = 2019,
	booktitle    = {International Conference on Machine Learning},
	pages        = {2242--2251}
}
@article{ghorbani2020distributional,
	title        = {A Distributional Framework for Data Valuation},
	author       = {Ghorbani, Amirata and Kim, Michael P and Zou, James},
	year         = 2020,
	journal      = {ICML}
}
@article{belinkov2019analysis,
	title        = {Analysis methods in neural language processing: A survey},
	author       = {Belinkov, Yonatan and Glass, James},
	year         = 2019,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	volume       = 7,
	pages        = {49--72}
}
@inproceedings{jain2019attention,
	title        = {Attention is not Explanation},
	author       = {Jain, Sarthak and Wallace, Byron C},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	pages        = {3543--3556}
}
@inproceedings{wiegreffe2019attention,
	title        = {Attention is not not Explanation},
	author       = {Wiegreffe, Sarah and Pinter, Yuval},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	pages        = {11--20},
	url          = {https://arxiv.org/pdf/1908.04626.pdf}
}
@article{zhong2019fine,
	title        = {Fine-grained sentiment analysis with faithful attention},
	author       = {Zhong, Ruiqi and Shao, Steven and McKeown, Kathleen},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1908.06870},
	url          = {https://arxiv.org/pdf/1908.06870.pdf}
}
@article{simonyan_2013_deep,
	title        = {Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps},
	author       = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
	year         = 2013,
	journal      = {Workshop at International Conference on Learning Representations.},
	url          = {https://arxiv.org/pdf/1312.6034.pdf}
}
@inproceedings{shrikumar2017learning,
	title        = {Learning Important Features Through Propagating Activation Differences},
	author       = {Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
	year         = 2017,
	booktitle    = {International Conference on Machine Learning},
	pages        = {3145--3153},
	url          = {https://arxiv.org/pdf/1704.02685.pdf}
}
@inproceedings{sundararajan_2017_axiomatic,
	title        = {Axiomatic Attribution for Deep Networks},
	author       = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	year         = 2017,
	booktitle    = {International Conference on Machine Learning},
	pages        = {3319--3328},
	url          = {https://arxiv.org/pdf/1703.01365.pdf}
}
@article{smilkov2017smoothgrad,
	title        = {Smoothgrad: removing noise by adding noise},
	author       = {Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1706.03825},
	url          = {https://arxiv.org/pdf/1706.03825.pdf}
}
@inproceedings{feng2018pathologies,
	title        = {Pathologies of Neural Models Make Interpretations Difficult},
	author       = {Feng, Shi and Wallace, Eric and Grissom II, Alvin and Iyyer, Mohit and Rodriguez, Pedro and Boyd-Graber, Jordan},
	year         = 2018,
	booktitle    = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
	pages        = {3719--3728}
}
@inproceedings{ribeiro2020beyond,
	title        = {Beyond Accuracy: Behavioral Testing of NLP models with CheckList},
	author       = {Marco Tulio Ribeiro and Tongshuang Wu and Carlos Guestrin and Sameer Singh},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2005.04118},
	booktitle    = {Association for Computational Linguistics (ACL)},
	url          = {https://arxiv.org/pdf/2005.04118.pdf}
}
@inproceedings{wallace2019allennlp,
	title        = {AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models},
	author       = {Wallace, Eric and Tuyls, Jens and Wang, Junlin and Subramanian, Sanjay and Gardner, Matt and Singh, Sameer},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations},
	pages        = {7--12}
}
@inproceedings{chen2019looks,
	title        = {This looks like that: deep learning for interpretable image recognition},
	author       = {Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K},
	year         = 2019,
	booktitle    = {Advances in neural information processing systems},
	pages        = {8930--8941}
}
@inproceedings{hase2019interpretable,
	title        = {Interpretable Image Recognition with Hierarchical Prototypes},
	author       = {Hase, Peter and Chen, Chaofan and Li, Oscar and Rudin, Cynthia},
	year         = 2019,
	booktitle    = {Proceedings of the AAAI Conference on Human Computation and Crowdsourcing}
}
@article{joshi2018xgems,
	title        = {xGEMs: Generating examplars to explain black-box models},
	author       = {Joshi, Shalmali and Koyejo, Oluwasanmi and Kim, Been and Ghosh, Joydeep},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1806.08867}
}
@inproceedings{samangouei2018explaingan,
	title        = {Explaingan: Model explanation via decision boundary crossing transformations},
	author       = {Samangouei, Pouya and Saeedi, Ardavan and Nakagawa, Liam and Silberman, Nathan},
	year         = 2018,
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)},
	pages        = {666--681}
}
@article{rajani2020explaining,
	title        = {Explaining and Improving Model Behavior with k Nearest Neighbor Representations},
	author       = {Rajani, Nazneen Fatema and Krause, Ben and Yin, Wengpeng and Niu, Tong and Socher, Richard and Xiong, Caiming},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2010.09030}
}
@article{Meng2020PairTD,
	title        = {Pair the Dots: Jointly Examining Training History and Test Stimuli for Model Interpretability},
	author       = {Yuxian Meng and C. Fan and Zijun Sun and E. Hovy and Fei Wu and J. Li},
	year         = 2020,
	journal      = {ArXiv},
	volume       = {abs/2010.06943},
	url          = {https://arxiv.org/abs/2010.06943}
}
@article{agarwal2017second,
	title        = {Second-Order Stochastic Optimization for Machine Learning in Linear Time},
	author       = {Agarwal, Naman and Bullins, Brian and Hazan, Elad},
	year         = 2017,
	journal      = {Journal of Machine Learning Research},
	volume       = 18,
	number       = 116,
	pages        = {1--40}
}
@incollection{NEURIPS2019_9015,
	title        = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
	author       = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems 32},
	publisher    = {Curran Associates, Inc.},
	pages        = {8024--8035},
	url          = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}
@article{lee2019would,
	title        = {What Would Elsa Do? Freezing Layers During Transformer Fine-Tuning},
	author       = {Lee, Jaejun and Tang, Raphael and Lin, Jimmy},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1911.03090}
}
@inproceedings{kobayashi-etal-2020-efficient,
	title        = {Efficient Estimation of Influence of a Training Instance},
	author       = {Kobayashi, Sosuke  and Yokoi, Sho  and Suzuki, Jun  and Inui, Kentaro},
	year         = 2020,
	month        = nov,
	booktitle    = {Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {41--47},
	url          = {https://www.aclweb.org/anthology/2020.sustainlp-1.6},
	abstract     = {Understanding the influence of a training instance on a neural network model leads to improving interpretability. However, it is difficult and inefficient to evaluate the influence, which shows how a model{'}s prediction would be changed if a training instance were not used. In this paper, we propose an efficient method for estimating the influence. Our method is inspired by dropout, which zero-masks a sub-network and prevents the sub-network from learning each training instance. By switching between dropout masks, we can use sub-networks that learned or did not learn each training instance and estimate its influence. Through experiments with BERT and VGGNet on classification datasets, we demonstrate that the proposed method can capture training influences, enhance the interpretability of error predictions, and cleanse the training dataset for improving generalization.}
}
@inproceedings{treviso-martins-2020-explanation,
	title        = {The Explanation Game: Towards Prediction Explainability through Sparse Communication},
	author       = {Treviso, Marcos  and Martins, Andr{\'e} F. T.},
	year         = 2020,
	month        = nov,
	booktitle    = {Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {107--118},
	url          = {https://www.aclweb.org/anthology/2020.blackboxnlp-1.10}
}
@book{hastie2009elements,
	title        = {The elements of statistical learning: data mining, inference, and prediction},
	author       = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	year         = 2009,
	publisher    = {Springer Science \& Business Media}
}
@inproceedings{mccoy2019right,
	title        = {Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference},
	author       = {McCoy, Tom and Pavlick, Ellie and Linzen, Tal},
	year         = 2019,
	booktitle    = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
	pages        = {3428--3448}
}
@inproceedings{williams2018broad,
	title        = {A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference},
	author       = {Williams, Adina and Nangia, Nikita and Bowman, Samuel R},
	year         = 2018,
	booktitle    = {Proceedings of NAACL-HLT},
	pages        = {1112--1122}
}
@inproceedings{devlin2019bert,
	title        = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	author       = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	pages        = {4171--4186}
}
@inproceedings{schulam2019can,
	title        = {Can You Trust This Prediction? Auditing Pointwise Reliability After Learning},
	author       = {Schulam, Peter and Saria, Suchi},
	year         = 2019,
	booktitle    = {The 22nd International Conference on Artificial Intelligence and Statistics},
	pages        = {1022--1031}
}
@inproceedings{brunet2019understanding,
	title        = {Understanding the origins of bias in word embeddings},
	author       = {Brunet, Marc-Etienne and Alkalay-Houlihan, Colleen and Anderson, Ashton and Zemel, Richard},
	year         = 2019,
	booktitle    = {International Conference on Machine Learning},
	pages        = {803--811},
	organization = {PMLR}
}
@article{koh2018stronger,
	title        = {Stronger data poisoning attacks break data sanitization defenses},
	author       = {Koh, Pang Wei and Steinhardt, Jacob and Liang, Percy},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1811.00741}
}
@inproceedings{basu2020second,
	title        = {On Second-Order Group Influence Functions for Black-Box Predictions},
	author       = {Basu, Samyadeep and You, Xuchen and Feizi, Soheil},
	year         = 2020,
	booktitle    = {International Conference on Machine Learning},
	pages        = {715--724},
	organization = {PMLR}
}
@inproceedings{jia2019towards,
	title        = {Towards Efficient Data Valuation Based on the Shapley Value},
	author       = {Jia, Ruoxi and Dao, David and Wang, Boxin and Hubis, Frances Ann and Hynes, Nick and G{\"u}rel, Nezihe Merve and Li, Bo and Zhang, Ce and Song, Dawn and Spanos, Costas J},
	year         = 2019,
	booktitle    = {The 22nd International Conference on Artificial Intelligence and Statistics},
	pages        = {1167--1176}
}
@article{jia2019efficient,
	title        = {Efficient task-specific data valuation for nearest neighbor algorithms},
	author       = {Jia, Ruoxi and Dao, David and Wang, Boxin and Hubis, Frances Ann and Gurel, Nezihe Merve and Li, Bo and Zhang, Ce and Spanos, Costas and Song, Dawn},
	year         = 2019,
	journal      = {Proceedings of the VLDB Endowment},
	publisher    = {VLDB Endowment},
	volume       = 12,
	number       = 11,
	pages        = {1610--1623}
}
@article{kwon2020efficient,
	title        = {Efficient computation and analysis of distributional Shapley values},
	author       = {Kwon, Yongchan and Rivas, Manuel A and Zou, James},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2007.01357}
}
@inproceedings{khandelwal2019generalization,
	title        = {Generalization through Memorization: Nearest Neighbor Language Models},
	author       = {Khandelwal, Urvashi and Levy, Omer and Jurafsky, Dan and Zettlemoyer, Luke and Lewis, Mike},
	year         = 2019,
	booktitle    = {International Conference on Learning Representations}
}
@article{feldman2020neural,
	title        = {What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation},
	author       = {Feldman, Vitaly and Zhang, Chiyuan},
	year         = 2020,
	journal      = {Advances in Neural Information Processing Systems},
	booktitle    = {Advances in Neural Information Processing Systems},
	volume       = 33
}
@article{wiegreffe2020,
	title        = {Measuring Association Between Labels and Free-Text Rationales},
	author       = {Sarah Wiegreffe and Ana Marasovic and Noah A. Smith},
	year         = 2020,
	journal      = {CoRR},
	volume       = {abs/2010.12762},
	url          = {https://arxiv.org/abs/2010.12762},
	archiveprefix = {arXiv},
	eprint       = {2010.12762},
	timestamp    = {Mon, 02 Nov 2020 18:17:09 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2010-12762.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{pruthi2020,
	title        = {Evaluating Explanations: How much do explanations from the teacher aid students?},
	author       = {Danish Pruthi and Bhuwan Dhingra and Livio Baldini Soares and Michael Collins and Zachary C. Lipton and Graham Neubig and William W. Cohen},
	year         = 2020,
	journal      = {CoRR},
	volume       = {abs/2012.00893},
	url          = {https://arxiv.org/abs/2012.00893},
	archiveprefix = {arXiv},
	eprint       = {2012.00893},
	timestamp    = {Fri, 04 Dec 2020 12:07:23 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2012-00893.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{li2016understanding,
	title        = {Understanding Neural Networks through Representation Erasure},
	author       = {Li, Jiwei and Monroe, Will and Jurafsky, Dan},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1612.08220},
	url          = {https://arxiv.org/pdf/1612.08220.pdf}
}
@article{wolf2019huggingface,
	title        = {HuggingFace's Transformers: State-of-the-art Natural Language Processing},
	author       = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
	year         = 2019,
	journal      = {ArXiv},
	pages        = {arXiv--1910}
}
@inproceedings{zaidan-etal-2007-using,
	title        = {Using {``}Annotator Rationales{''} to Improve Machine Learning for Text Categorization},
	author       = {Zaidan, Omar  and Eisner, Jason  and Piatko, Christine},
	year         = 2007,
	month        = apr,
	booktitle    = {NAACL HLT},
	publisher    = {Association for Computational Linguistics},
	address      = {Rochester, New York},
	pages        = {260--267},
	url          = {https://www.aclweb.org/anthology/N07-1033}
}
@inproceedings{small2011constrained,
	title        = {The constrained weight space svm: learning with ranked features},
	author       = {Small, Kevin and Wallace, Byron C and Brodley, Carla E and Trikalinos, Thomas A},
	year         = 2011,
	booktitle    = {ICML},
	pages        = {865--872},
	urk          = {https://icml.cc/2011/papers/465_icmlpaper.pdf}
}
@inproceedings{zhang-etal-2016-rationale,
	title        = {Rationale-Augmented Convolutional Neural Networks for Text Classification},
	author       = {Zhang, Ye  and Marshall, Iain  and Wallace, Byron C.},
	year         = 2016,
	month        = nov,
	booktitle    = {EMNLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Austin, Texas},
	pages        = {795--804},
	doi          = {10.18653/v1/D16-1076},
	url          = {https://www.aclweb.org/anthology/D16-1076}
}
@inproceedings{wang2019learning,
	title        = {Learning from explanations with neural execution tree},
	author       = {Wang, Ziqi and Qin, Yujia and Zhou, Wenxuan and Yan, Jun and Ye, Qinyuan and Neves, Leonardo and Liu, Zhiyuan and Ren, Xiang},
	year         = 2019,
	booktitle    = {ICLR},
	url          = {https://openreview.net/pdf?id=rJlUt0EYwS}
}
@inproceedings{bao-etal-2018-deriving,
	title        = {Deriving Machine Attention from Human Rationales},
	author       = {Bao, Yujia  and Chang, Shiyu  and Yu, Mo  and Barzilay, Regina},
	year         = 2018,
	month        = oct # {-} # nov,
	booktitle    = {EMNLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Brussels, Belgium},
	pages        = {1903--1913},
	doi          = {10.18653/v1/D18-1216},
	url          = {https://www.aclweb.org/anthology/D18-1216}
}
@inproceedings{zhou2020towards,
	title        = {Towards Interpretable Natural Language Understanding with Explanations as Latent Variables},
	author       = {Zhou, Wangchunshu and Hu, Jinyi and Zhang, Hanlin and Liang, Xiaodan and Sun, Maosong and Xiong, Chenyan and Tang, Jian},
	year         = 2020,
	booktitle    = {NeurIPS},
	url          = {https://arxiv.org/pdf/2011.05268.pdf}
}
@inproceedings{zhao2020lirex,
	title        = {LIREx: Augmenting language inference with relevant explanation},
	author       = {Zhao, Xinyan and Vydiswaran, VG},
	year         = 2021,
	booktitle    = {AAAI}
}
@inproceedings{liang2020alice,
	title        = {{ALICE:} Active Learning with Contrastive Natural Language Explanations},
	author       = {Weixin Liang and James Zou and Zhou Yu},
	year         = 2020,
	booktitle    = {EMNLP},
	publisher    = {Association for Computational Linguistics},
	pages        = {4380--4391},
	url          = {https://www.aclweb.org/anthology/2020.emnlp-main.355/},
	editor       = {Bonnie Webber and Trevor Cohn and Yulan He and Yang Liu},
	timestamp    = {Thu, 19 Nov 2020 16:13:16 +0100},
	biburl       = {https://dblp.org/rec/conf/emnlp/LiangZY20.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{murty2020expbert,
	title        = {ExpBERT: Representation Engineering with Natural Language Explanations},
	author       = {Shikhar Murty and Pang Wei Koh and Percy Liang},
	year         = 2020,
	booktitle    = {ACL},
	publisher    = {Association for Computational Linguistics},
	pages        = {2106--2113},
	url          = {https://www.aclweb.org/anthology/2020.acl-main.190/},
	editor       = {Dan Jurafsky and Joyce Chai and Natalie Schluter and Joel R. Tetreault},
	timestamp    = {Wed, 24 Jun 2020 17:15:07 +0200},
	biburl       = {https://dblp.org/rec/conf/acl/MurtyKL20.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{ba2015predicting,
	title        = {Predicting Deep Zero-Shot Convolutional Neural Networks Using Textual Descriptions},
	author       = {Lei Jimmy Ba and Kevin Swersky and Sanja Fidler and Ruslan Salakhutdinov},
	year         = 2015,
	booktitle    = {2015 {IEEE} International Conference on Computer Vision, {ICCV} 2015, Santiago, Chile, December 7-13, 2015},
	publisher    = {{IEEE} Computer Society},
	pages        = {4247--4255},
	doi          = {10.1109/ICCV.2015.483},
	url          = {https://doi.org/10.1109/ICCV.2015.483},
	timestamp    = {Wed, 16 Oct 2019 14:14:51 +0200},
	biburl       = {https://dblp.org/rec/conf/iccv/BaSFS15.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{weller-etal-2020-learning,
	title        = {Learning from Task Descriptions},
	author       = {Weller, Orion  and Lourie, Nicholas  and Gardner, Matt  and Peters, Matthew},
	year         = 2020,
	month        = nov,
	booktitle    = {EMNLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {1361--1375},
	doi          = {10.18653/v1/2020.emnlp-main.105},
	url          = {https://www.aclweb.org/anthology/2020.emnlp-main.105}
}
@inproceedings{de-cao-etal-2020-decisions,
	title        = {How do Decisions Emerge across Layers in Neural Models? Interpretation with Differentiable Masking},
	author       = {De Cao, Nicola  and Schlichtkrull, Michael Sejr  and Aziz, Wilker  and Titov, Ivan},
	year         = 2020,
	month        = nov,
	booktitle    = {EMNLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {3243--3255},
	doi          = {10.18653/v1/2020.emnlp-main.262},
	url          = {https://www.aclweb.org/anthology/2020.emnlp-main.262}
}
@inproceedings{karpukhin-etal-2020-dense,
	title        = {Dense Passage Retrieval for Open-Domain Question Answering},
	author       = {Karpukhin, Vladimir  and Oguz, Barlas  and Min, Sewon  and Lewis, Patrick  and Wu, Ledell  and Edunov, Sergey  and Chen, Danqi  and Yih, Wen-tau},
	year         = 2020,
	month        = nov,
	booktitle    = {EMNLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {6769--6781},
	doi          = {10.18653/v1/2020.emnlp-main.550},
	url          = {https://www.aclweb.org/anthology/2020.emnlp-main.550}
}
@article{JDH17,
	title        = {Billion-scale similarity search with GPUs},
	author       = {Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
	year         = 2017,
	journal      = {IEEE Transactions on Big Data},
	url          = {https://arxiv.org/pdf/1702.08734.pdf}
}
@inproceedings{madumal2020explainable,
	title        = {Explainable Reinforcement Learning through a Causal Lens},
	author       = {Prashan Madumal and Tim Miller and Liz Sonenberg and Frank Vetere},
	year         = 2020,
	booktitle    = {AAAI},
	publisher    = {{AAAI} Press},
	pages        = {2493--2500},
	url          = {https://aaai.org/ojs/index.php/AAAI/article/view/5631},
	timestamp    = {Fri, 05 Jun 2020 09:50:08 +0200},
	biburl       = {https://dblp.org/rec/conf/aaai/Madumal0SV20.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{reed2017few-shot,
	title        = {Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions},
	author       = {Scott E. Reed and Yutian Chen and Thomas Paine and A{\"{a}}ron van den Oord and S. M. Ali Eslami and Danilo Jimenez Rezende and Oriol Vinyals and Nando de Freitas},
	year         = 2017,
	journal      = {CoRR},
	volume       = {abs/1710.10304},
	url          = {http://arxiv.org/abs/1710.10304},
	archiveprefix = {arXiv},
	eprint       = {1710.10304},
	timestamp    = {Mon, 13 Aug 2018 16:46:27 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1710-10304.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{McCann2018Natural,
	title        = {The Natural Language Decathlon: Multitask Learning as Question Answering},
	author       = {Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},
	year         = 2018,
	journal      = {CoRR},
	volume       = {abs/1806.08730},
	url          = {http://arxiv.org/abs/1806.08730},
	archiveprefix = {arXiv},
	eprint       = {1806.08730},
	timestamp    = {Mon, 13 Aug 2018 16:49:05 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1806-08730.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{reimers-gurevych-2019-sentence,
	title        = {Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks},
	author       = {Reimers, Nils  and Gurevych, Iryna},
	year         = 2019,
	month        = nov,
	booktitle    = {EMNLP-IJCNLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Hong Kong, China},
	pages        = {3982--3992},
	doi          = {10.18653/v1/D19-1410},
	url          = {https://www.aclweb.org/anthology/D19-1410}
}
@article{beltagy2020longformer,
	title        = {Longformer: The Long-Document Transformer},
	author       = {Iz Beltagy and Matthew E. Peters and Arman Cohan},
	year         = 2020,
	journal      = {CoRR},
	volume       = {abs/2004.05150},
	url          = {https://arxiv.org/abs/2004.05150},
	archiveprefix = {arXiv},
	eprint       = {2004.05150},
	timestamp    = {Tue, 14 Apr 2020 16:40:34 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2004-05150.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{baldini-soares-etal-2019-matching,
	title        = {Matching the Blanks: Distributional Similarity for Relation Learning},
	author       = {Baldini Soares, Livio  and FitzGerald, Nicholas  and Ling, Jeffrey  and Kwiatkowski, Tom},
	year         = 2019,
	month        = jul,
	booktitle    = {ACL},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {2895--2905},
	doi          = {10.18653/v1/P19-1279},
	url          = {https://www.aclweb.org/anthology/P19-1279}
}
@article{lewis2020pretraining,
	title        = {Pre-training via Paraphrasing},
	author       = {Mike Lewis and Marjan Ghazvininejad and Gargi Ghosh and Armen Aghajanyan and Sida I. Wang and Luke Zettlemoyer},
	year         = 2020,
	journal      = {CoRR},
	volume       = {abs/2006.15020},
	url          = {https://arxiv.org/abs/2006.15020},
	archiveprefix = {arXiv},
	eprint       = {2006.15020},
	timestamp    = {Wed, 23 Sep 2020 10:33:27 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2006-15020.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{guu2020retrieval,
	title        = {Retrieval Augmented Language Model Pre-Training},
	author       = {Kelvin Guu and Kenton Lee and Zora Tung and Panupong Pasupat and Ming{-}Wei Chang},
	year         = 2020,
	booktitle    = {ICML},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research},
	volume       = 119,
	pages        = {3929--3938},
	url          = {http://proceedings.mlr.press/v119/guu20a.html},
	timestamp    = {Tue, 15 Dec 2020 17:40:18 +0100},
	biburl       = {https://dblp.org/rec/conf/icml/GuuLTPC20.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{sun2020selfexplaining,
	title        = {Self-Explaining Structures Improve {NLP} Models},
	author       = {Zijun Sun and Chun Fan and Qinghong Han and Xiaofei Sun and Yuxian Meng and Fei Wu and Jiwei Li},
	year         = 2020,
	journal      = {CoRR},
	volume       = {abs/2012.01786},
	url          = {https://arxiv.org/abs/2012.01786},
	archiveprefix = {arXiv},
	eprint       = {2012.01786},
	timestamp    = {Fri, 04 Dec 2020 12:07:23 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2012-01786.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{hendrickx-etal-2010-semeval,
	title        = {{S}em{E}val-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals},
	author       = {Hendrickx, Iris  and Kim, Su Nam  and Kozareva, Zornitsa  and Nakov, Preslav  and {\'O} S{\'e}aghdha, Diarmuid  and Pad{\'o}, Sebastian  and Pennacchiotti, Marco  and Romano, Lorenza  and Szpakowicz, Stan},
	year         = 2010,
	month        = jul,
	booktitle    = {Proceedings of the 5th International Workshop on Semantic Evaluation},
	publisher    = {Association for Computational Linguistics},
	address      = {Uppsala, Sweden},
	pages        = {33--38},
	url          = {https://www.aclweb.org/anthology/S10-1006}
}
@inproceedings{zhang2017tacred,
	title        = {Position-aware Attention and Supervised Data Improve Slot Filling},
	author       = {Zhang, Yuhao and Zhong, Victor and Chen, Danqi and Angeli, Gabor and Manning, Christopher D.},
	year         = 2017,
	booktitle    = {EMNLP},
	pages        = {35--45},
	url          = {https://nlp.stanford.edu/pubs/zhang2017tacred.pdf}
}
@article{liu2021can,
	title        = {Can Small and Synthetic Benchmarks Drive Modeling Innovation? A Retrospective Study of Question Answering Modeling Approaches},
	author       = {Nelson F. Liu and Tony Lee and Robin Jia and Percy Liang},
	year         = 2021,
	journal      = {CoRR},
	url          = {https://arxiv.org/pdf/2102.01065.pdf},
	eprint       = {arXiv:2102.01065}
}
@article{stammer2020right,
	title        = {Right for the Right Concept: Revising Neuro-Symbolic Concepts by Interacting with their Explanations},
	author       = {Wolfgang Stammer and Patrick Schramowski and Kristian Kersting},
	year         = 2020,
	journal      = {CoRR},
	volume       = {abs/2011.12854},
	url          = {https://arxiv.org/abs/2011.12854},
	archiveprefix = {arXiv},
	eprint       = {2011.12854},
	timestamp    = {Tue, 01 Dec 2020 14:59:59 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2011-12854.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{ross2017right,
	title        = {Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations},
	author       = {Andrew Slavin Ross and Michael C. Hughes and Finale Doshi-Velez},
	year         = 2017,
	booktitle    = {IJCAI},
	pages        = {2662--2670},
	doi          = {10.24963/ijcai.2017/371},
	url          = {https://doi.org/10.24963/ijcai.2017/371}
}
@inproceedings{selvaraju2019taking,
	title        = {Taking a {HINT:} Leveraging Explanations to Make Vision and Language Models More Grounded},
	author       = {Ramprasaath Ramasamy Selvaraju and Stefan Lee and Yilin Shen and Hongxia Jin and Shalini Ghosh and Larry P. Heck and Dhruv Batra and Devi Parikh},
	year         = 2019,
	booktitle    = {ICCV},
	publisher    = {{IEEE}},
	pages        = {2591--2600},
	doi          = {10.1109/ICCV.2019.00268},
	url          = {https://doi.org/10.1109/ICCV.2019.00268},
	timestamp    = {Thu, 05 Mar 2020 13:43:22 +0100},
	biburl       = {https://dblp.org/rec/conf/iccv/SelvarajuLSJGHB19.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{ravfogel-etal-2020-null,
	title        = {Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection},
	author       = {Ravfogel, Shauli  and Elazar, Yanai  and Gonen, Hila  and Twiton, Michael  and Goldberg, Yoav},
	year         = 2020,
	month        = jul,
	booktitle    = ACL,
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {7237--7256},
	doi          = {10.18653/v1/2020.acl-main.647},
	url          = {https://www.aclweb.org/anthology/2020.acl-main.647}
}
@article{Elazar2020amnesic,
	title        = {{Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals}},
	author       = {{Elazar}, Yanai and {Ravfogel}, Shauli and {Jacovi}, Alon and {Goldberg}, Yoav},
	year         = 2020,
	month        = jun,
	journal      = {arXiv e-prints},
	pages        = {arXiv:2006.00995},
	keywords     = {Computer Science - Computation and Language},
	eid          = {arXiv:2006.00995},
	archiveprefix = {arXiv},
	eprint       = {2006.00995},
	primaryclass = {cs.CL},
	adsurl       = {https://ui.adsabs.harvard.edu/abs/2020arXiv200600995E}
}
@inproceedings{kim-etal-2020-interpretation,
	title        = {Interpretation of {NLP} models through input marginalization},
	author       = {Kim, Siwon  and Yi, Jihun  and Kim, Eunji  and Yoon, Sungroh},
	year         = 2020,
	month        = nov,
	booktitle    = {EMNLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {3154--3167},
	doi          = {10.18653/v1/2020.emnlp-main.255},
	url          = {https://www.aclweb.org/anthology/2020.emnlp-main.255}
}
@article{Janizek2020Explaining,
	title        = {Explaining Explanations: Axiomatic Feature Interactions for Deep Networks},
	author       = {Joseph D. Janizek and Pascal Sturmfels and Su{-}In Lee},
	year         = 2020,
	journal      = {CoRR},
	volume       = {abs/2002.04138},
	url          = {https://arxiv.org/abs/2002.04138},
	archiveprefix = {arXiv},
	eprint       = {2002.04138},
	timestamp    = {Wed, 12 Feb 2020 16:38:55 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2002-04138.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{ebrahimi-etal-2018-hotflip,
	title        = {{H}ot{F}lip: White-Box Adversarial Examples for Text Classification},
	author       = {Ebrahimi, Javid  and Rao, Anyi  and Lowd, Daniel  and Dou, Dejing},
	year         = 2018,
	month        = jul,
	booktitle    = {ACL},
	publisher    = {Association for Computational Linguistics},
	address      = {Melbourne, Australia},
	pages        = {31--36},
	doi          = {10.18653/v1/P18-2006},
	url          = {https://www.aclweb.org/anthology/P18-2006}
}
@inproceedings{paranjape-etal-2020-information,
	title        = {An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction},
	author       = {Paranjape, Bhargavi  and Joshi, Mandar  and Thickstun, John  and Hajishirzi, Hannaneh  and Zettlemoyer, Luke},
	year         = 2020,
	month        = nov,
	booktitle    = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {1938--1952},
	doi          = {10.18653/v1/2020.emnlp-main.153},
	url          = {https://www.aclweb.org/anthology/2020.emnlp-main.153}
}
@inproceedings{chen-ji-2020-learning,
	title        = {Learning Variational Word Masks to Improve the Interpretability of Neural Text Classifiers},
	author       = {Chen, Hanjie  and Ji, Yangfeng},
	year         = 2020,
	month        = nov,
	booktitle    = {EMNLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {4236--4251},
	doi          = {10.18653/v1/2020.emnlp-main.347},
	url          = {https://www.aclweb.org/anthology/2020.emnlp-main.347}
}
@inproceedings{maksymilian2020feature,
	title        = {Feature Importance Ranking for Deep Learning},
	author       = {Wojtas, Maksymilian and Chen, Ke},
	year         = 2020,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 33,
	pages        = {5105--5114},
	url          = {https://proceedings.neurips.cc/paper/2020/file/36ac8e558ac7690b6f44e2cb5ef93322-Paper.pdf},
	editor       = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin}
}
@inproceedings{belanger2016structured,
	title        = {Structured Prediction Energy Networks},
	author       = {David Belanger and Andrew McCallum},
	year         = 2016,
	booktitle    = {ICML},
	publisher    = {JMLR.org},
	series       = {{JMLR} Workshop and Conference Proceedings},
	volume       = 48,
	pages        = {983--992},
	url          = {http://proceedings.mlr.press/v48/belanger16.html},
	editor       = {Maria{-}Florina Balcan and Kilian Q. Weinberger},
	timestamp    = {Wed, 29 May 2019 08:41:46 +0200},
	biburl       = {https://dblp.org/rec/conf/icml/BelangerM16.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{carton-etal-2020-evaluating,
	title        = {Evaluating and Characterizing Human Rationales},
	author       = {Carton, Samuel  and Rathore, Anirudh  and Tan, Chenhao},
	year         = 2020,
	month        = nov,
	booktitle    = EMNLP,
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {9294--9307},
	doi          = {10.18653/v1/2020.emnlp-main.747},
	url          = {https://www.aclweb.org/anthology/2020.emnlp-main.747}
}
@inproceedings{tu2018learning,
	title        = {Learning Approximate Inference Networks for Structured Prediction},
	author       = {Lifu Tu and Kevin Gimpel},
	year         = 2018,
	booktitle    = {ICLR},
	publisher    = {OpenReview.net},
	url          = {https://openreview.net/forum?id=H1WgVz-AZ},
	timestamp    = {Thu, 25 Jul 2019 14:25:44 +0200},
	biburl       = {https://dblp.org/rec/conf/iclr/TuG18.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{mothilal2020explaining,
	title        = {Explaining machine learning classifiers through diverse counterfactual explanations},
	author       = {Ramaravind Kommiya Mothilal and Amit Sharma and Chenhao Tan},
	year         = 2020,
	booktitle    = {FAT* '20: Conference on Fairness, Accountability, and Transparency},
	publisher    = {{ACM}},
	pages        = {607--617},
	doi          = {10.1145/3351095.3372850},
	url          = {https://doi.org/10.1145/3351095.3372850},
	editor       = {Mireille Hildebrandt and Carlos Castillo and Elisa Celis and Salvatore Ruggieri and Linnet Taylor and Gabriela Zanfir{-}Fortuna},
	timestamp    = {Thu, 26 Mar 2020 12:29:40 +0100},
	biburl       = {https://dblp.org/rec/conf/fat/MothilalST20.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{schafer2013particle,
	title        = {Particle algorithms for optimization on binary spaces},
	author       = {Sch{\"a}fer, Christian},
	year         = 2013,
	journal      = {ACM Transactions on Modeling and Computer Simulation (TOMACS)},
	publisher    = {ACM New York, NY, USA},
	volume       = 23,
	number       = 1,
	pages        = {1--25},
	url          = {https://arxiv.org/pdf/1111.0574.pdf}
}
@inproceedings{lakkaraju2019faithful,
	title        = {Faithful and customizable explanations of black box models},
	author       = {Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
	pages        = {131--138},
	url          = {https://papers.nips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf}
}
@inproceedings{baptista2018bayesian,
	title        = {Bayesian optimization of combinatorial structures},
	author       = {Baptista, Ricardo and Poloczek, Matthias},
	year         = 2018,
	booktitle    = {International Conference on Machine Learning},
	pages        = {462--471},
	url          = {http://proceedings.mlr.press/v80/baptista18a/baptista18a.pdf},
	organization = {PMLR}
}
@inproceedings{belanger2017end-to-end,
	title        = {End-to-End Learning for Structured Prediction Energy Networks},
	author       = {David Belanger and Bishan Yang and Andrew McCallum},
	year         = 2017,
	booktitle    = {Proceedings of the 34th International Conference on Machine Learning, {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research},
	volume       = 70,
	pages        = {429--439},
	url          = {http://proceedings.mlr.press/v70/belanger17a.html},
	editor       = {Doina Precup and Yee Whye Teh},
	timestamp    = {Wed, 29 May 2019 08:41:45 +0200},
	biburl       = {https://dblp.org/rec/conf/icml/BelangerYM17.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{RobnikSikonja2008ExplainingCF,
	title        = {Explaining Classifications For Individual Instances},
	author       = {M. Robnik-Sikonja and I. Kononenko},
	year         = 2008,
	journal      = {IEEE Transactions on Knowledge and Data Engineering},
	volume       = 20,
	pages        = {589--600},
	url          = {http://lkm.fri.uni-lj.si/rmarko/papers/RobnikSikonjaKononenko08-TKDE.pdf}
}
@article{alvarez2019weight,
	title        = {Weight of evidence as a basis for human-oriented explanations},
	author       = {Alvarez-Melis, David and Daum{\'e} III, Hal and Vaughan, Jennifer Wortman and Wallach, Hanna},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1910.13503},
	url          = {https://arxiv.org/pdf/1910.13503.pdf}
}
@article{li2015visualizing,
	title        = {Visualizing and understanding neural models in nlp},
	author       = {Li, Jiwei and Chen, Xinlei and Hovy, Eduard and Jurafsky, Dan},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1506.01066},
	url          = {https://arxiv.org/pdf/1506.01066.pdf}
}
@article{hendrycks2016baseline,
	title        = {A baseline for detecting misclassified and out-of-distribution examples in neural networks},
	author       = {Hendrycks, Dan and Gimpel, Kevin},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1610.02136},
	url          = {https://arxiv.org/pdf/1610.02136.pdf}
}
A unifying view on dataset shift in classification
@article{moreno2012unifying,
	title        = {A unifying view on dataset shift in classification},
	author       = {Moreno-Torres, Jose G and Raeder, Troy and Alaiz-Rodr{\'\i}guez, Roc{\'\i}o and Chawla, Nitesh V and Herrera, Francisco},
	year         = 2012,
	journal      = {Pattern recognition},
	publisher    = {Elsevier},
	volume       = 45,
	number       = 1,
	pages        = {521--530},
	url          = {https://rtg.cis.upenn.edu/cis700-2019/papers/dataset-shift/dataset-shift-terminology.pdf}
}
@article{bernardo1998regression,
	title        = {Regression and classification using Gaussian process priors},
	author       = {Bernardo, J and Berger, J and Dawid, APAFMS and Smith, A and others},
	year         = 1998,
	journal      = {Bayesian statistics},
	volume       = 6,
	pages        = 475,
	url          = {http://www.cs.toronto.edu/~radford/ftp/val6gp.pdf}
}
@misc{yin2021faithfulness,
	title        = {On the Faithfulness Measurements for Model Interpretations},
	author       = {Fan Yin and Zhouxing Shi and Cho-Jui Hsieh and Kai-Wei Chang},
	year         = 2021,
	url          = {https://arxiv.org/pdf/2104.08782.pdf},
	eprint       = {arXiv:2104.08782}
}
@misc{chrysostomou2021variable,
	title        = {Variable Instance-Level Explainability for Text Classification},
	author       = {George Chrysostomou and Nikolaos Aletras},
	year         = 2021,
	url          = {https://arxiv.org/pdf/2104.08219.pdf},
	eprint       = {arXiv:2104.08219}
}
@article{claesen2015hyperparameter,
	title        = {Hyperparameter search in machine learning},
	author       = {Claesen, Marc and De Moor, Bart},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1502.02127},
	url          = {https://arxiv.org/pdf/1502.02127.pdf}
}
@article{probst2019tunability,
	title        = {Tunability: Importance of hyperparameters of machine learning algorithms.},
	author       = {Probst, Philipp and Boulesteix, Anne-Laure and Bischl, Bernd},
	year         = 2019,
	journal      = {J. Mach. Learn. Res.},
	volume       = 20,
	number       = 53,
	pages        = {1--32},
	url          = {https://arxiv.org/pdf/1802.09596.pdf}
}
@inproceedings{van2018hyperparameter,
	title        = {Hyperparameter importance across datasets},
	author       = {Van Rijn, Jan N and Hutter, Frank},
	year         = 2018,
	booktitle    = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
	pages        = {2367--2376},
	url          = {https://arxiv.org/pdf/1710.04725.pdf}
}
@inproceedings{socher2013recursive,
	title        = {Recursive deep models for semantic compositionality over a sentiment treebank},
	author       = {Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
	year         = 2013,
	booktitle    = {Proceedings of the 2013 conference on empirical methods in natural language processing},
	pages        = {1631--1642},
	url          = {https://www.aclweb.org/anthology/D13-1170.pdf}
}
@article{brown2010ensemble,
	title        = {Ensemble Learning.},
	author       = {Brown, Gavin},
	year         = 2010,
	journal      = {Encyclopedia of machine learning},
	volume       = 312,
	pages        = {15--19},
	url          = {http://www.cs.man.ac.uk/~gbrown/research/brown10ensemblelearning.pdf}
}
@article{samek2016evaluating,
	title        = {Evaluating the visualization of what a deep neural network has learned},
	author       = {Samek, Wojciech and Binder, Alexander and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and M{\"u}ller, Klaus-Robert},
	year         = 2016,
	journal      = {IEEE transactions on neural networks and learning systems},
	publisher    = {IEEE},
	volume       = 28,
	number       = 11,
	pages        = {2660--2673},
	url          = {https://arxiv.org/pdf/1509.06321.pdf}
}
@inproceedings{dabkowski2017real,
	title        = {Real Time Image Saliency for Black Box Classifiers},
	author       = {Dabkowski, Piotr and Gal, Yarin},
	year         = 2017,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 30,
	pages        = {},
	url          = {https://proceedings.neurips.cc/paper/2017/file/0060ef47b12160b9198302ebdb144dcf-Paper.pdf},
	editor       = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett}
}
@inproceedings{chang2018explaining,
	title        = {Explaining image classifiers by counterfactual generation},
	author       = {Chang, Chun-Hao and Creager, Elliot and Goldenberg, Anna and Duvenaud, David},
	year         = 2019,
	booktitle    = {ICLR},
	url          = {https://arxiv.org/pdf/1807.08024.pdf}
}
@article{yi2020information,
	title        = {Information-theoretic visual explanation for black-box classifiers},
	author       = {Yi, Jihun and Kim, Eunji and Kim, Siwon and Yoon, Sungroh},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2009.11150},
	url          = {https://arxiv.org/pdf/2009.11150.pdf}
}
@inproceedings{fong2017interpretable,
	title        = {Interpretable explanations of black boxes by meaningful perturbation},
	author       = {Fong, Ruth C and Vedaldi, Andrea},
	year         = 2017,
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision},
	pages        = {3429--3437},
	url          = {https://arxiv.org/pdf/1704.03296.pdf}
}
@article{hsieh2020evaluations,
	title        = {Evaluations and Methods for Explanation through Robustness Analysis},
	author       = {Hsieh, Cheng-Yu and Yeh, Chih-Kuan and Liu, Xuanqing and Ravikumar, Pradeep and Kim, Seungyeon and Kumar, Sanjiv and Hsieh, Cho-Jui},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.00442},
	url          = {https://arxiv.org/pdf/2006.00442.pdf}
}
@inproceedings{jang2016categorical,
	title        = {Categorical reparameterization with gumbel-softmax},
	author       = {Jang, Eric and Gu, Shixiang and Poole, Ben},
	year         = 2016,
	booktitle    = {ICLR},
	url          = {https://arxiv.org/pdf/1611.01144.pdf}
}
@article{pirlot1996general,
	title        = {General local search methods},
	author       = {Pirlot, Marc},
	year         = 1996,
	journal      = {European journal of operational research},
	publisher    = {Elsevier},
	volume       = 92,
	number       = 3,
	pages        = {493--511}
}
@inproceedings{clark-etal-2019-boolq,
	title        = {{B}ool{Q}: Exploring the Surprising Difficulty of Natural Yes/No Questions},
	author       = {Clark, Christopher  and Lee, Kenton  and Chang, Ming-Wei  and Kwiatkowski, Tom  and Collins, Michael  and Toutanova, Kristina},
	year         = 2019,
	month        = jun,
	booktitle    = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Minneapolis, Minnesota},
	pages        = {2924--2936},
	doi          = {10.18653/v1/N19-1300},
	url          = {https://www.aclweb.org/anthology/N19-1300}
}
@inproceedings{khashabi-etal-2018-looking,
	title        = {Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences},
	author       = {Khashabi, Daniel  and Chaturvedi, Snigdha  and Roth, Michael  and Upadhyay, Shyam  and Roth, Dan},
	year         = 2018,
	month        = jun,
	booktitle    = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {New Orleans, Louisiana},
	pages        = {252--262},
	doi          = {10.18653/v1/N18-1023},
	url          = {https://www.aclweb.org/anthology/N18-1023}
}
@inproceedings{lehman-etal-2019-inferring,
	title        = {Inferring Which Medical Treatments Work from Reports of Clinical Trials},
	author       = {Lehman, Eric  and DeYoung, Jay  and Barzilay, Regina  and Wallace, Byron C.},
	year         = 2019,
	month        = jun,
	booktitle    = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Minneapolis, Minnesota},
	pages        = {3705--3717},
	doi          = {10.18653/v1/N19-1371},
	url          = {https://www.aclweb.org/anthology/N19-1371}
}
@inproceedings{socher-etal-2013-recursive,
	title        = {Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank},
	author       = {Socher, Richard  and Perelygin, Alex  and Wu, Jean  and Chuang, Jason  and Manning, Christopher D.  and Ng, Andrew  and Potts, Christopher},
	year         = 2013,
	month        = oct,
	booktitle    = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Seattle, Washington, USA},
	pages        = {1631--1642},
	url          = {https://www.aclweb.org/anthology/D13-1170}
}
@article{arras2017relevant,
	title        = {" What is relevant in a text document?": An interpretable machine learning approach},
	author       = {Arras, Leila and Horn, Franziska and Montavon, Gr{\'e}goire and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
	year         = 2017,
	journal      = {PloS one},
	publisher    = {Public Library of Science San Francisco, CA USA},
	volume       = 12,
	number       = 8,
	pages        = {e0181142}
}
@inproceedings{arras-etal-2019-evaluating,
	title        = {Evaluating Recurrent Neural Network Explanations},
	author       = {Arras, Leila  and Osman, Ahmed  and M{\"u}ller, Klaus-Robert  and Samek, Wojciech},
	year         = 2019,
	month        = aug,
	booktitle    = {Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {113--126},
	doi          = {10.18653/v1/W19-4813},
	url          = {https://www.aclweb.org/anthology/W19-4813}
}
@article{zhou2021feature,
	title        = {Do Feature Attribution Methods Correctly Attribute Features?},
	author       = {Zhou, Yilun and Booth, Serena and Ribeiro, Marco Tulio and Shah, Julie},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2104.14403},
	url          = {https://arxiv.org/pdf/2104.14403.pdf}
}
@inproceedings{sundararajan2020many,
	title        = {The many Shapley values for model explanation},
	author       = {Sundararajan, Mukund and Najmi, Amir},
	year         = 2020,
	booktitle    = {International Conference on Machine Learning},
	pages        = {9269--9278},
	url          = {https://arxiv.org/pdf/1908.08474.pdf},
	organization = {PMLR}
}
@article{sturmfels2020visualizing,
	title        = {Visualizing the impact of feature attribution baselines},
	author       = {Sturmfels, Pascal and Lundberg, Scott and Lee, Su-In},
	year         = 2020,
	journal      = {Distill},
	volume       = 5,
	number       = 1,
	pages        = {e22},
	url          = {https://distill.pub/2020/attribution-baselines/}
}
@inproceedings{janzing2020feature,
	title        = {Feature relevance quantification in explainable AI: A causal problem},
	author       = {Janzing, Dominik and Minorics, Lenon and Bl{\"o}baum, Patrick},
	year         = 2020,
	booktitle    = {International Conference on Artificial Intelligence and Statistics},
	pages        = {2907--2916},
	url          = {https://arxiv.org/pdf/1910.13413.pdf},
	organization = {PMLR}
}
@inproceedings{zintgraf2017visualizing,
	title        = {Visualizing deep neural network decisions: Prediction difference analysis},
	author       = {Zintgraf, Luisa M and Cohen, Taco S and Adel, Tameem and Welling, Max},
	year         = 2017,
	booktitle    = {ICLR},
	url          = {https://arxiv.org/pdf/1702.04595.pdf}
}
@misc{turner-nodate-gaussian,
	title        = {Gaussian Processes: From the Basics to the State-of-the-Art},
	author       = {Turner, Richard E},
	year         = 2016,
	url          = {http://cbl.eng.cam.ac.uk/pub/Public/Turner/News/imperial-gp-tutorial.pdf}
}
@article{miyato2018virtual,
	title        = {Virtual adversarial training: a regularization method for supervised and semi-supervised learning},
	author       = {Miyato, Takeru and Maeda, Shin-ichi and Koyama, Masanori and Ishii, Shin},
	year         = 2018,
	journal      = {IEEE transactions on pattern analysis and machine intelligence},
	publisher    = {IEEE},
	volume       = 41,
	number       = 8,
	pages        = {1979--1993},
	url          = {https://arxiv.org/pdf/1704.03976.pdf}
}
@inproceedings{wolf-etal-2020-transformers,
	title        = {Transformers: State-of-the-Art Natural Language Processing},
	author       = {Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
	year         = 2020,
	month        = oct,
	booktitle    = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {38--45},
	url          = {https://www.aclweb.org/anthology/2020.emnlp-demos.6}
}
@article{lucic2021multistakeholder,
	title        = {A Multistakeholder Approach Towards Evaluating AI Transparency Mechanisms},
	author       = {Lucic, Ana and Srikumar, Madhulika and Bhatt, Umang and Xiang, Alice and Taly, Ankur and Liao, Q Vera and de Rijke, Maarten},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2103.14976},
	url          = {https://arxiv.org/pdf/2103.14976.pdf}
}
@inproceedings{haug2021baselines,
	title        = {On Baselines for Local Feature Attributions},
	author       = {Haug, Johannes and Z{\"u}rn, Stefan and El-Jiz, Peter and Kasneci, Gjergji},
	year         = 2021,
	booktitle    = {AAAI},
	url          = {https://arxiv.org/pdf/2101.00905.pdf}
}
@article{ehsan2021explainable,
	title        = {The who in explainable ai: How ai background shapes perceptions of ai explanations},
	author       = {Ehsan, Upol and Passi, Samir and Liao, Q Vera and Chan, Larry and Lee, I and Muller, Michael and Riedl, Mark O and others},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2107.13509},
	url          = {https://arxiv.org/pdf/2107.13509.pdf}
}
@article{qiu2021resisting,
	title        = {Resisting Out-of-Distribution Data Problem in Perturbation of XAI},
	author       = {Qiu, Luyu and Yang, Yi and Cao, Caleb Chen and Liu, Jing and Zheng, Yueyuan and Ngai, Hilary Hei Ting and Hsiao, Janet and Chen, Lei},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2107.14000}
}
@article{sanyal2021discretized,
	title        = {Discretized Integrated Gradients for Explaining Language Models},
	author       = {Sanyal, Soumya and Ren, Xiang},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2108.13654},
	url          = {https://arxiv.org/pdf/2108.13654.pdf}
}
@inproceedings{dumodel,
	title        = {Model-Agnostic Local Explanations with Genetic Algorithms for Text Classification},
	author       = {Du, Qingfeng and Xu, Jincheng},
	year         = 2021,
	booktitle    = {The 33rd International Conference on Software Engineering \& Knowledge Engineering},
	url          = {https://ksiresearch.org/seke/seke21paper/paper040.pdf}
}
@inproceedings{jethani2021have,
	title        = {Have We Learned to Explain?: How Interpretability Methods Can Learn to Encode Predictions in their Interpretations.},
	author       = {Jethani, Neil and Sudarshan, Mukund and Aphinyanaphongs, Yindalon and Ranganath, Rajesh},
	year         = 2021,
	booktitle    = {International Conference on Artificial Intelligence and Statistics},
	pages        = {1459--1467},
	url          = {https://arxiv.org/pdf/2103.01890.pdf},
	organization = {PMLR}
}
@inproceedings{vafa2021rationales,
	title        = {Rationales for Sequential Predictions},
	author       = {Vafa, Keyon and Deng, Yuntian and Blei, David M and Rush, Alexander M},
	year         = 2021,
	booktitle    = {EMNLP},
	url          = {https://arxiv.org/pdf/2109.06387.pdf}
}
@inproceedings{ribeiro_anchors:_nodate,
	title        = {Anchors: High-Precision Model-Agnostic Explanations},
	author       = {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
	year         = 2018,
	booktitle    = {AAAI 2018},
	url          = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16982}
}
@inproceedings{radford_language_nodate,
	title        = {Language Models are Unsupervised Multitask Learners},
	author       = {Alec Radford and Jeffrey Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
	year         = 2019,
	booktitle    = {OpenAI Technical Report},
	url          = {https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf}
}
@inproceedings{radford_improving_nodate,
	title        = {Improving Language Understanding by Generative Pre-Training},
	author       = {Alec Radford},
	year         = 2018,
	url          = {https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf}
}
@article{jacovi2020aligning,
	title        = {Aligning Faithful Interpretations with their Social Attribution},
	author       = {Jacovi, Alon and Goldberg, Yoav},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.01067},
	url          = {https://arxiv.org/abs/2006.01067}
}
@inproceedings{bastings-2019,
	title        = {Interpretable Neural Predictions with Differentiable Binary Variables},
	author       = {Bastings, Jasmijn  and Aziz, Wilker  and Titov, Ivan},
	year         = 2019,
	month        = jul,
	booktitle    = {ACL 2019},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {2963--2977},
	doi          = {10.18653/v1/P19-1284},
	url          = {https://www.aclweb.org/anthology/P19-1284}
}
% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@article{simonyan2013deep,
	title        = {Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps},
	author       = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
	year         = 2013,
	journal      = {Workshop at International Conference on Learning Representations.}
}
@inproceedings{sundararajan2017axiomatic,
	title        = {Axiomatic Attribution for Deep Networks},
	author       = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	year         = 2017,
	booktitle    = {International Conference on Machine Learning},
	pages        = {3319--3328}
}
@inproceedings{li2016deep,
	title        = {Deep Reinforcement Learning for Dialogue Generation},
	author       = {Li, Jiwei and Monroe, Will and Ritter, Alan and Jurafsky, Dan and Galley, Michel and Gao, Jianfeng},
	year         = 2016,
	booktitle    = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
	pages        = {1192--1202}
}
@inproceedings{ribeiro2016should,
	title        = {" Why should I trust you?" Explaining the predictions of any classifier},
	author       = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	year         = 2016,
	booktitle    = {Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
	pages        = {1135--1144}
}
@inproceedings{ribeiro2018anchors,
	title        = {Anchors: High-Precision Model-Agnostic Explanations.},
	author       = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	year         = 2018,
	booktitle    = {AAAI}
}
@inproceedings{mothilal2020dice,
	title        = {Explaining machine learning classifiers through diverse counterfactual explanations},
	author       = {Mothilal, Ramaravind K and Sharma, Amit and Tan, Chenhao},
	year         = 2020,
	booktitle    = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
	pages        = {607--617}
}
@article{pruthi2021,
	title        = {Evaluating Explanations: How much do explanations from the teacher aid students?},
	author       = {Danish Pruthi and Bhuwan Dhingra and Livio Baldini Soares and Michael Collins and Zachary C. Lipton and Graham Neubig and William W. Cohen},
	year         = 2021,
	journal      = {TACL},
	volume       = {abs/2012.00893},
	url          = {https://arxiv.org/abs/2012.00893},
	archiveprefix = {arXiv},
	eprint       = {2012.00893},
	timestamp    = {Fri, 04 Dec 2020 12:07:23 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2012-00893.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@misc{lovering2021predicting,
	title        = {PREDICTING INDUCTIVE BIASES OF PRE-TRAINED MODELS},
	author       = {Lovering, Charles and Jha, Rohan and Linzen, Tal and Pavlick, Ellie},
	year         = 2021,
	publisher    = {ICLR},
	url          = {https://openreview.net/pdf/5f8e7508b216ea50a36e7f4584e4e6d8953917be.pdf}
}
@inproceedings{wiegreffe2021teach,
	title        = {Teach me to explain: A review of datasets for explainable natural language processing},
	author       = {Wiegreffe, Sarah and Marasovic, Ana},
	year         = 2021,
	booktitle    = {Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},
	url          = {https://openreview.net/forum?id=ogNcxJn32BZ}
}
@inproceedings{stacey2022supervising,
	title        = {Supervising Model Attention with Human Explanations for Robust Natural Language Inference},
	author       = {Stacey, Joe and Belinkov, Yonatan and Rei, Marek},
	year         = 2022,
	booktitle    = {AAAI},
	url          = {https://arxiv.org/pdf/2104.08142.pdf}
}
@article{lampinen2022can,
	title        = {Can language models learn from explanations in context?},
	author       = {Lampinen, Andrew K and Dasgupta, Ishita and Chan, Stephanie CY and Matthewson, Kory and Tessler, Michael Henry and Creswell, Antonia and McClelland, James L and Wang, Jane X and Hill, Felix},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2204.02329},
	url          = {https://arxiv.org/pdf/2204.02329.pdf}
}
@inproceedings{hase-bansal-2020-evaluating,
	title        = {Evaluating Explainable {AI}: Which Algorithmic Explanations Help Users Predict Model Behavior?},
	author       = {Hase, Peter  and Bansal, Mohit},
	year         = 2020,
	month        = jul,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {5540--5552},
	doi          = {10.18653/v1/2020.acl-main.491},
	url          = {https://aclanthology.org/2020.acl-main.491},
	abstract     = {Algorithmic approaches to interpreting machine learning models have proliferated in recent years. We carry out human subject tests that are the first of their kind to isolate the effect of algorithmic explanations on a key aspect of model interpretability, simulatability, while avoiding important confounding experimental factors. A model is simulatable when a person can predict its behavior on new inputs. Through two kinds of simulation tests involving text and tabular data, we evaluate five explanations methods: (1) LIME, (2) Anchor, (3) Decision Boundary, (4) a Prototype model, and (5) a Composite approach that combines explanations from each method. Clear evidence of method effectiveness is found in very few cases: LIME improves simulatability in tabular classification, and our Prototype method is effective in counterfactual simulation tests. We also collect subjective ratings of explanations, but we do not find that ratings are predictive of how helpful explanations are. Our results provide the first reliable and comprehensive estimates of how explanations influence simulatability across a variety of explanation methods and data domains. We show that (1) we need to be careful about the metrics we use to evaluate explanation methods, and (2) there is significant room for improvement in current methods.}
}
@inproceedings{zhou-etal-2022-exsum,
	title        = {{ExSum}: {F}rom Local Explanations to Model Understanding},
	author       = {Zhou, Yilun  and Ribeiro, Marco Tulio  and Shah, Julie},
	year         = 2022,
	month        = jul,
	booktitle    = {Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {Seattle, United States},
	pages        = {5359--5378},
	doi          = {10.18653/v1/2022.naacl-main.392},
	url          = {https://aclanthology.org/2022.naacl-main.392},
	abstract     = {Interpretability methods are developed to understand the working mechanisms of black-box models, which is crucial to their responsible deployment. Fulfilling this goal requires both that the explanations generated by these methods are correct and that people can easily and reliably understand them. While the former has been addressed in prior work, the latter is often overlooked, resulting in informal model understanding derived from a handful of local explanations. In this paper, we introduce explanation summary (ExSum), a mathematical framework for quantifying model understanding, and propose metrics for its quality assessment. On two domains, ExSum highlights various limitations in the current practice, helps develop accurate model understanding, and reveals easily overlooked properties of the model. We also connect understandability to other properties of explanations such as human alignment, robustness, and counterfactual similarity and plausibility.}
}
@article{wei2022chain,
	title        = {Chain of thought prompting elicits reasoning in large language models},
	author       = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2201.11903},
	url          = {https://arxiv.org/pdf/2201.11903.pdf}
}
@inproceedings{poursabzi2021manipulating,
	title        = {Manipulating and measuring model interpretability},
	author       = {Poursabzi-Sangdeh, Forough and Goldstein, Daniel G and Hofman, Jake M and Wortman Vaughan, Jennifer Wortman and Wallach, Hanna},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 CHI conference on human factors in computing systems},
	pages        = {1--52},
	url          = {https://arxiv.org/pdf/1802.07810.pdf}
}
@inproceedings{arora2022explain,
	title        = {Explain, edit, and understand: Rethinking user study design for evaluating model explanations},
	author       = {Arora, Siddhant and Pruthi, Danish and Sadeh, Norman and Cohen, William W and Lipton, Zachary C and Neubig, Graham},
	year         = 2022,
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 36,
	number       = 5,
	pages        = {5277--5285},
	url          = {https://arxiv.org/pdf/2112.09669.pdf}
}
@article{bastings2021will,
	title        = {" Will You Find These Shortcuts?" A Protocol for Evaluating the Faithfulness of Input Salience Methods for Text Classification},
	author       = {Bastings, Jasmijn and Ebert, Sebastian and Zablotskaia, Polina and Sandholm, Anders and Filippova, Katja},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2111.07367},
	url          = {https://arxiv.org/pdf/2111.07367.pdf}
}
@inproceedings{swayamdipta2020dataset,
	title        = {Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics},
	author       = {Swayamdipta, Swabha and Schwartz, Roy and Lourie, Nicholas and Wang, Yizhong and Hajishirzi, Hannaneh and Smith, Noah A and Choi, Yejin},
	year         = 2020,
	booktitle    = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
	pages        = {9275--9293},
	url          = {https://arxiv.org/pdf/2009.10795.pdf}
}
@article{slack2022talktomodel,
	title        = {TalkToModel: Understanding Machine Learning Models With Open Ended Dialogues},
	author       = {Slack, Dylan and Krishna, Satyapriya and Lakkaraju, Himabindu and Singh, Sameer},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2207.04154},
	url          = {https://arxiv.org/pdf/2207.04154.pdf}
}
@article{jung2022maieutic,
	title        = {Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations},
	author       = {Jung, Jaehun and Qin, Lianhui and Welleck, Sean and Brahman, Faeze and Bhagavatula, Chandra and Bras, Ronan Le and Choi, Yejin},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2205.11822},
	url          = {https://arxiv.org/pdf/2205.11822.pdf}
}
@inproceedings{vafa-etal-2021-rationales,
	title        = {Rationales for Sequential Predictions},
	author       = {Vafa, Keyon  and Deng, Yuntian  and Blei, David  and Rush, Alexander},
	year         = 2021,
	month        = nov,
	booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Online and Punta Cana, Dominican Republic},
	pages        = {10314--10332},
	doi          = {10.18653/v1/2021.emnlp-main.807},
	url          = {https://aclanthology.org/2021.emnlp-main.807}
}
@inproceedings{jacovi-etal-2021-contrastive,
	title        = {Contrastive Explanations for Model Interpretability},
	author       = {Jacovi, Alon  and Swayamdipta, Swabha  and Ravfogel, Shauli  and Elazar, Yanai  and Choi, Yejin  and Goldberg, Yoav},
	year         = 2021,
	month        = nov,
	booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Online and Punta Cana, Dominican Republic},
	pages        = {1597--1611},
	doi          = {10.18653/v1/2021.emnlp-main.120},
	url          = {https://aclanthology.org/2021.emnlp-main.120}
}
@inproceedings{wiegreffe2021reframing,
	title        = {Reframing Human-AI Collaboration for Generating Free-Text Explanations},
	author       = {Wiegreffe, Sarah and Hessel, Jack and Swayamdipta, Swabha and Riedl, Mark and Choi, Yejin},
	year         = 2022,
	booktitle    = {NAACL},
	url          = {https://arxiv.org/pdf/2112.08674.pdf}
}
@article{joshimeasuring,
	title        = {Measuring the Human Utility of Free-Text Rationales in Human-AI Collaboration},
	author       = {Joshi, Brihi and Liu, Ziyi and Ren, Zhewei Tong Aaron Chan Xiang},
	year         = 2022,
	url          = {https://openreview.net/pdf?id=h-aJ39Z3Tc}
}
@inproceedings{jacovi2021formalizing,
	title        = {Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI},
	author       = {Jacovi, Alon and Marasovi\'{c}, Ana and Miller, Tim and Goldberg, Yoav},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
	location     = {Virtual Event, Canada},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {FAccT '21},
	pages        = {624–635},
	doi          = {10.1145/3442188.3445923},
	isbn         = 9781450383097,
	url          = {https://doi.org/10.1145/3442188.3445923},
	numpages     = 12,
	keywords     = {formalization, distrust, warranted trust, sociology, contractual trust, trustworthy, artificial intelligence, trust}
}
@article{nye2021show,
	title        = {Show your work: Scratchpads for intermediate computation with language models},
	author       = {Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2112.00114},
	url          = {https://arxiv.org/pdf/2112.00114.pdf}
}
@article{hendrycks2020aligning,
	title        = {Aligning ai with shared human values},
	author       = {Hendrycks, Dan and Burns, Collin and Basart, Steven and Critch, Andrew and Li, Jerry and Song, Dawn and Steinhardt, Jacob},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2008.02275},
	url          = {https://arxiv.org/pdf/2008.02275.pdf}
}
@article{cobbe2021training,
	title        = {Training verifiers to solve math word problems},
	author       = {Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2110.14168},
	url          = {https://arxiv.org/pdf/2110.14168v1.pdf}
}
@inproceedings{dalvi2021explaining,
	title        = {Explaining answers with entailment trees},
	author       = {Dalvi, Bhavana and Jansen, Peter and Tafjord, Oyvind and Xie, Zhengnan and Smith, Hannah and Pipatanangkura, Leighanna and Clark, Peter},
	year         = 2021,
	booktitle    = {EMNLP},
	url          = {https://arxiv.org/pdf/2104.08661.pdf}
}
@article{sakaguchi2021winogrande,
	title        = {WinoGrande: An Adversarial Winograd Schema Challenge at Scale},
	author       = {Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin},
	year         = 2021,
	month        = {aug},
	journal      = {Commun. ACM},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	volume       = 64,
	number       = 9,
	pages        = {99–106},
	doi          = {10.1145/3474381},
	issn         = {0001-0782},
	url          = {https://doi.org/10.1145/3474381},
	issue_date   = {September 2021},
	numpages     = 8
}
@article{yoo2021gpt3mix,
	title        = {GPT3Mix: Leveraging large-scale language models for text augmentation},
	author       = {Yoo, Kang Min and Park, Dongju and Kang, Jaewook and Lee, Sang-Woo and Park, Woomyeong},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2104.08826},
	url          = {https://arxiv.org/pdf/2104.08826.pdf}
}
@inproceedings{tafjord2022entailer,
	title        = {Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning},
	author       = {Tafjord, Oyvind and Mishra, Bhavana Dalvi and Clark, Peter},
	year         = 2022,
	booktitle    = {EMNLP},
	url          = {https://arxiv.org/pdf/2210.12217.pdf}
}
@article{golovneva2022roscoe,
	title        = {ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning},
	author       = {Golovneva, Olga and Chen, Moya and Poff, Spencer and Corredor, Martin and Zettlemoyer, Luke and Fazel-Zarandi, Maryam and Celikyilmaz, Asli},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2212.07919},
	url          = {https://arxiv.org/pdf/2212.07919.pdf}
}
@inproceedings{perez2021rissanen,
	title        = {Rissanen data analysis: Examining dataset characteristics via description length},
	author       = {Perez, Ethan and Kiela, Douwe and Cho, Kyunghyun},
	year         = 2021,
	booktitle    = {International Conference on Machine Learning},
	pages        = {8500--8513},
	url          = {https://arxiv.org/pdf/2103.03872.pdf},
	organization = {PMLR}
}
@article{creswell2022faithful,
	title        = {Faithful reasoning using large language models},
	author       = {Creswell, Antonia and Shanahan, Murray},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2208.14271},
	url          = {https://arxiv.org/pdf/2208.14271.pdf}
}
@article{wang2022self,
	title        = {Self-consistency improves chain of thought reasoning in language models},
	author       = {Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Zhou, Denny},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2203.11171},
	url          = {https://arxiv.org/pdf/2203.11171.pdf}
}
@article{hase2024unreasonable,
	title        = {The unreasonable effectiveness of easy training data for hard tasks},
	author       = {Hase, Peter and Bansal, Mohit and Clark, Peter and Wiegreffe, Sarah},
	year         = 2024,
	journal      = {arXiv preprint arXiv:2401.06751},
	url          = {https://arxiv.org/pdf/2401.06751.pdf}
}
@article{liu2024rethinking,
	title        = {Rethinking Machine Unlearning for Large Language Models},
	author       = {Liu, Sijia and Yao, Yuanshun and Jia, Jinghan and Casper, Stephen and Baracaldo, Nathalie and Hase, Peter and Xu, Xiaojun and Yao, Yuguang and Li, Hang and Varshney, Kush R and others},
	year         = 2024,
	journal      = {arXiv preprint arXiv:2402.08787},
	url          = {https://arxiv.org/pdf/2402.08787.pdf}
}
@book{fitelson2010bayesian,
	title        = {How Bayesian confirmation theory handles the paradox of the ravens},
	author       = {Fitelson, Branden and Hawthorne, James},
	year         = 2010,
	publisher    = {Springer},
	url          = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=10a4b8ec84506cb70b13cd6e8cb500e14048ceea}
}
@article{hansson2006logic,
	title        = {Logic of belief revision},
	author       = {Hansson, Sven Ove},
	year         = 2006,
	url          = {https://plato.stanford.edu/entries/logic-belief-revision/}
}
@incollection{sep-logic-belief-revision,
	title        = {{Logic of Belief Revision}},
	author       = {Hansson, Sven Ove},
	year         = 2022,
	booktitle    = {The {Stanford} Encyclopedia of Philosophy},
	publisher    = {Metaphysics Research Lab, Stanford University},
	url          = {https://plato.stanford.edu/archives/spr2022/entries/logic-belief-revision/},
	editor       = {Edward N. Zalta},
	howpublished = {\url{https://plato.stanford.edu/archives/spr2022/entries/logic-belief-revision/}},
	edition      = {{S}pring 2022}
}
@incollection{sep-formal-belief,
	title        = {{Formal Representations of Belief}},
	author       = {Genin, Konstantin and Huber, Franz},
	year         = 2022,
	booktitle    = {The {Stanford} Encyclopedia of Philosophy},
	publisher    = {Metaphysics Research Lab, Stanford University},
	url          = {https://plato.stanford.edu/entries/formal-belief/},
	editor       = {Edward N. Zalta and Uri Nodelman},
	howpublished = {\url{https://plato.stanford.edu/archives/fall2022/entries/formal-belief/}},
	edition      = {{F}all 2022}
}
@incollection{sep-epistemology-bayesian,
	title        = {{Bayesian Epistemology}},
	author       = {Lin, Hanti},
	year         = 2024,
	booktitle    = {The {Stanford} Encyclopedia of Philosophy},
	publisher    = {Metaphysics Research Lab, Stanford University},
	url          = {https://plato.stanford.edu/entries/epistemology-bayesian/},
	editor       = {Edward N. Zalta and Uri Nodelman},
	howpublished = {\url{https://plato.stanford.edu/archives/sum2024/entries/epistemology-bayesian/}},
	edition      = {{S}ummer 2024}
}
@incollection{sep-counterfactuals,
	title        = {{Counterfactuals}},
	author       = {Starr, W.},
	year         = 2022,
	booktitle    = {The {Stanford} Encyclopedia of Philosophy},
	publisher    = {Metaphysics Research Lab, Stanford University},
	url          = {https://plato.stanford.edu/entries/counterfactuals/},
	editor       = {Edward N. Zalta and Uri Nodelman},
	howpublished = {\url{https://plato.stanford.edu/archives/win2022/entries/counterfactuals/}},
	edition      = {{W}inter 2022}
}
@book{quine1982methods,
	title        = {Methods of logic},
	author       = {Quine, Willard Van Orman},
	year         = 1982,
	publisher    = {Harvard University Press}
}
@article{miller2020contrastive,
	title        = {Contrastive explanation: A structural-model approach},
	author       = {Miller, Tim},
	year         = 2020,
	journal      = {The Knowledge Engineering Review},
	publisher    = {Cambridge University Press},
	volume       = 36,
	pages        = {e14},
	url          = {https://arxiv.org/pdf/2103.01378.pdf}
}
@article{lewis1979counterfactual,
	title        = {Counterfactual dependence and time's arrow},
	author       = {Lewis, David},
	year         = 1979,
	journal      = {No{\^u}s},
	publisher    = {JSTOR},
	pages        = {455--476}
}
@inproceedings{soares2015corrigibility,
	title        = {Corrigibility},
	author       = {Soares, Nate and Fallenstein, Benja and Armstrong, Stuart and Yudkowsky, Eliezer},
	year         = 2015,
	booktitle    = {Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence},
	url          = {https://cdn.aaai.org/ocs/ws/ws0067/10124-45900-1-PB.pdf}
}
@article{quine1970web,
	title        = {The web of belief},
	author       = {Quine, Willard V and Ullian, Joseph Silbert},
	year         = 1970
}
@article{xu2023earth,
	title        = {The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation},
	author       = {Xu, Rongwu and Lin, Brian S and Yang, Shujian and Zhang, Tianqi and Shi, Weiyan and Zhang, Tianwei and Fang, Zhixuan and Xu, Wei and Qiu, Han},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2312.09085},
	url          = {https://arxiv.org/pdf/2312.09085.pdf}
}
@article{suter2011time,
	title        = {Time and moral judgment},
	author       = {Suter, Renata S and Hertwig, Ralph},
	year         = 2011,
	journal      = {Cognition},
	publisher    = {Elsevier},
	volume       = 119,
	number       = 3,
	pages        = {454--458},
	url          = {https://www.sciencedirect.com/science/article/pii/S0010027711000448?casa_token=PMCxBYDc2lQAAAAA:pRgT6ikY0IZ8JVplSG55iNavEYMb-9hUeoMdU59S0Q9msnkyt3X8N-Nwy13fe3LHIk8QuDA3T34}
}
@article{fragoso2018bayesian,
	title        = {Bayesian model averaging: A systematic review and conceptual classification},
	author       = {Fragoso, Tiago M and Bertoli, Wesley and Louzada, Francisco},
	year         = 2018,
	journal      = {International Statistical Review},
	publisher    = {Wiley Online Library},
	volume       = 86,
	number       = 1,
	pages        = {1--28},
	url          = {https://onlinelibrary.wiley.com/doi/abs/10.1111/insr.12243?casa_token=trg9sqMnVs4AAAAA%3AVy4Qi2kY5rU2KCIwzRq-8uMIpcNDILpvXZk5fV58xwpqM2E_BfAoANNOhz2Mxmfp4g2a-RM3DRRcM18}
}
@article{marks2023geometry,
	title        = {The geometry of truth: Emergent linear structure in large language model representations of true/false datasets},
	author       = {Marks, Samuel and Tegmark, Max},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2310.06824},
	url          = {https://arxiv.org/pdf/2310.06824.pdf}
}
@misc{casper2023explore,
	title        = {Explore, Establish, Exploit: Red Teaming Language Models from Scratch},
	author       = {Stephen Casper and Jason Lin and Joe Kwon and Gatlen Culp and Dylan Hadfield-Menell},
	year         = 2023,
	url          = {https://arxiv.org/pdf/2306.09442.pdf},
	eprint       = {2306.09442},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@article{andreas2022language,
	title        = {Language models as agent models},
	author       = {Andreas, Jacob},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2212.01681},
	url          = {https://arxiv.org/pdf/2212.01681.pdf}
}
@article{rigaki2020survey,
	title        = {A survey of privacy attacks in machine learning},
	author       = {Rigaki, Maria and Garcia, Sebastian},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2007.07646}
}
@inproceedings{mitchell2022memory,
  title={Memory-based model editing at scale},
  author={Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Manning, Christopher D and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  pages={15817--15831},
  year={2022},
  organization={PMLR},
url={https://proceedings.mlr.press/v162/mitchell22a/mitchell22a.pdf}
}
@article{dhingra2022time,
	title        = {{Time-Aware Language Models as Temporal Knowledge Bases}},
	author       = {Dhingra, Bhuwan and Cole, Jeremy R. and Eisenschlos, Julian Martin and Gillick, Daniel and Eisenstein, Jacob and Cohen, William W.},
	year         = 2022,
	month        = {03},
	journal      = {Transactions of the Association for Computational Linguistics},
	volume       = 10,
	pages        = {257--273},
	doi          = {10.1162/tacl_a_00459},
	issn         = {2307-387X},
	url          = {https://doi.org/10.1162/tacl\_a\_00459},
	eprint       = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00459/2004543/tacl\_a\_00459.pdf}
}
@article{lazaridou2021mind,
	title        = {Mind the gap: Assessing temporal generalization in neural language models},
	author       = {Lazaridou, Angeliki and Kuncoro, Adhi and Gribovskaya, Elena and Agrawal, Devang and Liska, Adam and Terzi, Tayfun and Gimenez, Mai and de Masson d'Autume, Cyprien and Kocisky, Tomas and Ruder, Sebastian and others},
	year         = 2021,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 34,
	pages        = {29348--29363},
	url          = {https://proceedings.neurips.cc/paper/2021/file/f5bf0ba0a17ef18f9607774722f5698c-Paper.pdf}
}
@book{pearl2009causality,
	title        = {Causality},
	author       = {Pearl, J.},
	year         = 2009,
	publisher    = {Cambridge University Press},
	isbn         = 9781139643986,
	url          = {https://books.google.com/books?id=LLkhAwAAQBAJ}
}
@misc{nostalgebraist2020,
	title        = {interpreting GPT: the logit lens},
	author       = {nostalgebraist},
	year         = 2020,
	url          = {https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens}
}
@article{jagielski2022measuring,
	title        = {Measuring forgetting of memorized training examples},
	author       = {Jagielski, Matthew and Thakkar, Om and Tramer, Florian and Ippolito, Daphne and Lee, Katherine and Carlini, Nicholas and Wallace, Eric and Song, Shuang and Thakurta, Abhradeep and Papernot, Nicolas and others},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2207.00099},
	url          = {https://arxiv.org/pdf/2207.00099.pdf}
}
@article{huang2022large,
	title        = {Are Large Pre-Trained Language Models Leaking Your Personal Information?},
	author       = {Huang, Jie and Shao, Hanyin and Chang, Kevin Chen-Chuan},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2205.12628},
	url          = {https://arxiv.org/pdf/2205.12628.pdf}
}
@inproceedings{carlini2021extracting,
	title        = {Extracting Training Data from Large Language Models.},
	author       = {Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom B and Song, Dawn and Erlingsson, Ulfar and others},
	year         = 2021,
	booktitle    = {USENIX Security Symposium},
	volume       = 6,
	url          = {https://arxiv.org/pdf/2012.07805.pdf}
}
@article{tanno2022repairing,
	title        = {Repairing Neural Networks by Leaving the Right Past Behind},
	author       = {Tanno, Ryutaro and F Pradier, Melanie and Nori, Aditya and Li, Yingzhen},
	year         = 2022,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 35,
	pages        = {13132--13145},
	url          = {https://arxiv.org/pdf/2207.04806.pdf}
}
@article{guo2019certified,
	title        = {Certified data removal from machine learning models},
	author       = {Guo, Chuan and Goldstein, Tom and Hannun, Awni and Van Der Maaten, Laurens},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1911.03030},
	url          = {https://arxiv.org/pdf/1911.03030.pdf}
}
@article{sekhari2021remember,
	title        = {Remember what you want to forget: Algorithms for machine unlearning},
	author       = {Sekhari, Ayush and Acharya, Jayadev and Kamath, Gautam and Suresh, Ananda Theertha},
	year         = 2021,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 34,
	pages        = {18075--18086},
	url          = {https://arxiv.org/pdf/2103.03279.pdf}
}
@inproceedings{carlini2023quantifying,
	title        = {Quantifying Memorization Across Neural Language Models},
	author       = {Nicholas Carlini and Daphne Ippolito and Matthew Jagielski and Katherine Lee and Florian Tramer and Chiyuan Zhang},
	year         = 2023,
	booktitle    = {The Eleventh International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=TatRHT_1cK}
}
@article{shao2022gold,
	title        = {Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear Guarded Attribute Information},
	author       = {Shao, Shun and Ziser, Yftah and Cohen, Shay B},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2203.07893},
	url          = {https://arxiv.org/pdf/2203.07893.pdf}
}
@article{ravfogel2020null,
	title        = {Null it out: Guarding protected attributes by iterative nullspace projection},
	author       = {Ravfogel, Shauli and Elazar, Yanai and Gonen, Hila and Twiton, Michael and Goldberg, Yoav},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2004.07667},
	url          = {https://arxiv.org/pdf/2004.07667.pdf}
}
@article{krishna2023paraphrasing,
	title        = {Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense},
	author       = {Krishna, Kalpesh and Song, Yixiao and Karpinska, Marzena and Wieting, John and Iyyer, Mohit},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2303.13408},
	url          = {https://arxiv.org/pdf/2303.13408.pdf}
}
@article{wallace2019universal,
	title        = {Universal adversarial triggers for attacking and analyzing NLP},
	author       = {Wallace, Eric and Feng, Shi and Kandpal, Nikhil and Gardner, Matt and Singh, Sameer},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1908.07125},
	url          = {https://arxiv.org/pdf/1908.07125.pdf}
}
@inproceedings{ribeiro-etal-2018-semantically,
	title        = {Semantically Equivalent Adversarial Rules for Debugging {NLP} models},
	author       = {Ribeiro, Marco Tulio  and Singh, Sameer  and Guestrin, Carlos},
	year         = 2018,
	month        = jul,
	booktitle    = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Melbourne, Australia},
	pages        = {856--865},
	doi          = {10.18653/v1/P18-1079},
	url          = {https://aclanthology.org/P18-1079},
}
@article{apruzzese2022real,
	title        = {" Real Attackers Don't Compute Gradients": Bridging the Gap Between Adversarial ML Research and Practice},
	author       = {Apruzzese, Giovanni and Anderson, Hyrum S and Dambra, Savino and Freeman, David and Pierazzi, Fabio and Roundy, Kevin A},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2212.14315},
	url          = {https://arxiv.org/pdf/2212.14315.pdf}
}
@article{brown2020language,
	title        = {Language models are few-shot learners},
	author       = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
	year         = 2020,
	journal      = {Advances in neural information processing systems},
	volume       = 33,
	pages        = {1877--1901},
	url          = {https://arxiv.org/pdf/2005.14165.pdf}
}
@article{jastrzkebski2017residual,
	title        = {Residual connections encourage iterative inference},
	author       = {Jastrz{\k{e}}bski, Stanis{\l}aw and Arpit, Devansh and Ballas, Nicolas and Verma, Vikas and Che, Tong and Bengio, Yoshua},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1710.04773}
}
@article{belrose2023eliciting,
	title        = {Eliciting Latent Predictions from Transformers with the Tuned Lens},
	author       = {Belrose, Nora and Furman, Zach and Smith, Logan and Halawi, Danny and Ostrovsky, Igor and McKinney, Lev and Biderman, Stella and Steinhardt, Jacob},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2303.08112},
	url          = {https://arxiv.org/pdf/2303.08112.pdf}
}
@inproceedings{levy2017zero,
	title        = {Zero-Shot Relation Extraction via Reading Comprehension},
	author       = {Levy, Omer and Seo, Minjoon and Choi, Eunsol and Zettlemoyer, Luke},
	year         = 2017,
	booktitle    = {Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)},
	pages        = {333--342},
	url          = {https://aclanthology.org/K17-1034}
}
@article{weidinger2021ethical,
	title        = {Ethical and social risks of harm from language models},
	author       = {Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Conor and Uesato, Jonathan and Huang, Po-Sen and Cheng, Myra and Glaese, Mia and Balle, Borja and Kasirzadeh, Atoosa and others},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2112.04359},
	url          = {https://arxiv.org/pdf/2112.04359.pdf}
}
@article{kenton2021alignment,
	title        = {Alignment of language agents},
	author       = {Kenton, Zachary and Everitt, Tom and Weidinger, Laura and Gabriel, Iason and Mikulik, Vladimir and Irving, Geoffrey},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2103.14659},
	url          = {https://arxiv.org/pdf/2103.14659.pdf}
}
@article{ouyang2022training,
	title        = {Training language models to follow instructions with human feedback},
	author       = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
	year         = 2022,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 35,
	pages        = {27730--27744},
	url          = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf}
}
@article{bai2022constitutional,
	title        = {Constitutional AI: Harmlessness from AI Feedback},
	author       = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2212.08073},
	url          = {https://arxiv.org/pdf/2212.08073.pdf}
}
@article{burns2022discovering,
	title        = {Discovering latent knowledge in language models without supervision},
	author       = {Burns, Collin and Ye, Haotian and Klein, Dan and Steinhardt, Jacob},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2212.03827},
	url          = {https://arxiv.org/pdf/2212.03827.pdf}
}
@inproceedings{mohan2019analyzing,
	title        = {Analyzing GDPR compliance through the lens of privacy policy},
	author       = {Mohan, Jayashree and Wasserman, Melissa and Chidambaram, Vijay},
	year         = 2019,
	booktitle    = {Heterogeneous Data Management, Polystores, and Analytics for Healthcare: VLDB 2019 Workshops, Poly and DMAH, Los Angeles, CA, USA, August 30, 2019, Revised Selected Papers 5},
	pages        = {82--95},
	url          = {https://arxiv.org/pdf/1906.12038.pdf},
	organization = {Springer}
}
@article{taori2023alpaca,
	title        = {Alpaca: A Strong, Replicable Instruction-Following Model},
	author       = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto},
	year         = 2023,
	url          = {https://crfm.stanford.edu/2023/03/13/alpaca.html}
}
@inproceedings{cao2015towards,
	title        = {Towards making systems forget with machine unlearning},
	author       = {Cao, Yinzhi and Yang, Junfeng},
	year         = 2015,
	booktitle    = {2015 IEEE symposium on security and privacy},
	pages        = {463--480},
	url          = {https://www.ieee-security.org/TC/SP2015/papers-archived/6949a463.pdf},
	organization = {IEEE}
}
@article{tirumala2022memorization,
	title        = {Memorization without overfitting: Analyzing the training dynamics of large language models},
	author       = {Tirumala, Kushal and Markosyan, Aram and Zettlemoyer, Luke and Aghajanyan, Armen},
	year         = 2022,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 35,
	pages        = {38274--38290},
	url          = {https://proceedings.neurips.cc/paper_files/paper/2022/file/fa0509f4dab6807e2cb465715bf2d249-Paper-Conference.pdf}
}
@inproceedings{carlini2022membership,
	title        = {Membership inference attacks from first principles},
	author       = {Carlini, Nicholas and Chien, Steve and Nasr, Milad and Song, Shuang and Terzis, Andreas and Tramer, Florian},
	year         = 2022,
	booktitle    = {2022 IEEE Symposium on Security and Privacy (SP)},
	pages        = {1897--1914},
	url          = {https://arxiv.org/pdf/2112.03570.pdf},
	organization = {IEEE}
}
@article{JMLR:v21:20-074,
	title        = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
	author       = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
	year         = 2020,
	journal      = {Journal of Machine Learning Research},
	volume       = 21,
	number       = 140,
	pages        = {1--67},
	url          = {http://jmlr.org/papers/v21/20-074.html}
}
@article{anil2021large,
	title        = {Large-scale differentially private {BERT}},
	author       = {Anil, Rohan and Ghazi, Badih and Gupta, Vineet and Kumar, Ravi and Manurangsi, Pasin},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2108.01624}
}
@article{zhang2021counterfactual,
	title        = {Counterfactual Memorization in Neural Language Models},
	author       = {Zhang, Chiyuan and Ippolito, Daphne and Lee, Katherine and Jagielski, Matthew and Tram{\`e}r, Florian and Carlini, Nicholas},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2112.12938}
}
@inproceedings{NEURIPS2020_1457c0d6,
	title        = {Language Models are Few-Shot Learners},
	author       = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	year         = 2020,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 33,
	pages        = {1877--1901},
	url          = {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
	editor       = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin}
}
@inproceedings{devlin-etal-2019-bert,
	title        = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	author       = {Devlin, Jacob  and Chang, Ming-Wei  and Lee, Kenton  and Toutanova, Kristina},
	year         = 2019,
	month        = jun,
	booktitle    = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Minneapolis, Minnesota},
	pages        = {4171--4186},
	doi          = {10.18653/v1/N19-1423},
	url          = {https://aclanthology.org/N19-1423}
}
@article{DBLP:journals/corr/ChelbaMSGBK13,
	title        = {One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling},
	author       = {Ciprian Chelba and Tomas Mikolov and Mike Schuster and Qi Ge and Thorsten Brants and Phillipp Koehn},
	year         = 2013,
	journal      = {CoRR},
	volume       = {abs/1312.3005},
	url          = {http://arxiv.org/abs/1312.3005},
	archiveprefix = {arXiv},
	eprint       = {1312.3005},
	timestamp    = {Mon, 13 Aug 2018 16:46:16 +0200},
	biburl       = {https://dblp.org/rec/bib/journals/corr/ChelbaMSGBK13},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{kingma2014adam,
	title        = {Adam: A method for stochastic optimization},
	author       = {Kingma, Diederik P and Ba, Jimmy},
	year         = 2015,
	booktitle    = {The International Conference for Learning Representations}
}
@inproceedings{vaswani2017attention,
	title        = {Attention is all you need},
	author       = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	year         = 2017,
	booktitle    = {Advances in neural information processing systems},
	pages        = {5998--6008}
}
@inproceedings{zellers2019defending,
	title        = {Defending against neural fake news},
	author       = {Zellers, Rowan and Holtzman, Ari and Rashkin, Hannah and Bisk, Yonatan and Farhadi, Ali and Roesner, Franziska and Choi, Yejin},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@inproceedings{49029,
	title        = {Wiki-40B: Multilingual Language Model Dataset},
	author       = {Mandy Guo and Zihang Dai and Denny Vrandecic and Rami Al-Rfou},
	year         = 2020,
	booktitle    = {LREC 2020}
}
@inproceedings{thomas2020investigating,
	title        = {Investigating the impact of pre-trained word embeddings on memorization in neural networks},
	author       = {Thomas, Aleena and Adelani, David Ifeoluwa and Davody, Ali and Mogadala, Aditya and Klakow, Dietrich},
	year         = 2020,
	booktitle    = {International Conference on Text, Speech, and Dialogue},
	pages        = {273--281},
	organization = {Springer}
}
@article{devlin2018bert,
	title        = {Bert: Pre-training of deep bidirectional transformers for language understanding},
	author       = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1810.04805}
}
@article{fedus2021switch,
	title        = {Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
	author       = {Fedus, William and Zoph, Barret and Shazeer, Noam},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2101.03961}
}
@article{hampel1974influence,
	title        = {The influence curve and its role in robust estimation},
	author       = {Hampel, Frank R},
	year         = 1974,
	journal      = {Journal of the american statistical association},
	publisher    = {Taylor \& Francis},
	volume       = 69,
	number       = 346,
	pages        = {383--393}
}
@inproceedings{ganju2018property,
	title        = {Property inference attacks on fully connected neural networks using permutation invariant representations},
	author       = {Ganju, Karan and Wang, Qi and Yang, Wei and Gunter, Carl A and Borisov, Nikita},
	year         = 2018,
	booktitle    = {Proceedings of the 2018 ACM SIGSAC conference on computer and communications security},
	pages        = {619--633}
}
@inproceedings{fredrikson2015model,
	title        = {Model inversion attacks that exploit confidence information and basic countermeasures},
	author       = {Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
	year         = 2015,
	booktitle    = {Proceedings of the 22nd ACM SIGSAC conference on computer and communications security},
	pages        = {1322--1333}
}
@article{dodge2021documenting,
	title        = {Documenting the english colossal clean crawled corpus},
	author       = {Dodge, Jesse and Sap, Maarten and Marasovic, Ana and Agnew, William and Ilharco, Gabriel and Groeneveld, Dirk and Gardner, Matt},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2104.08758}
}
@article{lee2021dedup,
	title        = {Deduplicating Training Data Makes Language Models Better},
	author       = {Katherine Lee and Daphne Ippolito and Andrew Nystrom and Chiyuan Zhang and Douglas Eck and Chris Callison{-}Burch and Nicholas Carlini},
	year         = 2021,
	journal      = {CoRR},
	volume       = {abs/2107.06499},
	url          = {https://arxiv.org/abs/2107.06499},
	eprinttype   = {arXiv},
	eprint       = {2107.06499},
	timestamp    = {Wed, 21 Jul 2021 15:55:35 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2107-06499.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{carlini2020extracting,
	title        = {Extracting training data from large language models},
	author       = {Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2012.07805},
	url          = {https://arxiv.org/pdf/2012.07805.pdf}
}
@inproceedings{stephenson2021geometry,
	title        = {On the geometry of generalization and memorization in deep neural networks},
	author       = {Stephenson, Cory and Padhy, Suchismita and Ganesh, Abhinav and Hui, Yue and Tang, Hanlin and Chung, SueYeon},
	year         = 2021,
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{shokri2017membership,
	title        = {Membership inference attacks against machine learning models},
	author       = {Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
	year         = 2017,
	booktitle    = {2017 IEEE Symposium on Security and Privacy (SP)},
	pages        = {3--18},
	organization = {IEEE}
}
@article{neyshabur2014search,
	title        = {In search of the real inductive bias: On the role of implicit regularization in deep learning},
	author       = {Neyshabur, Behnam and Tomioka, Ryota and Srebro, Nathan},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1412.6614}
}
@article{collange2015numerical,
	title        = {Numerical reproducibility for the parallel reduction on multi-and many-core architectures},
	author       = {Collange, Sylvain and Defour, David and Graillat, Stef and Iakymchuk, Roman},
	year         = 2015,
	journal      = {Parallel Computing},
	publisher    = {Elsevier},
	volume       = 49,
	pages        = {83--97}
}
@article{squire2009memory,
	title        = {Memory and brain systems: 1969--2009},
	author       = {Squire, Larry R},
	year         = 2009,
	journal      = {Journal of Neuroscience},
	publisher    = {Soc Neuroscience},
	volume       = 29,
	number       = 41,
	pages        = {12711--12716}
}
@inproceedings{zhang2017understanding,
	title        = {Understanding deep learning requires rethinking generalization},
	author       = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	year         = 2017,
	booktitle    = {International Conference on Learning Representations (ICLR)}
}
@article{bartlett2017spectrally,
	title        = {Spectrally-normalized margin bounds for neural networks},
	author       = {Bartlett, Peter and Foster, Dylan J and Telgarsky, Matus},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1706.08498}
}
@article{neyshabur2017exploring,
	title        = {Exploring generalization in deep learning},
	author       = {Neyshabur, Behnam and Bhojanapalli, Srinadh and McAllester, David and Srebro, Nathan},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1706.08947}
}
@inproceedings{golowich2018size,
	title        = {Size-independent sample complexity of neural networks},
	author       = {Golowich, Noah and Rakhlin, Alexander and Shamir, Ohad},
	year         = 2018,
	booktitle    = {Conference On Learning Theory},
	pages        = {297--299},
	organization = {PMLR}
}
@article{zhao2018bias,
	title        = {Bias and generalization in deep generative models: An empirical study},
	author       = {Zhao, Shengjia and Ren, Hongyu and Yuan, Arianna and Song, Jiaming and Goodman, Noah and Ermon, Stefano},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1811.03259}
}
@inproceedings{recht2019imagenet,
	title        = {Do imagenet classifiers generalize to imagenet?},
	author       = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
	year         = 2019,
	booktitle    = {International Conference on Machine Learning},
	pages        = {5389--5400},
	organization = {PMLR}
}
@inproceedings{arpit2017closer,
	title        = {A closer look at memorization in deep networks},
	author       = {Arpit, Devansh and Jastrzebski, Stanislaw and Ballas, Nicolas and Krueger, David and Bengio, Emmanuel and Kanwal, Maxinder S and Maharaj, Tegan and Fischer, Asja and Courville, Aaron and Bengio, Yoshua and others},
	year         = 2017,
	booktitle    = {International Conference on Machine Learning},
	pages        = {233--242},
	organization = {PMLR}
}
@book{tulving1983elements,
	title        = {Elements of episodic memory},
	author       = {Tulving, Endel},
	year         = 1983,
	publisher    = {Oxford University Press},
	isbn         = 9780198521259
}
@misc{carlini2021membership,
	title        = {Membership Inference Attacks From First Principles},
	author       = {Nicholas Carlini and Steve Chien and Milad Nasr and Shuang Song and Andreas Terzis and Florian Tramer},
	year         = 2021,
	eprint       = {2112.03570},
	archiveprefix = {arXiv},
	primaryclass = {cs.CR}
}
@inproceedings{broder1997resemblance,
	title        = {On the resemblance and containment of documents},
	author       = {Broder, Andrei Z},
	year         = 1997,
	booktitle    = {Proceedings. Compression and Complexity of SEQUENCES 1997 (Cat. No. 97TB100171)},
	pages        = {21--29},
	organization = {IEEE}
}
@article{toneva2018empirical,
	title        = {An empirical study of example forgetting during deep neural network learning},
	author       = {Toneva, Mariya and Sordoni, Alessandro and Combes, Remi Tachet des and Trischler, Adam and Bengio, Yoshua and Gordon, Geoffrey J},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1812.05159}
}
@inproceedings{belkin2018understand,
	title        = {To understand deep learning we need to understand kernel learning},
	author       = {Belkin, Mikhail and Ma, Siyuan and Mandal, Soumik},
	year         = 2018,
	booktitle    = {International Conference on Machine Learning},
	pages        = {541--549},
	organization = {PMLR}
}
@article{squire1992memory,
	title        = {Memory and the hippocampus: a synthesis from findings with rats, monkeys, and humans.},
	author       = {Squire, Larry R},
	year         = 1992,
	journal      = {Psychological review},
	publisher    = {American Psychological Association},
	volume       = 99,
	number       = 2,
	pages        = 195
}
@software{gpt-neo,
	title        = {{GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow}},
	author       = {Black, Sid and Gao, Leo and Wang, Phil and Leahy, Connor and Biderman, Stella},
	year         = 2021,
	month        = mar,
	publisher    = {Zenodo},
	doi          = {10.5281/zenodo.5297715},
	url          = {https://doi.org/10.5281/zenodo.5297715},
	note         = {{If you use this software, please cite it using these metadata.}},
	version      = {1.0}
}
@article{gao2020pile,
	title        = {The {Pile}: An {800GB} Dataset of Diverse Text for Language Modeling},
	author       = {Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2101.00027}
}
@article{cohen1980preserved,
	title        = {Preserved learning and retention of pattern-analyzing skill in amnesia: Dissociation of knowing how and knowing that},
	author       = {Cohen, Neal J and Squire, Larry R},
	year         = 1980,
	journal      = {Science},
	publisher    = {American Association for the Advancement of Science},
	volume       = 210,
	number       = 4466,
	pages        = {207--210}
}
@article{t52020,
	title        = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
	author       = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
	year         = 2020,
	journal      = {Journal of Machine Learning Research},
	volume       = 21,
	number       = 140,
	pages        = {1--67},
	url          = {http://jmlr.org/papers/v21/20-074.html}
}
@article{Bommasani2021-rp,
	title        = {On the Opportunities and Risks of Foundation Models},
	author       = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Kohd, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and R{\'e}, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W and Tram{\`e}r, Florian and Wang, Rose E and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
	year         = 2021,
	month        = aug,
	archiveprefix = {arXiv},
	primaryclass = {cs.LG},
	eprint       = {2108.07258}
}
@inproceedings{feldman2020does,
	title        = {Does learning require memorization? {A} short tale about a long tail},
	author       = {Feldman, Vitaly},
	year         = 2020,
	booktitle    = {STOC}
}
@article{Basu2021InfluenceFI,
	title        = {Influence Functions in Deep Learning Are Fragile},
	author       = {Samyadeep Basu and Philip Pope and Soheil Feizi},
	year         = 2021,
	journal      = {ArXiv},
	volume       = {abs/2006.14651}
}
@article{Koh2017UnderstandingBP,
	title        = {Understanding Black-box Predictions via Influence Functions},
	author       = {Pang Wei Koh and Percy Liang},
	year         = 2017,
	journal      = {ArXiv},
	volume       = {abs/1703.04730}
}
@inproceedings{Koh2019OnTA,
	title        = {On the Accuracy of Influence Functions for Measuring Group Effects},
	author       = {Pang Wei Koh and Kai-Siang Ang and Hubert Hua Kian Teo and Percy Liang},
	year         = 2019,
	booktitle    = {NeurIPS}
}
@article{Pruthi2020EstimatingTD,
	title        = {Estimating Training Data Influence by Tracking Gradient Descent},
	author       = {Garima Pruthi and Frederick Liu and Mukund Sundararajan and Satyen Kale},
	year         = 2020,
	journal      = {ArXiv},
	volume       = {abs/2002.08484}
}
@inproceedings{song2017machine,
	title        = {Machine Learning Models that Remember Too Much},
	author       = {Song, Congzheng and Ristenpart, Thomas and Shmatikov, Vitaly},
	year         = 2017,
	booktitle    = {ACM CCS}
}
@article{zhang2016understanding,
	title        = {Understanding deep learning requires rethinking generalization},
	author       = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	year         = 2017,
	journal      = {ICLR}
}
@inproceedings{carlini2019secret,
	title        = {
		The secr

		et sharer: Evaluating and testing unintended memorization in neural networks
	},
	author       = {Carlini, Nicholas and Liu, Chang and Erlingsson, {\'U}lfar and Kos, Jernej and Song, Dawn},
	year         = 2019,
	booktitle    = {USENIX Security Symposium},
	url          = {https://arxiv.org/pdf/1802.08232.pdf}
}
@article{kaplan2020scaling,
	title        = {Scaling laws for neural language models},
	author       = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2001.08361}
}
@article{brown2020memorization,
	title        = {When is Memorization of Irrelevant Training Data Necessary for High-Accuracy Learning?},
	author       = {Brown, Gavin and Bun, Mark and Feldman, Vitaly and Smith, Adam and Talwar, Kunal},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2012.06421}
}
@inproceedings{khandelwal20generalization,
	title        = {{Generalization through Memorization: Nearest Neighbor Language Models}},
	author       = {Khandelwal, Urvashi and Levy, Omer and Jurafsky, Dan and Zettlemoyer, Luke and Lewis, Mike},
	year         = 2020,
	booktitle    = {International Conference on Learning Representations (ICLR)}
}
@misc{thakkar2020understanding,
	title        = {Understanding Unintended Memorization in Federated Learning},
	author       = {Om Thakkar and Swaroop Ramaswamy and Rajiv Mathews and Françoise Beaufays},
	year         = 2020,
	eprint       = {2006.07490},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@article{ramaswamy2020training,
	title        = {Training production language models without memorizing user data},
	author       = {Ramaswamy, Swaroop and Thakkar, Om and Mathews, Rajiv and Andrew, Galen and McMahan, H Brendan and Beaufays, Fran{\c{c}}oise},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2009.10031}
}
@article{Zanella_B_guelin_2020,
	title        = {Analyzing Information Leakage of Updates to Natural Language Models},
	author       = {Zanella-Béguelin, Santiago and Wutschitz, Lukas and Tople, Shruti and Rühle, Victor and Paverd, Andrew and Ohrimenko, Olga and Köpf, Boris and Brockschmidt, Marc},
	year         = 2020,
	month        = {Oct},
	journal      = {Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
	publisher    = {ACM},
	doi          = {10.1145/3372297.3417880},
	isbn         = 9781450370899,
	url          = {http://dx.doi.org/10.1145/3372297.3417880}
}
@article{goodfellow2014generative,
	title        = {Generative adversarial nets},
	author       = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	year         = 2014,
	journal      = {Advances in neural information processing systems},
	volume       = 27
}
@inproceedings{abadi2016deep,
	title        = {Deep learning with differential privacy},
	author       = {Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
	year         = 2016,
	booktitle    = {Proceedings of the 2016 ACM SIGSAC conference on computer and communications security},
	pages        = {308--318}
}
@article{mukherjee2006learning,
	title        = {Learning theory: stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization},
	author       = {Mukherjee, Sayan and Niyogi, Partha and Poggio, Tomaso and Rifkin, Ryan},
	year         = 2006,
	journal      = {Advances in Computational Mathematics},
	publisher    = {Springer},
	volume       = 25,
	number       = 1,
	pages        = {161--193}
}
@article{dwork2014algorithmic,
	title        = {The algorithmic foundations of differential privacy.},
	author       = {Dwork, Cynthia and Roth, Aaron and others},
	year         = 2014,
	journal      = {Found. Trends Theor. Comput. Sci.},
	volume       = 9,
	number       = {3-4},
	pages        = {211--407}
}
@inproceedings{arjovsky2017wasserstein,
	title        = {Wasserstein generative adversarial networks},
	author       = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
	year         = 2017,
	booktitle    = {International conference on machine learning},
	pages        = {214--223},
	organization = {PMLR}
}
@misc{ziegler2021copilot,
	title        = {{GitHub} {Copilot}: Parrot or Crow?},
	author       = {Albert Ziegler},
	year         = 2021,
	howpublished = {https://docs.github.com/en/github/copilot/research-recitation}
}
@misc{sablayrolles2019whitebox,
	title        = {White-box vs Black-box: Bayes Optimal Strategies for Membership Inference},
	author       = {Alexandre Sablayrolles and Matthijs Douze and Yann Ollivier and Cordelia Schmid and Hervé Jégou},
	year         = 2019,
	eprint       = {1908.11229},
	archiveprefix = {arXiv},
	primaryclass = {stat.ML}
}
@inproceedings{long2020pragmatic,
	title        = {A Pragmatic Approach to Membership Inferences on Machine Learning Models},
	author       = {Long, Yunhui and Wang, Lei and Bu, Diyue and Bindschaedler, Vincent and Wang, Xiaofeng and Tang, Haixu and Gunter, Carl A and Chen, Kai},
	year         = 2020,
	booktitle    = {2020 IEEE European Symposium on Security and Privacy (EuroS\&P)},
	pages        = {521--534},
	organization = {IEEE}
}
@article{mccoy2021raven,
	title        = {How much do language models copy from their training data? {Evaluating} linguistic novelty in text generation using {RAVEN}},
	author       = {R. Thomas McCoy and Paul Smolensky and Tal Linzen and Jianfeng Gao and Asli Celikyilmaz},
	year         = 2021,
	journal      = {CoRR},
	volume       = {abs/2111.09509},
	url          = {https://arxiv.org/abs/2111.09509},
	eprinttype   = {arXiv},
	eprint       = {2111.09509},
	timestamp    = {Mon, 22 Nov 2021 16:44:07 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2111-09509.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{dwork2006calibrating,
	title        = {Calibrating noise to sensitivity in private data analysis},
	author       = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
	year         = 2006,
	booktitle    = {Theory of cryptography conference},
	pages        = {265--284},
	organization = {Springer}
}
@inproceedings{yeom2018privacy,
	title        = {Privacy risk in machine learning: Analyzing the connection to overfitting},
	author       = {Yeom, Samuel and Giacomelli, Irene and Fredrikson, Matt and Jha, Somesh},
	year         = 2018,
	booktitle    = {2018 IEEE 31st Computer Security Foundations Symposium (CSF)},
	pages        = {268--282},
	organization = {IEEE}
}
@article{jagielski2020auditing,
	title        = {Auditing differentially private machine learning: How private is private {SGD}?},
	author       = {Jagielski, Matthew and Ullman, Jonathan and Oprea, Alina},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.07709}
}
@article{nasr2021adversary,
	title        = {Adversary instantiation: Lower bounds for differentially private machine learning},
	author       = {Nasr, Milad and Song, Shuang and Thakurta, Abhradeep and Papernot, Nicolas and Carlini, Nicholas},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2101.04535}
}
@article{chen2021evaluating,
	title        = {Evaluating large language models trained on code},
	author       = {Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2107.03374}
}
@inproceedings{jayaraman2019evaluating,
	title        = {Evaluating differentially private machine learning in practice},
	author       = {Jayaraman, Bargav and Evans, David},
	year         = 2019,
	booktitle    = {28th $\{$USENIX$\}$ Security Symposium ($\{$USENIX$\}$ Security 19)},
	pages        = {1895--1912}
}
@article{colinpaper,
	title        = {Deduplicating training data mitigates privacy risks in language models},
	author       = {Kandpal, Nikhil and Wallace, Eric and Raffel, Colin},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2202.06539},
	url          = {https://arxiv.org/pdf/2202.06539.pdf}
}
@misc{brown2022does,
	title        = {What Does it Mean for a Language Model to Preserve Privacy?},
	author       = {Hannah Brown and Katherine Lee and Fatemehsadat Mireshghallah and Reza Shokri and Florian Tramèr},
	year         = 2022,
	url          = {https://arxiv.org/pdf/2202.05520.pdf},
	eprint       = {2202.05520},
	archiveprefix = {arXiv},
	primaryclass = {stat.ML}
}
@article{zhang2022opt,
	title        = {OPT: Open Pre-trained Transformer Language Models},
	author       = {Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2205.01068}
}
@inproceedings{hewitt2019structural,
	title        = {A structural probe for finding syntax in word representations},
	author       = {Hewitt, John and Manning, Christopher D},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	pages        = {4129--4138},
	url          = {https://aclanthology.org/N19-1419.pdf}
}
@misc{ilharco2023editing,
	title        = {Editing Models with Task Arithmetic},
	author       = {Gabriel Ilharco and Marco Tulio Ribeiro and Mitchell Wortsman and Suchin Gururangan and Ludwig Schmidt and Hannaneh Hajishirzi and Ali Farhadi},
	year         = 2023,
	url          = {https://arxiv.org/pdf/2212.04089.pdf},
	eprint       = {2212.04089},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@inproceedings{perez2022ignore,
	title        = {Ignore Previous Prompt: Attack Techniques For Language Models},
	author       = {Perez, F{\'a}bio and Ribeiro, Ian},
	year         = 2022,
	booktitle    = {NeurIPS ML Safety Workshop}
}
@article{zou2023universal,
	title        = {Universal and transferable adversarial attacks on aligned language models},
	author       = {Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2307.15043},
	url          = {https://arxiv.org/pdf/2307.15043.pdf}
}
@article{belinkov2022probing,
	title        = {Probing classifiers: Promises, shortcomings, and advances},
	author       = {Belinkov, Yonatan},
	year         = 2022,
	journal      = {Computational Linguistics},
	publisher    = {MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…},
	volume       = 48,
	number       = 1,
	pages        = {207--219},
	url          = {https://arxiv.org/pdf/2102.12452.pdf}
}
@article{touvron2023llama,
	title        = {Llama 2: Open foundation and fine-tuned chat models},
	author       = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2307.09288},
	url          = {https://arxiv.org/pdf/2307.09288.pdf}
}
@article{carlini2019evaluating,
	title        = {On evaluating adversarial robustness},
	author       = {Carlini, Nicholas and Athalye, Anish and Papernot, Nicolas and Brendel, Wieland and Rauber, Jonas and Tsipras, Dimitris and Goodfellow, Ian and Madry, Aleksander and Kurakin, Alexey},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1902.06705},
	url          = {https://arxiv.org/pdf/1902.06705.pdf}
}
@article{hernandez2023measuring,
	title        = {Measuring and manipulating knowledge representations in language models},
	author       = {Hernandez, Evan and Li, Belinda Z and Andreas, Jacob},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2304.00740},
	url          = {https://arxiv.org/pdf/2304.00740.pdf}
}
@inproceedings{henderson2018ethical,
	title        = {Ethical challenges in data-driven dialogue systems},
	author       = {Henderson, Peter and Sinha, Koustuv and Angelard-Gontier, Nicolas and Ke, Nan Rosemary and Fried, Genevieve and Lowe, Ryan and Pineau, Joelle},
	year         = 2018,
	booktitle    = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
	pages        = {123--129},
	url          = {https://arxiv.org/pdf/1711.09050.pdf}
}
@software{flax2020github,
	title        = {flax.linen.scan},
	author       = {Jonathan Heek and Anselm Levskaya and Avital Oliver and Marvin Ritter and Bertrand Rondepierre and Andreas Steiner and Marc van {Z}ee},
	year         = 2023,
	url          = {https://flax.readthedocs.io/en/latest/api_reference/flax.linen/_autosummary/flax.linen.scan.html},
	version      = {0.7.2}
}
@article{mozes2023use,
	title        = {Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities},
	author       = {Mozes, Maximilian and He, Xuanli and Kleinberg, Bennett and Griffin, Lewis D},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2308.12833},
	url          = {https://arxiv.org/pdf/2308.12833.pdf}
}
@inproceedings{lukas2023analyzing,
	title        = {Analyzing Leakage of Personally Identifiable Information in Language Models},
	author       = {Lukas, Nils and Salem, Ahmed and Sim, Robert and Tople, Shruti and Wutschitz, Lukas and Zanella-Béguelin, Santiago},
	year         = 2023,
	booktitle    = {2023 IEEE Symposium on Security and Privacy (SP)},
	volume       = {},
	number       = {},
	pages        = {346--363},
	url          = {https://arxiv.org/pdf/2302.00539.pdf}
}
@article{ishihara2023training,
	title        = {Training Data Extraction From Pre-trained Language Models: A Survey},
	author       = {Ishihara, Shotaro},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.16157},
	url          = {https://aclanthology.org/2023.trustnlp-1.23.pdf}
}
@article{gandikota2023erasing,
	title        = {Erasing Concepts from Diffusion Models},
	author       = {Gandikota, Rohit and Materzynska, Joanna and Fiotto-Kaufman, Jaden and Bau, David},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2303.07345},
	url          = {https://arxiv.org/pdf/2303.07345.pdf}
}
@article{heng2023selective,
	title        = {Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models},
	author       = {Heng, Alvin and Soh, Harold},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.10120},
	url          = {https://arxiv.org/pdf/2305.10120.pdf}
}
@article{kumari2023ablating,
	title        = {Ablating concepts in text-to-image diffusion models},
	author       = {Kumari, Nupur and Zhang, Bingliang and Wang, Sheng-Yu and Shechtman, Eli and Zhang, Richard and Zhu, Jun-Yan},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2303.13516},
	url          = {https://arxiv.org/pdf/2303.13516.pdf}
}
@article{zhang2023forget,
	title        = {Forget-me-not: Learning to forget in text-to-image diffusion models},
	author       = {Zhang, Eric and Wang, Kai and Xu, Xingqian and Wang, Zhangyang and Shi, Humphrey},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2303.17591},
	url          = {https://arxiv.org/pdf/2303.17591.pdf}
}
@misc{min2023silo,
	title        = {SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore},
	author       = {Sewon Min and Suchin Gururangan and Eric Wallace and Hannaneh Hajishirzi and Noah A. Smith and Luke Zettlemoyer},
	year         = 2023,
	url          = {https://arxiv.org/pdf/2308.04430.pdf},
	eprint       = {2308.04430},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{zhang2023right,
	title        = {Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions},
	author       = {Dawen Zhang and Pamela Finckenberg-Broman and Thong Hoang and Shidong Pan and Zhenchang Xing and Mark Staples and Xiwei Xu},
	year         = 2023,
	url          = {https://arxiv.org/pdf/2307.03941.pdf},
	eprint       = {2307.03941},
	archiveprefix = {arXiv},
	primaryclass = {cs.CY}
}
@misc{henderson2023foundation,
	title        = {Foundation Models and Fair Use},
	author       = {Peter Henderson and Xuechen Li and Dan Jurafsky and Tatsunori Hashimoto and Mark A. Lemley and Percy Liang},
	year         = 2023,
	url          = {https://arxiv.org/pdf/2303.15715.pdf},
	eprint       = {2303.15715},
	archiveprefix = {arXiv},
	primaryclass = {cs.CY}
}
@misc{debenedetti2023privacy,
	title        = {Privacy Side Channels in Machine Learning Systems},
	author       = {Edoardo Debenedetti and Giorgio Severi and Nicholas Carlini and Christopher A. Choquette-Choo and Matthew Jagielski and Milad Nasr and Eric Wallace and Florian Tramèr},
	year         = 2023,
	url          = {https://arxiv.org/pdf/2309.05610.pdf},
	eprint       = {2309.05610},
	archiveprefix = {arXiv},
	primaryclass = {cs.CR}
}
@article{belrose2023leace,
	title        = {LEACE: Perfect linear concept erasure in closed form},
	author       = {Belrose, Nora and Schneider-Joseph, David and Ravfogel, Shauli and Cotterell, Ryan and Raff, Edward and Biderman, Stella},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2306.03819},
	url          = {https://arxiv.org/pdf/2306.03819.pdf}
}
% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
A unifying view on dataset shift in classification
% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@article{anwar2024foundational,
	title        = {Foundational Challenges in Assuring Alignment and Safety of Large Language Models},
	author       = {Anwar, Usman and Saparov, Abulhair and Rando, Javier and Paleka, Daniel and Turpin, Miles and Hase, Peter and Lubana, Ekdeep Singh and Jenner, Erik and Casper, Stephen and Sourbut, Oliver and others},
	year         = 2024,
	journal      = {arXiv preprint arXiv:2404.09932},
	url          = {https://arxiv.org/pdf/2404.09932.pdf}
}
@misc{joshi2024personas,
      title={Personas as a Way to Model Truthfulness in Language Models}, 
      author={Nitish Joshi and Javier Rando and Abulhair Saparov and Najoung Kim and He He},
      year={2024},
      eprint={2310.18168},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
url={https://arxiv.org/pdf/2310.18168.pdf}
}

@article{chen2024towards,
  title={Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning},
  author={Chen, Yanda and Singh, Chandan and Liu, Xiaodong and Zuo, Simiao and Yu, Bin and He, He and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2401.13986},
  year={2024},
url={https://arxiv.org/pdf/2401.13986.pdf}
}

@article{chen2023models,
  title={Do models explain themselves? counterfactual simulatability of natural language explanations},
  author={Chen, Yanda and Zhong, Ruiqi and Ri, Narutatsu and Zhao, Chen and He, He and Steinhardt, Jacob and Yu, Zhou and McKeown, Kathleen},
  journal={arXiv preprint arXiv:2307.08678},
  year={2023},
url={https://arxiv.org/pdf/2307.08678.pdf}
}
@article{gude2023factors,
  title={Factors Influencing ChatGpt Adoption for Product Research and Information Retrieval},
  author={Gude, Vinayaka},
  journal={Journal of Computer Information Systems},
  pages={1--10},
  year={2023},
  publisher={Taylor \& Francis},
url={https://www.tandfonline.com/doi/abs/10.1080/08874417.2023.2280918}
}

@inproceedings{ganguli2022predictability,
  title={Predictability and surprise in large generative models},
  author={Ganguli, Deep and Hernandez, Danny and Lovitt, Liane and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Dassarma, Nova and Drain, Dawn and Elhage, Nelson and others},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1747--1764},
  year={2022},
  url={https://arxiv.org/pdf/2202.07785}
}

@article{vrandevcic2014wikidata,
  title={Wikidata: a free collaborative knowledgebase},
  author={Vrande{\v{c}}i{\'c}, Denny and Kr{\"o}tzsch, Markus},
  journal={Communications of the ACM},
  volume={57},
  number={10},
  pages={78--85},
  year={2014},
  publisher={ACM New York, NY, USA},
url={https://dl.acm.org/doi/fullHtml/10.1145/2629489}
}

@article{gupta2024rebuilding,
  title={Rebuilding ROME: Resolving Model Collapse during Sequential Model Editing},
  author={Gupta, Akshat and Anumanchipalli, Gopala},
  journal={arXiv preprint arXiv:2403.07175},
  year={2024},
url={https://arxiv.org/pdf/2403.07175}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023},
url={https://arxiv.org/pdf/2303.08774}
}

@article{betz2023probabilistic,
  title={Probabilistic coherence, logical consistency, and Bayesian learning: Neural language models as epistemic agents},
  author={Betz, Gregor and Richardson, Kyle},
  journal={Plos one},
  volume={18},
  number={2},
  pages={e0281372},
  year={2023},
  publisher={Public Library of Science San Francisco, CA USA},
url={https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0281372}
}

@inproceedings{pinter-elhadad-2023-emptying,
    title = "Emptying the Ocean with a Spoon: Should We Edit Models?",
    author = "Pinter, Yuval  and
      Elhadad, Michael",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.1012",
    doi = "10.18653/v1/2023.findings-emnlp.1012",
    pages = "15164--15172",
}

@article{zhong2023mquake,
  title={Mquake: Assessing knowledge editing in language models via multi-hop questions},
  author={Zhong, Zexuan and Wu, Zhengxuan and Manning, Christopher D and Potts, Christopher and Chen, Danqi},
  journal={arXiv preprint arXiv:2305.14795},
  year={2023},
url={https://arxiv.org/pdf/2305.14795}
}

@article{cohen2024evaluating,
  title={Evaluating the ripple effects of knowledge editing in language models},
  author={Cohen, Roi and Biran, Eden and Yoran, Ori and Globerson, Amir and Geva, Mor},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={283--298},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…},
url={https://arxiv.org/pdf/2307.12976}
}

@article{powell2024taxi,
  title={TAXI: Evaluating Categorical Knowledge Editing for Language Models},
  author={Powell, Derek and Gerych, Walter and Hartvigsen, Thomas},
  journal={arXiv preprint arXiv:2404.15004},
  year={2024},
url={https://arxiv.org/pdf/2404.15004}
}

@article{li2023unveiling,
  title={Unveiling the pitfalls of knowledge editing for large language models},
  author={Li, Zhoubo and Zhang, Ningyu and Yao, Yunzhi and Wang, Mengru and Chen, Xi and Chen, Huajun},
  journal={arXiv preprint arXiv:2310.02129},
  year={2023},
url={https://arxiv.org/pdf/2310.02129}
}

@article{onoe2023can,
  title={Can lms learn new entities from descriptions? challenges in propagating injected knowledge},
  author={Onoe, Yasumasa and Zhang, Michael JQ and Padmanabhan, Shankar and Durrett, Greg and Choi, Eunsol},
  journal={arXiv preprint arXiv:2305.01651},
  year={2023},
url={https://arxiv.org/pdf/2305.01651}
}

@inproceedings{gupta2023editing,
  title={Editing common sense in transformers},
  author={Gupta, Anshita and Mondal, Debanjan and Sheshadri, Akshay and Zhao, Wenlong and Li, Xiang and Wiegreffe, Sarah and Tandon, Niket},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={8214--8232},
  year={2023},
url={https://arxiv.org/pdf/2305.14956}
}

@article{brown2023edit,
  title={Edit at your own risk: evaluating the robustness of edited models to distribution shifts},
  author={Brown, Davis and Godfrey, Charles and Nizinski, Cody and Tu, Jonathan and Kvinge, Henry},
  journal={arXiv preprint arXiv:2303.00046},
  year={2023},
url={https://arxiv.org/pdf/2303.00046}
}

@article{xu2022language,
  title={Language anisotropic cross-lingual model editing},
  author={Xu, Yang and Hou, Yutai and Che, Wanxiang and Zhang, Min},
  journal={arXiv preprint arXiv:2205.12677},
  year={2022},
url={https://arxiv.org/pdf/2205.12677}
}

@article{song2024knowledge,
  title={Knowledge Editing on Black-box Large Language Models},
  author={Song, Xiaoshuai and Wang, Zhengyang and He, Keqing and Dong, Guanting and Zhao, Jinxu and Xu, Weiran},
  journal={arXiv preprint arXiv:2402.08631},
  year={2024},
url={https://arxiv.org/pdf/2402.08631}
}

@article{peng2024event,
  title={Event-level Knowledge Editing},
  author={Peng, Hao and Wang, Xiaozhi and Li, Chunyang and Zeng, Kaisheng and Duo, Jiangshan and Cao, Yixin and Hou, Lei and Li, Juanzi},
  journal={arXiv preprint arXiv:2402.13093},
  year={2024},
url={https://arxiv.org/pdf/2402.13093}
}

@article{wang2023knowledge,
  title={Knowledge editing for large language models: A survey},
  author={Wang, Song and Zhu, Yaochen and Liu, Haochen and Zheng, Zaiyi and Chen, Chen and others},
  journal={arXiv preprint arXiv:2310.16218},
  year={2023},
url={https://arxiv.org/pdf/2310.16218}
}

@article{wei2023assessing,
  title={Assessing knowledge editing in language models via relation perspective},
  author={Wei, Yifan and Yu, Xiaoyan and Ma, Huanhuan and Lei, Fangyu and Weng, Yixuan and Song, Ran and Liu, Kang},
  journal={arXiv preprint arXiv:2311.09053},
  year={2023},
url={https://arxiv.org/pdf/2311.09053}
}

@article{wu2023depn,
  title={Depn: Detecting and editing privacy neurons in pretrained language models},
  author={Wu, Xinwei and Li, Junzhuo and Xu, Minghui and Dong, Weilong and Wu, Shuangzhi and Bian, Chao and Xiong, Deyi},
  journal={arXiv preprint arXiv:2310.20138},
  year={2023},
url={https://arxiv.org/pdf/2310.20138}
}

@article{wang2023easyedit,
  title={Easyedit: An easy-to-use knowledge editing framework for large language models},
  author={Wang, Peng and Zhang, Ningyu and Xie, Xin and Yao, Yunzhi and Tian, Bozhong and Wang, Mengru and Xi, Zekun and Cheng, Siyuan and Liu, Kangwei and Zheng, Guozhou and others},
  journal={arXiv preprint arXiv:2308.07269},
  year={2023},
url={https://arxiv.org/pdf/2308.07269}
}

@inproceedings{li2024pmet,
  title={Pmet: Precise model editing in a transformer},
  author={Li, Xiaopeng and Li, Shasha and Song, Shezheng and Yang, Jing and Ma, Jun and Yu, Jie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={18564--18572},
  year={2024},
url={https://arxiv.org/pdf/2308.08742}
}

@article{han2023divide,
  title={A divide and conquer framework for Knowledge Editing},
  author={Han, Xiaoqi and Li, Ru and Li, Xiaoli and Pan, Jeff Z},
  journal={Knowledge-Based Systems},
  volume={279},
  pages={110826},
  year={2023},
  publisher={Elsevier},
url={https://www.sciencedirect.com/science/article/abs/pii/S0950705123005762}
}

@article{yao2023editing,
  title={Editing large language models: Problems, methods, and opportunities},
  author={Yao, Yunzhi and Wang, Peng and Tian, Bozhong and Cheng, Siyuan and Li, Zhoubo and Deng, Shumin and Chen, Huajun and Zhang, Ningyu},
  journal={arXiv preprint arXiv:2305.13172},
  year={2023},
url={https://arxiv.org/pdf/2305.13172}
}

@article{hoelscher2023detecting,
  title={Detecting edit failures in large language models: An improved specificity benchmark},
  author={Hoelscher-Obermaier, Jason and Persson, Julia and Kran, Esben and Konstas, Ioannis and Barez, Fazl},
  journal={arXiv preprint arXiv:2305.17553},
  year={2023},
url={https://arxiv.org/pdf/2305.17553}
}


@article{alkhamissi2022review,
  title={A review on language models as knowledge bases},
  author={AlKhamissi, Badr and Li, Millicent and Celikyilmaz, Asli and Diab, Mona and Ghazvininejad, Marjan},
  journal={arXiv preprint arXiv:2204.06031},
  year={2022},
url={https://arxiv.org/pdf/2204.06031}
}


@article{hempel1945studies,
  title={Studies in the Logic of Confirmation (I.)},
  author={Hempel, Carl G},
  journal={Mind},
  volume={54},
  number={213},
  pages={1--26},
  year={1945},
  publisher={JSTOR}
}

@article{sharma2023towards,
  title={Towards understanding sycophancy in language models},
  author={Sharma, Mrinank and Tong, Meg and Korbak, Tomasz and Duvenaud, David and Askell, Amanda and Bowman, Samuel R and Cheng, Newton and Durmus, Esin and Hatfield-Dodds, Zac and Johnston, Scott R and others},
  journal={arXiv preprint arXiv:2310.13548},
  year={2023},
url={https://arxiv.org/pdf/2310.13548}
}

@InCollection{sep-speech-acts,
	author       =	{Green, Mitchell},
	title        =	{{Speech Acts}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta},
	year         =	{2021},
	edition      =	{{F}all 2021},
	publisher    =	{Metaphysics Research Lab, Stanford University},
url={https://plato.stanford.edu/archives/win2020/entries/speech-acts/#SpeActSco}
}

@article{tversky1974judgment,
  title={Judgment under Uncertainty: Heuristics and Biases: Biases in judgments reveal some heuristics of thinking under uncertainty.},
  author={Tversky, Amos and Kahneman, Daniel},
  journal={science},
  volume={185},
  number={4157},
  pages={1124--1131},
  year={1974},
  publisher={American association for the advancement of science},
url={https://www.science.org/doi/pdf/10.1126/science.185.4157.1124?casa_token=h8Dnb7ql6T4AAAAA:kco51ZIKjs4YcLeyaY_tay6nD0dCfcaTWSaku1VZDrOSDk51mnk3ORnpRWS2N_RQvazFhSc0Ld6d35Q}
}

@article{nie2020can,
  title={What can we learn from collective human opinions on natural language inference data?},
  author={Nie, Yixin and Zhou, Xiang and Bansal, Mohit},
  journal={arXiv preprint arXiv:2010.03532},
  year={2020},
url={https://arxiv.org/pdf/2010.03532}
}

@article{uma2021learning,
  title={Learning from disagreement: A survey},
  author={Uma, Alexandra N and Fornaciari, Tommaso and Hovy, Dirk and Paun, Silviu and Plank, Barbara and Poesio, Massimo},
  journal={Journal of Artificial Intelligence Research},
  volume={72},
  pages={1385--1470},
  year={2021},
url={https://www.jair.org/index.php/jair/article/view/12752}
}

@article{plank2022problem,
  title={The'Problem'of Human Label Variation: On Ground Truth in Data, Modeling and Evaluation},
  author={Plank, Barbara},
  journal={arXiv preprint arXiv:2211.02570},
  year={2022},
url={https://arxiv.org/pdf/2211.02570}
}

@article{liu2023we,
  title={We're afraid language models aren't modeling ambiguity},
  author={Liu, Alisa and Wu, Zhaofeng and Michael, Julian and Suhr, Alane and West, Peter and Koller, Alexander and Swayamdipta, Swabha and Smith, Noah A and Choi, Yejin},
  journal={arXiv preprint arXiv:2304.14399},
  year={2023},
url={https://arxiv.org/pdf/2304.14399}
}

@article{fierro2024mulan,
  title={MuLan: A Study of Fact Mutability in Language Models},
  author={Fierro, Constanza and Garneau, Nicolas and Bugliarello, Emanuele and Kementchedjhieva, Yova and S{\o}gaard, Anders},
  journal={arXiv preprint arXiv:2404.03036},
  year={2024},
url={https://arxiv.org/pdf/2404.03036}
}

@article{qi2023fine,
  title={Fine-tuning aligned language models compromises safety, even when users do not intend to!},
  author={Qi, Xiangyu and Zeng, Yi and Xie, Tinghao and Chen, Pin-Yu and Jia, Ruoxi and Mittal, Prateek and Henderson, Peter},
  journal={arXiv preprint arXiv:2310.03693},
  year={2023},
url={https://arxiv.org/pdf/2310.03693}
}

@misc{mistral,
    title = "Announcing {M}istral 7{B}", 
    url={https://mistral.ai/news/announcing-mistral-7b/}, 
    year = 2023,
    Author = {{Mistral AI}},
    Date-Added = {2023-09-27},
    Howpublished = {Blogpost},
}


@article{prystawski2024think,
  title={Why think step by step? Reasoning emerges from the locality of experience},
  author={Prystawski, Ben and Li, Michael and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023},
url={https://proceedings.neurips.cc/paper_files/paper/2023/file/e0af79ad53a336b4c4b4f7e2a68eb609-Paper-Conference.pdf}
}

@article{hua2024propagation,
  title={Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks},
  author={Hua, Wenyue and Guo, Jiang and Dong, Mingwen and Zhu, Henghui and Ng, Patrick and Wang, Zhiguo},
  journal={arXiv preprint arXiv:2401.17585},
  year={2024},
url={https://arxiv.org/pdf/2401.17585}
}

@article{farquhar2023challenges,
  title={Challenges with unsupervised LLM knowledge discovery},
  author={Farquhar, Sebastian and Varma, Vikrant and Kenton, Zachary and Gasteiger, Johannes and Mikulik, Vladimir and Shah, Rohin},
  journal={arXiv preprint arXiv:2312.10029},
  year={2023},
url={https://arxiv.org/pdf/2312.10029}
}

@inproceedings{henderson2023self,
  title={Self-destructing models: Increasing the costs of harmful dual uses of foundation models},
  author={Henderson, Peter and Mitchell, Eric and Manning, Christopher and Jurafsky, Dan and Finn, Chelsea},
  booktitle={Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={287--296},
  year={2023},
url={https://dl.acm.org/doi/pdf/10.1145/3600211.3604690?casa_token=1auWpvvbXlQAAAAA:rAle3U5NfZs8apFeILketoIn8Q4M0SQ23P44AqGAM01lNdq30m2GkRUoNT-0NpKWL_3mjtmTnCM_UwU}
}

@article{simon1956rational,
  title={Rational choice and the structure of the environment.},
  author={Simon, Herbert A},
  journal={Psychological review},
  volume={63},
  number={2},
  pages={129},
  year={1956},
  publisher={American Psychological Association},
url={https://pages.ucsd.edu/~mckenzie/Simon1956PsychReview.pdf}
}

@inproceedings{krasheninnikov2024implicit,
      title={Implicit meta-learning may lead language models to trust more reliable sources}, 
      author={Dmitrii Krasheninnikov and Egor Krasheninnikov and Bruno Mlodozeniec and Tegan Maharaj and David Krueger},
      year={2024},
      journal={ICML},
      url={https://arxiv.org/pdf/2310.15047}
}

@article{wan2024evidence,
  title={What Evidence Do Language Models Find Convincing?},
  author={Wan, Alexander and Wallace, Eric and Klein, Dan},
  journal={arXiv preprint arXiv:2402.11782},
  year={2024},
url={https://arxiv.org/pdf/2402.11782}
}

@inproceedings{hewitt-etal-2023-backpack,
    title = "Backpack Language Models",
    author = "Hewitt, John  and
      Thickstun, John  and
      Manning, Christopher  and
      Liang, Percy",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.506",
    doi = "10.18653/v1/2023.acl-long.506",
    pages = "9103--9125",
}


@article{hartvigsen2023aging,
  title={Aging with grace: Lifelong model editing with discrete key-value adaptors},
  author={Hartvigsen, Tom and Sankaranarayanan, Swami and Palangi, Hamid and Kim, Yoon and Ghassemi, Marzyeh},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023},
url={https://proceedings.neurips.cc/paper_files/paper/2023/file/95b6e2ff961580e03c0a662a63a71812-Paper-Conference.pdf}
}

@article{alchourron1985logic,
 ISSN = {00224812},
 URL = {https://fitelson.org/piksi/agm.pdf},
 author = {Carlos E. Alchourrón and Peter Gärdenfors and David Makinson},
 journal = {The Journal of Symbolic Logic},
 number = {2},
 pages = {510--530},
 publisher = {Association for Symbolic Logic},
 title = {On the Logic of Theory Change: Partial Meet Contraction and Revision Functions},
 urldate = {2024-06-21},
 volume = {50},
 year = {1985}
}

@misc{hofweber2024language,
      title={Are language models rational? The case of coherence norms and belief revision}, 
      author={Thomas Hofweber and Peter Hase and Elias Stengel-Eskin and Mohit Bansal},
      year={2024},
      eprint={2406.03442},
      archivePrefix={arXiv},
      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'},
    url={https://arxiv.org/pdf/2406.03442}
}

@article{rein2023gpqa,
  title={GPQA: A Graduate-Level Google-Proof Q\&A Benchmark},
  author={Rein, David and Hou, Betty Li and Stickland, Asa Cooper and Petty, Jackson and Pang, Richard Yuanzhe and Dirani, Julien and Michael, Julian and Bowman, Samuel R},
  journal={arXiv preprint arXiv:2311.12022},
  year={2023},
url={https://arxiv.org/pdf/2311.12022.pdf}
}

@article{gangadhar2024model,
  title={Model Editing by Pure Fine-Tuning},
  author={Gangadhar, Govind and Stratos, Karl},
  journal={arXiv preprint arXiv:2402.11078},
  year={2024},
url={https://arxiv.org/pdf/2402.11078v3}
}


@article{du2024context,
  title={Context versus Prior Knowledge in Language Models},
  author={Du, Kevin and Sn{\ae}bjarnarson, V{\'e}steinn and Stoehr, Niklas and White, Jennifer C and Schein, Aaron and Cotterell, Ryan},
  journal={arXiv preprint arXiv:2404.04633},
  year={2024},
url={https://arxiv.org/pdf/2404.04633}
}

@inproceedings{xie2023adaptive,
  title={Adaptive chameleon or stubborn sloth: Revealing the behavior of large language models in knowledge conflicts},
  author={Xie, Jian and Zhang, Kai and Chen, Jiangjie and Lou, Renze and Su, Yu},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023},
ur={https://arxiv.org/pdf/2305.13300}
}

@article{wang2023resolving,
  title={Resolving knowledge conflicts in large language models},
  author={Wang, Yike and Feng, Shangbin and Wang, Heng and Shi, Weijia and Balachandran, Vidhisha and He, Tianxing and Tsvetkov, Yulia},
  journal={arXiv preprint arXiv:2310.00935},
  year={2023},
url={https://arxiv.org/pdf/2310.00935}
}

@article{longpre2021entity,
  title={Entity-based knowledge conflicts in question answering},
  author={Longpre, Shayne and Perisetla, Kartik and Chen, Anthony and Ramesh, Nikhil and DuBois, Chris and Singh, Sameer},
  journal={arXiv preprint arXiv:2109.05052},
  year={2021},
url={https://arxiv.org/pdf/2109.05052}
}

@article{zhou2021distributed,
  title={Distributed NLI: Learning to predict human opinion distributions for language reasoning},
  author={Zhou, Xiang and Nie, Yixin and Bansal, Mohit},
  journal={arXiv preprint arXiv:2104.08676},
  year={2021},
url={https://arxiv.org/pdf/2104.08676}
}

@article{zhou2024relying,
  title={Relying on the Unreliable: The Impact of Language Models' Reluctance to Express Uncertainty},
  author={Zhou, Kaitlyn and Hwang, Jena D and Ren, Xiang and Sap, Maarten},
  journal={arXiv preprint arXiv:2401.06730},
  year={2024},
url={https://arxiv.org/pdf/2401.06730}
}

@article{li2024wmdp,
  title={The wmdp benchmark: Measuring and reducing malicious use with unlearning},
  author={Li, Nathaniel and Pan, Alexander and Gopal, Anjali and Yue, Summer and Berrios, Daniel and Gatti, Alice and Li, Justin D and Dombrowski, Ann-Kathrin and Goel, Shashwat and Phan, Long and others},
  journal={arXiv preprint arXiv:2403.03218},
  year={2024},
url={https://arxiv.org/pdf/2403.03218}
}

@article{hernandez2023inspecting,
  title={Inspecting and editing knowledge representations in language models},
  author={Hernandez, Evan and Li, Belinda Z and Andreas, Jacob},
  journal={arXiv preprint arXiv:2304.00740},
  year={2023},
url={https://arxiv.org/pdf/2304.00740}
}

@Misc{peft,
  title =        {PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods},
  author =       {Sourab Mangrulkar and Sylvain Gugger and Lysandre Debut and Younes Belkada and Sayak Paul and Benjamin Bossan},
  howpublished = {\url{https://github.com/huggingface/peft}},
  year =         {2022}
}
