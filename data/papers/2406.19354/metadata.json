{
  "arxivId": "2406.19354",
  "title": "Fundamental Problems With Model Editing: How Should Rational Belief\n  Revision Work in LLMs?",
  "authors": "Peter Hase, Thomas Hofweber, Xiang Zhou, Elias Stengel-Eskin, Mohit Bansal",
  "abstract": "The model editing problem concerns how language models should learn new facts\nabout the world over time. While empirical research on model editing has drawn\nwidespread attention, the conceptual foundations of model editing remain shaky\n-- perhaps unsurprisingly, since model editing is essentially belief revision,\na storied problem in philosophy that has eluded succinct solutions for decades.\nModel editing nonetheless demands a solution, since we need to be able to\ncontrol the knowledge within language models. With this goal in mind, this\npaper critiques the standard formulation of the model editing problem and\nproposes a formal testbed for model editing research. We first describe 12 open\nproblems with model editing, based on challenges with (1) defining the problem,\n(2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the\nfirst place. Many of these challenges are extremely difficult to address, e.g.\ndetermining far-reaching consequences of edits, labeling probabilistic\nentailments between facts, and updating beliefs of agent simulators. Next, we\nintroduce a semi-synthetic dataset for model editing based on Wikidata, where\nwe can evaluate edits against labels given by an idealized Bayesian agent. This\nenables us to say exactly how belief revision in language models falls short of\na desirable epistemic standard. We encourage further research exploring\nsettings where such a gold standard can be compared against. Our code is\npublicly available at: https://github.com/peterbhase/LLM-belief-revision",
  "url": "https://arxiv.org/abs/2406.19354",
  "issue_number": 129,
  "issue_url": "https://github.com/dmarx/arxiv-archive/issues/129",
  "created_at": "2024-12-24T19:26:48.736089",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 0,
  "last_read": null
}