{
  "arxivId": "2408.06663",
  "title": "Amuro & Char: Analyzing the Relationship between Pre-Training and\n  Fine-Tuning of Large Language Models",
  "authors": "Kaiser Sun, Mark Dredze",
  "abstract": "The development of large language models leads to the formation of a\npre-train-then-align paradigm, in which the model is typically pre-trained on a\nlarge text corpus and undergoes a tuning stage to align the model with human\npreference or downstream tasks. In this work, we investigate the relationship\nbetween pre-training and fine-tuning by fine-tuning multiple intermediate\npre-trained model checkpoints. Our results on 18 datasets suggest that i)\ncontinual pre-training improves the model in a latent way that unveils after\nfine-tuning; ii) with extra fine-tuning, the datasets that the model does not\ndemonstrate capability gain much more than those that the model performs well\nduring the pre-training stage; iii) although model benefits significantly\nthrough supervised fine-tuning, it may forget previously known domain knowledge\nand the tasks that are not seen during fine-tuning; iv) the model resembles\nhigh sensitivity to evaluation prompts after supervised fine-tuning, but this\nsensitivity can be alleviated by more pre-training.",
  "url": "https://arxiv.org/abs/2408.06663",
  "issue_number": 611,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/611",
  "created_at": "2024-12-30T20:01:05.240118",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 9,
  "last_read": "2024-12-30T20:01:05.259876",
  "last_visited": "2024-12-30T19:58:19.782Z",
  "main_tex_file": null,
  "published_date": "2024-08-13T06:28:43Z",
  "arxiv_tags": [
    "cs.CL",
    "cs.AI"
  ]
}