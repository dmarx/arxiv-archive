\begin{table}[t!]
\centering
\small
\begin{tabular}{@{}llll@{}}
\toprule
\multicolumn{4}{c}{\textbf{Supervised Fine-Tuning}} \\ \midrule
\textbf{Task} & \textbf{Training} & \textbf{ID Test} & \textbf{OOD Test} \\ \midrule
\begin{tabular}[c]{@{}l@{}}Summary \\ Generation\end{tabular} & XSum & \begin{tabular}[c]{@{}l@{}}XSum, \\ XLSum\end{tabular} & CNN \\  \arrayrulecolor{black!30}\midrule
\begin{tabular}[c]{@{}l@{}}Question \\ Generation\end{tabular} & SocialIQa & SocialIQA & \begin{tabular}[c]{@{}l@{}}SciQ, \\ TweetQA\end{tabular} \\  \arrayrulecolor{black!30}\midrule
\begin{tabular}[c]{@{}l@{}}Natural Language \\ Inference\end{tabular} & MNLI & \begin{tabular}[c]{@{}l@{}}MNLI1, \\ MNLI2\end{tabular} & \begin{tabular}[c]{@{}l@{}}RTE, \\ GPT3NLI\tablefootnote{\href{https://huggingface.co/datasets/pietrolesci/gpt3_nli}{https://huggingface.co/datasets/pietrolesci/gpt3\_nli}} \end{tabular} \\  \arrayrulecolor{black!30}\midrule
\begin{tabular}[c]{@{}l@{}}Paraphrase \\ Detection\end{tabular} & Paws & Paws & \begin{tabular}[c]{@{}l@{}}QQP, \\ STS-B\end{tabular} \\ \arrayrulecolor{black}\midrule

\multicolumn{4}{c}{\textbf{Instruction Tuning}} \\ \midrule
\textbf{Dataset} & \multicolumn{3}{l}{\textbf{Description}} \\
\midrule
T\"ULU-v2 & \multicolumn{3}{l}{A mixture of instruction datasets.} \\ 


ARC & \multicolumn{3}{l}{Grade-school multiple-choice QA.}   \\
OpenbookQA &  \multicolumn{3}{l}{Open book exam QA.} \\
Hellaswag &  \multicolumn{3}{l}{Commonsense inference.} \\
BoolQ & \multicolumn{3}{l}{Reading comprehension.}  \\
SciQ & \multicolumn{3}{l}{Science exam multiple choice QA.}  \\ \arrayrulecolor{black}\bottomrule

\end{tabular}
\caption{Dataset information. For Generation tasks, ROUGE-L is used as evaluation metric, and accuracy is used for classification tasks.}
\label{tab:tasks}
\end{table}