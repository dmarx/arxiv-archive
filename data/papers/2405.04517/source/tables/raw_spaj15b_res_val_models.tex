\begin{tabular}{llrr}
\toprule
 & run_name_disamb & num_model_params & _Perplexity-train_step-best \\
\midrule
0 & spaj15b-xlstmblock2-350M_slstmv2seed42_fprodv0_0-B48E1024H4gbs256 & 418 & 16.82 \\
1 & spaj15b-rwkv6_lm-350M_rwkv6_fprodv0_0-B24E1024H0gbs256 & 442 & 17.40 \\
2 & spaj15b-xlstmblock2U-350M_slstmv2u_fprodv0_3-B48E1024H4gbs256 & 406 & 18.86 \\
3 & spaj15b-h3_lm-350M_h3_fprodv0_0-B48E1024H0gbs256 & 420 & 18.23 \\
4 & spaj15b-transformer_lm-350M_retention_fprodv0_1-B48E1024H0gbs256 & 758 & 14.59 \\
5 & spaj15b-rwkv5_lm-350M_rwkv5wd_fprodv2_1-B24E1024H0gbs256 & 456 & 16.58 \\
6 & spaj15b-rwkv5_lm-350M_rwkv5_fprodv0_0-B48E1024H0gbs256 & 808 & 15.75 \\
7 & spaj15b-vlstm-350M_vlstmv1_fprodv0_0-B24E1024H4gbs256 & 430 & 13.89 \\
8 & spaj15b-lstm-350M_lstmseqmix_fprodv0_0-B24E1024H0gbs256 & 506 & 26.07 \\
9 & spaj15b-rwkv5_lm-350M_rwkv5wd_fprodv0_0-B48E1024H0gbs256 & 808 & 15.71 \\
10 & spaj15b-xlstmblock2-350M_slstmv2_fprodv0_2-B48E1024H4gbs256 & 418 & 16.99 \\
11 & spaj15b-lstm_lm-350Mwi_lstmmultilayer_fprodv0_0-B24E1536H0gbs256 & 608 & 2417.88 \\
12 & spaj15b-rwkv5_lm-350M_rwkv5_fprodv1_0-B24E1024H0gbs256 & 456 & 16.53 \\
13 & spaj15b-transformer_lm-350M_retention_fprodv1_0-B24E1024H0gbs256 & 431 & 16.23 \\
14 & spaj15b-transformer_lm-350Mde_lstmmultilayerblock_fprodv0_0-B48E1024H0gbs256 & 506 & 35.45 \\
15 & spaj15b-transformer_lm-350Mwi_lstmmultilayerblock_fprodv0_0-B24E1536H0gbs256 & 608 & 30.28 \\
16 & spaj15b-xlstmblock2P-350M_slstmv1_fprodv0_2-B48E1024H4gbs256 & 402 & 18.08 \\
17 & spaj15b-xlstmblock2P-350M_slstmv1_fprodv0_3-B48E1024H4gbs256 & 402 & 18.18 \\
18 & spaj15b-xlstmblock2-125M_vlstmv2_fprodv0_0-B24E768H4gbs256 & 164 & 16.12 \\
19 & spaj15b-xlstmblock2-350M_vlstmv2_fprodv0_0-B48E1024H4gbs256 & 409 & 13.43 \\
20 & spaj15b-xlstmblock2P-350M_slstmv2p_fprodv0_4-B48E1024H4gbs256 & 405 & 22.08 \\
21 & spaj15b-xlstmblock2P-350M_slstmv1noconvact_fprodv0_0-B24E1024H4gbs256 & 427 & 17.14 \\
22 & spaj15b-xlstmblock2P-350M_slstmv1noconvact_fprodv0_0-B48E1024H4gbs256 & 402 & 17.70 \\
23 & spaj15b-customselfattention-350M_llama_fprodv0_1-B24E1024H16gbs256 & 407 & 14.25 \\
24 & spaj15b-xlstmblock2-350M_xlstmv2_fprodv0_0-B48E1024H4gbs256 & 408 & 13.48 \\
25 & spaj15b-mamba-350M_mamba_fprodv1_0-B48E1024H0gbs256 & 423 & 14.06 \\
26 & spaj15b-hyena_lm-350M_hyena_fprodv0_0-B48E1024H0gbs256 & 435 & 17.59 \\
27 & spaj15b-rwkv4_lm-350M_rwkv4_fprodv1_0-B24E1024H0gbs256 & 430 & 15.62 \\
28 & spaj15b-customselfattention-350M_gpt_fprodv0_0-B24E1024H16gbs256_lr0.0003 & 356 & 16.08 \\
29 & spaj15b-mamba-350M_mamba_fprodv0_0-B48E1024H0gbs256_tie_weightsFalse & 423 & 13.70 \\
30 & spaj15b-mamba-350M_mamba_fprodv0_0-B48E1024H0gbs256_tie_weightsTrue & 372 & 13.71 \\
31 & spaj15b-xlstmblock2P-350M_slstmv1_fprodv0_0-B24E1024H4gbs256_kernel_size0.0 & 427 & 17.49 \\
32 & spaj15b-xlstmblock2P-350M_slstmv1_fprodv0_0-B24E1024H4gbs256_kernel_size4.0 & 427 & 17.68 \\
33 & spaj15b-customselfattention-350M_gpt_fprodv0_0-B24E1024H16gbs256_precision_pos_emb_adddefault & 356 & 14.26 \\
34 & spaj15b-customselfattention-350M_gpt_fprodv0_0-B24E1024H16gbs256_precision_pos_emb_addfloat32 & 356 & 14.29 \\
35 & GLA & 412& 19.56
36 & HGRN2 & 411& 16.77
37 & HGRN & 411 & 21.83
\bottomrule
\caption{xLSTM Benchmark Models Val PPL}
\end{tabular}
