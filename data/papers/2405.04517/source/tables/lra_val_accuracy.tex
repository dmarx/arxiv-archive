\begin{table}
    \centering
    \begin{adjustbox}{width=1.0\textwidth}
    \begin{tabular}{lcccccc}
    \toprule
    & \textbf{Retrieval} & \textbf{ListOps} & \textbf{Pathfinder} & \textbf{G-Image} & \textbf{RGB-Image} & \textbf{Ranking} \\ \midrule
Random Baseline & 0.500 & 0.100 & 0.500 & 0.100 & 0.100 &  \\ \midrule
Transformer & 0.834 & 0.415 & 0.848 & 0.537 & 0.655 & 6 \\ 
Llama & 0.859 & 0.583 & 0.833 & 0.551 & 0.647 & 5\\ \midrule
Mamba & 0.911 & \underline{0.599} & \textbf{0.970} & 0.740 & \textbf{0.828} & 2 \\ \midrule
LSTM & X & 0.377 & X & 0.721 & 0.754 & 6 \\ 
RWKV-4 & \underline{0.912} & 0.595 & 0.885 & 0.726 & 0.804 & 3\\ 
LSTM-SM & 0.887 & 0.546 & X & \underline{0.741} & 0.804 & 4 \\ \midrule
xLSTM & \textbf{0.915} & \textbf{0.623} & \underline{0.912} & \textbf{0.751} & \underline{0.816} & 1 \\ 
\bottomrule
    \end{tabular}
    \end{adjustbox}
    \caption{Long Range Arena validation tasks. Bold highlights the best performing model, underlined the second best. X denotes models that fail to outperform random baselines.
    \GK{
    %removed the vertical lines to fit style of other tables; 
    smaller other formatting changes}
    }
    \label{tab:lra_val_accuracy}
    
\end{table}