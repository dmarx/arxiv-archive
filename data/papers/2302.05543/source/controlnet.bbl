\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{arfin2020weight}
Sadia Afrin.
\newblock Weight initialization in neural network, inspired by andrew ng,
  https://medium.com/@safrin1128/weight-initialization-in-neural-network-inspired-by-andrew-ng-e0066dc4a566,
  2020.

\bibitem{aghajanyan2021intrinsic}
Armen Aghajanyan, Sonal Gupta, and Luke Zettlemoyer.
\newblock Intrinsic dimensionality explains the effectiveness of language model
  fine-tuning.
\newblock In {\em Proceedings of the 59th Annual Meeting of the Association for
  Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing}, pages 7319--7328, Online, Aug. 2021.
  Association for Computational Linguistics.

\bibitem{alaluf2021matter}
Yuval Alaluf, Or Patashnik, and Daniel Cohen-Or.
\newblock Only a matter of style: Age transformation using a style-based
  regression model.
\newblock {\em ACM Transactions on Graphics (TOG)}, 40(4), 2021.

\bibitem{alaluf2022hyperstyle}
Yuval Alaluf, Omer Tov, Ron Mokady, Rinon Gal, and Amit Bermano.
\newblock Hyperstyle: Stylegan inversion with hypernetworks for real image
  editing.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 18511--18521, 2022.

\bibitem{disco}
Alembics.
\newblock Disco diffusion, https://github.com/alembics/disco-diffusion, 2022.

\bibitem{avrahami2022spatext}
Omri Avrahami, Thomas Hayes, Oran Gafni, Sonal Gupta, Yaniv Taigman, Devi
  Parikh, Dani Lischinski, Ohad Fried, and Xi Yin.
\newblock Spatext: Spatio-textual representation for controllable image
  generation.
\newblock {\em arXiv preprint arXiv:2211.14305}, 2022.

\bibitem{avrahami2022blended}
Omri Avrahami, Dani Lischinski, and Ohad Fried.
\newblock Blended diffusion for text-driven editing of natural images.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 18208--18218, 2022.

\bibitem{bar2023multidiffusion}
Omer Bar-Tal, Lior Yariv, Yaron Lipman, and Tali Dekel.
\newblock Multidiffusion: Fusing diffusion paths for controlled image
  generation.
\newblock {\em arXiv preprint arXiv:2302.08113}, 2023.

\bibitem{bashkirova2023masksketch}
Dina Bashkirova, Jose Lezama, Kihyuk Sohn, Kate Saenko, and Irfan Essa.
\newblock Masksketch: Unpaired structure-guided masked image generation.
\newblock {\em arXiv preprint arXiv:2302.05496}, 2023.

\bibitem{brooks2022instructpix2pix}
Tim Brooks, Aleksander Holynski, and Alexei~A Efros.
\newblock Instructpix2pix: Learning to follow image editing instructions.
\newblock {\em arXiv preprint arXiv:2211.09800}, 2022.

\bibitem{canny1986computational}
John Canny.
\newblock A computational approach to edge detection.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  (6):679--698, 1986.

\bibitem{cao2019openpose}
Z. {Cao}, G. {Hidalgo Martinez}, T. {Simon}, S. {Wei}, and Y.~A. {Sheikh}.
\newblock Openpose: Realtime multi-person 2d pose estimation using part
  affinity fields.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  2019.

\bibitem{chen2021pre}
Hanting Chen, Yunhe Wang, Tianyu Guo, Chang Xu, Yiping Deng, Zhenhua Liu, Siwei
  Ma, Chunjing Xu, Chao Xu, and Wen Gao.
\newblock Pre-trained image processing transformer.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12299--12310, 2021.

\bibitem{chen2022vision}
Zhe Chen, Yuchen Duan, Wenhai Wang, Junjun He, Tong Lu, Jifeng Dai, and Yu
  Qiao.
\newblock Vision transformer adapter for dense predictions.
\newblock {\em International Conference on Learning Representations}, 2023.

\bibitem{choi2018stargan}
Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul
  Choo.
\newblock Stargan: Unified generative adversarial networks for multi-domain
  image-to-image translation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8789--8797, 2018.

\bibitem{protogen}
darkstorm2150.
\newblock Protogen x3.4 (photorealism) official release,
  https://civitai.com/models/3666/protogen-x34-photorealism-official-release,
  2022.

\bibitem{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock {\em Advances in Neural Information Processing Systems},
  34:8780--8794, 2021.

\bibitem{dinh2022hyperinverter}
Tan~M. Dinh, Anh~Tuan Tran, Rang Nguyen, and Binh-Son Hua.
\newblock Hyperinverter: Improving stylegan inversion via hypernetwork.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11389--11398, 2022.

\bibitem{esser2021taming}
Patrick Esser, Robin Rombach, and Bjorn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12873--12883, 2021.

\bibitem{gafni2022make}
Oran Gafni, Adam Polyak, Oron Ashual, Shelly Sheynin, Devi Parikh, and Yaniv
  Taigman.
\newblock Make-a-scene: Scene-based text-to-image generation with human priors.
\newblock In {\em European Conference on Computer Vision (ECCV)}, pages
  89--106. Springer, 2022.

\bibitem{gal2022image}
Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit~H Bermano, Gal
  Chechik, and Daniel Cohen-Or.
\newblock An image is worth one word: Personalizing text-to-image generation
  using textual inversion.
\newblock {\em arXiv preprint arXiv:2208.01618}, 2022.

\bibitem{gal2022stylegan}
Rinon Gal, Or Patashnik, Haggai Maron, Amit~H Bermano, Gal Chechik, and Daniel
  Cohen-Or.
\newblock Stylegan-nada: Clip-guided domain adaptation of image generators.
\newblock {\em ACM Transactions on Graphics (TOG)}, 41(4):1--13, 2022.

\bibitem{gao2021clip}
Peng Gao, Shijie Geng, Renrui Zhang, Teli Ma, Rongyao Fang, Yongfeng Zhang,
  Hongsheng Li, and Yu Qiao.
\newblock Clip-adapter: Better vision-language models with feature adapters.
\newblock {\em arXiv preprint arXiv:2110.04544}, 2021.

\bibitem{gu2021realtime}
Geonmo Gu, Byungsoo Ko, SeoungHyun Go, Sung-Hyun Lee, Jingeun Lee, and Minchul
  Shin.
\newblock Towards light-weight and real-time line segment detection.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2022.

\bibitem{ha2017hypernetworks}
David Ha, Andrew~M. Dai, and Quoc~V. Le.
\newblock Hypernetworks.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem{heathen}
Heathen.
\newblock Hypernetwork style training, a tiny guide, stable-diffusion-webui,
  https://github.com/automatic1111/stable-diffusion-webui/discussions/2670,
  2022.

\bibitem{hertz2022prompt}
Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel
  Cohen-Or.
\newblock Prompt-to-prompt image editing with cross attention control.
\newblock {\em arXiv preprint arXiv:2208.01626}, 2022.

\bibitem{NIPS2017_8a1d6947}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock In I. Guyon, U.~Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S.
  Vishwanathan, and R. Garnett, editors, {\em Advances in Neural Information
  Processing Systems}, volume~30. Curran Associates, Inc., 2017.

\bibitem{cfg}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance, 2022.

\bibitem{houlsby2019parameter}
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin
  De~Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly.
\newblock Parameter-efficient transfer learning for nlp.
\newblock In {\em International Conference on Machine Learning}, pages
  2790--2799, 2019.

\bibitem{hu2021lora}
Edward~J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
  Wang, Lu Wang, and Weizhu Chen.
\newblock Lora: Low-rank adaptation of large language models.
\newblock {\em arXiv preprint arXiv:2106.09685}, 2021.

\bibitem{lhhuang2023composer}
Lianghua Huang, Di Chen, Yu Liu, Shen Yujun, Deli Zhao, and Zhou Jingren.
\newblock Composer: Creative and controllable image synthesis with composable
  conditions.
\newblock 2023.

\bibitem{huang2023region}
Nisha Huang, Fan Tang, Weiming Dong, Tong-Yee Lee, and Changsheng Xu.
\newblock Region-aware diffusion for zero-shot text-driven image editing.
\newblock {\em arXiv preprint arXiv:2302.11797}, 2023.

\bibitem{isola2017image}
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei~A Efros.
\newblock Image-to-image translation with conditional adversarial networks.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 1125--1134, 2017.

\bibitem{jain2022oneformer}
Jitesh Jain, Jiachen Li, MangTik Chiu, Ali Hassani, Nikita Orlov, and Humphrey
  Shi.
\newblock {OneFormer: One Transformer to Rule Universal Image Segmentation}.
\newblock 2023.

\bibitem{karras2017progressive}
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
\newblock Progressive growing of gans for improved quality, stability, and
  variation.
\newblock {\em International Conference on Learning Representations}, 2018.

\bibitem{karras2019style}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 4401--4410, 2019.

\bibitem{karras2021style}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock {\em IEEE Transactions on Pattern Analysis}, 2021.

\bibitem{katzir2022multi}
Oren Katzir, Vicky Perepelook, Dani Lischinski, and Daniel Cohen-Or.
\newblock Multi-level latent space structuring for generative control.
\newblock {\em arXiv preprint arXiv:2202.05910}, 2022.

\bibitem{kawar2022imagic}
Bahjat Kawar, Shiran Zada, Oran Lang, Omer Tov, Huiwen Chang, Tali Dekel, Inbar
  Mosseri, and Michal Irani.
\newblock Imagic: Text-based real image editing with diffusion models.
\newblock {\em arXiv preprint arXiv:2210.09276}, 2022.

\bibitem{kim2022diffusionclip}
Gwanghyun Kim, Taesung Kwon, and Jong~Chul Ye.
\newblock Diffusionclip: Text-guided diffusion models for robust image
  manipulation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 2426--2435, 2022.

\bibitem{kingma2021variational}
Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho.
\newblock Variational diffusion models.
\newblock {\em Advances in Neural Information Processing Systems},
  34:21696--21707, 2021.

\bibitem{nai}
Kurumuz.
\newblock Novelai improvements on stable diffusion,
  https://blog.novelai.net/novelai-improvements-on-stable-diffusion-e10d38db82ac,
  2022.

\bibitem{LeCun2015}
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.
\newblock Deep learning.
\newblock {\em Nature}, 521(7553):436--444, May 2015.

\bibitem{lecun1998gradient}
Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11):2278--2324, 1998.

\bibitem{lehtinen2018noise2noise}
Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras,
  Miika Aittala, and Timo Aila.
\newblock Noise2noise: Learning image restoration without clean data.
\newblock {\em Proceedings of the 35th International Conference on Machine
  Learning}, 2018.

\bibitem{li2018measuring}
Chunyuan Li, Heerad Farkhoor, Rosanne Liu, and Jason Yosinski.
\newblock Measuring the intrinsic dimension of objective landscapes.
\newblock {\em International Conference on Learning Representations}, 2018.

\bibitem{li2023gligen}
Yuheng Li, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao,
  Chunyuan Li, and Yong~Jae Lee.
\newblock Gligen: Open-set grounded text-to-image generation.
\newblock 2023.

\bibitem{li2022exploring}
Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He.
\newblock Exploring plain vision transformer backbones for object detection.
\newblock {\em arXiv preprint arXiv:2203.16527}, 2022.

\bibitem{li2021benchmarking}
Yanghao Li, Saining Xie, Xinlei Chen, Piotr Dollar, Kaiming He, and Ross
  Girshick.
\newblock Benchmarking detection transfer learning with vision transformers.
\newblock {\em arXiv preprint arXiv:2111.11429}, 2021.

\bibitem{mallya2018piggyback}
Arun Mallya, Dillon Davis, and Svetlana Lazebnik.
\newblock Piggyback: Adapting a single network to multiple tasks by learning to
  mask weights.
\newblock In {\em European Conference on Computer Vision (ECCV)}, pages 67--82,
  2018.

\bibitem{mallya2018packnet}
Arun Mallya and Svetlana Lazebnik.
\newblock Packnet: Adding multiple tasks to a single network by iterative
  pruning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7765--7773, 2018.

\bibitem{meng2021sdedit}
Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and
  Stefano Ermon.
\newblock Sdedit: Guided image synthesis and editing with stochastic
  differential equations.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{midjourney}
Midjourney.
\newblock https://www.midjourney.com/, 2023.

\bibitem{mokady2022selfdistilled}
Ron Mokady, Omer Tov, Michal Yarom, Oran Lang, Inbar Mosseri, Tali Dekel,
  Daniel Cohen-Or, and Michal Irani.
\newblock Self-distilled stylegan: Towards generation from internet photos.
\newblock In {\em ACM SIGGRAPH 2022 Conference Proceedings}, pages 1--9, 2022.

\bibitem{mou2023t2i}
Chong Mou, Xintao Wang, Liangbin Xie, Jian Zhang, Zhongang Qi, Ying Shan, and
  Xiaohu Qie.
\newblock T2i-adapter: Learning adapters to dig out more controllable ability
  for text-to-image diffusion models.
\newblock {\em arXiv preprint arXiv:2302.08453}, 2023.

\bibitem{glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin,
  Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock {GLIDE:} towards photorealistic image generation and editing with
  text-guided diffusion models.
\newblock {\em CoRR}, 2021.

\bibitem{nichol2021glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin,
  Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock Glide: Towards photorealistic image generation and editing with
  text-guided diffusion models.
\newblock 2022.

\bibitem{nichol2021improved}
Alexander~Quinn Nichol and Prafulla Dhariwal.
\newblock Improved denoising diffusion probabilistic models.
\newblock In {\em International Conference on Machine Learning}, pages
  8162--8171. PMLR, 2021.

\bibitem{nitzan2022mystyle}
Yotam Nitzan, Kfir Aberman, Qiurui He, Orly Liba, Michal Yarom, Yossi
  Gandelsman, Inbar Mosseri, Yael Pritch, and Daniel Cohen-Or.
\newblock Mystyle: A personalized generative prior.
\newblock {\em arXiv preprint arXiv:2203.17272}, 2022.

\bibitem{comicdiff}
ogkalu.
\newblock Comic-diffusion v2, trained on 6 styles at once,
  https://huggingface.co/ogkalu/comic-diffusion, 2022.

\bibitem{DALLE2}
OpenAI.
\newblock Dall-e-2, https://openai.com/product/dall-e-2, 2023.

\bibitem{park2019semantic}
Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu.
\newblock Semantic image synthesis with spatially-adaptive normalization.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 2337--2346, 2019.

\bibitem{parmar2023zero}
Gaurav Parmar, Krishna~Kumar Singh, Richard Zhang, Yijun Li, Jingwan Lu, and
  Jun-Yan Zhu.
\newblock Zero-shot image-to-image translation.
\newblock {\em arXiv preprint arXiv:2302.03027}, 2023.

\bibitem{Patashnik_2021_ICCV}
Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, and Dani Lischinski.
\newblock Styleclip: Text-driven manipulation of stylegan imagery.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 2085--2094, October 2021.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock {\em arXiv preprint arXiv:2204.06125}, 2022.

\bibitem{ramesh2021zero}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
  Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In {\em International Conference on Machine Learning}, pages
  8821--8831. PMLR, 2021.

\bibitem{ranftl2020towards}
Ren{\'e} Ranftl, Katrin Lasinger, David Hafner, Konrad Schindler, and Vladlen
  Koltun.
\newblock Towards robust monocular depth estimation: Mixing datasets for
  zero-shot cross-dataset transfer.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  44(3):1623--1637, 2020.

\bibitem{rebuffi2018efficient}
Sylvestre-Alvise Rebuffi, Hakan Bilen, and Andrea Vedaldi.
\newblock Efficient parametrization of multi-domain deep neural networks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8119--8127, 2018.

\bibitem{richardson2021encoding}
Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav
  Shapiro, and Daniel Cohen-Or.
\newblock Encoding in style: a stylegan encoder for image-to-image translation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2021.

\bibitem{rombach2021highresolution}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10684--10695, 2022.

\bibitem{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In {\em Medical Image Computing and Computer-Assisted Intervention
  MICCAI International Conference}, pages 234--241, 2015.

\bibitem{rosenfeld2018incremental}
Amir Rosenfeld and John~K Tsotsos.
\newblock Incremental learning through deep adaptation.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  42(3):651--663, 2018.

\bibitem{ruiz2022dreambooth}
Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and
  Kfir Aberman.
\newblock Dreambooth: Fine tuning text-to-image diffusion models for
  subject-driven generation.
\newblock {\em arXiv preprint arXiv:2208.12242}, 2022.

\bibitem{Rumelhart1986}
David~E. Rumelhart, Geoffrey~E. Hinton, and Ronald~J. Williams.
\newblock Learning representations by back-propagating errors.
\newblock {\em Nature}, 323(6088):533--536, Oct. 1986.

\bibitem{saharia2022palette}
Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim
  Salimans, David Fleet, and Mohammad Norouzi.
\newblock Palette: Image-to-image diffusion models.
\newblock In {\em ACM SIGGRAPH 2022 Conference Proceedings}, SIGGRAPH '22, New
  York, NY, USA, 2022. Association for Computing Machinery.

\bibitem{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily
  Denton, Seyed Kamyar~Seyed Ghasemipour, Burcu~Karagol Ayan, S~Sara Mahdavi,
  Rapha~Gontijo Lopes, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock {\em arXiv preprint arXiv:2205.11487}, 2022.

\bibitem{schuhmann2022laionb}
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade~W Gordon, Ross
  Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell
  Wortsman, Patrick Schramowski, Srivatsa~R Kundurthy, Katherine Crowson,
  Ludwig Schmidt, Robert Kaczmarczyk, and Jenia Jitsev.
\newblock {LAION}-5b: An open large-scale dataset for training next generation
  image-text models.
\newblock In {\em Thirty-sixth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track}, 2022.

\bibitem{serra2018overcoming}
Joan Serra, Didac Suris, Marius Miron, and Alexandros Karatzoglou.
\newblock Overcoming catastrophic forgetting with hard attention to the task.
\newblock In {\em International Conference on Machine Learning}, pages
  4548--4557. PMLR, 2018.

\bibitem{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In {\em International Conference on Machine Learning}, pages
  2256--2265. PMLR, 2015.

\bibitem{sd15}
Stability.
\newblock Stable diffusion v1.5 model card,
  https://huggingface.co/runwayml/stable-diffusion-v1-5, 2022.

\bibitem{sdd}
Stability.
\newblock Stable diffusion v2 model card, stable-diffusion-2-depth,
  https://huggingface.co/stabilityai/stable-diffusion-2-depth, 2022.

\bibitem{stickland2019bert}
Asa~Cooper Stickland and Iain Murray.
\newblock Bert and pals: Projected attention layers for efficient adaptation in
  multi-task learning.
\newblock In {\em International Conference on Machine Learning}, pages
  5986--5995, 2019.

\bibitem{sung2021vl}
Yi-Lin Sung, Jaemin Cho, and Mohit Bansal.
\newblock Vl-adapter: Parameter-efficient transfer learning for
  vision-and-language tasks.
\newblock {\em arXiv preprint arXiv:2112.06825}, 2021.

\bibitem{pnpDiffusion2022}
Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel.
\newblock Plug-and-play diffusion features for text-driven image-to-image
  translation.
\newblock {\em arXiv preprint arXiv:2211.12572}, 2022.

\bibitem{diode_dataset}
Igor Vasiljevic, Nick Kolkin, Shanyi Zhang, Ruotian Luo, Haochen Wang, Falcon~Z
  Dai, Andrea~F Daniele, Mohammadreza Mostajabi, Steven Basart, Matthew~R
  Walter, et~al.
\newblock Diode: A dense indoor and outdoor depth dataset.
\newblock {\em arXiv preprint arXiv:1908.00463}, 2019.

\bibitem{voynov2022sketch}
Andrey Voynov, Kfir Abernan, and Daniel Cohen-Or.
\newblock Sketch-guided text-to-image diffusion models.
\newblock 2022.

\bibitem{wang2022pretraining}
Tengfei Wang, Ting Zhang, Bo Zhang, Hao Ouyang, Dong Chen, Qifeng Chen, and
  Fang Wen.
\newblock Pretraining is all you need for image-to-image translation.
\newblock 2022.

\bibitem{wang2018high}
Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan
  Catanzaro.
\newblock High-resolution image synthesis and semantic manipulation with
  conditional gans.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8798--8807, 2018.

\bibitem{xie2015holistically}
Saining Xie and Zhuowen Tu.
\newblock Holistically-nested edge detection.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision (ICCV)}, pages 1395--1403, 2015.

\bibitem{zhang2020side}
Jeffrey~O. Zhang, Alexander Sax, Amir Zamir, Leonidas~J. Guibas, and Jitendra
  Malik.
\newblock Side-tuning: Network adaptation via additive side networks.
\newblock In {\em European Conference on Computer Vision (ECCV)}, pages
  698--714. Springer, 2020.

\bibitem{zhang2020cross}
Pan Zhang, Bo Zhang, Dong Chen, Lu Yuan, and Fang Wen.
\newblock Cross-domain correspondence learning for exemplar-based image
  translation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 5143--5153, 2020.

\bibitem{zhang2021tip}
Renrui Zhang, Rongyao Fang, Peng Gao, Wei Zhang, Kunchang Li, Jifeng Dai, Yu
  Qiao, and Hongsheng Li.
\newblock Tip-adapter: Training-free clip-adapter for better vision-language
  modeling.
\newblock {\em arXiv preprint arXiv:2111.03930}, 2021.

\bibitem{zhao2021zero}
Jiawei Zhao, Florian Sch{\"a}fer, and Anima Anandkumar.
\newblock Zero initialization: Initializing residual networks with only zeros
  and ones.
\newblock {\em arXiv}, 2021.

\bibitem{zhou2017scene}
Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio
  Torralba.
\newblock Scene parsing through ade20k dataset.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 633--641, 2017.

\bibitem{zhou2021cocosnet}
Xingran Zhou, Bo Zhang, Ting Zhang, Pan Zhang, Jianmin Bao, Dong Chen, Zhongfei
  Zhang, and Fang Wen.
\newblock Cocosnet v2: Full-resolution correspondence learning for image
  translation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11465--11475, 2021.

\bibitem{CycleGAN2017}
Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei~A Efros.
\newblock Unpaired image-to-image translation using cycle-consistent
  adversarial networks.
\newblock In {\em Computer Vision (ICCV), 2017 IEEE International Conference
  on}, 2017.

\bibitem{zhu2017toward}
Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei~A Efros,
  Oliver Wang, and Eli Shechtman.
\newblock Toward multimodal image-to-image translation.
\newblock {\em Advances in Neural Information Processing Systems}, 30, 2017.

\end{thebibliography}
