{
  "arxivId": "2302.05543",
  "title": "Adding Conditional Control to Text-to-Image Diffusion Models",
  "authors": "Lvmin Zhang, Anyi Rao, Maneesh Agrawala",
  "abstract": "We present ControlNet, a neural network architecture to add spatial\nconditioning controls to large, pretrained text-to-image diffusion models.\nControlNet locks the production-ready large diffusion models, and reuses their\ndeep and robust encoding layers pretrained with billions of images as a strong\nbackbone to learn a diverse set of conditional controls. The neural\narchitecture is connected with \"zero convolutions\" (zero-initialized\nconvolution layers) that progressively grow the parameters from zero and ensure\nthat no harmful noise could affect the finetuning. We test various conditioning\ncontrols, eg, edges, depth, segmentation, human pose, etc, with Stable\nDiffusion, using single or multiple conditions, with or without prompts. We\nshow that the training of ControlNets is robust with small (<50k) and large\n(>1m) datasets. Extensive results show that ControlNet may facilitate wider\napplications to control image diffusion models.",
  "url": "http://arxiv.org/abs/2302.05543v3",
  "issue_number": 205,
  "issue_url": "https://github.com/dmarx/arxiv-archive/issues/205",
  "created_at": "2024-12-24T02:44:41.401461",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 23,
  "last_read": "2024-12-24T03:19:07.557119"
}