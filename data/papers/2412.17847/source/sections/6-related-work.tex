\section{Extended Related Work}
\label{app:related-work}
Progress in machine learning across modalities from speech \citep{radford2023robust} to vision \citep{dosovitskiy2021image} to text \citep{browngpt3, weifinetuned} has benefited from advancements in large pre-training and fine-tuning corpora. The development of multimodal corpora has also been key to several recent advances, as with CLIP in the image/text domain \cite{clip_radford2021learning}, CLAP for audio/text settings \cite{elizalde2022clap}, and a number of other models involving both text and images, audio or video \citep{radford2023robust, ramirez2024anatomy, singerMakeVideoTextVideoGeneration2022, rameshHierarchicalTextConditionalImage2022}.
% zhang2024conformer, sahariaPhotorealisticTextImageDiffusion2022

The datasets powering these advances are not, however, always well-documented, despite the existence of standards and frameworks for recording and annotating dataset metadata that range from `data statements' \citep{bender-friedman-2018-data} to `datasheets for datasets' \citep{gebru2021datasheets} and others \citep{mitchell2019model}. The key problem is not a deficiency of any particular framework, but rather inconsistent adoption and fragmentation \citep{Longpre2024Data}. Much prior work has argued for the need to document and audit these datasets \citep{rogers-2021-changing, paullada2021data}, motivated by concerns from reproducibility \citep{kapoor2022leakage} to interpretability \citep{longpre2023pretrainers} to bias and fairness problems that may stem from problematic content in training data \citep{birhane2021multimodal}. 

There have been several attempts to carry out such audits, with prior work examining pretraining data \citep{longpre2024consent}, general web corpora \citep{gao2020pile, dodge2021documenting}, instruction fine-tuning datasets \citep{longpre2023data}, and the documentation fields of the HuggingFace Datasets platform in particular \citep{yang2024navigatingdatasetdocumentationsai}. For speech and vision, there has been less work, with many discussions of datasets in the aggregate occurring in survey papers \citep{SchiappaSSLV2023, chaquetVideoDatasetSurvey2013}, research aimed directly at improving model performance \cite{GadreDataComp2023} or close examinations of questions like bias in small groups of datasets \citep{buolamwiniGenderShades2018,romanou2024includeevaluatingmultilinguallanguage}. 

Prior work has also examined the identities, affiliations and national origin of paper authors \citep{movva2024topics} in AI, but an analogous look at the producers of datasets is lacking. We aim to carry out such analyses: replicating those for pretraining and text finetuning datasets in video and audio domains, and surveying provenance and legal status. Finally, there has also been significant recent attention to legal questions in the collection and use of AI training data \citep{Sag2020TheNL, henderson2023foundation}. The complex process involved in preparing these datasets \citep{lee2023talkin}, and the ambiguous licensing of inputs, can make understanding the legal status of the final output quite difficult.