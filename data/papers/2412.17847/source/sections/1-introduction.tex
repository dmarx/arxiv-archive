\section{Introduction}
\label{sec:introduction}

% INTRODUCTION STRUCTURE:
% AI relies on data.
% Data is poorly documented and understood, especially for multimodal. We investigate 3 facets: source evoluation, use restrictions, and geographical/linguistic representation.
% Why do sources matter? 
% Why do use restrictions matter?
% Why does data representation matter?
% What we did (audit-wise)
% Our key contributions enumerated in bullets.

The capabilities and flaws of multimodal foundation models are often directly attributable to their training data \citep{carlini2023quantifying,rando2022redteamingstablediffusionsafety,carlini2023, parmar2024datadataeverywhereguide, liu2023llava, liu2023improvedllava, nvlm2024}. 
While the importance of \emph{data measurement} has been widely established by prior work  \citep{gadre2024datacomp}, so has a prevailing absence of data documentation \citep{gebru2021datasheets, bender-friedman-2018-data}, transparency \citep{bommasani2023foundation}, and detailed understanding \citep{dodge2021documenting, bandy2021addressing, sambasivan2021everyone}---especially for modalities other than text.
A lack of thorough data analysis has led to significant challenges, including privacy issues \citep{Subramani2023-gj}, retracting datasets with harmful content \citep{birhane2021multimodal,David2023AIDatasetCSAM}, adversarially bypassing safety filters \citep{rando2022redteamingstablediffusionsafety}, facial recognition bias with respect to gender and skin type \citep{Buolamwini2018}, gender bias in hiring \citep{AWSGenderBias}, benchmark contamination from overlapping train and test sets~\citep{platypus2023}, and challenges in copyright \citep{henderson2023foundation}. 
Understanding data provenance can aid mitigation attempts to reduce model bias and toxicity \citep{welbl2021challenges,pozzobon2023} address representation in data \citep{xu2021detoxifying}, contamination \citep{elazars}, and quality \citep{kreutzer2022quality,marion2023moreinvestigatingdatapruning}, as well as practical challenges with identifying copyright-free and permissively licensed sets \citep{min2023SILOLM}.

Despite the urgent need for the provenance and characteristics of widely used datasets, the majority of attention to date has centered on text datasets \citep{elazars, longpre2023data}, or a single feature such as prevalence of hate content  \citep{dodge2021documenting,birhane2021multimodal}. In contrast, in this work, we will critically examine several provenance features of data \emph{across} text, speech, and video. We conduct the largest and most comprehensive multimodal audit of AI data, to date, reviewing nearly 4000 datasets between 1990-2024, covering 443 unique tasks, 608 languages, derived from 798 original sources, and constructed by 659 organizations, spanning 67 countries, over 1T tokens of text, and 1.9M hours of speech and video content (see \Cref{tab:audit-stats}).

There is an unprecedented acceleration in the development of multimodal AI systems, making all the more urgent an understanding of the datasets that underpin these breakthroughs. Our extensive collection of features from unstructured academic papers, websites, and repositories enables us to provide empirical grounding to an ambitious set of research questions surrounding data sourcing trends, intended licenses, and geographical and linguistic representation.
Our key findings include:
\begin{enumerate}[noitemsep]
    \item \textbf{Multimodal data is increasingly sourced from the web, social media platforms, or synthetically generated;} rather than more curated sources such as movies, audiobooks or manually collected. These sources comprise the vast majority of text tokens, as well as speech and video hours in public data. 
    However, while social media platforms provide data scale, heterogeneity and freshness by nature, they are also particularly prone to anti-crawling, copyright, privacy, and factuality concerns.
    
    \item \textbf{Whereas only 25\% of text, speech, and video datasets have non-commercial licenses, over 80\% of content from each modality carries undocumented restrictions in the dataset's sources.} Dataset licenses are inconsistent with their source's restrictions for over 55\% of content. 
    Our audit provides the tools for multimodal developers to identify dataset restrictions, and apply their own standards.
    \item \textbf{Geographical and linguistic representation have not improved for a decade, across the data ecosystem.} 
    While the amount of data from under-represented creators and languages increases each year, to over 600 languages and 60 countries in 2024, their \emph{relative representation} remains consistently western-centric, with no significant improvements from $>0.7$ Gini coefficients.
    While Africa and South America organizations account for $<0.2\%$ of all modality content, North America or European organizations span 93\% of text tokens and 60\%+ hours of speech and video. 
    
\end{enumerate}
Our work provides critical insights into the landscape of available multimodal data. We release the entire audit, collected data, and analysis tools, which we believe will bring immense value for data creators, developers, and researchers interested in promoting the responsible development of AI systems and analysis of the AI data ecosystem.