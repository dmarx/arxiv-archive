\section{Datasets}
\label{app:datasets}
This section provides a detailed overview of the datasets we have collected and analyzed. \autoref{tab:collections-text} summarizes the text datasets, \autoref{tab:collections-speech} the audio datasets, and \autoref{tab:collections-video} the video datasets. Each of these tables lists broad collections of data, sorted in chronological order, and provides information about their properties, sizes, sources and permissions. Each collection can include multiple datasets, and they generally reflect the ways dataset creators have grouped their datasets (such as in the same paper). Because of the large number of datasets, we provide detailed information about their licenses and original published papers, where applicable, in the supplementary Attribution Card in \Cref{sec:attribution-card}.

\paragraph{Annotation Details: Text}
For post-training text datasets it is common to package many together as collections, such as Flan \citep{weifinetuned} or P3 \citep{sanh2021multitask}. 
This practice is not common to the same extent for speech or video datasets.
For much of the text analysis, where possible, we chose to analyze statistics at the collection-level, since practitioners are more likely to adopt a collection for general-purpose post-training, than an individual dataset within the collection.
Also, in dataset-level statistics, metadata for a single collection with many datasets can get repeated and overwhelm the statistics unfairly (e.g. the dataset aggregator/creator being repeated hundreds of times).
Consequently, our collection-level analysis of the text modality is reflected in  \Cref{fig:temporal-source-categories}, \Cref{fig:creator-worldmaps}, \Cref{fig:creator-orgs}, \Cref{fig:representation}, \Cref{fig:tasks}, and \Cref{fig:dimensions}.
However, for \Cref{fig:license-terms} we draw the distinction between collection and dataset metrics, as practitioners may wish to unpack collections to extract only commercially licensed data.
In that case a Collection inherits the most restrictive license and terms of its constituent datasets.

For annotating creator organizations, we follow prior work's instructions \citep{longpre2023data}.
For each dataset they record the affiliations listed on the academic paper or GitHub or HuggingFace object in which the dataset was released.
This does not include the organizations who created or owned the sources from which the data was derived.
For instance, the SQuAD dataset \citep{rajpurkar2016squad} would be associated with Stanford (the authors' affiliation), but not Wikipedia, which the data was partially derived from.
For a dataset that has authors affiliated with multiple organizations, the dataset will be counted towards each organization.

\paragraph{Annotation Details: Speech}
In many cases, multiple versions of a dataset exist due to datasets being expanded or updated. In these scenarios, we used the release date from the initial version (since release dates for subsequent versions were not always clear), but used metadata from the most recently released version for which information was available to offer an overview of the current landscape of data. However, if the dataset versions could not be meaningfully aggregated (e.g. different licenses), or did not appear to be cumulatively designed (non-overlapping or otherwise semantically disjoint data), we maintained separate records. We kept only datasets for which ASR was noted as a primary task. For example, if a dataset was primarily intended for text-to-speech or speaker recognition, we did not keep it even if it could conceivably be repurposed for ASR. When computing hours, we excluded any hours without supervisory transcripts/scripts (unlabeled data), but kept hours with ``weak supervision'' (e.g. model-generated transcripts from speech audio). 
We recognize the difficulty in comprehensively covering all relevant datasets. 

\paragraph{Annotation Details: Video} In video, a single dataset can be re-purposed and annotated to address different tasks \cite{monfort2019moments, monfortSpokenMomentsLearning2021}. We consider these as two different datasets even if they have the same video source since now they can be used for different computer vision tasks. 

\clearpage

\input{tables/collections-text}
\input{tables/collections-audio}
\input{tables/collections-video}