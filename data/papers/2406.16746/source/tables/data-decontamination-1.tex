

\begin{table}[H]
% \begin{tabular}{@{}lllll@{}}
\begin{tabular}{@{}p{\colOneSize}p{\colTwoSize}p{\colThreeSize}p{\colFourSize}@{}}
\toprule
\textsc{Modality} & \textsc{Name} & \textsc{Description} & \textsc{Links} \\ 
\midrule

    \multicolumn{4}{c}{\textsc{\emph{Dataset Decontamination}}} \\
    \midrule

\TextCircle\EmptyCircle\EmptyCircle & \textbf{BigBench Canaries} & BigBench's "Training on the Test Set" Task provies guidance on using canaries to check if an evaluation set was trained on. & \emojiblank\emojiblank\href{https://github.com/google/BIG-bench/blob/main/bigbench/benchmark_tasks/training_on_test_set/README.md#training-on-the-test-set}{\egithub}\emojiblank \\
\TextCircle\EmptyCircle\EmptyCircle & \textbf{Carper AI Decontamination Tool} & A repository, heavily based by the BigCode repository, to decontaminate evaluation sets from a text training set. & \emojiblank\emojiblank\href{https://github.com/CarperAI/decontamination/tree/main}{\egithub}\emojiblank \\
\TextCircle\EmptyCircle\EmptyCircle & \textbf{Data Portraits} & A tool to test if a model has seen certain data, e.g. in the The Pile or The Stack \citep{marone2023data}. & \href{https://arxiv.org/abs/2303.03919}{\earxiv}\emojiblank\emojiblank\href{https://dataportraits.org/}{\eweb} \\
\TextCircle\EmptyCircle\EmptyCircle & \textbf{Detect Data (Min-K Prob)} & A codebase that implements "Min-K\% Prob", a method to detect if a language model was pretrained on some text \citep{shi2023detecting}. & \href{https://arxiv.org/abs/2310.16789}{\earxiv}\emojiblank\href{https://github.com/swj0419/detect-pretrain-code}{\egithub}\href{https://swj0419.github.io/detect-pretrain.github.io/}{\eweb} \\
% \TextCircle\EmptyCircle\EmptyCircle & \textbf{Interpreting Canary Exposure} & An explanation on how to interpret canary exposure, including by relating it to membership inference attacks, and differential privacy \citep{jagielski2023note}. & \href{https://arxiv.org/abs/2306.00133}{\earxiv}\emojiblank\emojiblank\emojiblank \\
% \TextCircle\EmptyCircle\EmptyCircle & \textbf{Proving Test Set Contamination in Black Box Language Models} & A paper that provides methods for provable guarantees of test set contamination in language models without access to pretraining data or model weights \citep{oren2023proving}. & \href{https://arxiv.org/abs/2310.17623}{\earxiv}\emojiblank\emojiblank\emojiblank \\
\bottomrule
\end{tabular}
\end{table}