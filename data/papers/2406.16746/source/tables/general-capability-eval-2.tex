\begin{table}[H]
% \begin{tabular}{@{}lllll@{}}
\begin{tabular}{@{}p{\colOneSize}p{\colTwoSize}p{\colThreeSize}p{\colFourSize}@{}}
\toprule
\textsc{Modality} & \textsc{Name} & \textsc{Description} & \textsc{Links} \\ 
\midrule
\multicolumn{4}{c}{\textsc{\emph{Common Benchmarks for Multimodal Capability Evaluation}}} \\
\midrule

\TextCircle\VisionCircle\EmptyCircle & \textbf{CLIP benchmark} & Image classification, retrieval and captioning. & \emojiblank\emojiblank\href{https://github.com/LAION-AI/CLIP_benchmark}{\egithub}\emojiblank \\

\TextCircle\VisionCircle\EmptyCircle & \textbf{DataComp eval suite} & 38 image classification and retrieval downstream tasks \citep{gadre2023datacomp}. & \href{https://arxiv.org/abs/2304.14108}{\earxiv}\emojiblank\href{https://github.com/mlfoundations/datacomp#evaluation}{\egithub}\href{https://www.datacomp.ai/}{\eweb} \\

\TextCircle\VisionCircle\EmptyCircle & \textbf{HEIM} & A large suite of text-to-image evaluations. Useful for thorough capability analysis of these model types \citep{lee2023holistic}. & \href{https://arxiv.org/abs/2311.04287}{\earxiv}\emojiblank\emojiblank\href{https://crfm.stanford.edu/heim/v1.1.0/}{\eweb} \\

\EmptyCircle\EmptyCircle\SpeechCircle & \textbf{The Edinburgh International Accents of English Corpus} & Benchmark dataset of diverse English varieties for evaluating automatic speech recognition models (typically trained and tested only on US English) \citep{sanabria2023edinburgh}. & \href{https://arxiv.org/abs/2303.18110}{\earxiv}\emojiblank\emojiblank\href{https://groups.inf.ed.ac.uk/edacc/}{\eweb} \\

\TextCircle\VisionCircle\EmptyCircle & \textbf{MMBench} & A joint vision and text benchmark evaluating dozens of capabilities, using curated datasets and ChatGPT in the loop \citep{liu2023mmbench}. & \href{https://arxiv.org/abs/2307.06281}{\earxiv}\emojiblank\href{https://github.com/open-compass/MMBench}{\egithub}\href{https://opencompass.org.cn/mmbench}{\eweb} \\

\TextCircle\VisionCircle\EmptyCircle & \textbf{MME} & An evaluation benchmark for multimodal large language models with 14 manually curated subtasks, to avoid data leakage \citep{fu2023mme}. & \href{https://arxiv.org/abs/2306.13394}{\earxiv}\emojiblank\href{https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/}{\egithub}\emojiblank \\

\TextCircle\VisionCircle\EmptyCircle & \textbf{MMMU} & A benchmark to evaluate joint text and vision models on 11k examples spanning 30 college-level subject domains \citep{yue2023mmmu}. & \href{https://arxiv.org/abs/2311.16502}{\earxiv}\href{https://huggingface.co/datasets/MMMU/MMMU}{\ehf}\href{https://github.com/MMMU-Benchmark/MMMU}{\egithub}\href{https://mmmu-benchmark.github.io/}{\eweb} \\

\TextCircle\VisionCircle\EmptyCircle & \textbf{OpenFlamingo eval suite} & VQA, captioning, classification evaluation suite \citep{awadalla2023openflamingo}. & \href{https://arxiv.org/abs/2308.01390}{\earxiv}\emojiblank\href{https://github.com/mlfoundations/open_flamingo/tree/main/open_flamingo/eval}{\egithub}\emojiblank \\

\midrule
\multicolumn{4}{c}{\textsc{\emph{Common Leaderboards for Capability Evaluation}}} \\
\midrule

\TextCircle\VisionCircle\SpeechCircle & \textbf{Hugging Face Leaderboards} & A set of popular model leaderboards on Hugging Face for ranking on generic metrics. & \emojiblank\href{https://huggingface.co/open-llm-leaderboard}{\ehf}\emojiblank\emojiblank \\
\TextCircle\EmptyCircle\EmptyCircle & \textbf{LMSys Chatbot Arena} & A leaderboard of models based on Elo ratings where humans or models select their preferred response between two anonymous models. Chatbot Arena, MT-Bench, and 5-shot MMLU are used as benchmarks. This resource provides a general purpose, and GPT-4 biased perspective into model capabilities \citep{zheng2023judging}. & \href{https://arxiv.org/abs/2306.05685}{\earxiv}\href{https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard}{\ehf}\href{https://github.com/lm-sys/FastChat/blob/main/docs/dataset_release.md}{\egithub}\emojiblank \\

\EmptyCircle\EmptyCircle\SpeechCircle & \textbf{OpenASR Leaderboard} & An automatic leaderboard ranking and evaluating speech recognition models on common benchmarks. & \emojiblank\href{https://huggingface.co/spaces/hf-audio/open_asr_leaderboard}{\ehf}\href{https://github.com/huggingface/open_asr_leaderboard}{\egithub}\emojiblank \\

\bottomrule
\end{tabular}
\end{table}