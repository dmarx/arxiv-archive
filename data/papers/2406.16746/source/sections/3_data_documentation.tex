\section{Data Documentation and Release}
\label{sec:documentation}
\vspace{-2mm}

% https://www.latex4technics.com/?note=MOB
% \begin{tcolorbox}[width=\textwidth,title={Data Preparation Best Practices}]
\begin{tcolorbox}[
    width=\textwidth,
    title={Documentation Best Practices},
    colback=backgroundcol, % Background color of the box
    colframe=darkgray, % Frame color
    colbacktitle=dataprep, % Background color of the title
    coltitle=white, % Title text color
    coltext=black % Text color
]

\begin{itemize}[itemsep=0pt, wide=3pt]    
    \item Data documentation is essential for reproducibility, avoiding misuse, and helping downstream users build constructively on prior work.
    \item We recommend to start the documentation process early, as data is collected and processed.
    \item For datasets with multiple stakeholders or derived from community efforts, it is important to be proactive in decision-making about access, licenses, and stewardship.
\end{itemize}
\end{tcolorbox}

% \subsection{Survey}

\subsection{Data Documentation}

When releasing new data resources with a model, it is important to thoroughly document the data~\citep{bender-friedman-2018-data,holland2020dataset,gebru2021datasheets,bommasani2024foundation}. Documentation allows users to understand its intended uses, legal restrictions, attribution, relevant contents, privacy concerns, and other limitations. An example of how to describe and document data governance decisions can be found in the BLOOM project's report~\citep{jernite2022data}. The StackV2~\citep{lozhkov2024starcoder} is another example of a carefully curated and well documented dataset. Data documentation can also be a way to empower model trainers and downstream users of AI systems to 
It is common for datasets to be widely used by practitioners who may be unaware of undesirable properties \citep{David2023AIDatasetCSAM}. While many data documentation standards have been proposed, their adoption has been uneven, or when crowdsourced, as with Hugging Face Datasets, they may contain errors and omissions \citep{lhoest2021datasets, longpre2023data}.

\subsection{Data Governance}

Releasing all datasets involved in the development of a Foundation Model, including pretraining, fine-tuning, and evaluation data, can facilitate external scrutiny and support further research. However, releasing and hosting the data as it was used may not always be an option, especially when it includes data with external rights-holders; e.g., when data subjects' privacy, intellectual property, or other rights need to be taken into account. Proper data governance practices can be required at the curation and release stages to account for these rights.

In some jurisdictions, projects may be required to start with a Data Management Plan that requires developers to ensure that the data collection has a sufficient legal basis, follows principles of data minimization, and allows data subject to have sufficient visibility into and control over their representation in a dataset (\href{https://www.cnil.fr/en/ai-how-sheets}{CNIL resource sheet}). Data curation steps to that end can include respecting opt-out preference signals (Spawning, HaveIBeenTrained), or applying pseudonymization or PII redaction (BigCode Governance card). 

Once a dataset is released, it can be made available either broadly or with access control based on research needs (ROOTS, BigCode PII training dataset). Developers can also enable data subjects to ask for removal from the hosted version of the dataset by providing a contact address (OSCAR, PAraCrawl), possibly complemented by a membership test to check whether their data is included (Stack data portraits) or an automated process (BigCode, AmIinTheStack).


% \subsection{Recommendations}

% Data documentation is essential for reproducibility, avoiding misuse, and helping downstream users build constructively on prior work. Datasheets for datasets~\citep{gebru2021datasheets} are a tool to provide structure and consistency to dataset reporting. Reasons for why a dataset was created, how it was collected, processed, distributed and maintained as well as the legal considerations are included in datasheets.

% We recommend to start the documentation process early, as data is collected and processed. An example of how to describe and document data governance decisions can be found in the BLOOM project's report~\citep{jernite2022data}. The StarCoder 2 and the StackV2~\citep{lozhkov2024starcoder} is another example of carefully curated and well documented dataset.
% For datasets with multiple stakeholders, or derived from community efforts, it is important to appropriately proactively organize its access, licenses, and stewardship.

\subsection{Review}

\textbf{Better data documentation of existing and new datasets is still needed.} Most datasets still lack appropriate documentation. While data documentation tools exist they are underutilized at present.
\citet{longpre2024data} illustrate challenges in documenting provenance, consent, and authenticity of datasets at scale, and driving adoption of rigorous data standards.

\textbf{Datasheets and Data Cards are just a start.} While data documentation tools, such as datasheets and data cards are very useful, it is preferred to begin projects with a Data Management Plan and ensure that data collection is designed thoroughly. Considerations should include: the legal basis for collecting data, ensuring that collection is limited to the necessary data, transparency, respecting opt-out preferences and redaction of PII. 




% \paragraph{Data Documentation}
% \vspace{-2mm}

% When releasing new data resources with a model, it is important to thoroughly document the data\citep{bender-friedman-2018-data,holland2020dataset}.
% Documentation allows users to understand its intended uses, legal restrictions, attribution, relevant contents, privacy concerns, and other limitations.
% It is common for datasets to be widely used by practitioners, who may be unaware of undesirable properties \citep{David2023AIDatasetCSAM}.
% While many data documentation standards have been proposed, their adoption has been uneven, or when crowdsourced, as with Hugging Face Datasets, they may contain errors and omissions \citep{lhoest2021datasets, longpre2023data}.

% \input{tables/data-documentation-1}
% \vspace{-2mm}

% \subsection{Data Governance}
% \vspace{-2mm}

% Releasing all datasets involved in the development of a Foundation Model, including training, fine-tuning, and evaluation data, can facilitate external scrutiny and support further research. However, releasing and hosting the data as it was used may not always be an option, especially when it includes data with external rights-holders; e.g., when data subjects' privacy, intellectual property, or other rights need to be taken into account. Proper data governance practices can be required at the curation and release stages to account for these rights.

% In some jurisdictions, projects may be required to start with a Data Management Plan that requires developers to ensure that the data collection has a sufficient legal basis, follows principles of data minimization, and allows data subject to have sufficient visibility into and control over their representation in a dataset (\href{https://www.cnil.fr/en/ai-how-sheets}{CNIL resource sheet}). Data curation steps to that end can include respecting opt-out preference signals (Spawning, HaveIBeenTrained), or applying pseudonymization or PII redaction (BigCode Governance card). 

% Once a dataset is released, it can be made available either broadly or with access control based on research needs (ROOTS, BigCode PII training dataset). Developers can also enable data subjects to ask for removal from the hosted version of the dataset by providing a contact address (OSCAR, PAraCrawl), possibly complemented by a membership test to check whether their data is included (Stack data portraits) or an automated process (BigCode, AmIinTheStack).


% \input{tables/data-governance-1}
% \vspace{-2mm}