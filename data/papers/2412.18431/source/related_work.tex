\section{Related Work}


Our work draws inspiration from two branches of research: \begin{inparaenum}[(i)]\item retrieval-augmented models for QA and \item multi-hop QA using combinations of LLMs with graphical structures\end{inparaenum}.

\subsection{Retrieval-augmented Models for QA}
Since \citeauthor{Lewis2020} showcased the benefits of augmenting the input context of language models with relevant passages, several solutions have been proposed for addressing different knowledge-intensive scenarios \cite{Pan2023}.

Recent works by \citeauthor{Wang2023a,Shen2024} explore query expansion approaches, generating pseudo-documents from the LLM to expand the content of the original query.

Subsequent frameworks, starting with IRCoT, looked into interleaving retrieval and prompting steps, allowing each step to guide and refine the other iteratively \cite{Trivedi2023,Jiang2023,Su2024}.



\subsection{Multi-hop QA with LLMs and Graphs}

In the recent years, several architectures introduce a separate, offline indexing phase during which they form a hierarchical summary of passages  \cite{Chen2023,Sarthi2024,Edge2024}.
However, the summarisation process must be repeated whenever new data is added. This can be computationally expensive and inefficient for updating the knowledge base. 


More recently several approaches sought to leverage the benefits of incorporating structured knowledge for addressing multi-hop QA challenges with LLMs~\cite{Park2023,Fang2024,Li2024,Gutierrez2024,Liang2024,Wang2024}.
GraphReader, TRACE and HippoRAG propose offline methodologies for extracting entities and atomic facts or semantic triples from passages \cite{Li2024,Fang2024,Gutierrez2024}.
In this way, chunks that include same or neighbouring entities are captured, and a graph of the indexed passages is constructed. 
TRACE relies on an LLM to iteratively select triples to construct reasoning chains, which are then used for grounding the answer generation directly or for filtering retrieved results. However, the search space is limited as an already filtered candidate list is provided for each query. \citeauthor{Li2024} utilise an LLM agent capable of selecting from a set of predefined actions to traverse the nodes of a knowledge graph in real time given an input question. More recently, \citeauthor{Liang2024} introduced further standardisation for the offline graph, such as instance-to-concept linking and semantic relation completion. Nonetheless, the approach relies heavily on associating triples with pre-defined concepts to facilitate logical form-based retrieval.


HippoRAG leverages an alignment of passages and extracted triples to retrieve passages based on the Personalised PageRank algorithm \cite{Gutierrez2024}. 
While achieving considerable improvements for single- and multi-step retrieval (i.e. when coupled with IRCoT \cite{Trivedi2023}), it remains agnostic to the semantic relationships of the extracted triples. In this paper, we leverage a similar alignment of passages and extracted triples; but, instead of fully relying on expensive LLM calls, we introduce a new graph-based retrieval framework that uses a small semantic model for exploring multi-hop relationships. 
Our framework considers the contributions of all the triples elements participating in the reasoning chains, offering a more robust solution for associating questions with triple reasoning chains.
