\section{Comparison of Triple Extraction Prompting Strategies}
\label{appendix_sec:hipporag_results_original_prompt}

\begin{table*}[thbp]
\small
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{l l ccc ccc ccc}
\toprule
& & \multicolumn{3}{c}{\textbf{MuSiQue}} & \multicolumn{3}{c}{\textbf{2Wiki}} & \multicolumn{3}{c}{\textbf{HotpotQA}} \\ 
\cmidrule(lr){3-5} \cmidrule(lr){6-8} \cmidrule(lr){9-11}
& & R@5 & R@10 & R@15 & R@5 & R@10 & R@15 & R@5 & R@10 & R@15 \\ 
\midrule
\multirow{2}{*}{\parbox[t]{4cm}{\textbf{HippoRAG}}}
& original prompt & \textbf{41.9} & 46.9 & 51.1 & \textbf{75.4} & \textbf{83.5} & \textbf{86.9} & 79.7 & 88.4 & 91.4 \\ 
& our prompt & 41.0 & \textbf{47.0} & \textbf{51.4} & 75.1 & 83.2 & 86.4 & \textbf{79.8} & \textbf{89.0} & \textbf{92.4} \\ 
\midrule
\multirow{2}{*}{\parbox[t]{4cm}{\textbf{HippoRAG w/ IRCoT}}}
& original prompt & \textbf{49.9} & \textbf{56.4} & \textbf{59.3} & 81.5 & 90.2 & 92.3 & \textbf{90.2} & \textbf{94.7} & 95.8 \\ 
& our prompt & 48.8 & 54.5 & 58.9 & \textbf{82.9} & \textbf{90.6} & \textbf{93.0} & 90.1 & \textbf{94.7} & \textbf{95.9} \\ 
\bottomrule
\end{tabular}}
\caption{Retrieval performance comparison between HippoRAG's sequential triple extraction method and our joint extraction approach across three datasets.}
\label{tab:hippo_prompt_vs_our_prompt}
\end{table*}

HippoRAG employs a sequential approach to triple extraction: it first identifies named entities from a text chunk, and then uses these entities to guide triple extraction in a second step. In contrast, our method extracts both entities and triples simultaneously. Table \ref{tab:hippo_prompt_vs_our_prompt} shows that both approaches achieve comparable retrieval performance across all datasets, with each method excelling in different scenarios. These results validate that joint entity and triple extraction can match the effectiveness of sequential extraction while reducing the number of required processing steps.
