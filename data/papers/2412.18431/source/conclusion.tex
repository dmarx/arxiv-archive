\section{Conclusion}
\label{sec: conclusion}
We propose \gear, a novel framework that incorporates a graph-based retriever within a multi-step retrieval agent to model the information-seeking process for multi-hop question answering. 

We showcase the synergy between our proposed graph retriever (i.e. SyncGE) and the LLM within the \gear framework. SyncGE leverages the LLM to synchronise information from passages with triples and expands the graph by exploring diverse beams of triples that link multi-hop contexts. Our experiments reveal that this strategy improves over more naive implementations, demonstrating the LLM's capability to guide the exploration of initial nodes for graph expansion. Furthermore, \gear utilises multi-hop contexts returned by SyncGE and constructs a gist memory which is used for effectively summarising information across iterations. \gear archives superior performance compared to other multi-step retrieval methods while requiring fewer iterations and LLM tokens.




\section*{Limitations}
\label{sec:limitations}


The scope of this paper is limited to retrieval with the aid of a graph of triples that bridge corresponding passages. While we demonstrated the efficacy of our graph expansion approach and \gear, we acknowledge that the implementation of the underlying graph is rather simple. Better graph construction that addresses challenges such as entity disambiguation \cite{Dredze2010} and knowledge graph completion \cite{Lin2015} can lead to further improvements. 

We focused on employing a dense embedding model for our diverse triple beam search scoring function, though alternative functions could open up promising avenues for future research. For example, one can study the feasibility of formulating the scoring of neighbours as a natural language inference task \cite{Wang2021}, using a model that predicts how confidently a sequence of triples answers the given query.

Additionally, our approach relies on LLMs that can be better prompted to achieve superior performance on the relevant \gear tasks. Nonetheless, we provide more experiments in Appendix \ref{appendix_sec:open_source_model_experiments} showcasing that \gear can achieve equivalent performance with open-weight LLMs.
