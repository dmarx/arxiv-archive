\section{Introduction}\label{sec.introduction}
In recent years, there has been an exponential increase in the development and deployment of 
large language models (LLMs) \cite{abdalla-etal-2023-elephant,abs-2405-14487}. The most 
prominent and accurate models are often the products of major technology companies and 
are available either through APIs (e.g. OpenAI's GPT models) or with non-open licenses 
(e.g. Meta's LLaMA family\footnote{Meta restricts commercial use based on monthly active users and restricts the use of LLaMa model to improve other LLMs.%% License available at \url{https://ai.meta.com/llama/license/}.
}).
Moreover, these models are often US-centric, predominantly 
fluent in American English, and imbued with the values inherent to that cultural context.
Conversely, open and unrestricted models that focus on a variety of languages and 
cultures often emerge from academic settings. However, these models generally lack the 
accuracy and power of their more robust commercial counterparts. 
This disparity is primarily due to the differences in the resources available for 
training, such as the diversity and quality of data sources. The training data is 
crucial in shaping the behavior and values these models learn.
The OpenGPT-X\footnote{\url{https://opengpt-x.de/en/}} project aims to bridge this 
gap by merging the best of both worlds: delivering an open, unrestricted, high-performance 
model trained on a diverse dataset that covers all major European languages. OpenGPT-X targets 
real-world use cases, e.g. from media and the automotive sector within the European Union.

In this paper, we present a comprehensive overview of the data processing pipelines developed 
for the OpenGPT-X project. Our focus is solely on the collection, preparation, and curation 
of the data, detailing the steps for data selection, conversion, normalization, quality 
filtering, and deduplication. This processed data was then made available for the subsequent 
training of the OpenGPT-X models, such as those released in \cite{opengpt_x_2024_13866365}, which utilized a subset of the complete dataset for their development.
Our main contribution are:
\begin{itemize}

    \item A comprehensive outline of the data selection requirements, serving as practical guidelines for future projects.

    \item A detailed explanation of our multilingual data pipelines, highlighting distinct processing approaches for web and curated datasets.
    
    \item A thorough analysis of the processed datasets to ensure transparency and compliance with European data regulations (e.g. GDPR\footnote{General Data Protection Regulation, available at: \url{https://gdpr-info.eu/}}, Ethics Guidelines for Trustworthy AI\footnote{\url{https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai}}, Open Data Directive\footnote{\url{https://digital-strategy.ec.europa.eu/en/policies/legislation-open-data}}).
    
    \item Identification of project-specific challenges and lessons learned to guide future efforts in multilingual LLM development.
    
\end{itemize}

The remainder of this paper is organized as follows:  
Section \ref{sec:rel_work} provides context in the field of data processing and 
generation, specifically compiling a list of monolingual and multilingual datasets 
along with their methodologies.  
Next, the data selection process for curated data and web data is based on 
specific requirements that are outlined in Section \ref{sec:datasets}. This division leads to distinct software pipelines 
for processing each type in Section \ref{sec:pipelines}.
%where the curated data pipeline requires less filtering, while the web data pipeline emphasizes deduplication and filtering. 
Results are analyzed separately for curated and web data in Section \ref{sec:analysis}, 
providing insights on their use for model training.
The paper also discusses challenges and lessons learned in Section \ref{sec:insights}, 
offering guidance on potential data, legal, and organizational obstacles in future projects.
Finally, we conclude the paper in Section \ref{sec:conclusion} and provide an outlook on future work.
