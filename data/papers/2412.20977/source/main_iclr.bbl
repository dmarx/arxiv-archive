\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Chaplot et~al.(2020)Chaplot, Gandhi, Gupta, Gupta, and Salakhutdinov]{chaplot2020learning}
Devendra~Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta, and Ruslan Salakhutdinov.
\newblock Learning to explore using active neural slam.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=HklXn1BKDH}.

\bibitem[Chen et~al.(2024)Chen, Geng, Zhong, Ji, Jiang, Lu, Dong, and Yang]{chen2023bi}
Yuanpei Chen, Yiran Geng, Fangwei Zhong, Jiaming Ji, Jiechuang Jiang, Zongqing Lu, Hao Dong, and Yaodong Yang.
\newblock Bi-dexhands: Towards human-level bimanual dexterous manipulation.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 46\penalty0 (5):\penalty0 2804--2818, 2024.
\newblock \doi{10.1109/TPAMI.2023.3339515}.

\bibitem[Cheng et~al.(2024)Cheng, Wang, Hu, Hu, Liu, Tu, Li, Shi, Liu, and Sun]{cheng2024legent}
Zhili Cheng, Zhitong Wang, Jinyi Hu, Shengding Hu, An~Liu, Yuge Tu, Pengkai Li, Lei Shi, Zhiyuan Liu, and Maosong Sun.
\newblock Legent: Open platform for embodied agents.
\newblock \emph{arXiv preprint arXiv:2404.18243}, 2024.

\bibitem[Ci et~al.(2023)Ci, Liu, Pan, Zhong, and Wang]{ci2023proactive}
Hai Ci, Mickel Liu, Xuehai Pan, Fangwei Zhong, and Yizhou Wang.
\newblock Proactive multi-camera collaboration for 3d human pose estimation.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=CPIy9TWFYBG}.

\bibitem[Davison(2018)]{davison2018futuremapping}
Andrew~J Davison.
\newblock Futuremapping: The computational structure of spatial ai systems.
\newblock \emph{arXiv preprint arXiv:1803.11288}, 2018.

\bibitem[Dosovitskiy et~al.(2017)Dosovitskiy, Ros, Codevilla, Lopez, and Koltun]{CARLA}
Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen Koltun.
\newblock Carla: An open urban driving simulator.
\newblock In \emph{Conference on Robot Learning}, pp.\  1--16. PMLR, 2017.

\bibitem[Duan et~al.(2022)Duan, Yu, Tan, Zhu, and Tan]{duan2022survey}
Jiafei Duan, Samson Yu, Hui~Li Tan, Hongyuan Zhu, and Cheston Tan.
\newblock A survey of embodied ai: From simulators to research tasks.
\newblock \emph{IEEE Transactions on Emerging Topics in Computational Intelligence}, 6\penalty0 (2):\penalty0 230--244, 2022.

\bibitem[Du{\'e}{\~n}ez-Guzm{\'a}n et~al.(2023)Du{\'e}{\~n}ez-Guzm{\'a}n, Sadedin, Wang, McKee, and Leibo]{duenez2023social}
Edgar~A Du{\'e}{\~n}ez-Guzm{\'a}n, Suzanne Sadedin, Jane~X Wang, Kevin~R McKee, and Joel~Z Leibo.
\newblock A social path to human-like artificial intelligence.
\newblock \emph{Nature Machine Intelligence}, 5\penalty0 (11):\penalty0 1181--1188, 2023.

\bibitem[Ehsani et~al.(2021)Ehsani, Han, Herrasti, VanderBilt, Weihs, Kolve, Kembhavi, and Mottaghi]{ehsani2021manipulathor}
Kiana Ehsani, Winson Han, Alvaro Herrasti, Eli VanderBilt, Luca Weihs, Eric Kolve, Aniruddha Kembhavi, and Roozbeh Mottaghi.
\newblock Manipulathor: A framework for visual object manipulation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  4497--4506, 2021.

\bibitem[Gadre et~al.(2022)Gadre, Ehsani, Song, and Mottaghi]{gadre2022continuous}
Samir~Yitzhak Gadre, Kiana Ehsani, Shuran Song, and Roozbeh Mottaghi.
\newblock Continuous scene representations for embodied ai.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  14849--14859, 2022.

\bibitem[Gaidon et~al.(2016)Gaidon, Wang, Cabon, and Vig]{virtual_kitti}
Adrien Gaidon, Qiao Wang, Yohann Cabon, and Eleonora Vig.
\newblock Virtual worlds as proxy for multi-object tracking analysis.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pp.\  4340--4349, 2016.

\bibitem[Gan et~al.(2021)Gan, Schwartz, Alter, Mrowca, Schrimpf, Traer, Freitas, Kubilius, Bhandwaldar, Haber, Sano, Kim, Wang, Lingelbach, Curtis, Feigelis, Bear, Gutfreund, Cox, Torralba, DiCarlo, Tenenbaum, Mcdermott, and Yamins]{gan2020threedworld}
Chuang Gan, Jeremy Schwartz, Seth Alter, Damian Mrowca, Martin Schrimpf, James Traer, Julian~De Freitas, Jonas Kubilius, Abhishek Bhandwaldar, Nick Haber, Megumi Sano, Kuno Kim, Elias Wang, Michael Lingelbach, Aidan Curtis, Kevin~Tyler Feigelis, Daniel Bear, Dan Gutfreund, David~Daniel Cox, Antonio Torralba, James~J. DiCarlo, Joshua~B. Tenenbaum, Josh Mcdermott, and Daniel~LK Yamins.
\newblock Three{DW}orld: A platform for interactive multi-modal physical simulation.
\newblock In \emph{Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2021.
\newblock URL \url{https://openreview.net/forum?id=db1InWAwW2T}.

\bibitem[Guan et~al.(2024)Guan, Kong, Zhong, and Wang]{guan2024richelieu}
Zhenyu Guan, Xiangyu Kong, Fangwei Zhong, and Yizhou Wang.
\newblock Richelieu: Self-evolving {LLM}-based agents for {AI} diplomacy.
\newblock In \emph{The Thirty-eighth Annual Conference on Neural Information Processing Systems}, 2024.
\newblock URL \url{https://openreview.net/forum?id=7Jb4NJS8Yk}.

\bibitem[Gupta et~al.(2017)Gupta, Davidson, Levine, Sukthankar, and Malik]{gupta2017cognitive}
Saurabh Gupta, James Davidson, Sergey Levine, Rahul Sukthankar, and Jitendra Malik.
\newblock Cognitive mapping and planning for visual navigation.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pp.\  2616--2625, 2017.

\bibitem[Jin et~al.(2024)Jin, Wu, Cao, Xiang, Kuo, Hu, Ullman, Torralba, Tenenbaum, and Shu]{jin-etal-2024-mmtom}
Chuanyang Jin, Yutong Wu, Jing Cao, Jiannan Xiang, Yen-Ling Kuo, Zhiting Hu, Tomer Ullman, Antonio Torralba, Joshua Tenenbaum, and Tianmin Shu.
\newblock {MMT}o{M}-{QA}: Multimodal theory of mind question answering.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  16077--16102, 2024.

\bibitem[Kadian et~al.(2020)Kadian, Truong, Gokaslan, Clegg, Wijmans, Lee, Savva, Chernova, and Batra]{kadian2020sim2real}
Abhishek Kadian, Joanne Truong, Aaron Gokaslan, Alexander Clegg, Erik Wijmans, Stefan Lee, Manolis Savva, Sonia Chernova, and Dhruv Batra.
\newblock Sim2real predictivity: Does evaluation in simulation predict real-world performance?
\newblock \emph{IEEE Robotics and Automation Letters}, 5\penalty0 (4):\penalty0 6670--6677, 2020.

\bibitem[Kolve et~al.(2017)Kolve, Mottaghi, Han, VanderBilt, Weihs, Herrasti, Deitke, Ehsani, Gordon, Zhu, et~al.]{kolve2017ai2}
Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli VanderBilt, Luca Weihs, Alvaro Herrasti, Matt Deitke, Kiana Ehsani, Daniel Gordon, Yuke Zhu, et~al.
\newblock {AI2-THOR}: An interactive 3d environment for visual ai.
\newblock \emph{arXiv preprint arXiv:1712.05474}, 2017.

\bibitem[Kumar et~al.(2020)Kumar, Zhou, Tucker, and Levine]{kumar2020conservative}
Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 1179--1191, 2020.

\bibitem[Li et~al.(2023)Li, Zhang, Wong, Gokmen, Srivastava, Mart{\'\i}n-Mart{\'\i}n, Wang, Levine, Lingelbach, Sun, et~al.]{li2023behavior}
Chengshu Li, Ruohan Zhang, Josiah Wong, Cem Gokmen, Sanjana Srivastava, Roberto Mart{\'\i}n-Mart{\'\i}n, Chen Wang, Gabrael Levine, Michael Lingelbach, Jiankai Sun, et~al.
\newblock Behavior-1k: A benchmark for embodied ai with 1,000 everyday activities and realistic simulation.
\newblock In \emph{Conference on Robot Learning}, pp.\  80--93. PMLR, 2023.

\bibitem[Long et~al.(2024)Long, Cai, Wang, Zhan, and Dong]{long2024instructnav}
Yuxing Long, Wenzhe Cai, Hongcheng Wang, Guanqi Zhan, and Hao Dong.
\newblock Instructnav: Zero-shot system for generic instruction navigation in unexplored environment.
\newblock In \emph{8th Annual Conference on Robot Learning}, 2024.
\newblock URL \url{https://openreview.net/forum?id=fCDOfpTCzZ}.

\bibitem[Luo et~al.(2018)Luo, Sun, Zhong, Liu, Zhang, and Wang]{luo2018end}
Wenhan Luo, Peng Sun, Fangwei Zhong, Wei Liu, Tong Zhang, and Yizhou Wang.
\newblock End-to-end active object tracking via reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\  3286--3295. PMLR, 2018.

\bibitem[Luo et~al.(2020)Luo, Sun, Zhong, Liu, Zhang, and Wang]{luo2019pami}
Wenhan Luo, Peng Sun, Fangwei Zhong, Wei Liu, Tong Zhang, and Yizhou Wang.
\newblock End-to-end active object tracking and its real-world deployment via reinforcement learning.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 42\penalty0 (6):\penalty0 1317--1332, 2020.
\newblock \doi{10.1109/TPAMI.2019.2899570}.

\bibitem[Ma et~al.(2024)Ma, Li, Zhang, Liu, Wang, Chen, Shen, Wang, and Tao]{ma2023revisiting}
Guozheng Ma, Lu~Li, Sen Zhang, Zixuan Liu, Zhen Wang, Yixin Chen, Li~Shen, Xueqian Wang, and Dacheng Tao.
\newblock Revisiting plasticity in visual reinforcement learning: Data, modules and training stages.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=0aR1s9YxoL}.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley, Silver, and Kavukcuoglu]{mnih2016asynchronous}
Volodymyr Mnih, Adria~Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\  1928--1937, 2016.

\bibitem[Puig et~al.(2018)Puig, Ra, Boben, Li, Wang, Fidler, and Torralba]{puig2018virtualhome}
Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang, Sanja Fidler, and Antonio Torralba.
\newblock Virtualhome: Simulating household activities via programs.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pp.\  8494--8502, 2018.

\bibitem[Puig et~al.(2024)Puig, Undersander, Szot, Cote, Yang, Partsey, Desai, Clegg, Hlavac, Min, Vondru{\v{s}}, Gervet, Berges, Turner, Maksymets, Kira, Kalakrishnan, Malik, Chaplot, Jain, Batra, Rai, and Mottaghi]{puig2023habitat}
Xavier Puig, Eric Undersander, Andrew Szot, Mikael~Dallaire Cote, Tsung-Yen Yang, Ruslan Partsey, Ruta Desai, Alexander Clegg, Michal Hlavac, So~Yeon Min, Vladim{\'\i}r Vondru{\v{s}}, Theophile Gervet, Vincent-Pierre Berges, John~M Turner, Oleksandr Maksymets, Zsolt Kira, Mrinal Kalakrishnan, Jitendra Malik, Devendra~Singh Chaplot, Unnat Jain, Dhruv Batra, Akshara Rai, and Roozbeh Mottaghi.
\newblock Habitat 3.0: A co-habitat for humans, avatars, and robots.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=4znwzG92CE}.

\bibitem[Qiu et~al.(2017)Qiu, Zhong, Zhang, Qiao, Xiao, Kim, and Wang]{qiu2017unrealcv}
Weichao Qiu, Fangwei Zhong, Yi~Zhang, Siyuan Qiao, Zihao Xiao, Tae~Soo Kim, and Yizhou Wang.
\newblock Unrealcv: Virtual worlds for computer vision.
\newblock In \emph{Proceedings of the 25th ACM International Conference on Multimedia}, pp.\  1221--1224, 2017.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and Klimov]{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Shah et~al.(2018)Shah, Dey, Lovett, and Kapoor]{airsim}
Shital Shah, Debadeepta Dey, Chris Lovett, and Ashish Kapoor.
\newblock Airsim: High-fidelity visual and physical simulation for autonomous vehicles.
\newblock In \emph{Field and Service Robotics}, pp.\  621--635, 2018.

\bibitem[Wang et~al.(2023)Wang, Zhao, Jiao, Zhu, Zhu, and Liu]{wang2023rearrange}
Weiqi Wang, Zihang Zhao, Ziyuan Jiao, Yixin Zhu, Song-Chun Zhu, and Hangxin Liu.
\newblock Rearrange indoor scenes for human-robot co-activity.
\newblock In \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}, pp.\  11943--11949. IEEE, 2023.

\bibitem[Wang et~al.(2022)Wang, fangwei zhong, Xu, and Wang]{wang2022tomc}
Yuanfei Wang, fangwei zhong, Jing Xu, and Yizhou Wang.
\newblock Tom2c: Target-oriented multi-agent communication and cooperation with theory of mind.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=2t7CkQXNpuq}.

\bibitem[Weihs et~al.(2021)Weihs, Deitke, Kembhavi, and Mottaghi]{weihs2021visual}
Luca Weihs, Matt Deitke, Aniruddha Kembhavi, and Roozbeh Mottaghi.
\newblock Visual room rearrangement.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  5922--5931, 2021.

\bibitem[Wu et~al.(2018)Wu, Wu, Gkioxari, and Tian]{house3D}
Yi~Wu, Yuxin Wu, Georgia Gkioxari, and Yuandong Tian.
\newblock Building generalizable agents with a realistic and rich 3d environment.
\newblock \emph{arXiv preprint arXiv:1801.02209}, 2018.

\bibitem[Xia et~al.(2018)Xia, Zamir, He, Sax, Malik, and Savarese]{xia2018gibson}
Fei Xia, Amir~R Zamir, Zhiyang He, Alexander Sax, Jitendra Malik, and Silvio Savarese.
\newblock Gibson env: Real-world perception for embodied agents.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pp.\  9068--9079, 2018.

\bibitem[Xu et~al.(2024)Xu, Zheng, Liang, Wang, Yuan, Ji, Luo, Liu, Yuan, Hua, Li, Ze, III, Huang, and Xu]{xu2023drm}
Guowei Xu, Ruijie Zheng, Yongyuan Liang, Xiyao Wang, Zhecheng Yuan, Tianying Ji, Yu~Luo, Xiaoyu Liu, Jiaxin Yuan, Pu~Hua, Shuzhen Li, Yanjie Ze, Hal~Daum{\'e} III, Furong Huang, and Huazhe Xu.
\newblock Drm: Mastering visual reinforcement learning through dormant ratio minimization.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=MSe8YFbhUE}.

\bibitem[Yadav et~al.(2023)Yadav, Ramrakhya, Majumdar, Berges, Kuhar, Batra, Baevski, and Maksymets]{yadav2023offline}
Karmesh Yadav, Ram Ramrakhya, Arjun Majumdar, Vincent-Pierre Berges, Sachit Kuhar, Dhruv Batra, Alexei Baevski, and Oleksandr Maksymets.
\newblock Offline visual representation learning for embodied navigation.
\newblock In \emph{Workshop on Reincarnating Reinforcement Learning at ICLR 2023}, 2023.

\bibitem[Yang et~al.(2024)Yang, Ding, Brown, Qi, and Xie]{yang2024v}
Jihan Yang, Runyu Ding, Ellis Brown, Xiaojuan Qi, and Saining Xie.
\newblock V-irl: Grounding virtual intelligence in real life.
\newblock \emph{arXiv preprint arXiv:2402.03310}, 2024.

\bibitem[Yang et~al.(2023)Yang, Gao, Li, Gao, Wang, and Zheng]{yang2023track}
Jinyu Yang, Mingqi Gao, Zhe Li, Shang Gao, Fangjing Wang, and Feng Zheng.
\newblock Track anything: Segment anything meets videos.
\newblock \emph{arXiv preprint arXiv:2304.11968}, 2023.

\bibitem[Yokoyama et~al.(2024)Yokoyama, Ha, Batra, Wang, and Bucher]{yokoyama2024vlfm}
Naoki Yokoyama, Sehoon Ha, Dhruv Batra, Jiuguang Wang, and Bernadette Bucher.
\newblock Vlfm: Vision-language frontier maps for zero-shot semantic navigation.
\newblock In \emph{International Conference on Robotics and Automation (ICRA)}, 2024.

\bibitem[Yu et~al.(2020)Yu, Quillen, He, Julian, Hausman, Finn, and Levine]{yu2020meta}
Tianhe Yu, Deirdre Quillen, Zhanpeng He, Ryan Julian, Karol Hausman, Chelsea Finn, and Sergey Levine.
\newblock Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning.
\newblock In \emph{Conference on Robot Learning}, pp.\  1094--1100. PMLR, 2020.

\bibitem[Yuan et~al.(2022)Yuan, Xue, Yuan, Wang, Wu, Gao, and Xu]{yuan2022pre}
Zhecheng Yuan, Zhengrong Xue, Bo~Yuan, Xueqian Wang, Yi~Wu, Yang Gao, and Huazhe Xu.
\newblock Pre-trained image encoder for generalizable visual reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~35, pp.\  13022--13037, 2022.

\bibitem[Zhang et~al.(2024)Zhang, Wang, Xu, Zhou, Hong, Fang, Wu, Zhang, and He]{zhang2024navid}
Jiazhao Zhang, Kunyu Wang, Rongtao Xu, Gengze Zhou, Yicong Hong, Xiaomeng Fang, Qi~Wu, Zhizheng Zhang, and Wang He.
\newblock Navid: Video-based vlm plans the next step for vision-and-language navigation.
\newblock \emph{arXiv preprint arXiv:2402.15852}, 2024.

\bibitem[Zhong et~al.(2019)Zhong, Sun, Luo, Yan, and Wang]{zhong2018advat}
Fangwei Zhong, Peng Sun, Wenhan Luo, Tingyun Yan, and Yizhou Wang.
\newblock {AD}-{VAT}: An asymmetric dueling mechanism for learning visual active tracking.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=HkgYmhR9KX}.

\bibitem[Zhong et~al.(2021)Zhong, Sun, Luo, Yan, and Wang]{zhong2021distractor}
Fangwei Zhong, Peng Sun, Wenhan Luo, Tingyun Yan, and Yizhou Wang.
\newblock Towards distraction-robust active visual tracking.
\newblock In \emph{International Conference on Machine Learning}, pp.\  12782--12792. PMLR, 2021.

\bibitem[Zhong et~al.(2023)Zhong, Bi, Zhang, Zhang, and Wang]{zhong2023rspt}
Fangwei Zhong, Xiao Bi, Yudi Zhang, Wei Zhang, and Yizhou Wang.
\newblock Rspt: reconstruct surroundings and predict trajectory for generalizable active object tracking.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, pp.\  3705--3714, 2023.

\bibitem[Zhong et~al.(2024)Zhong, Wu, Ci, Wang, and Chen]{zhong2024empowering}
Fangwei Zhong, Kui Wu, Hai Ci, Churan Wang, and Hao Chen.
\newblock Empowering embodied visual tracking with visual foundation models and offline rl.
\newblock In \emph{European Conference on Computer Vision}, pp.\  139--155. Springer, 2024.

\bibitem[Zhou et~al.(2024{\natexlab{a}})Zhou, Hong, and Wu]{zhou2024navgpt}
Gengze Zhou, Yicong Hong, and Qi~Wu.
\newblock Navgpt: Explicit reasoning in vision-and-language navigation with large language models.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~38, pp.\  7641--7649, 2024{\natexlab{a}}.

\bibitem[Zhou et~al.(2024{\natexlab{b}})Zhou, Chen, Wang, Xu, Du, Zhang, Du, Tenenbaum, and Gan]{zhou2024hazard}
Qinhong Zhou, Sunli Chen, Yisong Wang, Haozhe Xu, Weihua Du, Hongxin Zhang, Yilun Du, Joshua~B. Tenenbaum, and Chuang Gan.
\newblock {HAZARD} challenge: Embodied decision making in dynamically changing environments.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=n6mLhaBahJ}.

\bibitem[Zhu et~al.(2017)Zhu, Mottaghi, Kolve, Lim, Gupta, Fei{-}Fei, and Farhadi]{thor2017}
Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph~J. Lim, Abhinav Gupta, Li~Fei{-}Fei, and Ali Farhadi.
\newblock Target-driven visual navigation in indoor scenes using deep reinforcement learning.
\newblock In \emph{International Conference on Robotics and Automation (ICRA)}, 2017.

\end{thebibliography}
