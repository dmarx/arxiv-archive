\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Balaji et~al.(2019)Balaji, Min, Bai, Chellappa, and Graf]{balaji2019fid-fvd}
Yogesh Balaji, Martin~Renqiang Min, Bing Bai, Rama Chellappa, and Hans~Peter Graf.
\newblock Conditional gan with discriminative filter generation for text-to-video synthesis.
\newblock In \emph{IJCAI}, volume~1, pp.\ ~2, 2019.

\bibitem[Blattmann et~al.(2023{\natexlab{a}})Blattmann, Dockhorn, Kulal, Mendelevitch, Kilian, Lorenz, Levi, English, Voleti, Letts, et~al.]{blattmann2023svd}
Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, et~al.
\newblock Stable video diffusion: Scaling latent video diffusion models to large datasets.
\newblock \emph{arXiv preprint arXiv:2311.15127}, 2023{\natexlab{a}}.

\bibitem[Blattmann et~al.(2023{\natexlab{b}})Blattmann, Rombach, Ling, Dockhorn, Kim, Fidler, and Kreis]{blattmann2023align}
Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung~Wook Kim, Sanja Fidler, and Karsten Kreis.
\newblock Align your latents: High-resolution video synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  22563--22575, 2023{\natexlab{b}}.

\bibitem[Cao et~al.(2017)Cao, Simon, Wei, and Sheikh]{cao2017openpose}
Zhe Cao, Tomas Simon, Shih-En Wei, and Yaser Sheikh.
\newblock Realtime multi-person 2d pose estimation using part affinity fields.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  7291--7299, 2017.

\bibitem[Chang et~al.(2023)Chang, Shi, Gao, Xu, Fu, Song, Yan, Zhu, Yang, and Soleymani]{chang2023magicpose}
Di~Chang, Yichun Shi, Quankai Gao, Hongyi Xu, Jessica Fu, Guoxian Song, Qing Yan, Yizhe Zhu, Xiao Yang, and Mohammad Soleymani.
\newblock Magicpose: Realistic human poses and facial expressions retargeting with identity-aware diffusion.
\newblock In \emph{Forty-first International Conference on Machine Learning}, 2023.

\bibitem[Ge et~al.(2023)Ge, Nah, Liu, Poon, Tao, Catanzaro, Jacobs, Huang, Liu, and Balaji]{ge2023preserve}
Songwei Ge, Seungjun Nah, Guilin Liu, Tyler Poon, Andrew Tao, Bryan Catanzaro, David Jacobs, Jia-Bin Huang, Ming-Yu Liu, and Yogesh Balaji.
\newblock Preserve your own correlation: A noise prior for video diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  22930--22941, 2023.

\bibitem[Ge et~al.(2024)Ge, Mahapatra, Parmar, Zhu, and Huang]{ge2024content}
Songwei Ge, Aniruddha Mahapatra, Gaurav Parmar, Jun-Yan Zhu, and Jia-Bin Huang.
\newblock On the content bias in fr{\'e}chet video distance.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  7277--7288, 2024.

\bibitem[Gu et~al.(2024)Gu, Zhou, Wu, Yu, Liu, Zhao, Wu, Zhang, Shou, and Tang]{gu2024videoswap}
Yuchao Gu, Yipin Zhou, Bichen Wu, Licheng Yu, Jia-Wei Liu, Rui Zhao, Jay~Zhangjie Wu, David~Junhao Zhang, Mike~Zheng Shou, and Kevin Tang.
\newblock Videoswap: Customized video subject swapping with interactive semantic point correspondence.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  7621--7630, 2024.

\bibitem[G{\"u}ler et~al.(2018)G{\"u}ler, Neverova, and Kokkinos]{guler2018densepose}
R{\i}za~Alp G{\"u}ler, Natalia Neverova, and Iasonas Kokkinos.
\newblock Densepose: Dense human pose estimation in the wild.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  7297--7306, 2018.

\bibitem[Guo et~al.(2023)Guo, Yang, Rao, Liang, Wang, Qiao, Agrawala, Lin, and Dai]{guo2023animatediff}
Yuwei Guo, Ceyuan Yang, Anyi Rao, Zhengyang Liang, Yaohui Wang, Yu~Qiao, Maneesh Agrawala, Dahua Lin, and Bo~Dai.
\newblock Animatediff: Animate your personalized text-to-image diffusion models without specific tuning.
\newblock \emph{arXiv preprint arXiv:2307.04725}, 2023.

\bibitem[He et~al.(2024)He, Xu, Guo, Wetzstein, Dai, Li, and Yang]{he2024cameractrl}
Hao He, Yinghao Xu, Yuwei Guo, Gordon Wetzstein, Bo~Dai, Hongsheng Li, and Ceyuan Yang.
\newblock Cameractrl: Enabling camera control for text-to-video generation.
\newblock \emph{arXiv preprint arXiv:2404.02101}, 2024.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  770--778, 2016.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Hu et~al.(2023)Hu, Gao, Zhang, Sun, Zhang, and Bo]{hu2023animate}
Li~Hu, Xin Gao, Peng Zhang, Ke~Sun, Bang Zhang, and Liefeng Bo.
\newblock Animate anyone: Consistent and controllable image-to-video synthesis for character animation.
\newblock \emph{arXiv preprint arXiv:2311.17117}, 2023.

\bibitem[Huang et~al.(2024)Huang, He, Yu, Zhang, Si, Jiang, Zhang, Wu, Jin, Chanpaisit, et~al.]{huang2024vbench}
Ziqi Huang, Yinan He, Jiashuo Yu, Fan Zhang, Chenyang Si, Yuming Jiang, Yuanhan Zhang, Tianxing Wu, Qingyang Jin, Nattapol Chanpaisit, et~al.
\newblock Vbench: Comprehensive benchmark suite for video generative models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  21807--21818, 2024.

\bibitem[Jafarian \& Park(2021)Jafarian and Park]{jafarian2021tiktok}
Yasamin Jafarian and Hyun~Soo Park.
\newblock Learning high fidelity depths of dressed humans by watching social media dance videos.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  12753--12762, 2021.

\bibitem[Li et~al.(2024)Li, Wang, Zhang, Wang, Yuan, Xie, Zou, and Shan]{li2024image}
Yaowei Li, Xintao Wang, Zhaoyang Zhang, Zhouxia Wang, Ziyang Yuan, Liangbin Xie, Yuexian Zou, and Ying Shan.
\newblock Image conductor: Precision control for interactive video synthesis.
\newblock \emph{arXiv preprint arXiv:2406.15339}, 2024.

\bibitem[Loper et~al.(2015)Loper, Mahmood, Romero, Pons-Moll, and Black]{SMPL:2015}
Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael~J. Black.
\newblock {SMPL}: A skinned multi-person linear model.
\newblock \emph{ACM Transactions on Graphics, (Proc. SIGGRAPH Asia)}, 34\penalty0 (6):\penalty0 248:1--248:16, October 2015.

\bibitem[MooreThreads(2024)]{moore-animateanyone}
MooreThreads.
\newblock Moorethreads/moore-animateanyone, 2024.
\newblock URL \url{https://github.com/MooreThreads/Moore-AnimateAnyone}.

\bibitem[Niu et~al.(2025)Niu, Cun, Wang, Zhang, Shan, and Zheng]{niu2025mofa}
Muyao Niu, Xiaodong Cun, Xintao Wang, Yong Zhang, Ying Shan, and Yinqiang Zheng.
\newblock Mofa-video: Controllable image animation via generative motion field adaptions in frozen image-to-video diffusion model.
\newblock In \emph{European Conference on Computer Vision}, pp.\  111--128. Springer, 2025.

\bibitem[Peng et~al.(2024)Peng, Wang, Zhang, Li, Yang, and Jia]{peng2024controlnext}
Bohao Peng, Jian Wang, Yuechen Zhang, Wenbo Li, Ming-Chang Yang, and Jiaya Jia.
\newblock Controlnext: Powerful and efficient control for image and video generation.
\newblock \emph{arXiv preprint arXiv:2408.06070}, 2024.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pp.\  8748--8763. PMLR, 2021.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  10684--10695, 2022.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and Brox]{ronneberger2015unet}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18}, pp.\  234--241. Springer, 2015.

\bibitem[Song et~al.(2020)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole]{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock \emph{arXiv preprint arXiv:2011.13456}, 2020.

\bibitem[Tang et~al.(2023)Tang, Jia, Wang, Phoo, and Hariharan]{tang2023emergent}
Luming Tang, Menglin Jia, Qianqian Wang, Cheng~Perng Phoo, and Bharath Hariharan.
\newblock Emergent correspondence from image diffusion.
\newblock \emph{Advances in Neural Information Processing Systems}, 36:\penalty0 1363--1389, 2023.

\bibitem[Teed \& Deng(2020)Teed and Deng]{teed2020raft}
Zachary Teed and Jia Deng.
\newblock Raft: Recurrent all-pairs field transforms for optical flow.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16}, pp.\  402--419. Springer, 2020.

\bibitem[Tong et~al.(2024)Tong, Li, Chen, Wu, and Zhou]{musepose}
Zhengyan Tong, Chao Li, Zhaokang Chen, Bin Wu, and Wenjiang Zhou.
\newblock Musepose: a pose-driven image-to-video framework for virtual human generation, 2024.
\newblock URL \url{https://github.com/TMElyralab/MusePose}.

\bibitem[Unterthiner et~al.(2018)Unterthiner, Van~Steenkiste, Kurach, Marinier, Michalski, and Gelly]{unterthiner2018fvd}
Thomas Unterthiner, Sjoerd Van~Steenkiste, Karol Kurach, Raphael Marinier, Marcin Michalski, and Sylvain Gelly.
\newblock Towards accurate generative models of video: A new metric \& challenges.
\newblock \emph{arXiv preprint arXiv:1812.01717}, 2018.

\bibitem[Wang et~al.(2024{\natexlab{a}})Wang, Bai, Wang, Qin, and Chen]{wang2024instantid}
Qixun Wang, Xu~Bai, Haofan Wang, Zekui Qin, and Anthony Chen.
\newblock Instantid: Zero-shot identity-preserving generation in seconds.
\newblock \emph{arXiv preprint arXiv:2401.07519}, 2024{\natexlab{a}}.

\bibitem[Wang et~al.(2024{\natexlab{b}})Wang, Li, Lin, Zhai, Lin, Yang, Zhang, Liu, and Wang]{wang2024disco}
Tan Wang, Linjie Li, Kevin Lin, Yuanhao Zhai, Chung-Ching Lin, Zhengyuan Yang, Hanwang Zhang, Zicheng Liu, and Lijuan Wang.
\newblock Disco: Disentangled control for realistic human dance generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  9326--9336, 2024{\natexlab{b}}.

\bibitem[Wang et~al.(2024{\natexlab{c}})Wang, Yuan, Wang, Li, Chen, Xia, Luo, and Shan]{wang2024motionctrl}
Zhouxia Wang, Ziyang Yuan, Xintao Wang, Yaowei Li, Tianshui Chen, Menghan Xia, Ping Luo, and Ying Shan.
\newblock Motionctrl: A unified and flexible motion controller for video generation.
\newblock In \emph{ACM SIGGRAPH 2024 Conference Papers}, pp.\  1--11, 2024{\natexlab{c}}.

\bibitem[Wu et~al.(2024)Wu, Li, Gu, Zhao, He, Zhang, Shou, Li, Gao, and Zhang]{wu2024draganything}
Wejia Wu, Zhuang Li, Yuchao Gu, Rui Zhao, Yefei He, David~Junhao Zhang, Mike~Zheng Shou, Yan Li, Tingting Gao, and Di~Zhang.
\newblock Draganything: Motion control for anything using entity representation.
\newblock \emph{arXiv preprint arXiv:2403.07420}, 2024.

\bibitem[Xu et~al.(2023)Xu, Zhang, Cai, Rezatofighi, Yu, Tao, and Geiger]{xu2023unifying}
Haofei Xu, Jing Zhang, Jianfei Cai, Hamid Rezatofighi, Fisher Yu, Dacheng Tao, and Andreas Geiger.
\newblock Unifying flow, stereo and depth estimation.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2023.

\bibitem[Xu et~al.(2024)Xu, Zhang, Liew, Yan, Liu, Zhang, Feng, and Shou]{xu2024magicanimate}
Zhongcong Xu, Jianfeng Zhang, Jun~Hao Liew, Hanshu Yan, Jia-Wei Liu, Chenxu Zhang, Jiashi Feng, and Mike~Zheng Shou.
\newblock Magicanimate: Temporally consistent human image animation using diffusion model.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  1481--1490, 2024.

\bibitem[Yang et~al.(2024)Yang, Kang, Huang, Xu, Feng, and Zhao]{yang2024depth}
Lihe Yang, Bingyi Kang, Zilong Huang, Xiaogang Xu, Jiashi Feng, and Hengshuang Zhao.
\newblock Depth anything: Unleashing the power of large-scale unlabeled data.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  10371--10381, 2024.

\bibitem[Yang et~al.(2023)Yang, Zeng, Yuan, and Li]{yang2023dwpose}
Zhendong Yang, Ailing Zeng, Chun Yuan, and Yu~Li.
\newblock Effective whole-body pose estimation with two-stages distillation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  4210--4220, 2023.

\bibitem[Ye et~al.(2023)Ye, Zhang, Liu, Han, and Yang]{ye2023ip}
Hu~Ye, Jun Zhang, Sibo Liu, Xiao Han, and Wei Yang.
\newblock Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2308.06721}, 2023.

\bibitem[Yin et~al.(2023)Yin, Wu, Liang, Shi, Li, Ming, and Duan]{yin2023dragnuwa}
Shengming Yin, Chenfei Wu, Jian Liang, Jie Shi, Houqiang Li, Gong Ming, and Nan Duan.
\newblock Dragnuwa: Fine-grained control in video generation by integrating text, image, and trajectory.
\newblock \emph{arXiv preprint arXiv:2308.08089}, 2023.

\bibitem[Zhan et~al.(2019)Zhan, Pan, Liu, Lin, and Loy]{zhan2019self}
Xiaohang Zhan, Xingang Pan, Ziwei Liu, Dahua Lin, and Chen~Change Loy.
\newblock Self-supervised learning via conditional motion propagation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  1881--1889, 2019.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Rao, and Agrawala]{zhang2023adding}
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  3836--3847, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Wei, Jiang, Zhang, Zuo, and Tian]{zhang2023controlvideo}
Yabo Zhang, Yuxiang Wei, Dongsheng Jiang, Xiaopeng Zhang, Wangmeng Zuo, and Qi~Tian.
\newblock Controlvideo: Training-free controllable text-to-video generation.
\newblock \emph{arXiv preprint arXiv:2305.13077}, 2023{\natexlab{b}}.

\bibitem[Zhang et~al.(2024)Zhang, Gu, Wang, Wang, Cheng, Zhu, and Zou]{zhang2024mimicmotion}
Yuang Zhang, Jiaxi Gu, Li-Wen Wang, Han Wang, Junqi Cheng, Yuefeng Zhu, and Fangyuan Zou.
\newblock Mimicmotion: High-quality human motion video generation with confidence-aware pose guidance.
\newblock \emph{arXiv preprint arXiv:2406.19680}, 2024.

\bibitem[Zhu et~al.(2024)Zhu, Chen, Dai, Xu, Cao, Yao, Zhu, and Zhu]{zhu2024champ}
Shenhao Zhu, Junming~Leo Chen, Zuozhuo Dai, Yinghui Xu, Xun Cao, Yao Yao, Hao Zhu, and Siyu Zhu.
\newblock Champ: Controllable and consistent human image animation with 3d parametric guidance.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, 2024.

\end{thebibliography}
