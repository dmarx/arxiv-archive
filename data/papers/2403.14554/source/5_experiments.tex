\section{Experiments}

\input{figures/fuzzy_materials_closeup}

\subsection{Implementation Details}


We implemented our method with PyTorch~\cite{paszke-nips19-pytorch} and optimized the representations on a single GPU Nvidia Tesla V100~SXM2~32~Go.
Optimizing a full, editable Frosting model takes between 45 and 90 minutes on a single GPU, depending on the complexity of the scene. This optimization is much faster than the most similar approach to Frosting in the literature, namely Adaptive~Shells~\cite{wang-siggraphasia2023-adaptive-shells}, that requires 8~hours on a single GPU for a synthetic scene, and 1.7 times more iterations for a real scene.

\subsubsection{Extracting the surface mesh.} When reconstructing real scenes, we follow the approach from vanilla 3DGS~\cite{kerbl3Dgaussians} and first use COLMAP to estimate the camera poses and extract a  point cloud for initialization. For synthetic scenes with known camera poses, we just use a random point cloud for initialization. Then, we optimize an unconstrained Gaussian Splatting representation for 7,000 iterations. We save these Gaussians aside and apply the regularization term from SuGaR until iteration~15,000. We finally compute an optimal depth parameter $\bar{D}$ with $\gamma=100$ and extract a mesh from the regularized Gaussians by applying Poisson surface reconstruction as described in~\cite{guedon2023sugar}.

\subsubsection{Optimizing the Gaussian Frosting.} Given a budget of $N$ Gaussians, we initialize $N$ Gaussians in the Frosting layer and optimize them for 15,000 additional iterations, which gives a total of 30,000 iterations, similarly to 3DGS~\cite{kerbl3Dgaussians}. Vanilla 3DGS optimization generally produces between 1 and 5 million Gaussians. In practice, we use $N$=5~million for real scenes and $N$=2~million for synthetic scenes.


\subsection{Real-Time Rendering in Complex Scenes}

To evaluate the quality of Frosting's rendering, we compute the standard metrics PSNR, SSIM and LPIPS~\cite{zhang-2018-cvpr-lpips} and compare to several baselines, some of them focusing only on Novel View Synthesis~\cite{mildenhall2020nerf,wang2021neus,barron2021mipnerf,barron2022mipnerf360,mueller2022instantngp,yu_and_fridovichkeil2021plenoxels,kerbl3Dgaussians} and others relying on an editable representation~\cite{chen2022mobilenerf,rakotosaona2023nerfmeshing,yariv-2023-bakedsdf,reiser2024binaryopacitygrid,wang-siggraphasia2023-adaptive-shells,guedon2023sugar}, just like Frosting. We compute metrics on several challenging datasets containing synthetic and real scenes.\\

\noindent
\textbf{Shelly.} We first compare Frosting to state-of-the-art methods on the dataset Shelly introduced in Adaptive~Shells~\cite{wang-siggraphasia2023-adaptive-shells}. Shelly includes six synthetic scenes with challenging fuzzy materials that surface-based approaches struggle to reconstruct accurately. As we show in Table~\ref{tab:nvsmetrics_shelly} and Figure~\ref{fig:fuzzy-material-closeup}, Frosting outperforms every other methods for all three metrics. Frosting even outperforms with a wide margin vanilla Gaussian Splatting, which is free from any surface constraints and only focuses on optimizing the rendering quality. Indeed, the sampling of Gaussians inside the Frosting layer provides a much more efficient densification of Gaussians than the strategy proposed in 3DGS~\cite{kerbl3Dgaussians}, targeting the challenging fuzzy areas close to the surface and allocating more Gaussians where volumetric rendering is needed.\\

\noindent
\textbf{NeRFSynthetic.} Table~\ref{tab:nvsmetrics_shelly} provides a comparison on the NeRFSynthetic data\-set~\cite{mildenhall2020nerf}, which consists in eight synthetic scenes. Frosting performs the best among the editable methods, surpassing Su\-GaR~\cite{guedon2023sugar}, and achieves results on par with vanilla 3DGS and other radiance field methods.\\

\input{tables/nvs_metrics_shelly}

\noindent
\textbf{Mip-NeRF~360.} We also compare Frosting to state-of-the-art approaches on the real scenes from the Mip-NeRF~360 dataset~\cite{barron2022mipnerf360}. This dataset contains images from seven challenging real scenes, but was captured with ideal lighting condition and provides really good camera calibration data and initial SfM~points. Results are available in Table~\ref{tab:nvsmetrics_mipnerf360} and Figure~\ref{fig:frosting-renders}. Frosting reaches the best performance among all editable methods, and obtains worse but competitive results compared to vanilla Gaussian Splatting. When Gaussian Splatting is given a very good initialization with a large amount of SfM points, the benefits from the Gaussian Frosting densification are not as effective, and optimizing Gaussians without additional constraints as in 3DGS slightly improves performance.\\

\noindent
\textbf{Additional real scenes.} We finally compare Frosting to the baselines with captures of real scenes that present variations in exposure or white balance. To this end, we follow the approach from 3DGS~\cite{kerbl3Dgaussians} and select the same two subsets of two scenes from \emph{Tanks\&Temples} (\emph{Truck} and \emph{Train}) and \emph{Deep~Blending}~(\emph{Playroom} and \emph{Dr.~Johnson}). We also evaluate a few methods on a custom dataset that consists of four casual captures made with a smartphone (we call these scenes \emph{SleepyCat}, \emph{Buzz}, \emph{RedPanda}, and \emph{Knight}), illustrated in Figures~\ref{fig:teaser} and~\ref{fig:frosting-renders}. Results are available in Table~\ref{tab:nvsmetrics_tandtdb}. In these more realistic scenarios, Frosting achieves once again similar or better performance than unconstrained Gaussian Splatting even though it is an editable representation that relies on a single, animatable mesh.

\input{tables/nvs_metrics_mipnerf360}
\input{tables/nvs_metrics_tandtdb}

\subsection{Editing, Compositing, and Animating Gaussian Frosting}

\input{figures/edition_examples}

As shown in Figure~\ref{fig:sugar-comparison}, Figure~\ref{fig:scene-composition} and Figure~\ref{fig:edition-examples}, our Frosting representation automatically adapts when editing, rescaling, deforming, combining or animating base meshes.
Frosting offers editing, composition and animation capabilities similar to surface-based approaches like SuGaR~\cite{guedon2023sugar}, but achieves much better performance thanks to its frosting layer with variable thickness that adapts to the volumetric effects and fuzzy materials in the scene.


\subsection{Ablation Study: Octree Depth}
\input{tables/ablation_octree_depth}

To demonstrate how our technique for automatically computing the optimal octree depth $\bar{D}$ for Poisson reconstruction improves the performance of Frosting, we provide in Table~\ref{tab:ablation-octree-depth} a comparison in rendering performance between our full model, and a version of Frosting that uses the same predefined depth parameter as SuGaR. This technique results in equivalent or better rendering performance with much fewer triangles.


\subsection{Ablation Study: Thickness of the Frosting Layer}
\input{tables/ablation_proposal_intervals}
\input{figures/artifacts}

We also provide in Table~\ref{tab:ablation-proposal-intervals} an ablation study comparing different strategies for computing the thickness of the Frosting layer. 
%
Specifically, we first evaluate the rendering performance of a Frosting layer with constant thickness. We repeat the experiment for small, medium and large thickness values, using different quantiles of our inner and outer shifts~$\innershift$ and $\outershift$ for computing the constant thickness.
%
We show that using an adaptive thickness improves performance over a constant thickness, as (a) some fuzzy materials need a thicker frosting to be accurately rendered, and (b) some flat surfaces are better rendered with a very thin frosting. 
%
As a consequence, even though using a large constant thickness improves performance in scenes with very fuzzy materials like Shelly~\cite{wang-siggraphasia2023-adaptive-shells}, it lowers performance in scenes with flat surfaces. Moreover, using an adaptive thickness rather than a constant thickness with a large value helps to greatly reduce artifacts, as we demonstrate in Figure~\ref{fig:artifacts}.

We also show that using unconstrained Gaussians to refine the thickness of the Frosting is necessary to achieve top performance. To this end, we skip the refinement process and evaluate the rendering performance of a Frosting layer with $\innershift=\propinnershift$ and $\outershift=\propoutershift$. This results in lower performance, as shown in Table~\ref{tab:ablation-proposal-intervals}.