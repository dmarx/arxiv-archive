{
  "arxivId": "1810.01588",
  "title": "Interpreting Layered Neural Networks via Hierarchical Modular\n  Representation",
  "authors": "Chihiro Watanabe",
  "abstract": "Interpreting the prediction mechanism of complex models is currently one of\nthe most important tasks in the machine learning field, especially with layered\nneural networks, which have achieved high predictive performance with various\npractical data sets. To reveal the global structure of a trained neural network\nin an interpretable way, a series of clustering methods have been proposed,\nwhich decompose the units into clusters according to the similarity of their\ninference roles. The main problems in these studies were that (1) we have no\nprior knowledge about the optimal resolution for the decomposition, or the\nappropriate number of clusters, and (2) there was no method with which to\nacquire knowledge about whether the outputs of each cluster have a positive or\nnegative correlation with the input and output dimension values. In this paper,\nto solve these problems, we propose a method for obtaining a hierarchical\nmodular representation of a layered neural network. The application of a\nhierarchical clustering method to a trained network reveals a tree-structured\nrelationship among hidden layer units, based on their feature vectors defined\nby their correlation with the input and output dimension values.",
  "url": "https://arxiv.org/abs/1810.01588",
  "issue_number": 230,
  "issue_url": "https://github.com/dmarx/arxiv-archive/issues/230",
  "created_at": "2024-12-24T19:26:09.743541",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 6,
  "last_read": "2024-12-24T19:26:09.745189"
}