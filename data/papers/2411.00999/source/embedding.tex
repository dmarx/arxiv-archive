\begin{algorithm}
\caption{Embedding Layer Simultaneous Per-Example Gradient Norm Computation}
\label{alg:embedding-layer}
\begin{algorithmic}[1]
\Require gradient tensor $\gB$ of shape $(B, T, D)$, input id tensor $\xB$ of shape $(B, T)$, vocabulary size $V$
\Ensure weight gradient tensor $\wB'$ of shape $(V, D)$, mean of per-example squared norms $\sqn{\wB_b'}$
\State $\oB \gets \text{onehot}(\xB, V)$
\State $\wB_b' \gets \text{einsum}(\mlq b t v,b t d \rightarrow b v d \mrq, \oB, \gB)$
\State $\mathbf{s}_{w} \gets \text{einsum}(\mlq b v d \rightarrow b \mrq, \wB_b'^2)$
\State $\wB' \gets \text{einsum}(\mlq b v d \rightarrow v d \mrq, \wB_b')$
\State $\sqn{\wB_b'} \gets 1/B \times \text{einsum}(\mathbf{s}_w, \mlq b \rightarrow \mrq) \times B^2$ \# reduce by mean then apply correction
\State \Return $\wB', \sqn{\wB_b'}$
\end{algorithmic}
\end{algorithm}
