{
  "arxivId": "2302.04222",
  "title": "Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models",
  "authors": "Shawn Shan, Jenna Cryan, Emily Wenger, Haitao Zheng, Rana Hanocka, Ben Y. Zhao",
  "abstract": "Recent text-to-image diffusion models such as MidJourney and Stable Diffusion\nthreaten to displace many in the professional artist community. In particular,\nmodels can learn to mimic the artistic style of specific artists after\n\"fine-tuning\" on samples of their art. In this paper, we describe the design,\nimplementation and evaluation of Glaze, a tool that enables artists to apply\n\"style cloaks\" to their art before sharing online. These cloaks apply barely\nperceptible perturbations to images, and when used as training data, mislead\ngenerative models that try to mimic a specific artist. In coordination with the\nprofessional artist community, we deploy user studies to more than 1000\nartists, assessing their views of AI art, as well as the efficacy of our tool,\nits usability and tolerability of perturbations, and robustness across\ndifferent scenarios and against adaptive countermeasures. Both surveyed artists\nand empirical CLIP-based scores show that even at low perturbation levels\n(p=0.05), Glaze is highly successful at disrupting mimicry under normal\nconditions (>92%) and against adaptive countermeasures (>85%).",
  "url": "https://arxiv.org/abs/2302.04222",
  "issue_number": 147,
  "issue_url": "https://github.com/dmarx/arxiv-archive/issues/147",
  "created_at": "2024-12-25T08:52:23.548718",
  "state": "open",
  "labels": [
    "paper",
    "rating:downvote"
  ],
  "total_reading_time_seconds": 0,
  "last_read": null,
  "last_visited": "2024-12-22T16:18:52.405Z"
}