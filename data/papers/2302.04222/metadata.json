{
  "arxivId": "2302.04222",
  "title": "Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models",
  "authors": "Shawn Shan, Jenna Cryan, Emily Wenger, Haitao Zheng, Rana Hanocka, Ben Y. Zhao",
  "abstract": "Recent text-to-image diffusion models such as MidJourney and Stable Diffusion threaten to displace many in the professional artist community. In particular, models can learn to mimic the artistic style of specific artists after \"fine-tuning\" on samples of their art. In this paper, we describe the design, implementation and evaluation of Glaze, a tool that enables artists to apply \"style cloaks\" to their art before sharing online. These cloaks apply barely perceptible perturbations to images, and when used as training data, mislead generative models that try to mimic a specific artist. In coordination with the professional artist community, we deploy user studies to more than 1000 artists, assessing their views of AI art, as well as the efficacy of our tool, its usability and tolerability of perturbations, and robustness across different scenarios and against adaptive countermeasures. Both surveyed artists and empirical CLIP-based scores show that even at low perturbation levels (p=0.05), Glaze is highly successful at disrupting mimicry under normal conditions (&gt;92%) and against adaptive countermeasures (&gt;85%).",
  "url": "https://arxiv.org/abs/2302.04222",
  "issue_number": 147,
  "issue_url": "https://github.com/dmarx/arxiv-archive/issues/147",
  "created_at": "2024-12-22T16:18:53Z",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_minutes": 0,
  "last_read": null
}