\section{Related Work}

%Photorealistic rendering and animation of humans is an important area of research. 
Early works on photorealistic rendering and animation employed traditional computer graphics pipelines which involved large multi-camera setups such as lightstages ~\cite{debevec2012light} to capture the detailed texture and material of the human body. The animation of human bodies involved the rigging of an artist-created template of a human body mesh~\cite{alexander2013digitalira, alexander2010emily}. The introduction of statistical body shape models~\cite{anguelov2005scape, SMPL:2015, pavlakos2019smplx, STAR:ECCV:2020, SUPR} enabled representation of diverse human shape and animation of the human body by a single model. This reduced the manual effort in creating template meshes and rigging them.
%\jg{more quickly? More realistically? more easily? by non professionals?}. 
However, these shape models do not account for many details such as clothing, hair, accessories etc. Follow up works such as DRAPE~\cite{drape2012guan} or CAPE~\cite{ma2020cape} augment the shape models to add an additional layer of clothing or altogether choose a different representation such as occupancy~\cite{saito2019pifu, saito2020pifuhd, chen2021snarf, xiu2023econ, xiu2022icon} to represent the details of the geometry. This led to improved estimation of geometry, however the capturing appearance without large capture setups still remained a challenge.

In recent years, Neural Radiance Fields (NeRF)~\cite{mildenhall2020nerf} have enabled a joint representation of geometry and appearance for view-synthesis using multiview images without the need of a large capture setup. Although, a NeRF is designed for capturing static objects, recent work~\cite{peng2021neuralbody, weng2020vid2actor, liu2021neuralactor, weng2022humannerf, jiang2022neuman, Su21arxiv_A_NeRF, guo2023vid2avatar, Feng2022scarf,Mihajlovic:KeypointNeRF:ECCV2022} has extended the NeRF to enable capturing a dynamic moving humans
%by using a multi-camera setup in a capture lab. 
Weng et al.~\cite{weng2022humannerf} propose a method to model a NeRF representation of a human using a single monocular video enabling 360 degree view generation of a human. Furthermore, NeuMan~\cite{jiang2022neuman} introduces a joint NeRF representation of human and the scene capable of view synthesis and animation of the human in the scene. However, a major limitation of NeRF-based methods is that NeRFs are slow to train and render. Several methods have emerged to speed up training and rendering of NeRFs. These include using an explicit representation such as learning a function at grid points \cite{chen2022tensorf, reiser2021kilonerf}, using hash encoding \cite{muller2022instantngp} or altogether discarding the learnable component~\cite{fridovich2022plenoxels,liu2020neural}. 

Recent work on 3D Gaussian Splatting~\cite{kerbl3Dgaussians} uses a set of 3D Gaussians to represent a scene and renders it by splatting and rasterizing the Gaussians. This approach significantly improves the training and rendering times over traditional NeRFs. Recent work has addressed the extension of 3DGS scenes to controlled dynamic scenes~\cite{wu20234dgs} and multi-camera capture setup~\cite{luiten2023dynamicgs}. However, the 3D Gaussian Splatting framework is not trivial to extend to dynamic humans that allows for both novel-view and novel-pose synthesis of human and the scene.

Our methods builds on the 3D Gaussian Splatting framework~\cite{kerbl3Dgaussians} and utilize the \smpl body shape model~\cite{SMPL:2015} as a prior and learns a deformation model for animation control. 
We use a triplane and three MLPs to coordinate the Gaussians (\eg, their rotation, scale, color, and LBS weights). 
%
%We use a graph representation to bind the Gaussian points and use graph 
% \ar{No graph convs anymore. change this $\rightarrow$}
% convolutions~\cite{graph-conv, coma, cape} to regress the properties of the Gaussian points. 

%While neural fields have established themselves as state-of-the-art approach for representing static 3D scenes, the generalization to dynamic scenes, especially involving humans has been difficult.

%Traditional approaches for representing a human body mainly focused on geometry. Early works~\cite{SMPL:2015, CAPE} learn a mesh representation for humans and their clothing respectively. This enables 
%Following works such as PiFU~\cite{PiFU} use an implicit representation using an occupancy field~\cite{occupancy_nets} .

%GCN works coma, cape, meshcnn
%This problem is inherent to the structure-from-motion ambiguity where the camera motion and the object motion in the scene are entangled. To deal with this, recent approaches~\cite{neuralavatar_zju3d, neuralactor} use multi-camera setup in a capture lab to disentangle camera motion and human motion. 


