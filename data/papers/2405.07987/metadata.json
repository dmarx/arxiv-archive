{
  "arxivId": "2405.07987",
  "title": "The Platonic Representation Hypothesis",
  "authors": "Minyoung Huh, Brian Cheung, Tongzhou Wang, Phillip Isola",
  "abstract": "We argue that representations in AI models, particularly deep networks, are\nconverging. First, we survey many examples of convergence in the literature:\nover time and across multiple domains, the ways by which different neural\nnetworks represent data are becoming more aligned. Next, we demonstrate\nconvergence across data modalities: as vision models and language models get\nlarger, they measure distance between datapoints in a more and more alike way.\nWe hypothesize that this convergence is driving toward a shared statistical\nmodel of reality, akin to Plato's concept of an ideal reality. We term such a\nrepresentation the platonic representation and discuss several possible\nselective pressures toward it. Finally, we discuss the implications of these\ntrends, their limitations, and counterexamples to our analysis.",
  "url": "https://arxiv.org/abs/2405.07987",
  "issue_number": 439,
  "issue_url": "https://github.com/dmarx/papers-feed/issues/439",
  "created_at": "2024-12-30T08:28:13.570462",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 0,
  "last_read": null,
  "last_visited": "2024-12-29T01:39:54.598Z",
  "main_tex_file": null,
  "published_date": "2024-05-13T17:58:30Z",
  "arxiv_tags": [
    "cs.LG",
    "cs.AI",
    "cs.CV",
    "cs.NE"
  ]
}