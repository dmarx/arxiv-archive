\begin{thebibliography}{144}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdou et~al.(2021)Abdou, Kulmizev, Hershcovich, Frank, Pavlick, and
  S{\o}gaard]{abdou2021can}
Abdou, M., Kulmizev, A., Hershcovich, D., Frank, S., Pavlick, E., and
  S{\o}gaard, A.
\newblock Can language models encode perceptual structure without grounding? a
  case study in color.
\newblock \emph{arXiv preprint arXiv:2109.06129}, 2021.

\bibitem[Ainsworth et~al.(2022)Ainsworth, Hayase, and
  Srinivasa]{ainsworth2022git}
Ainsworth, S.~K., Hayase, J., and Srinivasa, S.
\newblock Git re-basin: Merging models modulo permutation symmetries.
\newblock \emph{arXiv preprint arXiv:2209.04836}, 2022.

\bibitem[Antonello \& Huth(2024)Antonello and Huth]{antonello2024predictive}
Antonello, R. and Huth, A.
\newblock Predictive coding or just feature discovery? an alternative account
  of why language models fit brain data.
\newblock \emph{Neurobiology of Language}, 5\penalty0 (1):\penalty0 64--79,
  2024.

\bibitem[Aronszajn(1950)]{aronszajn1950theory}
Aronszajn, N.
\newblock Theory of reproducing kernels.
\newblock \emph{Transactions of the American mathematical society}, 68\penalty0
  (3):\penalty0 337--404, 1950.

\bibitem[Arora et~al.(2019{\natexlab{a}})Arora, Cohen, Hu, and
  Luo]{arora2019implicit}
Arora, S., Cohen, N., Hu, W., and Luo, Y.
\newblock Implicit regularization in deep matrix factorization.
\newblock \emph{Advances in Neural Information Processing Systems}, 32,
  2019{\natexlab{a}}.

\bibitem[Arora et~al.(2019{\natexlab{b}})Arora, Khandeparkar, Khodak,
  Plevrakis, and Saunshi]{arora2019theoretical}
Arora, S., Khandeparkar, H., Khodak, M., Plevrakis, O., and Saunshi, N.
\newblock A theoretical analysis of contrastive unsupervised representation
  learning.
\newblock \emph{arXiv preprint arXiv:1902.09229}, 2019{\natexlab{b}}.

\bibitem[Balestriero \& Baraniuk(2018)Balestriero and
  Baraniuk]{balestriero2018spline}
Balestriero, R. and Baraniuk, R.~G.
\newblock A spline theory of deep learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  374--383. PMLR, 2018.

\bibitem[Bansal et~al.(2021)Bansal, Nakkiran, and Barak]{bansal2021revisiting}
Bansal, Y., Nakkiran, P., and Barak, B.
\newblock Revisiting model stitching to compare neural representations.
\newblock \emph{Advances in neural information processing systems},
  34:\penalty0 225--236, 2021.

\bibitem[Baradad et~al.(2021)Baradad, Wulff, Wang, Isola, and
  Torralba]{baradad2021learning}
Baradad, M., Wulff, J., Wang, T., Isola, P., and Torralba, A.
\newblock Learning to see by looking at noise.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Baradad et~al.(2022)Baradad, Chen, Wulff, Wang, Feris, Torralba, and
  Isola]{baradad2022procedural}
Baradad, M., Chen, R., Wulff, J., Wang, T., Feris, R., Torralba, A., and Isola,
  P.
\newblock Procedural image programs for representation learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 6450--6462, 2022.

\bibitem[Barlow et~al.(1961)]{barlow1961possible}
Barlow, H.~B. et~al.
\newblock Possible principles underlying the transformation of sensory
  messages.
\newblock \emph{Sensory communication}, 1\penalty0 (01):\penalty0 217--233,
  1961.

\bibitem[Betker et~al.(2023)Betker, Goh, Jing, Brooks, Wang, Li, Ouyang,
  Zhuang, Lee, Guo, et~al.]{betker2023improving}
Betker, J., Goh, G., Jing, L., Brooks, T., Wang, J., Li, L., Ouyang, L.,
  Zhuang, J., Lee, J., Guo, Y., et~al.
\newblock Improving image generation with better captions.
\newblock \emph{Computer Science. https://cdn. openai. com/papers/dall-e-3.
  pdf}, 2\penalty0 (3):\penalty0 8, 2023.

\bibitem[BigScience et~al.(2022)BigScience, Scao, Fan, Akiki, Pavlick,
  Ili{\'c}, Hesslow, Castagn{\'e}, Luccioni, Yvon, et~al.]{bigscience2022bloom}
BigScience, Scao, T.~L., Fan, A., Akiki, C., Pavlick, E., Ili{\'c}, S.,
  Hesslow, D., Castagn{\'e}, R., Luccioni, A.~S., Yvon, F., et~al.
\newblock Bloom: A 176b-parameter open-access multilingual language model.
\newblock \emph{arXiv preprint arXiv:2211.05100}, 2022.

\bibitem[Bommasani et~al.(2021)Bommasani, Hudson, Adeli, Altman, Arora, von
  Arx, Bernstein, Bohg, Bosselut, Brunskill,
  et~al.]{bommasani2021opportunities}
Bommasani, R., Hudson, D.~A., Adeli, E., Altman, R., Arora, S., von Arx, S.,
  Bernstein, M.~S., Bohg, J., Bosselut, A., Brunskill, E., et~al.
\newblock On the opportunities and risks of foundation models.
\newblock \emph{arXiv preprint arXiv:2108.07258}, 2021.

\bibitem[Brohan et~al.(2023)Brohan, Brown, Carbajal, Chebotar, Chen,
  Choromanski, Ding, Driess, Dubey, Finn, et~al.]{brohan2023rt}
Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Chen, X., Choromanski, K.,
  Ding, T., Driess, D., Dubey, A., Finn, C., et~al.
\newblock Rt-2: Vision-language-action models transfer web knowledge to robotic
  control.
\newblock \emph{arXiv preprint arXiv:2307.15818}, 2023.

\bibitem[Cao \& Yamins(2024)Cao and Yamins]{cao2021explanatory}
Cao, R. and Yamins, D.
\newblock Explanatory models in neuroscience: Part 2--constraint-based
  intelligibility.
\newblock \emph{Cognitive Systems Research}, 85, 2024.

\bibitem[Caron et~al.(2021)Caron, Touvron, Misra, J{\'e}gou, Mairal,
  Bojanowski, and Joulin]{caron2021emerging}
Caron, M., Touvron, H., Misra, I., J{\'e}gou, H., Mairal, J., Bojanowski, P.,
  and Joulin, A.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  9650--9660, 2021.

\bibitem[Chambers \& Jurafsky(2008)Chambers and
  Jurafsky]{chambers2008unsupervised}
Chambers, N. and Jurafsky, D.
\newblock Unsupervised learning of narrative event chains.
\newblock In \emph{Proceedings of ACL-08: HLT}, pp.\  789--797, 2008.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, pp.\
  1597--1607. PMLR, 2020.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser,
  Plappert, Tworek, Hilton, Nakano, Hesse, and Schulman]{cobbe2021gsm8k}
Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert,
  M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., and Schulman, J.
\newblock Training verifiers to solve math word problems.
\newblock \emph{arXiv preprint arXiv:2110.14168}, 2021.

\bibitem[Conwell et~al.(2022)Conwell, Prince, Kay, Alvarez, and
  Konkle]{conwell2022can}
Conwell, C., Prince, J.~S., Kay, K.~N., Alvarez, G.~A., and Konkle, T.
\newblock What can 1.8 billion regressions tell us about the pressures shaping
  high-level visual representation in brains and machines?
\newblock \emph{BioRxiv}, pp.\  2022--03, 2022.

\bibitem[Dettmers et~al.(2022)Dettmers, Lewis, Belkada, and
  Zettlemoyer]{dettmers2022gpt3}
Dettmers, T., Lewis, M., Belkada, Y., and Zettlemoyer, L.
\newblock Gpt3. int8 (): 8-bit matrix multiplication for transformers at scale.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 30318--30332, 2022.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Diamond(1998)]{diamond1998guns}
Diamond, J.~M.
\newblock \emph{Guns, germs and steel: a short history of everybody for the
  last 13,000 years}.
\newblock Vintage London, 1998.

\bibitem[Dingle et~al.(2018)Dingle, Camargo, and Louis]{dingle2018input}
Dingle, K., Camargo, C.~Q., and Louis, A.~A.
\newblock Input--output maps are strongly biased towards simple outputs.
\newblock \emph{Nature communications}, 9\penalty0 (1):\penalty0 761, 2018.

\bibitem[Doppelt(2007)]{doppelt2007reconstructing}
Doppelt, G.
\newblock Reconstructing scientific realism to rebut the pessimistic
  meta-induction.
\newblock \emph{Philosophy of Science}, 74\penalty0 (1):\penalty0 96--118,
  2007.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Dravid et~al.(2023)Dravid, Gandelsman, Efros, and
  Shocher]{dravid2023rosetta}
Dravid, A., Gandelsman, Y., Efros, A.~A., and Shocher, A.
\newblock Rosetta neurons: Mining the common units in a model zoo.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  1934--1943, 2023.

\bibitem[Driess et~al.(2023)Driess, Xia, Sajjadi, Lynch, Chowdhery, Ichter,
  Wahid, Tompson, Vuong, Yu, et~al.]{driess2023palm}
Driess, D., Xia, F., Sajjadi, M.~S., Lynch, C., Chowdhery, A., Ichter, B.,
  Wahid, A., Tompson, J., Vuong, Q., Yu, T., et~al.
\newblock Palm-e: An embodied multimodal language model.
\newblock \emph{arXiv preprint arXiv:2303.03378}, 2023.

\bibitem[Gao et~al.(2021)Gao, Yao, and Chen]{gao2021simcse}
Gao, T., Yao, X., and Chen, D.
\newblock {SimCSE}: Simple contrastive learning of sentence embeddings.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  2021.

\bibitem[Garipov et~al.(2018)Garipov, Izmailov, Podoprikhin, Vetrov, and
  Wilson]{garipov2018loss}
Garipov, T., Izmailov, P., Podoprikhin, D., Vetrov, D.~P., and Wilson, A.~G.
\newblock Loss surfaces, mode connectivity, and fast ensembling of dnns.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Gell-Mann(1995)]{gell1995quark}
Gell-Mann, M.
\newblock \emph{The Quark and the Jaguar: Adventures in the Simple and the
  Complex}.
\newblock Macmillan, 1995.

\bibitem[Geng \& Liu(2023)Geng and Liu]{openlm2023openllama}
Geng, X. and Liu, H.
\newblock {OpenLLaMA}: An open reproduction of {LLaMA}, May 2023.
\newblock URL \url{https://github.com/openlm-research/open_llama}.

\bibitem[Gokaslan \& Cohen(2019)Gokaslan and Cohen]{Gokaslan2019OpenWeb}
Gokaslan, A. and Cohen, V.
\newblock Openwebtext corpus.
\newblock \url{http://Skylion007.github.io/OpenWebTextCorpus}, 2019.

\bibitem[Goldblum et~al.(2023)Goldblum, Finzi, Rowan, and
  Wilson]{goldblum2023no}
Goldblum, M., Finzi, M., Rowan, K., and Wilson, A.~G.
\newblock The no free lunch theorem, {K}olmogorov complexity, and the role of
  inductive biases in machine learning.
\newblock \emph{arXiv preprint arXiv:2304.05366}, 2023.

\bibitem[Google(2023)]{team2023gemini}
Google.
\newblock Gemini: a family of highly capable multimodal models.
\newblock \emph{arXiv preprint arXiv:2312.11805}, 2023.

\bibitem[Gretton et~al.(2005)Gretton, Bousquet, Smola, and
  Sch{\"o}lkopf]{gretton2005measuring}
Gretton, A., Bousquet, O., Smola, A., and Sch{\"o}lkopf, B.
\newblock Measuring statistical dependence with hilbert-schmidt norms.
\newblock In \emph{International conference on algorithmic learning theory},
  pp.\  63--77. Springer, 2005.

\bibitem[Groeneveld et~al.(2024)Groeneveld, Beltagy, Walsh, Bhagia, Kinney,
  Tafjord, Jha, Ivison, Magnusson, Wang, et~al.]{groeneveld2024olmo}
Groeneveld, D., Beltagy, I., Walsh, P., Bhagia, A., Kinney, R., Tafjord, O.,
  Jha, A.~H., Ivison, H., Magnusson, I., Wang, Y., et~al.
\newblock Olmo: Accelerating the science of language models.
\newblock \emph{arXiv preprint arXiv:2402.00838}, 2024.

\bibitem[Gunasekar et~al.(2018)Gunasekar, Lee, Soudry, and
  Srebro]{gunasekar2018implicit}
Gunasekar, S., Lee, J.~D., Soudry, D., and Srebro, N.
\newblock Implicit bias of gradient descent on linear convolutional networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  9461--9471, 2018.

\bibitem[Gutmann \& Hyv{\"a}rinen(2010)Gutmann and
  Hyv{\"a}rinen]{gutmann2010noise}
Gutmann, M. and Hyv{\"a}rinen, A.
\newblock Noise-contrastive estimation: A new estimation principle for
  unnormalized statistical models.
\newblock In \emph{Proceedings of the thirteenth international conference on
  artificial intelligence and statistics}, pp.\  297--304. JMLR Workshop and
  Conference Proceedings, 2010.

\bibitem[Ha \& Schmidhuber(2018)Ha and Schmidhuber]{ha2018world}
Ha, D. and Schmidhuber, J.
\newblock World models.
\newblock \emph{arXiv preprint arXiv:1803.10122}, 2018.

\bibitem[Hall et~al.(2022)Hall, van~der Maaten, Gustafson, Jones, and
  Adcock]{hall2022systematic}
Hall, M., van~der Maaten, L., Gustafson, L., Jones, M., and Adcock, A.
\newblock A systematic study of bias amplification.
\newblock \emph{arXiv preprint arXiv:2201.11706}, 2022.

\bibitem[Hardin \& Rosenberg(1982)Hardin and Rosenberg]{hardin1982defense}
Hardin, C.~L. and Rosenberg, A.
\newblock In defense of convergent realism.
\newblock \emph{Philosophy of Science}, 49\penalty0 (4):\penalty0 604--615,
  1982.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  9729--9738, 2020.

\bibitem[He et~al.(2021)He, Chen, Xie, Li, Doll’ar, and
  Girshick]{he2021masked}
He, K., Chen, X., Xie, S., Li, Y., Doll’ar, P., and Girshick, R.~B.
\newblock Masked autoencoders are scalable vision learners. 2022 ieee.
\newblock In \emph{CVF Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  15979--15988, 2021.

\bibitem[Held et~al.(2011)Held, Ostrovsky, de~Gelder, Gandhi, Ganesh, Mathur,
  and Sinha]{held2011newly}
Held, R., Ostrovsky, Y., de~Gelder, B., Gandhi, T., Ganesh, S., Mathur, U., and
  Sinha, P.
\newblock The newly sighted fail to match seen with felt.
\newblock \emph{Nature neuroscience}, 14\penalty0 (5):\penalty0 551--553, 2011.

\bibitem[Hestness et~al.(2017)Hestness, Narang, Ardalani, Diamos, Jun,
  Kianinejad, Patwary, Yang, and Zhou]{hestness2017deep}
Hestness, J., Narang, S., Ardalani, N., Diamos, G., Jun, H., Kianinejad, H.,
  Patwary, M. M.~A., Yang, Y., and Zhou, Y.
\newblock Deep learning scaling is predictable, empirically.
\newblock \emph{arXiv preprint arXiv:1712.00409}, 2017.

\bibitem[Hooker(2021)]{hooker2021hardware}
Hooker, S.
\newblock The hardware lottery.
\newblock \emph{Communications of the ACM}, 64\penalty0 (12):\penalty0 58--65,
  2021.

\bibitem[Huh et~al.(2023)Huh, Mobahi, Zhang, Cheung, Agrawal, and
  Isola]{huh2023simplicitybias}
Huh, M., Mobahi, H., Zhang, R., Cheung, B., Agrawal, P., and Isola, P.
\newblock The low-rank simplicity bias in deep networks.
\newblock \emph{Transactions on Machine Learning Research}, 2023.
\newblock ISSN 2835-8856.
\newblock URL \url{https://openreview.net/forum?id=bCiNWDmlY2}.

\bibitem[Isola(2015)]{isola_thesis}
Isola, P.
\newblock The discovery of perceptual structure from visual co-occurrences in
  space and time.
\newblock In \emph{MIT Ph.D. Thesis}, 2015.

\bibitem[Isola et~al.(2014)Isola, Zoran, Krishnan, and
  Adelson]{crisp_boundaries}
Isola, P., Zoran, D., Krishnan, D., and Adelson, E.~H.
\newblock Crisp boundary detection using pointwise mutual information.
\newblock In \emph{ECCV}, 2014.

\bibitem[Isola et~al.(2016)Isola, Zoran, Krishnan, and Adelson]{isola_cooc}
Isola, P., Zoran, D., Krishnan, D., and Adelson, E.~H.
\newblock Learning visual groups from co-occurrences in space and time.
\newblock In \emph{ICLR, Workshop paper}, 2016.

\bibitem[Jiang et~al.(2023)Jiang, Sablayrolles, Mensch, Bamford, Chaplot,
  Casas, Bressand, Lengyel, Lample, Saulnier, et~al.]{jiang2023mistral}
Jiang, A.~Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D.~S., Casas,
  D. d.~l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., et~al.
\newblock Mistral 7b.
\newblock \emph{arXiv preprint arXiv:2310.06825}, 2023.

\bibitem[Jiang et~al.(2024)Jiang, Sablayrolles, Roux, Mensch, Savary, Bamford,
  Chaplot, Casas, Hanna, Bressand, et~al.]{jiang2024mixtral}
Jiang, A.~Q., Sablayrolles, A., Roux, A., Mensch, A., Savary, B., Bamford, C.,
  Chaplot, D.~S., Casas, D. d.~l., Hanna, E.~B., Bressand, F., et~al.
\newblock Mixtral of experts.
\newblock \emph{arXiv preprint arXiv:2401.04088}, 2024.

\bibitem[Jordan et~al.(2022)Jordan, Sedghi, Saukh, Entezari, and
  Neyshabur]{jordan2022repair}
Jordan, K., Sedghi, H., Saukh, O., Entezari, R., and Neyshabur, B.
\newblock Repair: Renormalizing permuted activations for interpolation repair.
\newblock \emph{arXiv preprint arXiv:2211.08403}, 2022.

\bibitem[Kabsch(1976)]{kabsch1976solution}
Kabsch, W.
\newblock A solution for the best rotation to relate two sets of vectors.
\newblock \emph{Acta Crystallographica Section A: Crystal Physics, Diffraction,
  Theoretical and General Crystallography}, 32\penalty0 (5):\penalty0 922--923,
  1976.

\bibitem[Kabsch(1978)]{kabsch1978discussion}
Kabsch, W.
\newblock A discussion of the solution for the best rotation to relate two sets
  of vectors.
\newblock \emph{Acta Crystallographica Section A: Crystal Physics, Diffraction,
  Theoretical and General Crystallography}, 34\penalty0 (5):\penalty0 827--828,
  1978.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child,
  Gray, Radford, Wu, and Amodei]{kaplan2020scaling}
Kaplan, J., McCandlish, S., Henighan, T., Brown, T.~B., Chess, B., Child, R.,
  Gray, S., Radford, A., Wu, J., and Amodei, D.
\newblock Scaling laws for neural language models.
\newblock \emph{arXiv preprint arXiv:2001.08361}, 2020.

\bibitem[Klabunde et~al.(2023)Klabunde, Schumacher, Strohmaier, and
  Lemmerich]{klabunde2023similarity}
Klabunde, M., Schumacher, T., Strohmaier, M., and Lemmerich, F.
\newblock Similarity of neural network models: A survey of functional and
  representational measures.
\newblock \emph{arXiv preprint arXiv:2305.06329}, 2023.

\bibitem[Koh et~al.(2023)Koh, Salakhutdinov, and Fried]{koh2023grounding}
Koh, J.~Y., Salakhutdinov, R., and Fried, D.
\newblock Grounding language models to images for multimodal inputs and
  outputs.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  17283--17300. PMLR, 2023.

\bibitem[Kornblith et~al.(2019)Kornblith, Norouzi, Lee, and
  Hinton]{kornblith2019similarity}
Kornblith, S., Norouzi, M., Lee, H., and Hinton, G.
\newblock Similarity of neural network representations revisited.
\newblock In \emph{International conference on machine learning}, pp.\
  3519--3529. PMLR, 2019.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Krizhevsky et~al.(2017)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2017imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Communications of the ACM}, 60\penalty0 (6):\penalty0 84--90,
  2017.

\bibitem[Lample et~al.(2018)Lample, Ott, Conneau, Denoyer, and
  Ranzato]{lample-etal-2018-phrase}
Lample, G., Ott, M., Conneau, A., Denoyer, L., and Ranzato, M.
\newblock Phrase-based {\&} neural unsupervised machine translation.
\newblock In Riloff, E., Chiang, D., Hockenmaier, J., and Tsujii, J. (eds.),
  \emph{Proceedings of the 2018 Conference on Empirical Methods in Natural
  Language Processing}, Brussels, Belgium, October-November 2018. Association
  for Computational Linguistics.

\bibitem[Lenc \& Vedaldi(2015)Lenc and Vedaldi]{lenc2015understanding}
Lenc, K. and Vedaldi, A.
\newblock Understanding image representations by measuring their equivariance
  and equivalence.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  991--999, 2015.

\bibitem[Li et~al.(2023)Li, Katabi, and He]{RCG2023}
Li, T., Katabi, D., and He, K.
\newblock Return of unconditional generation: A self-supervised representation
  generation method.
\newblock \emph{arXiv:2312.03701}, 2023.

\bibitem[Lian et~al.(2023{\natexlab{a}})Lian, Li, Yala, and
  Darrell]{lian2023llm}
Lian, L., Li, B., Yala, A., and Darrell, T.
\newblock {LLM}-grounded diffusion: Enhancing prompt understanding of
  text-to-image diffusion models with large language models.
\newblock \emph{arXiv preprint arXiv:2305.13655}, 2023{\natexlab{a}}.

\bibitem[Lian et~al.(2023{\natexlab{b}})Lian, Shi, Yala, Darrell, and
  Li]{lian2023llmvideo}
Lian, L., Shi, B., Yala, A., Darrell, T., and Li, B.
\newblock {LLM}-grounded video diffusion models.
\newblock \emph{arXiv preprint arXiv:2309.17444}, 2023{\natexlab{b}}.

\bibitem[Lindsey \& Brown(2014)Lindsey and Brown]{lindsey2014color}
Lindsey, D.~T. and Brown, A.~M.
\newblock The color lexicon of american english.
\newblock \emph{Journal of vision}, 14\penalty0 (2):\penalty0 17--17, 2014.

\bibitem[Liu et~al.(2023)Liu, Li, Wu, and Lee]{liu2023llava}
Liu, H., Li, C., Wu, Q., and Lee, Y.~J.
\newblock Visual instruction tuning.
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Liu et~al.(2020)Liu, Wang, Bau, Zhu, and
  Torralba]{liu2020selfconditioned}
Liu, S., Wang, T., Bau, D., Zhu, J.-Y., and Torralba, A.
\newblock Diverse image generation via self-conditioned {GANs}.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, 2020.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov]{liu2019roberta}
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M.,
  Zettlemoyer, L., and Stoyanov, V.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem[Locke(1690)]{locke_molyneaux}
Locke, J.
\newblock \emph{An Essay Concerning Human Understanding}.
\newblock 1690.

\bibitem[L{\'o}pez-Cifuentes et~al.(2020)L{\'o}pez-Cifuentes, Escudero-Vinolo,
  Besc{\'o}s, and Garc{\'\i}a-Mart{\'\i}n]{lopez2020semantic}
L{\'o}pez-Cifuentes, A., Escudero-Vinolo, M., Besc{\'o}s, J., and
  Garc{\'\i}a-Mart{\'\i}n, {\'A}.
\newblock Semantic-aware scene recognition.
\newblock \emph{Pattern Recognition}, 102:\penalty0 107256, 2020.

\bibitem[Lu et~al.(2021)Lu, Grover, Abbeel, and Mordatch]{lu2021pretrained}
Lu, K., Grover, A., Abbeel, P., and Mordatch, I.
\newblock Pretrained transformers as universal computation engines.
\newblock \emph{arXiv preprint arXiv:2103.05247}, 1, 2021.

\bibitem[Lubana et~al.(2023)Lubana, Bigelow, Dick, Krueger, and
  Tanaka]{lubana2023mechanistic}
Lubana, E.~S., Bigelow, E.~J., Dick, R.~P., Krueger, D., and Tanaka, H.
\newblock Mechanistic mode connectivity.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  22965--23004. PMLR, 2023.

\bibitem[Ma et~al.(2024)Ma, He, Li, Han, You, and Wang]{ma2024segment}
Ma, J., He, Y., Li, F., Han, L., You, C., and Wang, B.
\newblock Segment anything in medical images.
\newblock \emph{Nature Communications}, 15\penalty0 (1):\penalty0 654, 2024.

\bibitem[Maniparambil et~al.(2024)Maniparambil, Akshulakov, Djilali,
  El~Amine~Seddik, Narayan, Mangalam, and O'Connor]{maniparambil2024vision}
Maniparambil, M., Akshulakov, R., Djilali, Y. A.~D., El~Amine~Seddik, M.,
  Narayan, S., Mangalam, K., and O'Connor, N.~E.
\newblock Do vision and language encoders represent the world similarly?
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  14334--14343, 2024.

\bibitem[McInnes et~al.(2018)McInnes, Healy, and Melville]{mcinnes2018umap}
McInnes, L., Healy, J., and Melville, J.
\newblock Umap: Uniform manifold approximation and projection for dimension
  reduction.
\newblock \emph{arXiv preprint arXiv:1802.03426}, 2018.

\bibitem[Merullo et~al.(2022)Merullo, Castricato, Eickhoff, and
  Pavlick]{merullo2022linearly}
Merullo, J., Castricato, L., Eickhoff, C., and Pavlick, E.
\newblock Linearly mapping from image to text space.
\newblock \emph{arXiv preprint arXiv:2209.15162}, 2022.

\bibitem[{Meta}(2024)]{meta2024llama3}
{Meta}.
\newblock {Meta LLaMA 3}, 2024.
\newblock URL \url{https://ai.meta.com/blog/meta-llama-3/}.

\bibitem[Mirchandani et~al.(2023)Mirchandani, Xia, Florence, Ichter, Driess,
  Arenas, Rao, Sadigh, and Zeng]{mirchandani2023large}
Mirchandani, S., Xia, F., Florence, P., Ichter, B., Driess, D., Arenas, M.~G.,
  Rao, K., Sadigh, D., and Zeng, A.
\newblock Large language models as general pattern machines.
\newblock \emph{arXiv preprint arXiv:2307.04721}, 2023.

\bibitem[Mirza \& Osindero(2014)Mirza and Osindero]{mirza2014conditional}
Mirza, M. and Osindero, S.
\newblock Conditional generative adversarial nets.
\newblock \emph{arXiv preprint arXiv:1411.1784}, 2014.

\bibitem[Moschella et~al.(2022)Moschella, Maiorca, Fumero, Norelli, Locatello,
  and Rodol{\`a}]{moschella2022relative}
Moschella, L., Maiorca, V., Fumero, M., Norelli, A., Locatello, F., and
  Rodol{\`a}, E.
\newblock Relative representations enable zero-shot latent space communication.
\newblock \emph{arXiv preprint arXiv:2209.15430}, 2022.

\bibitem[Nagarajan \& Kolter(2019)Nagarajan and Kolter]{nagarajan2019uniform}
Nagarajan, V. and Kolter, J.~Z.
\newblock Uniform convergence may be unable to explain generalization in deep
  learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Nettleship(1897)]{nettleship1897lecturesplato}
Nettleship, R.~L.
\newblock \emph{Lectures on the `Republic' of Plato}, volume~2.
\newblock Macmillan, 1897.

\bibitem[Newton-Smith(1981)]{newton1981rationality}
Newton-Smith, W.
\newblock \emph{The Rationality of Science}.
\newblock International Library of Philosophy, Psychology, and Scientific
  Method. Routledge \& Kegan Paul, 1981.
\newblock ISBN 9780710009135.

\bibitem[Ng et~al.(2023)Ng, Subramanian, Klein, Kanazawa, Darrell, and
  Ginosar]{ng2023can}
Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., and Ginosar, S.
\newblock Can language models learn to listen?
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  10083--10093, 2023.

\bibitem[Ngo \& Kim(2024)Ngo and Kim]{ngo2024language}
Ngo, J. and Kim, Y.
\newblock What do language models hear? probing for auditory representations in
  language models, 2024.

\bibitem[Olshausen \& Field(1996)Olshausen and Field]{olshausen1996emergence}
Olshausen, B.~A. and Field, D.~J.
\newblock Emergence of simple-cell receptive field properties by learning a
  sparse code for natural images.
\newblock \emph{Nature}, 381\penalty0 (6583):\penalty0 607--609, 1996.

\bibitem[Olshausen \& Field(1997)Olshausen and Field]{olshausen1997sparse}
Olshausen, B.~A. and Field, D.~J.
\newblock Sparse coding with an overcomplete basis set: A strategy employed by
  v1?
\newblock \emph{Vision research}, 37\penalty0 (23):\penalty0 3311--3325, 1997.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[OpenAI(2023)]{achiam2023gpt}
OpenAI.
\newblock {GPT-4} technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Oquab et~al.(2023)Oquab, Darcet, Moutakanni, Vo, Szafraniec, Khalidov,
  Fernandez, Haziza, Massa, El-Nouby, Howes, Huang, Xu, Sharma, Li, Galuba,
  Rabbat, Assran, Ballas, Synnaeve, Misra, Jegou, Mairal, Labatut, Joulin, and
  Bojanowski]{oquab2023dinov2}
Oquab, M., Darcet, T., Moutakanni, T., Vo, H.~V., Szafraniec, M., Khalidov, V.,
  Fernandez, P., Haziza, D., Massa, F., El-Nouby, A., Howes, R., Huang, P.-Y.,
  Xu, H., Sharma, V., Li, S.-W., Galuba, W., Rabbat, M., Assran, M., Ballas,
  N., Synnaeve, G., Misra, I., Jegou, H., Mairal, J., Labatut, P., Joulin, A.,
  and Bojanowski, P.
\newblock Dinov2: Learning robust visual features without supervision, 2023.

\bibitem[Oron et~al.(2017)Oron, Dekel, Xue, Freeman, and Avidan]{oron2017best}
Oron, S., Dekel, T., Xue, T., Freeman, W.~T., and Avidan, S.
\newblock Best-buddies similarity—robust template matching using mutual
  nearest neighbors.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 40\penalty0 (8):\penalty0 1799--1813, 2017.

\bibitem[Papyan et~al.(2020)Papyan, Han, and Donoho]{papyan2020prevalence}
Papyan, V., Han, X., and Donoho, D.~L.
\newblock Prevalence of neural collapse during the terminal phase of deep
  learning training.
\newblock \emph{Proceedings of the National Academy of Sciences}, 117\penalty0
  (40):\penalty0 24652--24663, 2020.

\bibitem[Park et~al.(2024)Park, Wang, Ardeshir, and
  Azizan]{park2024quantifying}
Park, Y.-J., Wang, H., Ardeshir, S., and Azizan, N.
\newblock Quantifying representation reliability in self-supervised learning
  models.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, 2024.

\bibitem[Plato(c. 375 BC)]{plato_cave}
Plato.
\newblock Republic.
\newblock c. 375 BC.

\bibitem[Putnam(1982)]{putnam1982three}
Putnam, H.
\newblock Three kinds of scientific realism.
\newblock \emph{The Philosophical Quarterly (1950-)}, 32\penalty0
  (128):\penalty0 195--200, 1982.

\bibitem[Radford et~al.(2017)Radford, Jozefowicz, and
  Sutskever]{radford2017learning}
Radford, A., Jozefowicz, R., and Sutskever, I.
\newblock Learning to generate reviews and discovering sentiment.
\newblock \emph{arXiv preprint arXiv:1704.01444}, 2017.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever,
  et~al.]{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry,
  G., Askell, A., Mishkin, P., Clark, J., et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International conference on machine learning}, pp.\
  8748--8763. PMLR, 2021.

\bibitem[Raghu et~al.(2017)Raghu, Gilmer, Yosinski, and
  Sohl-Dickstein]{raghu2017svcca}
Raghu, M., Gilmer, J., Yosinski, J., and Sohl-Dickstein, J.
\newblock Svcca: Singular vector canonical correlation analysis for deep
  learning dynamics and interpretability.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Richens \& Everitt(2024)Richens and Everitt]{richens2024robust}
Richens, J. and Everitt, T.
\newblock Robust agents learn causal world models.
\newblock \emph{ICLR}, 2024.

\bibitem[Roeder et~al.(2021)Roeder, Metz, and Kingma]{roeder2021linear}
Roeder, G., Metz, L., and Kingma, D.
\newblock On linear identifiability of learned representations.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  9030--9039. PMLR, 2021.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115:\penalty0
  211--252, 2015.

\bibitem[Sauer et~al.(2022)Sauer, Schwarz, and Geiger]{sauer2022styleganxl}
Sauer, A., Schwarz, K., and Geiger, A.
\newblock {StylegGAN-XL}: Scaling {StyleGAN} to large diverse datasets.
\newblock In \emph{ACM SIGGRAPH 2022 conference proceedings}, pp.\  1--10,
  2022.

\bibitem[Schrimpf et~al.(2018)Schrimpf, Kubilius, Hong, Majaj, Rajalingham,
  Issa, Kar, Bashivan, Prescott-Roy, Geiger, et~al.]{schrimpf2018brain}
Schrimpf, M., Kubilius, J., Hong, H., Majaj, N.~J., Rajalingham, R., Issa,
  E.~B., Kar, K., Bashivan, P., Prescott-Roy, J., Geiger, F., et~al.
\newblock Brain-score: Which artificial neural network for object recognition
  is most brain-like?
\newblock \emph{BioRxiv}, pp.\  407007, 2018.

\bibitem[Sharma et~al.(2024)Sharma, Rott~Shaham, Baradad, Fu, Rodriguez-Munoz,
  Duggal, Isola, and Torralba]{sharma2024vision}
Sharma, P., Rott~Shaham, T., Baradad, M., Fu, S., Rodriguez-Munoz, A., Duggal,
  S., Isola, P., and Torralba, A.
\newblock A vision check-up for language models.
\newblock In \emph{arXiv preprint}, 2024.

\bibitem[Shepard(1980)]{shepard1980multidimensional}
Shepard, R.~N.
\newblock Multidimensional scaling, tree-fitting, and clustering.
\newblock \emph{Science}, 210\penalty0 (4468):\penalty0 390--398, 1980.

\bibitem[Shi et~al.(2024)Shi, De~Bortoli, Campbell, and
  Doucet]{shi2024diffusion}
Shi, Y., De~Bortoli, V., Campbell, A., and Doucet, A.
\newblock Diffusion schr{\"o}dinger bridge matching.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Smola \& Sch{\"o}lkopf(1998)Smola and
  Sch{\"o}lkopf]{smola1998learning}
Smola, A.~J. and Sch{\"o}lkopf, B.
\newblock \emph{Learning with kernels}, volume~4.
\newblock Citeseer, 1998.

\bibitem[Solomonoff(1964)]{solomonoff1964formal}
Solomonoff, R.~J.
\newblock A formal theory of inductive inference. part i.
\newblock \emph{Information and control}, 7\penalty0 (1):\penalty0 1--22, 1964.

\bibitem[Song et~al.(2012)Song, Smola, Gretton, Bedo, and
  Borgwardt]{song2012feature}
Song, L., Smola, A., Gretton, A., Bedo, J., and Borgwardt, K.
\newblock Feature selection via dependence maximization.
\newblock \emph{Journal of Machine Learning Research}, 13\penalty0 (5), 2012.

\bibitem[Sorscher et~al.(2022)Sorscher, Ganguli, and
  Sompolinsky]{sorscher2022neural}
Sorscher, B., Ganguli, S., and Sompolinsky, H.
\newblock Neural representational geometry underlies few-shot concept learning.
\newblock \emph{Proceedings of the National Academy of Sciences}, 119\penalty0
  (43):\penalty0 e2200800119, 2022.

\bibitem[Srinivasan et~al.(2021)Srinivasan, Raman, Chen, Bendersky, and
  Najork]{srinivasan2021wit}
Srinivasan, K., Raman, K., Chen, J., Bendersky, M., and Najork, M.
\newblock Wit: Wikipedia-based image text dataset for multimodal multilingual
  machine learning.
\newblock In \emph{Proceedings of the 44th International ACM SIGIR Conference
  on Research and Development in Information Retrieval}, pp.\  2443--2449,
  2021.

\bibitem[Srivastava et~al.(2022)Srivastava, Rastogi, Rao, Shoeb, Abid, Fisch,
  Brown, Santoro, Gupta, Garriga-Alonso, et~al.]{srivastava2022beyond}
Srivastava, A., Rastogi, A., Rao, A., Shoeb, A. A.~M., Abid, A., Fisch, A.,
  Brown, A.~R., Santoro, A., Gupta, A., Garriga-Alonso, A., et~al.
\newblock Beyond the imitation game: Quantifying and extrapolating the
  capabilities of language models.
\newblock \emph{arXiv preprint arXiv:2206.04615}, 2022.

\bibitem[Steinberg et~al.(2021)Steinberg, Jung, Fries, Corbin, Pfohl, and
  Shah]{steinberg2021language}
Steinberg, E., Jung, K., Fries, J.~A., Corbin, C.~K., Pfohl, S.~R., and Shah,
  N.~H.
\newblock Language models are an effective representation learning technique
  for electronic health record data.
\newblock \emph{Journal of biomedical informatics}, 113:\penalty0 103637, 2021.

\bibitem[Stoica et~al.(2023)Stoica, Bolya, Bjorner, Hearn, and
  Hoffman]{stoica2023zipit}
Stoica, G., Bolya, D., Bjorner, J., Hearn, T., and Hoffman, J.
\newblock Zipit! merging models from different tasks without training.
\newblock \emph{arXiv preprint arXiv:2305.03053}, 2023.

\bibitem[Sucholutsky et~al.(2023)Sucholutsky, Muttenthaler, Weller, Peng, Bobu,
  Kim, Love, Grant, Groen, Achterberg, Tenenbaum, Collins, Hermann, Oktar,
  Greff, Hebart, Jacoby, Zhang, Marjieh, Geirhos, Chen, Kornblith, Rane,
  Konkle, O'Connell, Unterthiner, Lampinen, Müller, Toneva, and
  Griffiths]{sucholutsky2023getting}
Sucholutsky, I., Muttenthaler, L., Weller, A., Peng, A., Bobu, A., Kim, B.,
  Love, B.~C., Grant, E., Groen, I., Achterberg, J., Tenenbaum, J.~B., Collins,
  K.~M., Hermann, K.~L., Oktar, K., Greff, K., Hebart, M.~N., Jacoby, N.,
  Zhang, Q., Marjieh, R., Geirhos, R., Chen, S., Kornblith, S., Rane, S.,
  Konkle, T., O'Connell, T.~P., Unterthiner, T., Lampinen, A.~K., Müller,
  K.-R., Toneva, M., and Griffiths, T.~L.
\newblock Getting aligned on representational alignment, 2023.

\bibitem[Team et~al.(2024)Team, Mesnard, Hardin, Dadashi, Bhupatiraju, Pathak,
  Sifre, Rivi{\`e}re, Kale, Love, et~al.]{team2024gemma}
Team, G., Mesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S.,
  Sifre, L., Rivi{\`e}re, M., Kale, M.~S., Love, J., et~al.
\newblock Gemma: Open models based on gemini research and technology.
\newblock \emph{arXiv preprint arXiv:2403.08295}, 2024.

\bibitem[Tian et~al.(2020{\natexlab{a}})Tian, Krishnan, and
  Isola]{tian2020contrastive}
Tian, Y., Krishnan, D., and Isola, P.
\newblock Contrastive multiview coding.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XI 16}, pp.\  776--794.
  Springer, 2020{\natexlab{a}}.

\bibitem[Tian et~al.(2020{\natexlab{b}})Tian, Wang, Krishnan, Tenenbaum, and
  Isola]{tian2020rethinking}
Tian, Y., Wang, Y., Krishnan, D., Tenenbaum, J.~B., and Isola, P.
\newblock Rethinking few-shot image classification: a good embedding is all you
  need?
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XIV 16}, pp.\  266--282.
  Springer, 2020{\natexlab{b}}.

\bibitem[Tolstoy(1877)]{tolstoy1877anna}
Tolstoy, L.
\newblock \emph{Anna Karenina}.
\newblock The Russian Messenger, 1877.

\bibitem[Torralba et~al.(2008)Torralba, Fergus, and Freeman]{torralba200880}
Torralba, A., Fergus, R., and Freeman, W.~T.
\newblock 80 million tiny images: A large data set for nonparametric object and
  scene recognition.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 30\penalty0 (11):\penalty0 1958--1970, 2008.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei,
  Bashlykov, Batra, Bhargava, Bhosale, et~al.]{touvron2023llama}
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y.,
  Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et~al.
\newblock {LLaMA} 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023.

\bibitem[Tran et~al.(2017)Tran, Burda, and Sutskever]{tranfeature2017tran}
Tran, D., Burda, Y., and Sutskever, I.
\newblock Feature-matching auto-encoders.
\newblock 2017.

\bibitem[Umeyama(1991)]{umeyama1991least}
Umeyama, S.
\newblock Least-squares estimation of transformation parameters between two
  point patterns.
\newblock \emph{IEEE Transactions on Pattern Analysis \& Machine Intelligence},
  13\penalty0 (04):\penalty0 376--380, 1991.

\bibitem[Urbanek et~al.(2023)Urbanek, Bordes, Astolfi, Williamson, Sharma, and
  Romero-Soriano]{urbanek2023picture}
Urbanek, J., Bordes, F., Astolfi, P., Williamson, M., Sharma, V., and
  Romero-Soriano, A.
\newblock A picture is worth more than 77 text tokens: Evaluating {CLIP}-style
  models on dense captions, 2023.

\bibitem[Valle-Perez et~al.(2019)Valle-Perez, Camargo, and
  Louis]{valle2018deep}
Valle-Perez, G., Camargo, C.~Q., and Louis, A.~A.
\newblock Deep learning generalizes because the parameter-function map is
  biased towards simple functions.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Wang \& Isola(2020)Wang and Isola]{tongzhouw2020hypersphere}
Wang, T. and Isola, P.
\newblock Understanding contrastive representation learning through alignment
  and uniformity on the hypersphere.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  9929--9939. PMLR, 2020.

\bibitem[Werbos(1987)]{werbos1987learning}
Werbos, P.~J.
\newblock Learning how the world works: Specifications for predictive networks
  in robots and brains.
\newblock In \emph{Proceedings of IEEE International Conference on Systems, Man
  and Cybernetics, NY}, 1987.

\bibitem[Wightman(2021)]{timm}
Wightman, R.
\newblock {PyTorch} image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2021.

\bibitem[Wolf et~al.(2019)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, et~al.]{wolf2019huggingface}
Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P.,
  Rault, T., Louf, R., Funtowicz, M., et~al.
\newblock Huggingface's transformers: State-of-the-art natural language
  processing.
\newblock \emph{arXiv preprint arXiv:1910.03771}, 2019.

\bibitem[Wortsman et~al.(2022)Wortsman, Ilharco, Gadre, Roelofs, Gontijo-Lopes,
  Morcos, Namkoong, Farhadi, Carmon, Kornblith, et~al.]{wortsman2022model}
Wortsman, M., Ilharco, G., Gadre, S.~Y., Roelofs, R., Gontijo-Lopes, R.,
  Morcos, A.~S., Namkoong, H., Farhadi, A., Carmon, Y., Kornblith, S., et~al.
\newblock Model soups: averaging weights of multiple fine-tuned models improves
  accuracy without increasing inference time.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  23965--23998. PMLR, 2022.

\bibitem[Wu et~al.(2023)Wu, Lian, Gonzalez, Li, and Darrell]{wu2023self}
Wu, T.-H., Lian, L., Gonzalez, J.~E., Li, B., and Darrell, T.
\newblock Self-correcting {LLM}-controlled diffusion models.
\newblock \emph{arXiv preprint arXiv:2311.16090}, 2023.

\bibitem[Xie et~al.(2022)Xie, Ho, and Zhang]{xie2022unsupervised}
Xie, S., Ho, Q., and Zhang, K.
\newblock Unsupervised image-to-image translation with density changing
  regularization.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 28545--28558, 2022.

\bibitem[Yamins et~al.(2014)Yamins, Hong, Cadieu, Solomon, Seibert, and
  DiCarlo]{yamins2014performance}
Yamins, D.~L., Hong, H., Cadieu, C.~F., Solomon, E.~A., Seibert, D., and
  DiCarlo, J.~J.
\newblock Performance-optimized hierarchical models predict neural responses in
  higher visual cortex.
\newblock \emph{Proceedings of the national academy of sciences}, 111\penalty0
  (23):\penalty0 8619--8624, 2014.

\bibitem[Zellers et~al.(2019)Zellers, Holtzman, Bisk, Farhadi, and
  Choi]{zellers2019hellaswag}
Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., and Choi, Y.
\newblock {H}ella{S}wag: Can a machine really finish your sentence?
\newblock In Korhonen, A., Traum, D., and M{\`a}rquez, L. (eds.),
  \emph{Proceedings of the 57th Annual Meeting of the Association for
  Computational Linguistics}, pp.\  4791--4800, Florence, Italy, July 2019.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P19-1472}.
\newblock URL \url{https://aclanthology.org/P19-1472}.

\bibitem[Zhai et~al.(2019)Zhai, Puigcerver, Kolesnikov, Ruyssen, Riquelme,
  Lucic, Djolonga, Pinto, Neumann, Dosovitskiy, et~al.]{zhai2019vtab}
Zhai, X., Puigcerver, J., Kolesnikov, A., Ruyssen, P., Riquelme, C., Lucic, M.,
  Djolonga, J., Pinto, A.~S., Neumann, M., Dosovitskiy, A., et~al.
\newblock The visual task adaptation benchmark.
\newblock 2019.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and
  Wang]{zhang2018unreasonable}
Zhang, R., Isola, P., Efros, A.~A., Shechtman, E., and Wang, O.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  586--595, 2018.

\bibitem[Zhou et~al.(2017)Zhou, Lapedriza, Khosla, Oliva, and
  Torralba]{zhou2017places}
Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., and Torralba, A.
\newblock Places: A 10 million image database for scene recognition.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 40\penalty0 (6):\penalty0 1452--1464, 2017.

\bibitem[Zhu et~al.(2017)Zhu, Park, Isola, and Efros]{CycleGAN2017}
Zhu, J.-Y., Park, T., Isola, P., and Efros, A.~A.
\newblock Unpaired image-to-image translation using cycle-consistent
  adversarial networks.
\newblock In \emph{Computer Vision (ICCV), 2017 IEEE International Conference
  on}, 2017.

\bibitem[Zimmermann et~al.(2021)Zimmermann, Sharma, Schneider, Bethge, and
  Brendel]{zimmermann2021contrastive}
Zimmermann, R.~S., Sharma, Y., Schneider, S., Bethge, M., and Brendel, W.
\newblock Contrastive learning inverts the data generating process.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  12979--12990. PMLR, 2021.

\end{thebibliography}
