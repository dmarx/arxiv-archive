\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bao et~al.(2023)Bao, Nie, Xue, Cao, Li, Su, and Zhu]{bao2023all}
Fan Bao, Shen Nie, Kaiwen Xue, Yue Cao, Chongxuan Li, Hang Su, and Jun Zhu.
\newblock All are worth words: A vit backbone for diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  22669--22679, 2023.

\bibitem[Cai et~al.(2020)Cai, Gan, Zhu, and Han]{cai2020tinytl}
Han Cai, Chuang Gan, Ligeng Zhu, and Song Han.
\newblock Tinytl: Reduce memory, not parameters for efficient on-device learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 11285--11297, 2020.

\bibitem[Cai et~al.(2023)Cai, Li, Hu, Gan, and Han]{cai2023efficientvit}
Han Cai, Junyan Li, Muyan Hu, Chuang Gan, and Song Han.
\newblock Efficientvit: Lightweight multi-scale attention for high-resolution dense prediction.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  17302--17313, 2023.

\bibitem[Cai et~al.(2024)Cai, Li, Zhang, Liu, and Han]{cai2024condition}
Han Cai, Muyang Li, Qinsheng Zhang, Ming-Yu Liu, and Song Han.
\newblock Condition-aware neural network for controlled image generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  7194--7203, 2024.

\bibitem[Chen et~al.(2024{\natexlab{a}})Chen, Ge, Xie, Wu, Yao, Ren, Wang, Luo, Lu, and Li]{chen2024pixart}
Junsong Chen, Chongjian Ge, Enze Xie, Yue Wu, Lewei Yao, Xiaozhe Ren, Zhongdao Wang, Ping Luo, Huchuan Lu, and Zhenguo Li.
\newblock Pixart-$\sigma$: Weak-to-strong training of diffusion transformer for 4k text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2403.04692}, 2024{\natexlab{a}}.

\bibitem[Chen et~al.(2024{\natexlab{b}})Chen, Jincheng, Chongjian, Yao, Xie, Wang, Kwok, Luo, Lu, and Li]{chenpixart}
Junsong Chen, YU~Jincheng, GE~Chongjian, Lewei Yao, Enze Xie, Zhongdao Wang, James Kwok, Ping Luo, Huchuan Lu, and Zhenguo Li.
\newblock Pixart-$\alpha$: Fast training of diffusion transformer for photorealistic text-to-image synthesis.
\newblock In \emph{International Conference on Learning Representations}, 2024{\natexlab{b}}.

\bibitem[Dai et~al.(2023)Dai, Hou, Ma, Tsai, Wang, Wang, Zhang, Vandenhende, Wang, Dubey, et~al.]{dai2023emu}
Xiaoliang Dai, Ji~Hou, Chih-Yao Ma, Sam Tsai, Jialiang Wang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiaofang Wang, Abhimanyu Dubey, et~al.
\newblock Emu: Enhancing image generation models using photogenic needles in a haystack.
\newblock \emph{arXiv preprint arXiv:2309.15807}, 2023.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Esser et~al.(2024)Esser, Kulal, Blattmann, Entezari, M{\"u}ller, Saini, Levi, Lorenz, Sauer, Boesel, et~al.]{esser2024scaling}
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas M{\"u}ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et~al.
\newblock Scaling rectified flow transformers for high-resolution image synthesis.
\newblock In \emph{Forty-first International Conference on Machine Learning}, 2024.

\bibitem[Fang et~al.(2024)Fang, Ma, and Wang]{fang2024structural}
Gongfan Fang, Xinyin Ma, and Xinchao Wang.
\newblock Structural pruning for diffusion models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  770--778, 2016.

\bibitem[He et~al.(2024)He, Liu, Liu, Wu, Zhou, and Zhuang]{he2024ptqd}
Yefei He, Luping Liu, Jing Liu, Weijia Wu, Hong Zhou, and Bohan Zhuang.
\newblock Ptqd: Accurate post-training quantization for diffusion models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Karras et~al.(2019)Karras, Laine, and Aila]{karras2019style}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial networks.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  4401--4410, 2019.

\bibitem[Kirillov et~al.(2023)Kirillov, Mintun, Ravi, Mao, Rolland, Gustafson, Xiao, Whitehead, Berg, Lo, et~al.]{kirillov2023segment}
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander~C Berg, Wan-Yen Lo, et~al.
\newblock Segment anything.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  4015--4026, 2023.

\bibitem[Labs(2024)]{flux2024}
Black~Forest Labs.
\newblock Flux.
\newblock \emph{Online}, 2024.
\newblock URL \url{https://github.com/black-forest-labs/flux}.

\bibitem[Li et~al.(2024{\natexlab{a}})Li, Kamko, Akhgari, Sabet, Xu, and Doshi]{li2024playground}
Daiqing Li, Aleks Kamko, Ehsan Akhgari, Ali Sabet, Linmiao Xu, and Suhail Doshi.
\newblock Playground v2. 5: Three insights towards enhancing aesthetic quality in text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2402.17245}, 2024{\natexlab{a}}.

\bibitem[Li et~al.(2022)Li, Lin, Meng, Ermon, Han, and Zhu]{li2022efficient}
Muyang Li, Ji~Lin, Chenlin Meng, Stefano Ermon, Song Han, and Jun-Yan Zhu.
\newblock Efficient spatially sparse inference for conditional gans and diffusion models.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 28858--28873, 2022.

\bibitem[Li et~al.(2024{\natexlab{b}})Li, Cai, Cao, Zhang, Cai, Bai, Jia, Li, and Han]{li2024distrifusion}
Muyang Li, Tianle Cai, Jiaxin Cao, Qinsheng Zhang, Han Cai, Junjie Bai, Yangqing Jia, Kai Li, and Song Han.
\newblock Distrifusion: Distributed parallel inference for high-resolution diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  7183--7193, 2024{\natexlab{b}}.

\bibitem[Li et~al.(2023)Li, Liu, Lian, Yang, Dong, Kang, Zhang, and Keutzer]{li2023q}
Xiuyu Li, Yijiang Liu, Long Lian, Huanrui Yang, Zhen Dong, Daniel Kang, Shanghang Zhang, and Kurt Keutzer.
\newblock Q-diffusion: Quantizing diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  17535--17545, 2023.

\bibitem[Li et~al.(2024{\natexlab{c}})Li, Wang, Jin, Hu, Chemerys, Fu, Wang, Tulyakov, and Ren]{li2024snapfusion}
Yanyu Li, Huan Wang, Qing Jin, Ju~Hu, Pavlo Chemerys, Yun Fu, Yanzhi Wang, Sergey Tulyakov, and Jian Ren.
\newblock Snapfusion: Text-to-image diffusion model on mobile devices within two seconds.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024{\natexlab{c}}.

\bibitem[Liu et~al.(2024)Liu, Yu, Tan, and Wang]{liu2024linfusion}
Songhua Liu, Weihao Yu, Zhenxiong Tan, and Xinchao Wang.
\newblock Linfusion: 1 gpu, 1 minute, 16k image.
\newblock \emph{arXiv preprint arXiv:2409.02097}, 2024.

\bibitem[Liu et~al.(2023)Liu, Zhang, Ma, Peng, et~al.]{liu2023instaflow}
Xingchao Liu, Xiwen Zhang, Jianzhu Ma, Jian Peng, et~al.
\newblock Instaflow: One step is enough for high-quality diffusion-based text-to-image generation.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2023.

\bibitem[Lu et~al.(2022{\natexlab{a}})Lu, Zhou, Bao, Chen, Li, and Zhu]{lu2022dpm}
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.
\newblock Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 5775--5787, 2022{\natexlab{a}}.

\bibitem[Lu et~al.(2022{\natexlab{b}})Lu, Zhou, Bao, Chen, Li, and Zhu]{lu2022dpm2}
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.
\newblock Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models.
\newblock \emph{arXiv preprint arXiv:2211.01095}, 2022{\natexlab{b}}.

\bibitem[Luo et~al.(2023)Luo, Tan, Huang, Li, and Zhao]{luo2023latent}
Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang Zhao.
\newblock Latent consistency models: Synthesizing high-resolution images with few-step inference.
\newblock \emph{arXiv preprint arXiv:2310.04378}, 2023.

\bibitem[Ma et~al.(2024)Ma, Fang, and Wang]{ma2024deepcache}
Xinyin Ma, Gongfan Fang, and Xinchao Wang.
\newblock Deepcache: Accelerating diffusion models for free.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  15762--15772, 2024.

\bibitem[Meng et~al.(2023)Meng, Rombach, Gao, Kingma, Ermon, Ho, and Salimans]{meng2023distillation}
Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik Kingma, Stefano Ermon, Jonathan Ho, and Tim Salimans.
\newblock On distillation of guided diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  14297--14306, 2023.

\bibitem[Neuhold et~al.(2017)Neuhold, Ollmann, Rota~Bulo, and Kontschieder]{neuhold2017mapillary}
Gerhard Neuhold, Tobias Ollmann, Samuel Rota~Bulo, and Peter Kontschieder.
\newblock The mapillary vistas dataset for semantic understanding of street scenes.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pp.\  4990--4999, 2017.

\bibitem[Peebles \& Xie(2023)Peebles and Xie]{peebles2023scalable}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  4195--4205, 2023.

\bibitem[Podell et~al.(2023)Podell, English, Lacey, Blattmann, Dockhorn, M{\"u}ller, Penna, and Rombach]{podell2023sdxl}
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas M{\"u}ller, Joe Penna, and Robin Rombach.
\newblock Sdxl: Improving latent diffusion models for high-resolution image synthesis.
\newblock \emph{arXiv preprint arXiv:2307.01952}, 2023.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  10684--10695, 2022.

\bibitem[Salimans \& Ho(2022)Salimans and Ho]{salimans2022progressive}
Tim Salimans and Jonathan Ho.
\newblock Progressive distillation for fast sampling of diffusion models.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Shi et~al.(2016)Shi, Caballero, Husz{\'a}r, Totz, Aitken, Bishop, Rueckert, and Wang]{shi2016real}
Wenzhe Shi, Jose Caballero, Ferenc Husz{\'a}r, Johannes Totz, Andrew~P Aitken, Rob Bishop, Daniel Rueckert, and Zehan Wang.
\newblock Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  1874--1883, 2016.

\bibitem[Shih et~al.(2024)Shih, Belkhale, Ermon, Sadigh, and Anari]{shih2024parallel}
Andy Shih, Suneel Belkhale, Stefano Ermon, Dorsa Sadigh, and Nima Anari.
\newblock Parallel sampling of diffusion models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Song et~al.(2021)Song, Meng, and Ermon]{songdenoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Song et~al.(2023)Song, Dhariwal, Chen, and Sutskever]{song2023consistency}
Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever.
\newblock Consistency models.
\newblock In \emph{International Conference on Machine Learning}, pp.\  32211--32252. PMLR, 2023.

\bibitem[Tang et~al.(2024)Tang, Tang, Luo, Wang, and Chang]{tang2024accelerating}
Zhiwei Tang, Jiasheng Tang, Hao Luo, Fan Wang, and Tsung-Hui Chang.
\newblock Accelerating parallel sampling of diffusion models.
\newblock In \emph{Forty-first International Conference on Machine Learning}, 2024.

\bibitem[Wang et~al.(2024)Wang, Fang, Li, and Yang]{wang2024pipefusion}
Jiannan Wang, Jiarui Fang, Aoyu Li, and PengCheng Yang.
\newblock Pipefusion: Displaced patch pipeline parallelism for inference of diffusion transformer models.
\newblock \emph{arXiv preprint arXiv:2405.14430}, 2024.

\bibitem[Yin et~al.(2024{\natexlab{a}})Yin, Gharbi, Park, Zhang, Shechtman, Durand, and Freeman]{yin2024improved}
Tianwei Yin, Micha{\"e}l Gharbi, Taesung Park, Richard Zhang, Eli Shechtman, Fredo Durand, and William~T Freeman.
\newblock Improved distribution matching distillation for fast image synthesis.
\newblock \emph{arXiv preprint arXiv:2405.14867}, 2024{\natexlab{a}}.

\bibitem[Yin et~al.(2024{\natexlab{b}})Yin, Gharbi, Zhang, Shechtman, Durand, Freeman, and Park]{yin2024one}
Tianwei Yin, Micha{\"e}l Gharbi, Richard Zhang, Eli Shechtman, Fredo Durand, William~T Freeman, and Taesung Park.
\newblock One-step diffusion with distribution matching distillation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  6613--6623, 2024{\natexlab{b}}.

\bibitem[Zhang \& Chen(2023)Zhang and Chen]{zhangfast}
Qinsheng Zhang and Yongxin Chen.
\newblock Fast sampling of diffusion models with exponential integrator.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Zhang et~al.(2023)Zhang, Tao, and Chen]{zhanggddim}
Qinsheng Zhang, Molei Tao, and Yongxin Chen.
\newblock gddim: Generalized denoising diffusion implicit models.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Zhao et~al.(2024{\natexlab{a}})Zhao, Fang, Liu, Rui, Soedarmadji, Li, Lin, Dai, Yan, Yang, et~al.]{zhao2024vidit}
Tianchen Zhao, Tongcheng Fang, Enshu Liu, Wan Rui, Widyadewi Soedarmadji, Shiyao Li, Zinan Lin, Guohao Dai, Shengen Yan, Huazhong Yang, et~al.
\newblock Vidit-q: Efficient and accurate quantization of diffusion transformers for image and video generation.
\newblock \emph{arXiv preprint arXiv:2406.02540}, 2024{\natexlab{a}}.

\bibitem[Zhao et~al.(2024{\natexlab{b}})Zhao, Bai, Rao, Zhou, and Lu]{zhao2024unipc}
Wenliang Zhao, Lujia Bai, Yongming Rao, Jie Zhou, and Jiwen Lu.
\newblock Unipc: A unified predictor-corrector framework for fast sampling of diffusion models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024{\natexlab{b}}.

\bibitem[Zheng et~al.(2023)Zheng, Lu, Chen, and Zhu]{zheng2023dpm}
Kaiwen Zheng, Cheng Lu, Jianfei Chen, and Jun Zhu.
\newblock Dpm-solver-v3: Improved diffusion ode solver with empirical model statistics.
\newblock \emph{Advances in Neural Information Processing Systems}, 36:\penalty0 55502--55542, 2023.

\bibitem[Zhu et~al.(2023)Zhu, Feng, Chen, Bao, Wang, Chen, Yuan, and Hua]{zhu2023designing}
Zixin Zhu, Xuelu Feng, Dongdong Chen, Jianmin Bao, Le~Wang, Yinpeng Chen, Lu~Yuan, and Gang Hua.
\newblock Designing a better asymmetric vqgan for stablediffusion.
\newblock \emph{arXiv preprint arXiv:2306.04632}, 2023.

\end{thebibliography}
