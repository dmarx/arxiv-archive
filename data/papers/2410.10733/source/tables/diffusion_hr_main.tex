\begin{table}[t]
\small\centering\setlength{\tabcolsep}{1pt}
\resizebox{1\linewidth}{!}{
\begin{tabular}{l | g | g | g g | g | g | g | g g}
\toprule
\multicolumn{10}{l}{\textbf{FFHQ 1024$\times$1024 (Unconditional) \& MJHQ 1024$\times$1024 (Class-Conditional)}} \\
\midrule
\rowcolor{white} Diffusion & & Patch & \multicolumn{2}{c|}{Throughput (image/s) $\uparrow$} & Latency & Memory & FFHQ FID $\downarrow$ & \multicolumn{2}{c}{MJHQ FID $\downarrow$} \\
\rowcolor{white} Model & \multirow{-2}{*}{Autoencoder} & Size & Training & Inference & (ms) $\downarrow$ & (GB) $\downarrow$ & w/o CFG & w/o CFG & w/ CFG \\
\midrule
\rowcolor{white} & SD3-VAE-f8 \tablecite{esser2024scaling}                 & 2 &   83 &   814 & 14.2 & 41.4 & 46.28 & 109.43 & 103.02 \\
\rowcolor{white} & Flux-VAE-f8 \tablecite{flux2024}                        & 2 &   83 &   814 & 14.2 & 41.4 & 59.15 & 143.16 & 139.06 \\
\cmidrule{2-10}
\rowcolor{white} & SDXL-VAE-f8 \tablecite{podell2023sdxl}                  & 2 &   84 &   833 & 14.1 & 41.2 & 16.82 & 49.00 & 39.21 \\
\rowcolor{white} & Asym-VAE-f8 \tablecite{zhu2023designing}                & 2 &   84 &   833 & 14.1 & 41.2 & 17.12 & 48.25 & 38.36 \\
\cmidrule{2-10}
\rowcolor{white} &                                                         & 2 &   84 &   833 & 14.1 & 41.2 & 16.98 & 48.05 & 38.19 \\
\rowcolor{white} & \multirow{-2}{*}{SD-VAE-f8 \tablecite{rombach2022high}} & 4 &  470 &  5566 &  2.5 & 10.7 & 23.81 & 60.94 & 51.29 \\ 
\cmidrule{2-10}
& \modelshort-f32                                                          & 1 &  475 &  5575 &  2.5 & 10.7 & 13.65 & 34.35 & 27.20 \\
& \;\;\modelshort-f32$^\ddag$                                                  & 1 &  475 &  5575 &  2.5 & 10.7 & \textbf{11.39} & \textbf{28.36} & \textbf{21.89} \\
\multirow{-9}{*}{DiT-S \tablecite{peebles2023scalable}}
& \modelshort-f64                                                          & 1 & \textbf{2085} & \textbf{25259} & \textbf{1.0} & \textbf{3.1} & 26.88 & 61.30 & 53.38 \\
\bottomrule
\toprule
\multicolumn{10}{l}{\textbf{MapillaryVistas 
 2048$\times$2048 (Unconditional)}} \\
\midrule
\rowcolor{white} Diffusion & & Patch & \multicolumn{2}{c|}{Throughput (image/s) $\uparrow$} & Latency & Memory & \multicolumn{3}{c}{MapillaryVistas FID $\downarrow$} \\
\rowcolor{white} Model & \multirow{-2}{*}{Autoencoder} & Size & Training & Inference & (ms) $\downarrow$ & (GB) $\downarrow$ & \multicolumn{3}{c}{w/o CFG}\\
\midrule
\rowcolor{white} & SD-VAE-f8 \tablecite{rombach2022high}                  & 4 &    84 &  810 & 14.3 & 41.4 & \multicolumn{3}{c}{69.50} \\
\cmidrule{2-10}
\multirow{-2}{*}{DiT-S \tablecite{peebles2023scalable}} & \modelshort-f64 & 1 &   \textbf{459} &  \textbf{5435} & \textbf{2.6} & \textbf{11.0} & \multicolumn{3}{g}{\textbf{59.55}} \\ 
\bottomrule
\end{tabular}
}
\vspace{-5pt}
\caption{\textbf{1024$\times$1024 and 2048$\times$2048 Image Generation Results.} $^\ddag$ represents the model is trained with 4$\times$ batch size (i.e., 256 $\rightarrow$ 1024).}
\label{tab:diffusion_hr_main}
\end{table}
