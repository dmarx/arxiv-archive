\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_arxiv,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{packages}

\def\modelfull{Deep Compression Autoencoder\xspace}
\def\modelshort{DC-AE\xspace}

\makeatletter
\def\blfootnote#1{\xdef\@thefnmark{}\@footnotetext{\scriptsize #1}}
\makeatother

\title{\modelfull for \\ Efficient High-Resolution Diffusion Models}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{
    Junyu Chen$^{1,2*}$, \space\space\space
    Han Cai$^{3*\dag}$, \space\space\space
    Junsong Chen$^3$, \space\space\space
    Enze Xie$^3$, \\
    \textbf{
    Shang Yang$^1$, \space\space\space
    Haotian Tang$^1$, \space\space\space
    Muyang Li$^1$, \space\space\space
    Yao Lu$^3$, \space\space\space
    Song Han$^{1,3}$
    } \\
    \:$^{1}$\normalfont{MIT} \quad
    $^{2}$\normalfont{Tsinghua University} \quad
    $^{3}$\normalfont{NVIDIA} \\
    \:\url{https://github.com/mit-han-lab/efficientvit}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\definecolor{mydarkred}{rgb}{0.8,0.02,0.02}
\newcommand{\SH}[1]{\textcolor{mydarkred}{[Song: #1]}}

\newcommand{\eg}{\emph{e.g.}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}

\maketitle

\blfootnote{$^*$Equal contribution. Junyu Chen is an intern at MIT during this work.}

\blfootnote{$^\dag$Project lead. Correspondence to: \texttt{hcai@nvidia.com, songhan@mit.edu}.}

\begin{abstract}
We present \modelfull (\modelshort), a new family of autoencoders for accelerating high-resolution diffusion models. Existing autoencoders have demonstrated impressive results at a moderate spatial compression ratio (e.g., 8$\times$), but fail to maintain satisfactory reconstruction accuracy for high spatial compression ratios (e.g., 64$\times$). We address this challenge by introducing two key techniques: (1) \textbf{Residual Autoencoding}, where we design our models to learn residuals based on the space-to-channel transformed features to alleviate the optimization difficulty of high spatial-compression autoencoders; (2) \textbf{Decoupled High-Resolution Adaptation}, an efficient decoupled three-phase training strategy for mitigating the generalization penalty of high spatial-compression autoencoders. With these designs, we improve the autoencoder's spatial compression ratio up to 128 while maintaining the reconstruction quality. Applying our \modelshort to latent diffusion models, we achieve significant speedup without accuracy drop. For example, on ImageNet $512 \times 512$, our \modelshort provides \textbf{19.1$\times$} inference speedup and \textbf{17.9$\times$} training speedup on H100 GPU for UViT-H while achieving a better FID, compared with the widely used SD-VAE-f8 autoencoder.
\end{abstract}

\input{sections/1_intro}
\input{sections/2_related}
\input{sections/3_method}
\input{sections/4_exp}
\input{sections/5_conclusion}

\bibliography{main}
\bibliographystyle{iclr2025_conference}

\newpage

\appendix
\input{sections/6_appendix}

\end{document}
