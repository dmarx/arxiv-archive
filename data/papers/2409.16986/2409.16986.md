---
abstract: |
  Data selection is of great significance in pretraining large language models, given the variation in quality within the large-scale available training corpora. To achieve this, researchers are currently investigating the use of data influence to measure the importance of data instances, $i.e.,$ a high influence score indicates that incorporating this instance to the training set is likely to enhance the model performance. Consequently, they select the top-$k$ instances with the highest scores. However, this approach has several limitations. (1) Calculating the accurate influence of all available data is time-consuming. (2) The selected data instances are not diverse enough, which may hinder the pretrained model’s ability to generalize effectively to various downstream tasks. In this paper, we introduce `Quad`, a data selection approach that considers both quality and diversity by using data influence to achieve state-of-the-art pretraining results. To compute the influence ($i.e.,$ the quality) more accurately and efficiently, we incorporate the attention layers to capture more semantic details, which can be accelerated through the Kronecker product. For the diversity, `Quad` clusters the dataset into similar data instances within each cluster and diverse instances across different clusters. For each cluster, if we opt to select data from it, we take some samples to evaluate the influence to prevent processing all instances. Overall, we favor clusters with highly influential instances (ensuring high quality) or clusters that have been selected less frequently (ensuring diversity), thereby well balancing between quality and diversity. Experiments on Slimpajama demonstrate that  `Quad` significantly outperforms other data selection methods with a low FLOPs consumption. Further analysis also validates the effectiveness of our influence calculation. Our code and data are available at (<https://anonymous.4open.science/r/Quad/>).
author:
- Chi Zhang <sup>\*</sup>
- Huaping Zhong <sup>\*</sup>
- Kuan Zhang
- Chengliang Chai <sup></sup>
- Rui Wang
- Xinlin Zhuang
- Tianyi Bai
- Jiantao Qiu
- Lei Cao
- Ju Fan
- Ye Yuan
- Guoren Wang
- Conghui He <sup></sup>
bibliography:
- iclr2025_conference.bib
citation-style: ieee
header-includes:
- 
- 
link-citations: true
reference-section-title: References
title: Harnessing Diversity for Important Data Selection in Pretraining Large Language Models
---




# Introduction

Recently, large language models (LLMs) have significantly advanced the field of artificial intelligence . Due to the unprecedented number of parameters (model size) and the pre-training on huge amount of training data, LLMs are generalizable a broad spectrum of downstream tasks. However, in practice, the computation resources limit both the model size and the volume of data used in pre-training. In this situation, judiciously selecting train datasets is critical for producing highly performance LLMs . In particular, the quality of the training datasets vary dramatically, while the LLaMA-3.1 report  shows that the use of high quality data in later training stages can greatly improve model performance.

Typical straightforward data selection approaches include rule-based data filtering , querying high-performance models (*e.g.*, GPT-4) , surrogate models , etc. Although these methods have achieved success on some datasets and models, they rely on simple heuristics to select training data. Without explicitly measuring the impact of the selected data on the model, these methods tend to produce sub-optimal pretraining results. To address this issue, some researchers  start evaluating each data instance by assigning it a score that reflects its impact on the model. Frequently used scoring methods include the influence function , early loss , and perplexity . Among these methods, the influence function consistently delivers state-of-the-art results by effectively approximating the impact of adding each instance to the training set. A higher score signifies a higher priority for selecting a data instance, and hence the top-$k$ (or gumble top-$k$) instances with the highest scores are chosen .

However, the above methodologies have the following limitations.

**Prohibitive Computation Cost.** First, accurately calculating the influence score of one data instance is expensive, because it involves the computation of the Hessian matrix. However, in the LLM pre-training, the number of the candidate data instances is extremely large. It is thus prohibitively expensive to compute the scores for all of the candidates.

**Lack of Diversity.** Second, assume that all influence scores have been calculated, as shown in Figure . We can see that the top-$k$ instances ($e.g.,$ some high-score instances in $C_1$) tend to be closely distributed in the feature space because the influence computation is closely related to the data features. That is, the training instances selected in this way are lack of diversity ($e.g.,$ other instances in $C_3$ with high influence are also worth selecting), while as confirmed by some studies , diversifying training samples mitigates overfitting, thereby enhancing the generalizability of the model. Therefore, an effective data training selection method should take both the influence scores and the diversity into consideration.

<figure id="fig:cluster_analysis">
<p><span class="image placeholder" data-original-image-src="intro-figure-new1.png" data-original-image-title="">image</span>  </p>
<p><span class="image placeholder" data-original-image-src="intro-figure-new2.png" data-original-image-title="">image</span>  </p>
<figcaption>Distribution of influence scores of some sampled data instances.</figcaption>
</figure>

We thus propose `Quad`, a scalabe and effective data selection approach, which successfully addressing above challenges, achieves state-of-the-art pretraining results. Initially, `Quad` organizes the given dataset into clusters where the data instances within each cluster are similar, and those in different clusters exhibit diversity. Hence, we can sample a data subset from a cluster to estimate the accurate average influence of the cluster, so as to represent the cluster quality $w.r.t$ the model performance.

Next, leveraging the property of the attention-based Transformer architecture which is widely adopted by the LLMs, we design a novel method to accurately compute the influence of an instance on LLM pre-training. More specifically, rather than solely relying on the MLP layers to compute the influence , we incorporate the attention layers such that the influence computation considers more semantic information. In addition, given that calculating the Hessian matrix is time-consuming, particularly for attention layers with complex interactions, we incorporate the Kronecker product to approximate the Hessian matrix, thereby greatly expediting the computation. This successfully addresses the computation cost challenge.

To improve diversity, we apply the Multi-Arm Bandit (MAB) technique, where each cluster is regarded as an arm of the MAB. Upon selecting an arm, we draw samples from the cluster to calculate influence scores. Subsequently, `Quad` iteratively samples from clusters, taking into account both the influence score and data diversity, e.g., whether the cluster has already been sampled. Moreover, because this sampling strategy effectively avoids calculating the influence of all instances, it further speeds up the data selection process.

We summarize our main contributions as follows:

- To balance the quality and diversity, we incorporate an iterative MAB solution to first cluster the data instances and select data instances from these clusters.

- We propose a novel method to compute the influence function in attention-based Transformer architecture, so as to precisely measure the data quality in LLM pre-training.

- Experiments on the widely-used dataset Slimpajama and 9 popular downstream tasks demonstrate that  `Quad` significantly outperforms state-of-art data selection methods by 1.39% in zero-shot accuracy, also with low computation resources consumption.

 

# Related Work

**Rule-based Methods.** Initially, researchers often relied on intuition to design hand-crafted heuristics  and  , aiming to improve data quality. Deduplication is another typical approach for selecting pretraining data, such as   and SemDedup   which use keyword-based and semantic deduplication, respectively. Additionally, certain approaches employ $n$-gram similarity  to assist in choosing corpora that is semantically aligned with the validation set data. Although these methods effectively filter out noise and redundant data from web sources, they rely on simple heuristics and cannot be well generalized.

**LLM As a Selector.** Although large models such as GPT-4 can effectively assess data quality due to their semantic comprehension capacity, the metrics utilized to rate data ($e.g.,$ writing style, educational value etc.) heavily rely on human intuition . This often leads to a mismatch between the selected data and the data desired by the model.

**Surrogate Models.** DeepSeekMath   proposes an active learning strategy to train a web data classifier. Similarly, in MATES , a surrogate model was developed to estimate the influence scores of the data instances. RHO-1   used a surrogate model trained with high-quality data to perform token-level data filtering. However, these surrogate models are not trained over large-scale data, and thus their generalizatio ability is limited.

**Perplexity** serves as a metric for selecting high-probability data in a language model. In  , perplexity (PPL) is utilized to filter data. As also discussed in Qurating , we observe that this method often incorporates a significant amount of simple and redundant data, because they are easy for the model to predict.

**Influence Function**   demonstrates that influence function can reveal the impact of training data on the performance of large models. Consequently, LESS  and MATES   utilize influence functions for selecting data during the SFT and pretraining phases, respectively. For large models, computing influence functions is computationally expensive.  . Hence, given the large amount of data handled during pretraining, directly using LESS  for data selection at this stage poses considerable difficulties. To overcome this, MATES  employs a proxy model to approximate the influence score across the full dataset. However, the limited capacity of this small proxy model hinders its ability to provide accurate influence scores. Furthermore, relying on the influence to select data solely often leads to a lack of diversity in the chosen data.

# Methods

First, we present our problem statement in §. Next, in §, we explain how our method achieves the balance between quality and diversity in selecting pretraining data. Finally, in §, we introduce how we compute the influence with attention layers more accurately and efficiently.

<figure id="fig3">
<div class="center">
<span class="image placeholder" data-original-image-src="mab-new.png" data-original-image-title="" width="100%"></span>
</div>
<p></p>
<figcaption>Overview of <code>Quad</code></figcaption>
</figure>

## Problem Definition

To enhance the capabilities of large models, it is necessary to retrieve relevant data from a large pool of candidate data and perform further training for the large model. Formally, given the pool $D_c$ and a reference set $D_r$, our problem is to select a subset $D_b \subset D_c$ to fine-tune the large model $M$, with the aim of minimizing the loss of the updated model $M'$ in the reference set $D_r$.

## balance between quality and diversity

  As shown in Figure , there are significant variations in the distribution of influence scores among different clusters. To achieve the quality-diversity balance, it is necessary to know the precise average influence score for instances in each cluster. However, Figure  shows that the influence scores for each cluster also fluctuate around the average, indicating a certain level of uncertainty. Estimating the average with a small sample size will not be accurate enough, while taking a large number of samples to compute the average influence is costly.

Hence, we propose to use the MAB  technique that is capable of making decisions iteratively under uncertainty. At a high level, each cluster represents an arm of the MAB, and during each iteration, a cluster with a high average influence score tends to be selected and sampled. We will then compute the influence of data instances to update the average. Moreover, clusters that are not visited often present significant opportunities for sampling to balance the diversity.

The overall process of this approach is illustrated in Figure . Specifically, our method can be divided into the following four steps: First, we *sample the top-$k$ clusters* with the highest cluster scores (denoted by CS) computed by MAB. Here, the cluster score is determined by both the influence score and the sample frequency. Then we *calculate the influence scores* for the samples in each cluster (Section 3.3). At this point, we *select high scoring samples* to be added for training and use their scores to *update the cluster score* for each cluster. Throughout the iterative process, the MAB algorithm focuses on frequently sampling high-quality clusters that have high influence scores, which also enhances the accuracy of their quality estimation ($i.e.,$ updating the average influence $\overline{I}_i$). Simultaneously, it ensures diversity by also sampling less-visited clusters. Next, we discuss how to compute and update the cluster score in details.

**Cluster Score (CS).** The Upper Confidence Bound can effectively balance exploration ($i.e.,$ data diversity) and exploitation ($i.e.,$ data quality), so we use it as the cluster score to evaluate each cluster, as shown in Equation (1). Specifically, the cluster score is determined by the average influence score $\bar{I_i}$ and the exploration score $\sqrt{\frac{2\ln {\sum_j{T(C_j)}}}{T(C_i)}}$, where $T(C_i)$ denotes the frequency of instances sampled from cluster $C_i$, and $\sum_j T(C_j)$ denotes the total times of samples taken from all clusters.

$$CS_{i}=\bar{I_i}+\alpha\sqrt{\frac{2\ln {\sum_j{T(C_j)}}}{T(C_i)}}$$

**Update the cluster score.** During each iteration, a subset of data $B_i$ is sampled from each cluster with a high cluster score (CS). The sum of their influence score $I_i$ can be used to denote the impact of the samples from the cluster $C_i$ on the model.

$$R(C_i) += \sum_{z \in B_i}I_\theta(D_r,z)  , \quad T(C_i) += 1$$

where $R(C_j)$ denotes the total reward accumulated by cluster $C_i$ over several iterations. Then the average influence score $\bar{I_{i}}$ for cluster $C_i$ can be represented as $\bar{I_i} = \frac{R(C_i)}{T(C_i)}$. As the sample size grows, $\bar{I_i}$ for each cluster $C_i$ steadily approaches the exact average influence of the cluster, which can be used to update the cluster scores for all clusters.

**Data selection.** During each iteration, we pick a small proportion($\gamma$) of data instances from selected clusters. We also require that these instances have influence scores higher than the threshold $\tau$, otherwise we will not select them, which are then added into the training dataset.

## Influence Calculation with attention layers

Instead of retraining the large model with each data sample $z$, the impact of $z$ on the model $M$ can be estimated by calculating the influence function for each instance. In this section, we extend the influence calculation to multi-head attention layers and provide acceleration techniques.

$$I_\theta(D_r,z)=-\nabla L(\theta,D_r)(H + \lambda I)^{-1}\nabla L(\theta,z)$$

In the above equation, $I_\theta(D_r,z)$ denote the influence function of data $z$ on model $\theta$. $\nabla L(\theta,D_r)$ and $\nabla L(\theta,z)$ denote the gradient of reference dataset $D_r$ and data $z$, respectively. Since the training of the large model does not often fully converge, resulting in a non-invertible Hessian matrix $H$, a regularization term $\lambda I$ is introduced . Equation (3) is typically divided into the following two stages to speed up the computation:

1\. Approximate the multiplication of the gradient of the validation set $\nabla L(\theta,D_r)$ and the inverse Hessian matrix $H^{-1}$ using the inverse Hessian vector product (iHVP).

2\. Compute the dot product between the iHVP and the gradient of each training data point $\nabla L(\theta,z)$.

While this framework can accelerate the computation of the influence function, scaling it up to large language models (LLMs) with massive parameters is still expensive. Hence, K-FAC  can be used to accelerate the iHVP computation by using the Kronecker product to decompose the Hessian matrix.

The K-FAC approximate the parameters of different MLP layer $\theta_1$, $\theta_2$ and $\theta_3$ as independent. That’s because, during the gradient computation and update process, there are usually only minimal direct dependencies between the gradients of different MLP layers. This is particularly evident during back propagation, where the weight updates for each MLP layer are primarily influenced by the parameters of that specific layer. Therefore, the influence function $I_{\theta_1, \theta_2, \theta_3}(D_r, z)$ in K-FAC method can be expressed as:

$$I_{\theta_1, \theta_2, \theta_3}(D_r, z) = I_{\theta_1}(D_r, z) + I_{\theta_2}(D_r, z) + I_{\theta_3}(D_r, z)$$

In attention mechanisms, there exist complex connections between the Query, Key, and Value layers. As the right-upper corner of Figure  shows, separately calculate the hessian matrix of Query, Key and Value layers, will miss massive information of Consequently, it is essential to consider the QKV layers as a unified layer $\theta_{qkv}$ when computing the influence function. Therefore, the influence function $I_{\theta_{att}}(D_r, z)$ can be expressed as: $$I_{\theta_{att}}(D_r, z) = I_{\theta_{qkv}}(D_r, z) + I_{\theta_{o}}(D_r, z)
%$I_{att}(D_r, z) = \nabla L(\theta_{qkv}, D_r) H_{\theta_{qkv}}^{-1} \nabla L(\theta_{qkv}, z) +\nabla L(\theta_{o}, D_r) H_{\theta_{o}}^{-1} \nabla L(\theta_{o}, z)$$$

<figure id="multi-head-attention">
<div class="center">
<span class="image placeholder" data-original-image-src="multi-head-attention.png" data-original-image-title="" width="100%"></span>
</div>
<figcaption>Kronecker Product in calculating iHVP</figcaption>
</figure>

Then, as the right-lower corner of Figure  shows, by decomposing the Hessian matrix into a kronecker product of smaller matrices and computing the inverse of each smaller matrix, we can avoid directly inverting the entire Hessian matrix, significantly reducing computational cost, and accelerate this process:

**Forward propagation**: $$Attention(Q,K,V) = softmax(\frac{QK^{T}}{\sqrt{d_k}})V$$

**Backward propagation**: $$D\theta =vec(DW)=\delta\otimes x$$ Here, $\otimes$ denotes the Kronecker product, and $vec()$ represents the vectorization operation. Thus, the gradient of $\theta_{qkv}$ can be written as:

$$D\theta_{qkv} = \begin{bmatrix} \mathbf{vec(DW_Q)} \\ \mathbf{vec(DW_K)} \\ \mathbf{vec(DW_V)} \end{bmatrix} \\
 = \begin{bmatrix} \mathbf{\delta}_q \\ \mathbf{\delta}_k \\ \mathbf{\delta}_v \end{bmatrix} \otimes x$$ Let $\delta_{qkv}$ $= \begin{bmatrix} \mathbf{\delta}_q \\ \mathbf{\delta}_k \\ \mathbf{\delta}_v \end{bmatrix}$. Then, the Hessian matrix $H_{qkv}$ can be estimates by: $$\begin{aligned}
    H_{qkv} = E(D\theta_{qkv} {D\theta_{qkv}}^T)=E(\delta_{qkv}\delta_{qkv}^T\otimes x_{qkv}x_{qkv}^T) \\
    \approx E(\delta_{qkv}\delta_{qkv}^T) \otimes E(x_{qkv}x_{qkv}^T) = \Delta_{qkv} \otimes X_{qkv}
\end{aligned}$$

Also, $H_o = \Delta_o \otimes X_o$. Thus, the iHVP of the attention layer can be estimated as follows:

$$\begin{aligned}
H_{att}^{-1}v_{att} = 
\begin{bmatrix}\mathbf {H_{qkv}^{-1}v_{qkv}} \\ \mathbf{H_o^{-1}v_o}  \end{bmatrix}
= \begin{bmatrix} \mathbf{(\Delta_{qkv} \otimes X_{qkv})^{-1}v_{qkv}} \\ \mathbf{(\Delta_{o} \otimes X_o)^{-1}v_o} \end{bmatrix} \\
= \begin{bmatrix} \mathbf{(\Delta_{qkv}^{-1} \otimes X_{qkv}^{-1})v_{qkv}} \\ \mathbf{(\Delta_{o}^{-1} \otimes X_o^{-1})v_o} \end{bmatrix}
= \begin{bmatrix} \mathbf{vec(\Delta_{qkv}^{-1} V_{qkv} X_{qkv}^{-1})} \\ \mathbf{vec(\Delta_{o}^{-1} V_o X_o^{-1})} \end{bmatrix}
\end{aligned}$$

where $v_{att}$, $v_{qkv}$, $v_{o}$ represent the gradient of reference dataset $D_r$ on parameters $\theta_{att}$, $\theta_{qkv}$, $\theta_{o}$, respectively. Thus, the influence score of attention layers can be written as: $I_{\theta_{att}} = -\nabla L(\theta_{att}, z)H_{att}^{-1}v_{att}$.

To avoid the excessive memory usage of validation set gradients, we apply the Johnson-Lindenstrauss Lemma to reduce the dimensionality of both the iHVP computation results and the training data gradients $\nabla L(\theta,z)$.

# Experiment

## Experiment Setup

**Dataset Preparation.** We use the entire 627B-token SlimPajama dataset as the candidate pool $D_c$. In the clustering process, the BAAI/bge-large-en-v1.5 model is employed to generate embeddings for the input data, and approximately 600 million data points from the candidate pool $D_c$ are clustered into 10,000 groups using the $k$-means algorithm. We use LAMBADA   as our reference set $D_r$, which is a widely used language modeling task and often serves as a validation benchmark for language model pretraining.  .

**Experimental settings.** We train a transformer-based decoder-only language model that contains 1.3B parameters, uses RoPE embeddings  , and has a maximum context window of 1024 tokens  . Following the setting of MATES , 30B tokens out of the 627B are selected for training using `Quad` and compare with baselines. The learning rate is set to $5 \times 10^{-5}$, the batch size is set to 4096, and the Adam optimizer is employed with hyperparameters $\beta_1 = 0.9, \beta_2 = 0.95, \epsilon = 10^{-8}$. As for Multi-Armed Badit, we set the $\alpha$ = 0.002 , sample proporation $\gamma$ = 0.05 and the sample threshold $\tau$ as 0.0025.

**Baselines.** We compare our methods with several baselines. (1) `Random` samples data from the entire candidate dataset randomly. (2) `Qurating` uses the large language model to select data. (3) `DSIR` selects data instances that are similar to the LAMBADA dataset. (4) `PPL` uses perplexity-based data selection, $i.e.,$ selecting data instances with the lowest perplexity scores. (5) `MATES` trains a surrogate model to evaluate the influence of each data instance on the target model.

**Evaluation datasets.** To comprehensively evaluate the capabilities of pretrained models, we conduct experiments on various downstream tasks covering three significant categories:

General Knowledge: ARC-C, ARC-E , and SciQ  .

Commonsense Reasoning: HellaSwag  , SIQA  , WinoGrande , Logiqa  .

Reading Comprehension: OpenbookQA  , and BoolQ .

Evaluations are conducted using the lm-evaluation-harness  framework and the average accuracy ($i.e.,$ Overall Score) is reported for comparison.

## Results

**Overall Performance.** As demonstrated in Table , our method surpasses all the baseline methods in downstream tasks with zero-shot evaluation. To be specific, we can observe that on General Knowledge and Reading Comprehension tasks, `Quad` has the improvement of 1.75% and 1.98% respectively compared with `Random`. `Quad` outperforms `DSIR` and `Semdedup` because they use rule-based heuristics to select data without considering the model. Although `PPL` and `MATES` consider the model, they do not perform well because the former one always selects some simple and duplicated instances, and the surrogate model of the latter one is small and lacking of enough training data. `Qurating` generally performs the best among other baselines, but still worse than our approach, and it incorporates the highest FLOPS(1e19) because of the usage of LLMs for data selection. In terms of the FLOPs, we can observe that except the methods ($i.e.,$ `DSIR`, `SemDeDup`) that use simple heuristics, we consume minimal computation resources because our MAB solution samples from clusters without considering the entire candidate dataset like `PPL`, `Qurating` and `MATES`.

<div class="center">

</div>

**Effectiveness of MAB.** This section evaluates the effectiveness of the MAB approach for data selection in contrast to the straightforward method of choosing the top-$k$ clusters with the highest influence scores for model training. To be specific, we randomly select an equivalent number of data points from the top 150, 500, and 1000 clusters. Figure  illustrates the trade-off between data quality and diversity: clusters with higher influence scores do not necessarily enhance model performance on downstream evaluation sets because of their lack of diversity. Hence, the multi-armed bandit method can more effectively capture the trade-off between quality and diversity across clusters, resulting in superior performance on downstream evaluation sets, as opposed to merely choosing the top-$k$ clusters.

<figure id="fig:experiment2">
<p><span class="image placeholder" data-original-image-src="exp-fig1.png" data-original-image-title="">image</span>  </p>
<p><span class="image placeholder" data-original-image-src="exp-fig2.png" data-original-image-title="">image</span>  </p>
<p><span class="image placeholder" data-original-image-src="exp-fig6.png" data-original-image-title="">image</span>  </p>
<p><span class="image placeholder" data-original-image-src="exp-fig4.png" data-original-image-title="">image</span>  </p>
<figcaption>(a) shows the effectiveness of the MAB method; (b) shows the accuracy of calculating the influence function on MLP and attention layers; (c) shows the correlation between Query, Key, Value layers impact a lot on the accuracy of influence calculation; (d) shows the model performance of varying sample threshold <span class="math inline">\(\tau\)</span>.</figcaption>
</figure>

**Effectiveness of Influence Calculation.** This experiment studies the effectiveness of our influence calculation method. In this section, we select the top 500 clusters with the highest scores using three methods: (1) `no-Hessian` ($i.e.,$ computing the gradient similarity between training data and reference data ) without considering the Hessian matrix; (2) `MLP`($i.e.,$ calculating influence function on MLP layers) and (3) `Ours` ($i.e.,$ calculating influence function on both MLP and attention layers). From each cluster, we uniformly sample data to train the large model. As shown in Figure , our solution (`MLP+Attention`) performs better than `MLP` because the attention layer considers more semantics. `no-Hessian` performs the worst because it does not precisely capture the impact of training data instances on the model without the Hessian matrix.

Also, we conduct experiments to verify the relationship between the Query, Key, Value matrices, which is shown in Figure . In this experiment, we compare the Pearson correlation coefficients between the following three methods and the baseline approach, which computes the influence score for the attention layer without any acceleration. (1) `No-Hessian`($i.e.,$ computing the gradient similarity between training data and reference data) without considering the Hessian matrix; (2) `Independent` ($i.e.,$ calculating the Hessian matrices of the query, key, and value layers independently) and (3) `Ours` ($i.e.,$ calculating the Hessian matrices of the query, key, and value layers as a whole).

## Ablation Study

This group of experiments performs ablation studies on the hyperparameters of `Quad`. Figure  and Figure  show the impact of sample threshold and $\alpha$ respectively.

**Sampling Threshold of Influence ($\tau$).** Setting the threshold too high or low will both degrade the model performance. This is because the selected data instances tend to exist in few clusters with high influence scores, resulting in poor diversity. In contrast, when the threshold is set too low, the sampled instances will be from many clusters with low influence scores, which also degrades the model performance.

**$\alpha$ for Quality-Diversity Balance.** Our approach employs $\alpha$ to balance the diversity and quality in the MAB framework. When $\alpha$ is small, we tend to focus on the several clusters with high influence scores without considering diversity much, so the MAB framework is likely to get stuck in a local optimum. For example, this results in the model enhancing its performance in specific areas (such as Common Sense Reasoning in Figure  when $\alpha = 1.5e-3$), while the performance in other areas ($i.e.,$ General Knowledge and Reading Comprehension) is not good enough. Thus the overall score is not the optimal. However, when $\alpha$ is large, the MAB framework focuses too much on diversity without selecting enough high-quality data, which ultimately results in a limited improvement of model performance.

<figure id="exploration">
<div class="center">
<span class="image placeholder" data-original-image-src="exp-fig5.png" data-original-image-title="" width="100%"></span>
</div>
<figcaption><span class="math inline">\(\alpha\)</span> for Quality-Diversity Balance.</figcaption>
</figure>

# conclusion

This paper presents `Quad`, a method designed to balance both the diversity and quality of data in pretraining data selection. `Quad` employs the influence function to identify data that benefits the model. First, we group the data into clusters and use a subset from each to represent the influence of the entire cluster. Given that influence scores within a cluster display some uncertainty, we view each cluster as an arm in an MAB framework. This method conducts samplings from high-quality clusters, allowing for more precise estimation of their influence scores and meanwhile maintaining the diversity. Moreover, we extend the influence function to attention layers and enhance the calculation efficiency to better measure the impact of data within each cluster on the model.

# Appendix

|  Hyperparameter               | Value               |
|:------------------------------|:--------------------|
| Vocabulary Size               | 32,000              |
| MLP Ratio                     | 8/3                 |
| Hidden Dimension Size         | 2048                |
| Number of Layers              | 24                  |
| Number of Attention Heads     | 16                  |
| Number of KV Attention Heads  | 16                  |
| RoPE Base                     | 10,000              |
| Maximum Context Window Length | 1024                |
| Number of Parameters          | 1,345,423,360(1.3B) |

Model Architecture
