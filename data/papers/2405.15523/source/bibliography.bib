@article{Alford_2005a, title={Not a Word}, journal={The New Yorker}, author={Alford, Henry}, year={2005}, month={Aug}} 

@misc{authorsguild,
  title = {More than 15,000 Authors Sign Authors Guild Letter Calling on AI Industry Leaders to Protect Writers},
  author = {USAuthorsGuild},
  year = {2023},
  publisher = {https://authorsguild.org},
  howpublished = {\href{https://authorsguild.org/news/thousands-sign-authors-guild-letter-calling-on-ai-industry-leaders-to-protect-writers/}{authors-guild-open-letter}},
  notes = {Accessed: 2023-10-14}
}

@misc{silvermanmeta,
  author = {LLMLitigation}, 
  title = {Kadrey, Silverman, Golden v Meta Platforms, Inc.},
  year = {2023},
  publisher = {llmlitigation.com},
  howpublished = {\url{https://llmlitigation.com/pdf/03417/kadrey-meta-complaint.pdf}},
  notes = {Accessed: 2023-10-14}
}

@misc{hoffmann2022training,
      title={Training Compute-Optimal Large Language Models}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{muennighoff2023scaling,
      title={Scaling Data-Constrained Language Models}, 
      author={Niklas Muennighoff and Alexander M. Rush and Boaz Barak and Teven Le Scao and Aleksandra Piktus and Nouamane Tazi and Sampo Pyysalo and Thomas Wolf and Colin Raffel},
      year={2023},
      eprint={2305.16264},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{anthropic,  author={FinancialTimes}, journal={Universal Music sues Anthropic over AI-generated lyrics}, publisher={Financial Times}, howpublished={\url{https://www.ft.com/content/0965d962-5c54-4fdc-aef8-18e4ef3b9df5}},year={2023}, month={Oct}
} 

@article{samuelson2023generative,
  title={Generative AI meets copyright},
  author={Samuelson, Pamela},
  journal={Science},
  volume={381},
  number={6654},
  pages={158--161},
  year={2023},
  publisher={American Association for the Advancement of Science}
}

@misc{nytimes, title={The Times sues OpenAI and Microsoft over A.I. use of copyrighted work}, howpublished={\url{https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html}}, author={NewYorkTimes}, year={2023}, month={Dec}} 

@inproceedings{carlini2022quantifying,
  title={Quantifying Memorization Across Neural Language Models},
  author={Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramer, Florian and Zhang, Chiyuan},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{carlini2022membership,
  title={Membership inference attacks from first principles},
  author={Carlini, Nicholas and Chien, Steve and Nasr, Milad and Song, Shuang and Terzis, Andreas and Tramer, Florian},
  booktitle={2022 IEEE Symposium on Security and Privacy (SP)},
  pages={1897--1914},
  year={2022},
  organization={IEEE}
}

@inproceedings{carlini2019secret,
  title={The secret sharer: Evaluating and testing unintended memorization in neural networks},
  author={Carlini, Nicholas and Liu, Chang and Erlingsson, {\'U}lfar and Kos, Jernej and Song, Dawn},
  booktitle={28th USENIX Security Symposium (USENIX Security 19)},
  pages={267--284},
  year={2019}
}

@article{nasr2023scalable,
  title={Scalable extraction of training data from (production) language models},
  author={Nasr, Milad and Carlini, Nicholas and Hayase, Jonathan and Jagielski, Matthew and Cooper, A Feder and Ippolito, Daphne and Choquette-Choo, Christopher A and Wallace, Eric and Tram{\`e}r, Florian and Lee, Katherine},
  journal={arXiv preprint arXiv:2311.17035},
  year={2023}
}

@inproceedings{kandpal2022deduplicating,
  title={Deduplicating training data mitigates privacy risks in language models},
  author={Kandpal, Nikhil and Wallace, Eric and Raffel, Colin},
  booktitle={International Conference on Machine Learning},
  pages={10697--10707},
  year={2022},
  organization={PMLR}
}

@article{ippolito2022preventing,
  title={Preventing verbatim memorization in language models gives a false sense of privacy},
  author={Ippolito, Daphne and Tram{\`e}r, Florian and Nasr, Milad and Zhang, Chiyuan and Jagielski, Matthew and Lee, Katherine and Choquette-Choo, Christopher A and Carlini, Nicholas},
  journal={arXiv preprint arXiv:2210.17546},
  year={2022}
}

@article{yu2023bag,
  title={Bag of tricks for training data extraction from language models},
  author={Yu, Weichen and Pang, Tianyu and Liu, Qian and Du, Chao and Kang, Bingyi and Huang, Yan and Lin, Min and Yan, Shuicheng},
  journal={arXiv preprint arXiv:2302.04460},
  year={2023}
}

@inproceedings{carlini2021extracting,
  title={Extracting training data from large language models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2633--2650},
  year={2021}
}

@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

@article{ateniese2015hacking,
  title={Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers},
  author={Ateniese, Giuseppe and Mancini, Luigi V and Spognardi, Angelo and Villani, Antonio and Vitali, Domenico and Felici, Giovanni},
  journal={International Journal of Security and Networks},
  volume={10},
  number={3},
  pages={137--150},
  year={2015},
  publisher={Inderscience Publishers (IEL)}
}

@article{meeus2024copyright,
  title={Copyright Traps for Large Language Models},
  author={Meeus, Matthieu and Shilov, Igor and Faysse, Manuel and de Montjoye, Yves-Alexandre},
  journal={arXiv preprint arXiv:2402.09363},
  year={2024}
}

@article{pyrgelis2017knock,
  title={Knock knock, who's there? Membership inference on aggregate location data},
  author={Pyrgelis, Apostolos and Troncoso, Carmela and De Cristofaro, Emiliano},
  journal={arXiv preprint arXiv:1708.06145},
  year={2017}
}

@misc{kpullygutenberg,
  author = {Katherine Pully},
  title = {Gutenberg scraper},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/kpully/gutenberg_scraper}},
  notes = {Accessed: 2023-08-01}
}

@misc{cerebras2023slimpajama,
author = {Soboleva, Daria and Al-Khateeb, Faisal and Myers, Robert and Steeves, Jacob R and Hestness, Joel and Dey, Nolan},
title = {{SlimPajama: A 627B token cleaned and deduplicated version of RedPajama}},
month ={June},
year = {2023},
url = {https://huggingface.co/datasets/cerebras/SlimPajama-627B},
}

@inproceedings{mireshghallah2022quantifying,
  title={Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks},
  author={Mireshghallah, Fatemehsadat and Goyal, Kartik and Uniyal, Archit and Berg-Kirkpatrick, Taylor and Shokri, Reza},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={8332--8347},
  year={2022}
}

@article{sharir2020cost,
  title={The cost of training nlp models: A concise overview},
  author={Sharir, Or and Peleg, Barak and Shoham, Yoav},
  journal={arXiv preprint arXiv:2004.08900},
  year={2020}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models, 2023},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={URL https://arxiv. org/abs/2307.09288},
  year={2023}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@misc{openlm2023openllama,
  author = {Geng, Xinyang and Liu, Hao},
  title = {OpenLLaMA: An Open Reproduction of LLaMA},
  month = {May},
  year = {2023},
  url = {https://github.com/openlm-research/open_llama}
}

@inproceedings{chen2019gmail,
  title={Gmail smart compose: Real-time assisted writing},
  author={Chen, Mia Xu and Lee, Benjamin N and Bansal, Gagan and Cao, Yuan and Zhang, Shuyuan and Lu, Justin and Tsay, Jackie and Wang, Yinan and Dai, Andrew M and Chen, Zhifeng and others},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2287--2295},
  year={2019}
}

@inproceedings{lehman2021does,
  title={Does BERT Pretrained on Clinical Notes Reveal Sensitive Data?},
  author={Lehman, Eric and Jain, Sarthak and Pichotta, Karl and Goldberg, Yoav and Wallace, Byron C},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={946--959},
  year={2021}
}

@article{zhang2021counterfactual,
  title={Counterfactual memorization in neural language models},
  author={Zhang, Chiyuan and Ippolito, Daphne and Lee, Katherine and Jagielski, Matthew and Tram{\`e}r, Florian and Carlini, Nicholas},
  journal={arXiv preprint arXiv:2112.12938},
  year={2021}
}

%% MIAs in general
@article{homer2008resolving,
  title={Resolving individuals contributing trace amounts of DNA to highly complex mixtures using high-density SNP genotyping microarrays},
  author={Homer, Nils and Szelinger, Szabolcs and Redman, Margot and Duggan, David and Tembe, Waibhav and Muehling, Jill and Pearson, John V and Stephan, Dietrich A and Nelson, Stanley F and Craig, David W},
  journal={PLoS genetics},
  volume={4},
  number={8},
  pages={e1000167},
  year={2008},
  publisher={Public Library of Science San Francisco, USA}
}

@article{meeus2023achilles,
  title={Achilles' Heels: Vulnerable Record Identification in Synthetic Data Publishing},
  author={Meeus, Matthieu and Guepin, Florent and Cretu, Ana-Maria and de Montjoye, Yves-Alexandre},
  journal={arXiv preprint arXiv:2306.10308},
  year={2023}
}

@inproceedings{sablayrolles2019white,
  title={White-box vs black-box: Bayes optimal strategies for membership inference},
  author={Sablayrolles, Alexandre and Douze, Matthijs and Schmid, Cordelia and Ollivier, Yann and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={5558--5567},
  year={2019},
  organization={PMLR}
}

@inproceedings{yeom2018privacy,
  title={Privacy risk in machine learning: Analyzing the connection to overfitting},
  author={Yeom, Samuel and Giacomelli, Irene and Fredrikson, Matt and Jha, Somesh},
  booktitle={2018 IEEE 31st computer security foundations symposium (CSF)},
  pages={268--282},
  year={2018},
  organization={IEEE}
}

@article{cretu2023re,
  title={Re-aligning Shadow Models can Improve White-box Membership Inference Attacks},
  author={Cretu, Ana-Maria and Jones, Daniel and de Montjoye, Yves-Alexandre and Tople, Shruti},
  journal={arXiv preprint arXiv:2306.05093},
  year={2023}
}

@inproceedings{nasr2018comprehensive,
  title={Comprehensive privacy analysis of deep learning},
  author={Nasr, Milad and Shokri, Reza and Houmansadr, Amir},
  booktitle={Proceedings of the 2019 IEEE Symposium on Security and Privacy (SP)},
  pages={1--15},
  year={2018}
}

@inproceedings{choquette2021label,
  title={Label-only membership inference attacks},
  author={Choquette-Choo, Christopher A and Tramer, Florian and Carlini, Nicholas and Papernot, Nicolas},
  booktitle={International conference on machine learning},
  pages={1964--1974},
  year={2021},
  organization={PMLR}
}

@inproceedings{song2019auditing,
  title={Auditing data provenance in text-generation models},
  author={Song, Congzheng and Shmatikov, Vitaly},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={196--206},
  year={2019}
}

@article{hisamoto2020membership,
  title={Membership inference attacks on sequence-to-sequence models: Is my data in your machine translation system?},
  author={Hisamoto, Sorami and Post, Matt and Duh, Kevin},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={49--63},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{mattern2023membership,
  title={Membership Inference Attacks against Language Models via Neighbourhood Comparison},
  author={Mattern, Justus and Mireshghallah, Fatemehsadat and Jin, Zhijing and Sch{\"o}lkopf, Bernhard and Sachan, Mrinmaya and Berg-Kirkpatrick, Taylor},
  journal={arXiv preprint arXiv:2305.18462},
  year={2023}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@misc{gpt4techreport,
  title = {GPT-4 Technical Report},
  author = {OpenAI},
  year = {2023},
  publisher = {https://cdn.openai.com/},
  howpublished = {\href{https://cdn.openai.com/papers/gpt-4.pdf}{https://cdn.openai.com/papers/gpt-4.pdf}},
  notes = {Accessed: 2023-10-14}
}

@article{li2023mope,
  title={MoPe: Model Perturbation-based Privacy Attacks on Language Models},
  author={Li, Marvin and Wang, Jason and Wang, Jeffrey and Neel, Seth},
  journal={arXiv preprint arXiv:2310.14369},
  year={2023}
}

@article{meeus2023did,
  title={Did the Neurons Read your Book? Document-level Membership Inference for Large Language Models},
  author={Meeus, Matthieu and Jain, Shubham and Rei, Marek and de Montjoye, Yves-Alexandre},
  journal={arXiv preprint arXiv:2310.15007},
  year={2023}
}

@article{shi2023detecting,
  title={Detecting pretraining data from large language models},
  author={Shi, Weijia and Ajith, Anirudh and Xia, Mengzhou and Huang, Yangsibo and Liu, Daogao and Blevins, Terra and Chen, Danqi and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2310.16789},
  year={2023}
}

@inproceedings{lee2023language,
  title={Do language models plagiarize?},
  author={Lee, Jooyoung and Le, Thai and Chen, Jinghui and Lee, Dongwon},
  booktitle={Proceedings of the ACM Web Conference 2023},
  pages={3637--3647},
  year={2023}
}

@article{thakkar2020understanding,
  title={Understanding unintended memorization in federated learning},
  author={Thakkar, Om and Ramaswamy, Swaroop and Mathews, Rajiv and Beaufays, Fran{\c{c}}oise},
  journal={arXiv preprint arXiv:2006.07490},
  year={2020}
}

@inproceedings{thomas2020investigating,
  title={Investigating the impact of pre-trained word embeddings on memorization in neural networks},
  author={Thomas, Aleena and Adelani, David Ifeoluwa and Davody, Ali and Mogadala, Aditya and Klakow, Dietrich},
  booktitle={Text, Speech, and Dialogue: 23rd International Conference, TSD 2020, Brno, Czech Republic, September 8--11, 2020, Proceedings 23},
  pages={273--281},
  year={2020},
  organization={Springer}
}

@misc{zhang2024tinyllama,
      title={TinyLlama: An Open-Source Small Language Model}, 
      author={Peiyuan Zhang and Guangtao Zeng and Tianduo Wang and Wei Lu},
      year={2024},
      eprint={2401.02385},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{Javaheripi_2023, title={Phi-2: The surprising power of small language models}, publisher={Microsoft Research}, author={Javaheripi, Mojan and Bubeck, Sébastien }, year={2023}, month={Dec}} 

@misc{biderman2023pythia,
      title={Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling}, 
      author={Stella Biderman and Hailey Schoelkopf and Quentin Anthony and Herbie Bradley and Kyle O'Brien and Eric Hallahan and Mohammad Aflah Khan and Shivanshu Purohit and USVSN Sai Prashanth and Edward Raff and Aviya Skowron and Lintang Sutawika and Oskar van der Wal},
      year={2023},
      eprint={2304.01373},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zhang2022opt,
      title={OPT: Open Pre-trained Transformer Language Models}, 
      author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
      year={2022},
      eprint={2205.01068},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{scao2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}

@misc{projectgutenberg, title={Project gutenberg}, url={https://www.gutenberg.org/}, journal={Project Gutenberg}, author={Hart, Michael}} 

@article{raecompressive2019,
  author = {Rae, Jack W and Potapenko, Anna and Jayakumar, Siddhant M and
            Hillier, Chloe and Lillicrap, Timothy P},
  title = {Compressive Transformers for Long-Range Sequence Modelling},
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/1911.05507},
  year = {2019},
}

@article{bommasani2023foundation,
  title={The foundation model transparency index},
  author={Bommasani, Rishi and Klyman, Kevin and Longpre, Shayne and Kapoor, Sayash and Maslej, Nestor and Xiong, Betty and Zhang, Daniel and Liang, Percy},
  journal={arXiv preprint arXiv:2310.12941},
  year={2023}
}


@misc{gettystability,
  title = {Getty Images v Stability AI},
  key = {Getty Images v Stability AI},
  year = {2023},
  publisher = {aboutblaw.com},
  howpublished = {\url{https://aboutblaw.com/6DW}},
  notes = {Accessed: 2023-10-14}
}

@misc{atlantic,
  title = {These 183,000 books are fueling the biggest fight in publishing and tech},
  author = {Alex Reisner},
  year = {2023},
  publisher = {The Atlantic},
  howpublished = {\href{https://www.theatlantic.com/technology/archive/2023/09/books3-database-generative-ai-training-copyright-infringement/675363/}{the-atlantic-books3-copyright}},
  notes = {Accessed: 2023-10-14}
}

@misc{wired,
  title = {The Battle Over Books3 Could Change AI Forever},
  author = {Kate Knibbs},
  year = {2023},
  publisher = {wired.com},
  howpublished = {\href{https://www.wired.com/story/battle-over-books3/}{wired-battle-over-books3}},
  notes = {Accessed: 2023-10-14}
}

@article{carlini2022privacy,
  title={The privacy onion effect: Memorization is relative},
  author={Carlini, Nicholas and Jagielski, Matthew and Zhang, Chiyuan and Papernot, Nicolas and Terzis, Andreas and Tramer, Florian},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={13263--13276},
  year={2022}
}

@inproceedings{feldman2020does,
  title={Does learning require memorization? a short tale about a long tail},
  author={Feldman, Vitaly},
  booktitle={Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing},
  pages={954--959},
  year={2020}
}

@inproceedings{henderson2018ethical,
  title={Ethical challenges in data-driven dialogue systems},
  author={Henderson, Peter and Sinha, Koustuv and Angelard-Gontier, Nicolas and Ke, Nan Rosemary and Fried, Genevieve and Lowe, Ryan and Pineau, Joelle},
  booktitle={Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={123--129},
  year={2018}
}

@inproceedings{lee2022deduplicating,
  title={Deduplicating Training Data Makes Language Models Better},
  author={Lee, Katherine and Ippolito, Daphne and Nystrom, Andrew and Zhang, Chiyuan and Eck, Douglas and Callison-Burch, Chris and Carlini, Nicholas},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={8424--8445},
  year={2022}
}

@article{kudugunta2024madlad,
  title={Madlad-400: A multilingual and document-level large audited dataset},
  author={Kudugunta, Sneha and Caswell, Isaac and Zhang, Biao and Garcia, Xavier and Xin, Derrick and Kusupati, Aditya and Stella, Romi and Bapna, Ankur and Firat, Orhan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{jiang2023mistral,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{kaplan2020scaling,
      title={Scaling Laws for Neural Language Models}, 
      author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
      year={2020},
      eprint={2001.08361},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{faysse2024croissantllm,
  title={CroissantLLM: A Truly Bilingual French-English Language Model},
  author={Faysse, Manuel and Fernandes, Patrick and Guerreiro, Nuno and Loison, Ant{\'o}nio and Alves, Duarte and Corro, Caio and Boizard, Nicolas and Alves, Jo{\~a}o and Rei, Ricardo and Martins, Pedro and others},
  journal={arXiv preprint arXiv:2402.00786},
  year={2024}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

% related work on dedup
@article{hernandez2022scaling,
  title={Scaling laws and interpretability of learning from repeated data},
  author={Hernandez, Danny and Brown, Tom and Conerly, Tom and DasSarma, Nova and Drain, Dawn and El-Showk, Sheer and Elhage, Nelson and Hatfield-Dodds, Zac and Henighan, Tom and Hume, Tristan and others},
  journal={arXiv preprint arXiv:2205.10487},
  year={2022}
}

@inproceedings{allamanis2019adverse,
  title={The adverse effects of code duplication in machine learning models of code},
  author={Allamanis, Miltiadis},
  booktitle={Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
  pages={143--153},
  year={2019}
}

@article{tirumala2024d4,
  title={D4: Improving llm pretraining via document de-duplication and diversification},
  author={Tirumala, Kushal and Simig, Daniel and Aghajanyan, Armen and Morcos, Ari},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{penedo2023refinedweb,
  title={The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only},
  author={Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
  journal={arXiv preprint arXiv:2306.01116},
  year={2023}
}

@article{manber1993suffix,
  title={Suffix arrays: a new method for on-line string searches},
  author={Manber, Udi and Myers, Gene},
  journal={siam Journal on Computing},
  volume={22},
  number={5},
  pages={935--948},
  year={1993},
  publisher={SIAM}
}

@inproceedings{broder1997resemblance,
  title={On the resemblance and containment of documents},
  author={Broder, Andrei Z},
  booktitle={Proceedings. Compression and Complexity of SEQUENCES 1997 (Cat. No. 97TB100171)},
  pages={21--29},
  year={1997},
  organization={IEEE}
}

@article{soldaini2024dolma,
  title={Dolma: An Open Corpus of Three Trillion Tokens for Language Model Pretraining Research},
  author={Soldaini, Luca and Kinney, Rodney and Bhagia, Akshita and Schwenk, Dustin and Atkinson, David and Authur, Russell and Bogin, Ben and Chandu, Khyathi and Dumas, Jennifer and Elazar, Yanai and others},
  journal={arXiv preprint arXiv:2402.00159},
  year={2024}
}

@article{bloom1970space,
  title={Space/time trade-offs in hash coding with allowable errors},
  author={Bloom, Burton H},
  journal={Communications of the ACM},
  volume={13},
  number={7},
  pages={422--426},
  year={1970},
  publisher={ACM New York, NY, USA}
}

@article{zeng2021pangu,
  title={PanGu-a: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation},
  author={Zeng, Wei and Ren, Xiaozhe and Su, Teng and Wang, Hui and Liao, Yi and Wang, Zhiwei and Jiang, Xin and Yang, ZhenZhang and Wang, Kaisheng and Zhang, Xiaoda and others},
  journal={arXiv preprint arXiv:2104.12369},
  year={2021}
}

@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@article{jaccard1912distribution,
  title={The distribution of the flora in the alpine zone. 1},
  author={Jaccard, Paul},
  journal={New phytologist},
  volume={11},
  number={2},
  pages={37--50},
  year={1912},
  publisher={Wiley Online Library}
}

@article{muennighoff2024scaling,
  title={Scaling data-constrained language models},
  author={Muennighoff, Niklas and Rush, Alexander and Barak, Boaz and Le Scao, Teven and Tazi, Nouamane and Piktus, Aleksandra and Pyysalo, Sampo and Wolf, Thomas and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{xue2024repeat,
  title={To repeat or not to repeat: Insights from scaling llm under token-crisis},
  author={Xue, Fuzhao and Fu, Yao and Zhou, Wangchunshu and Zheng, Zangwei and You, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{abbas2023semdedup,
  title={Semdedup: Data-efficient learning at web-scale through semantic deduplication},
  author={Abbas, Amro and Tirumala, Kushal and Simig, D{\'a}niel and Ganguli, Surya and Morcos, Ari S},
  journal={arXiv preprint arXiv:2303.09540},
  year={2023}
}

@article{kaddour2023minipile,
  title={The minipile challenge for data-efficient language models},
  author={Kaddour, Jean},
  journal={arXiv preprint arXiv:2304.08442},
  year={2023}
}

@inproceedings{song2017machine,
  title={Machine learning models that remember too much},
  author={Song, Congzheng and Ristenpart, Thomas and Shmatikov, Vitaly},
  booktitle={Proceedings of the 2017 ACM SIGSAC Conference on computer and communications security},
  pages={587--601},
  year={2017}
}

@inproceedings{lukas2023analyzing,
  title={Analyzing leakage of personally identifiable information in language models},
  author={Lukas, Nils and Salem, Ahmed and Sim, Robert and Tople, Shruti and Wutschitz, Lukas and Zanella-B{\'e}guelin, Santiago},
  booktitle={2023 IEEE Symposium on Security and Privacy (SP)},
  pages={346--363},
  year={2023},
  organization={IEEE}
}

@inproceedings{mireshghallah2023can,
  title={Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory},
  author={Mireshghallah, Niloofar and Kim, Hyunwoo and Zhou, Xuhui and Tsvetkov, Yulia and Sap, Maarten and Shokri, Reza and Choi, Yejin},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{zhang2023make,
  title={Make them spill the beans! coercive knowledge extraction from (production) llms},
  author={Zhang, Zhuo and Shen, Guangyu and Tao, Guanhong and Cheng, Siyuan and Zhang, Xiangyu},
  journal={arXiv preprint arXiv:2312.04782},
  year={2023}
}

@article{bordt2024elephants,
  title={Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models},
  author={Bordt, Sebastian and Nori, Harsha and Rodrigues, Vanessa and Nushi, Besmira and Caruana, Rich},
  journal={arXiv preprint arXiv:2404.06209},
  year={2024}
}

@article{duan2024membership,
  title={Do Membership Inference Attacks Work on Large Language Models?},
  author={Duan, Michael and Suri, Anshuman and Mireshghallah, Niloofar and Min, Sewon and Shi, Weijia and Zettlemoyer, Luke and Tsvetkov, Yulia and Choi, Yejin and Evans, David and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2402.07841},
  year={2024}
}

@article{peng2023near,
  title={Near-Duplicate Sequence Search at Scale for Large Language Model Memorization Evaluation},
  author={Peng, Zhencan and Wang, Zhizhi and Deng, Dong},
  journal={Proceedings of the ACM on Management of Data},
  volume={1},
  number={2},
  pages={1--18},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@article{broder1997syntactic,
  title={Syntactic clustering of the web},
  author={Broder, Andrei Z and Glassman, Steven C and Manasse, Mark S and Zweig, Geoffrey},
  journal={Computer networks and ISDN systems},
  volume={29},
  number={8-13},
  pages={1157--1166},
  year={1997},
  publisher={Elsevier}
}

@inproceedings{shivakumar1998finding,
  title={Finding near-replicas of documents on the web},
  author={Shivakumar, Narayanan and Garcia-Molina, Hector},
  booktitle={International Workshop on the World Wide Web and Databases},
  pages={204--212},
  year={1998},
  organization={Springer}
}

@inproceedings{atli2022effectiveness,
  title={On the effectiveness of dataset watermarking},
  author={Atli Tekgul, Buse Gul and Asokan, N},
  booktitle={Proceedings of the 2022 ACM on International Workshop on Security and Privacy Analytics},
  pages={93--99},
  year={2022}
}

@inproceedings{sablayrolles2020radioactive,
  title={Radioactive data: tracing through training},
  author={Sablayrolles, Alexandre and Douze, Matthijs and Schmid, Cordelia and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={8326--8335},
  year={2020},
  organization={PMLR}
}

@article{li2020open,
  title={Open-sourced dataset protection via backdoor watermarking},
  author={Li, Yiming and Zhang, Ziqi and Bai, Jiawang and Wu, Baoyuan and Jiang, Yong and Xia, Shu-Tao},
  journal={arXiv preprint arXiv:2010.05821},
  year={2020}
}

@article{shafahi2018poison,
  title={Poison frogs! targeted clean-label poisoning attacks on neural networks},
  author={Shafahi, Ali and Huang, W Ronny and Najibi, Mahyar and Suciu, Octavian and Studer, Christoph and Dumitras, Tudor and Goldstein, Tom},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{wenger2024data,
  title={Data Isotopes for Data Provenance in DNNs},
  author={Wenger, Emily and Li, Xiuyu and Zhao, Ben Y and Shmatikov, Vitaly},
  journal={Proceedings on Privacy Enhancing Technologies},
  year={2024}
}

@article{duarte2024cop,
  title={DE-COP: Detecting Copyrighted Content in Language Models Training Data},
  author={Duarte, Andr{\'e} V and Zhao, Xuandong and Oliveira, Arlindo L and Li, Lei},
  journal={arXiv preprint arXiv:2402.09910},
  year={2024}
}

@inproceedings{karamolegkou2023copyright,
  title={Copyright Violations and Large Language Models},
  author={Karamolegkou, Antonia and Li, Jiaang and Zhou, Li and S{\o}gaard, Anders},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  year={2023}
}

@article{wei2024proving,
  title={Proving membership in LLM pretraining data via data watermarks},
  author={Wei, Johnny Tian-Zheng and Wang, Ryan Yixiang and Jia, Robin},
  journal={arXiv preprint arXiv:2402.10892},
  year={2024}
}

@article{pile,
  title={The {P}ile: An 800GB Dataset of Diverse Text for Language Modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}

@article{2019t5,
    author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
    title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
    journal = {arXiv e-prints},
    year = {2019},
    archivePrefix = {arXiv},
    eprint = {1910.10683},
}

@misc{Gokaslan2019OpenWeb,  
	title={OpenWebText Corpus},
	author={Aaron Gokaslan and Vanya Cohen},
	howpublished={\url{http://Skylion007.github.io/OpenWebTextCorpus}}, 
	year={2019}
}

@misc{pile_uncopyrighted, 
title={Monology/Pile-uncopyrighted · datasets at hugging face}, 
url={https://huggingface.co/datasets/monology/pile-uncopyrighted}, 
journal={monology/pile-uncopyrighted · Datasets at Hugging Face}, 
author={account), Devin Gulliver (alt}
} 

@article{wenzek2019ccnet,
  title={CCNet: Extracting high quality monolingual datasets from web crawl data},
  author={Wenzek, Guillaume and Lachaux, Marie-Anne and Conneau, Alexis and Chaudhary, Vishrav and Guzm{\'a}n, Francisco and Joulin, Armand and Grave, Edouard},
  journal={arXiv preprint arXiv:1911.00359},
  year={2019}
}

@article{laurenccon2022bigscience,
  title={The bigscience roots corpus: A 1.6 tb composite multilingual dataset},
  author={Lauren{\c{c}}on, Hugo and Saulnier, Lucile and Wang, Thomas and Akiki, Christopher and Villanova del Moral, Albert and Le Scao, Teven and Von Werra, Leandro and Mou, Chenghao and Gonz{\'a}lez Ponferrada, Eduardo and Nguyen, Huu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={31809--31826},
  year={2022}
}

@article{albalak2024survey,
  title={A Survey on Data Selection for Language Models},
  author={Albalak, Alon and Elazar, Yanai and Xie, Sang Michael and Longpre, Shayne and Lambert, Nathan and Wang, Xinyi and Muennighoff, Niklas and Hou, Bairu and Pan, Liangming and Jeong, Haewon and others},
  journal={arXiv preprint arXiv:2402.16827},
  year={2024}
}

@inproceedings{dwork2006calibrating,
  title={Calibrating noise to sensitivity in private data analysis},
  author={Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
  booktitle={Theory of Cryptography: Third Theory of Cryptography Conference, TCC 2006, New York, NY, USA, March 4-7, 2006. Proceedings 3},
  pages={265--284},
  year={2006},
  organization={Springer}
}

@inproceedings{abadi2016deep,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC conference on computer and communications security},
  pages={308--318},
  year={2016}
}

@article{wang2023wasa,
  title={WASA: Watermark-based source attribution for large language model-generated data},
  author={Wang, Jingtan and Lu, Xinyang and Zhao, Zitong and Dai, Zhongxiang and Foo, Chuan-Sheng and Ng, See-Kiong and Low, Bryan Kian Hsiang},
  journal={arXiv preprint arXiv:2310.00646},
  year={2023}
}

@article{barnard2023self,
  title={Self-Diagnosis and Large Language Models: A New Front for Medical Misinformation},
  author={Barnard, Francois and Van Sittert, Marlize and Rambhatla, Sirisha},
  journal={arXiv preprint arXiv:2307.04910},
  year={2023}
}

@article{zhang2023siren,
  title={Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models},
  author={Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and others},
  journal={arXiv preprint arXiv:2309.01219},
  year={2023}
}

@article{solaiman2021process,
  title={Process for adapting language models to society (palms) with values-targeted datasets},
  author={Solaiman, Irene and Dennison, Christy},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={5861--5873},
  year={2021}
}

@inproceedings{bender2021dangers,
  title={On the dangers of stochastic parrots: Can language models be too big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={610--623},
  year={2021}
}

@article{magar2022data,
  title={Data contamination: From memorization to exploitation},
  author={Magar, Inbal and Schwartz, Roy},
  journal={arXiv preprint arXiv:2203.08242},
  year={2022}
}

@misc{sainz2023did,
  title={Did chatgpt cheat on your test},
  author={Sainz, Oscar and Campos, Jon Ander and Garc{\'\i}a-Ferrero, Iker and Etxaniz, Julen and Agirre, Eneko},
  year={2023}
}

@article{schaeffer2023pretraining,
  title={Pretraining on the test set is all you need},
  author={Schaeffer, Rylan},
  journal={arXiv preprint arXiv:2309.08632},
  year={2023}
}

@article{bertail2008bootstrapping,
  title={On bootstrapping the ROC curve},
  author={Bertail, Patrice and Cl{\'e}men{\c{c}}con, St{\'e}phan and Vayatis, Nicolas},
  journal={Advances in Neural Information Processing Systems},
  volume={21},
  year={2008}
}

@article{biderman2024emergent,
  title={Emergent and predictable memorization in large language models},
  author={Biderman, Stella and PRASHANTH, USVSN and Sutawika, Lintang and Schoelkopf, Hailey and Anthony, Quentin and Purohit, Shivanshu and Raff, Edward},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}