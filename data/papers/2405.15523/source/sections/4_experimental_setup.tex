\textbf{Models.} As target model \textit{LM} we use the pretrained 1.3B CroissantLLM~\cite{faysse2024croissantllm}, which we fine-tune on documents containing fuzzy trap sequences. As reference model $\textit{LM}_{\text{ref}}$, we use the pretrained LLaMA-2 7B~\cite{touvron2023llama2} to generate the synthetic reference trap sequences. Finally, as masked language model $\textit{MLM}$, we use RoBERTa~\cite{liu2019roberta} to generate the fuzzy duplicates.

\textbf{Fuzzy trap sequences.} We generate $100$ reference trap sequences using $\textit{LM}_{\text{ref}}$. We specifically control for the sequence length ($L_{\text{ref}}(X_{\text{ref}}) = 100$), and perplexity (between 90 and 100) to minimize variance in memorization, as previous works have shown length and perplexity to correlate with memorization~\cite{meeus2024copyright, carlini2022quantifying}. Unless stated otherwise, we use $k=50$ when selecting top $k$ tokens predicted by masked language model $\textit{MLM}$. For number of replacements we consider $R=\{1, 2, 4, 8, 16, 32\}$.

\textbf{Data.} We inject fuzzy trap sequences in a collection of books available in the public domain. We use the open-source library~\cite{kpullygutenberg} to collect $100$ books made available under a permissive license on Project Gutenberg~\cite{projectgutenberg} but have not been included in the training dataset of CroissantLLM~\cite{faysse2024croissantllm}. The books we selected contain $8.7$M tokens in total (tokenized with CroissantLLM tokenizer). For each of the $100$ reference trap sequences, we inject the $n_{\text{dup}}=10$ fuzzy trap sequences at random into one book and use this collection of modified books as dataset for fine-tuning. 

\textbf{Fine-tuning.} In all of our experiments we fine-tune CroissantLLM~\cite{faysse2024croissantllm} on the $100$ modified books for $1$ epoch. We use its maximum sequence length of $2048$ tokens, a batch size of $6$ and optimizer Adam with constant learning rate \num{3e-6} and weight decay of $0.01$. Unsurprisingly, we find that the extent to which the target model \textit{LM} memorizes the trap sequences at the fixed number of training steps, heavily depends on the learning rate. We elaborate on this in Sec~\ref{section:ablations} and throughout the rest of the experiments consider the learning rate fixed to \num{3e-6}. We argue, however, that the \emph{absolute} extent of memorization does not impact our findings, as we here study how fuzzy trap sequences are memorized \emph{relative} to exact duplication of trap sequences, which have been shown by Meeus et al.~\cite{meeus2024copyright} to be memorized in a real-world scenario. Fine-tuning one model on $100$ trap-injected books took roughly 2 GPU-hours on A100 NVIDIA GPUs.

\textbf{Membership Inference Attack (MIA).} To measure the memorization of the fuzzy trap sequences, we instantiate a sequence-level MIA to infer whether $X_{\text{ref}}$ has been seen by the target model \textit{LM}. For this, we generate $100$ new reference trap sequences, which we do not include in the training dataset and thus consider as \emph{non-members}. We consider the $100$ reference trap sequences that are included in the training dataset as \emph{members}. As MIA methodology, we use the \textit{Ratio} attack~\cite{carlini2021extracting}. For each $X_{\text{ref}}$, either \emph{member} or \emph{non-member}, we compute the target model loss divided by the loss computed using the reference model, which we call \emph{membership score} $\alpha(X_{\text{ref}}) = \mathcal{L}_{\textit{LM}}(X_{\text{ref}}) / \mathcal{L}_{\textit{LM}_{\text{ref}}}(X_{\text{ref}})$. We then use $\alpha(X_{\text{ref}})$ to compute the ROC AUC for the binary membership prediction task and use the AUC to measure to what extent the fully trained target model \textit{LM} memorizes the trap sequences. We compute the AUC on $25$ bootstrapped subsets of members and non-members and report both the mean and standard deviation across all results~\cite{bertail2008bootstrapping}. %\todo{See Q.7 in the checklist: we need to explain more on the error bars}

\textbf{Baselines.} The primary goal of this paper is to quantify how fuzzy trap sequences are memorized compared to exact duplication. For 10 fuzzy trap sequences $\{X_\text{ref}, X_2, X_3, \ldots X_{n_{\text{dup}}}\}$, where each $X_i$ has $R$ tokens replaced compared to $X_{\text{ref}}$, we consider the following baselines. As an upper bound, we consider the exact repetition of the reference trap sequence $X_{\text{ref}}$ for $n_{\text{dup}}=10$ times. As a lower bound we consider a single injection of the reference trap sequence, i.e. $n_{\text{dup}}=1$. 

\textbf{Reproducibility.} We will share the code to reproduce our results in the camera-ready version.