\begin{thebibliography}{}

\bibitem[Albergo et~al., 2023]{albergo2023stochastic}
Albergo, M.~S., Boffi, N.~M., and Vanden-Eijnden, E. (2023).
\newblock Stochastic interpolants: A unifying framework for flows and
  diffusions.
\newblock {\em arXiv preprint arXiv:2303.08797}.

\bibitem[Albergo and {Vanden-Eijnden}, 2023]{albergo_building_2023}
Albergo, M.~S. and {Vanden-Eijnden}, E. (2023).
\newblock Building normalizing flows with stochastic interpolants.
\newblock {\em International Conference on Learning Representations}.

\bibitem[Ambrosio et~al., 2008]{ambrosio200gradient}
Ambrosio, L., Gigli, N., and Savar\'{e}, G. (2008).
\newblock {\em Gradient Flows in Metric Spaces and in the Space of Probability
  Measures}.
\newblock Lectures in Mathematics ETH Z\"{u}rich. Birkh\"{a}user Verlag, Basel,
  second edition.

\bibitem[Bauschke and Kruk, 2004]{bauschke2004reflection}
Bauschke, H.~H. and Kruk, S.~G. (2004).
\newblock Reflection-projection method for convex feasibility problems with an
  obtuse cone.
\newblock {\em Journal of Optimization Theory and Applications},
  120(3):503--531.

\bibitem[Benamou and Brenier, 2000]{benamou2000computational}
Benamou, J.-D. and Brenier, Y. (2000).
\newblock A computational fluid mechanics solution to the
  {M}onge--{K}antorovich mass transfer problem.
\newblock {\em Numerische Mathematik}, 84(3):375--393.

\bibitem[Black et~al., 2023]{black2023training}
Black, K., Janner, M., Du, Y., Kostrikov, I., and Levine, S. (2023).
\newblock Training diffusion models with reinforcement learning.
\newblock {\em arXiv preprint arXiv:2305.13301}.

\bibitem[Brekelmans and Neklyudov, 2023]{brekelmans2023schrodinger}
Brekelmans, R. and Neklyudov, K. (2023).
\newblock On {Schr\"odinger} bridge matching and expectation maximization.
\newblock In {\em NeurIPS 2023 Workshop Optimal Transport and Machine
  Learning}.

\bibitem[Brock et~al., 2019]{brock2018large}
Brock, A., Donahue, J., and Simonyan, K. (2019).
\newblock Large scale {GAN} training for high fidelity natural image synthesis.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Cao et~al., 2024]{cao2024neural}
Cao, Z., Wu, X., and Deng, L.-J. (2024).
\newblock Neural shr\"odinger bridge matching for pansharpening.
\newblock {\em arXiv preprint arXiv:2404.11416}.

\bibitem[Chen et~al., 2023]{chen2024deep}
Chen, T., Liu, G.-H., Tao, M., and Theodorou, E. (2023).
\newblock Deep momentum multi-marginal {Schr\"odinger} bridge.
\newblock {\em Advances in Neural Information Processing Systems}.

\bibitem[Chen et~al., 2022]{chen2021likelihood}
Chen, T., Liu, G.-H., and Theodorou, E.~A. (2022).
\newblock Likelihood training of {S}chr\"odinger bridge using forward-backward
  {SDEs} theory.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Chen et~al., 2021]{chen2020optimal}
Chen, Y., Georgiou, T.~T., and Pavon, M. (2021).
\newblock Optimal transport in systems and control.
\newblock {\em Annual Review of Control, Robotics, and Autonomous Systems}, 4.

\bibitem[Chen et~al., 2024]{chen2024probabilistic}
Chen, Y., Goldstein, M., Hua, M., Albergo, M.~S., Boffi, N.~M., and
  Vanden-Eijnden, E. (2024).
\newblock Probabilistic forecasting with stochastic interpolants and
  {F}\"ollmer processes.
\newblock {\em arXiv preprint arXiv:2403.13724}.

\bibitem[Choi et~al., 2020]{choi2020starganv2}
Choi, Y., Uh, Y., Yoo, J., and Ha, J.-W. (2020).
\newblock Stargan v2: Diverse image synthesis for multiple domains.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}.

\bibitem[Chong and Forsyth, 2020]{unbiased_fid}
Chong, M.~J. and Forsyth, D. (2020).
\newblock Effectively unbiased {FID} and inception score and where to find
  them.
\newblock In {\em IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}.

\bibitem[Cohen et~al., 2017]{cohen2017emnist}
Cohen, G., Afshar, S., Tapson, J., and van Schaik, A. (2017).
\newblock {EMNIST:} an extension of {MNIST} to handwritten letters.
\newblock {\em arXiv preprint arXiv:1702.05373}.

\bibitem[Courant and Hilbert, 2008]{courant2008methods}
Courant, R. and Hilbert, D. (2008).
\newblock {\em Methods of Mathematical Physics: Partial Differential
  Equations}.
\newblock John Wiley \& Sons.

\bibitem[Cuturi, 2013]{cuturi2013sinkhorn}
Cuturi, M. (2013).
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Dai~Pra, 1991]{dai1991stochastic}
Dai~Pra, P. (1991).
\newblock A stochastic control approach to reciprocal diffusion processes.
\newblock {\em Applied Mathematics and Optimization}, 23(1):313--329.

\bibitem[Daras et~al., 2023a]{daras2024consistent}
Daras, G., Dagan, Y., Dimakis, A., and Daskalakis, C. (2023a).
\newblock Consistent diffusion models: Mitigating sampling drift by learning to
  be consistent.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Daras et~al., 2023b]{daras2024ambient}
Daras, G., Shah, K., Dagan, Y., Gollakota, A., Dimakis, A., and Klivans, A.
  (2023b).
\newblock Ambient diffusion: Learning clean distributions from corrupted data.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[De~Bortoli et~al., 2024]{debortoli2024target}
De~Bortoli, V., Hutchinson, M., Wirnsberger, P., and Doucet, A. (2024).
\newblock Target score matching.
\newblock {\em arXiv preprint arXiv:2402.08667}.

\bibitem[De~Bortoli et~al., 2023]{debortoli2023augmented}
De~Bortoli, V., Liu, G.-H., Chen, T., Theodorou, E.~A., and Nie, W. (2023).
\newblock Augmented bridge matching.
\newblock {\em arXiv preprint arXiv:2311.06978}.

\bibitem[De~Bortoli et~al., 2021]{debortoli2021diffusion}
De~Bortoli, V., Thornton, J., Heng, J., and Doucet, A. (2021).
\newblock Diffusion {S}chr{\"o}dinger bridge with applications to score-based
  generative modeling.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[De~Lange et~al., 2021]{de2021continual}
De~Lange, M., Aljundi, R., Masana, M., Parisot, S., Jia, X., Leonardis, A.,
  Slabaugh, G., and Tuytelaars, T. (2021).
\newblock A continual learning survey: Defying forgetting in classification
  tasks.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  44(7):3366--3385.

\bibitem[Deng et~al., 2024]{deng2024variational}
Deng, W., Luo, W., Tan, Y., Bilo{\v{s}}, M., Chen, Y., Nevmyvaka, Y., and Chen,
  R.~T. (2024).
\newblock Variational {S}chr\"odinger diffusion models.
\newblock {\em arXiv preprint arXiv:2405.04795}.

\bibitem[Dhariwal and Nichol, 2021]{dhariwal2021diffusion}
Dhariwal, P. and Nichol, A.~Q. (2021).
\newblock Diffusion models beat {GAN}s on image synthesis.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Diefenbacher et~al., 2024]{diefenbacher2024improving}
Diefenbacher, S., Liu, G.-H., Mikuni, V., Nachman, B., and Nie, W. (2024).
\newblock Improving generative model-based unfolding with {S}chr\"odinger
  bridges.
\newblock {\em Physical Review D}, 109(7):076011.

\bibitem[Dupuis and Ellis, 2011]{dupuis2011weak}
Dupuis, P. and Ellis, R.~S. (2011).
\newblock {\em A Weak Convergence Approach to the Theory of Large Deviations}.
\newblock John Wiley \& Sons.

\bibitem[Eyring et~al., 2024]{eyring2023unbalancedness}
Eyring, L., Klein, D., Uscidda, T., Palla, G., Kilbertus, N., Akata, Z., and
  Theis, F. (2024).
\newblock Unbalancedness in neural {M}onge maps improves unpaired domain
  translation.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Fan et~al., 2024]{fan2024reinforcement}
Fan, Y., Watkins, O., Du, Y., Liu, H., Ryu, M., Boutilier, C., Abbeel, P.,
  Ghavamzadeh, M., Lee, K., and Lee, K. (2024).
\newblock Reinforcement learning for fine-tuning text-to-image diffusion
  models.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Ge et~al., 2021]{ge2021ota}
Ge, Z., Liu, S., Li, Z., Yoshie, O., and Sun, J. (2021).
\newblock Ota: Optimal transport assignment for object detection.
\newblock In {\em IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}.

\bibitem[Genevay et~al., 2018]{genevay18a}
Genevay, A., Peyre, G., and Cuturi, M. (2018).
\newblock Learning generative models with {S}inkhorn divergences.
\newblock In {\em Artificial Intelligence and Statistics}.

\bibitem[Gushchin et~al., 2024a]{gushchin2024light}
Gushchin, N., Kholkin, S., Burnaev, E., and Korotin, A. (2024a).
\newblock Light and optimal schr\"odinger bridge matching.
\newblock {\em arXiv preprint arXiv:2402.03207}.

\bibitem[Gushchin et~al., 2024b]{gushchin2024entropic}
Gushchin, N., Kolesov, A., Korotin, A., Vetrov, D.~P., and Burnaev, E. (2024b).
\newblock Entropic neural optimal transport via diffusion processes.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Heusel et~al., 2017]{heusel2017gans}
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S.
  (2017).
\newblock {GAN}s trained by a two time-scale update rule converge to a local
  {N}ash equilibrium.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Ho et~al., 2020]{ho_denoising_2020}
Ho, J., Jain, A., and Abbeel, P. (2020).
\newblock Denoising diffusion probabilistic models.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Hoogeboom et~al., 2023]{hoogeboom2023simple}
Hoogeboom, E., Heek, J., and Salimans, T. (2023).
\newblock Simple diffusion: End-to-end diffusion for high resolution images.
\newblock In {\em International Conference on Machine Learning}.

\bibitem[Hu et~al., 2021]{hu2021lora}
Hu, E.~J., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., Chen, W.,
  et~al. (2021).
\newblock {LoRA}: Low-rank adaptation of large language models.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Hudson et~al., 2023]{hudson2023soda}
Hudson, D.~A., Zoran, D., Malinowski, M., Lampinen, A.~K., Jaegle, A.,
  McClelland, J.~L., Matthey, L., Hill, F., and Lerchner, A. (2023).
\newblock Soda: Bottleneck diffusion models for representation learning.
\newblock {\em arXiv preprint arXiv:2311.17901}.

\bibitem[Karimi et~al., 2024]{karimi2024sinkhorn}
Karimi, M.~R., Hsieh, Y.-P., and Krause, A. (2024).
\newblock Sinkhorn flow as mirror flow: A continuous-time framework for
  generalizing the {S}inkhorn algorithm.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}.

\bibitem[Karras et~al., 2022]{karras2022elucidating}
Karras, T., Aittala, M., Aila, T., and Laine, S. (2022).
\newblock Elucidating the design space of diffusion-based generative models.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Kim et~al., 2024]{kim2023unpaired}
Kim, B., Kwon, G., Kim, K., and Ye, J.~C. (2024).
\newblock Unpaired image-to-image translation via neural schr{\"o}dinger
  bridge.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Kingma and Ba, 2015]{kingma:adam}
Kingma, D.~P. and Ba, J. (2015).
\newblock Adam: A method for stochastic optimization.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Korotin et~al., 2024]{korotin2023light}
Korotin, A., Gushchin, N., and Burnaev, E. (2024).
\newblock Light {S}chr\"odinger bridge.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[LeCun and Cortes, 2010]{mnist}
LeCun, Y. and Cortes, C. (2010).
\newblock {MNIST} handwritten digit database.

\bibitem[Lee et~al., 2023]{lee2023aligning}
Lee, K., Liu, H., Ryu, M., Watkins, O., Du, Y., Boutilier, C., Abbeel, P.,
  Ghavamzadeh, M., and Gu, S.~S. (2023).
\newblock Aligning text-to-image models using human feedback.
\newblock {\em arXiv preprint arXiv:2302.12192}.

\bibitem[L{\'e}onard, 2014]{leonard2014survey}
L{\'e}onard, C. (2014).
\newblock A survey of the {S}chr{\"o}dinger problem and some of its connections
  with optimal transport.
\newblock {\em Discrete \& Continuous Dynamical Systems-A}, 34(4):1533--1574.

\bibitem[L{\'e}onard et~al., 2014]{leonard2014reciprocal}
L{\'e}onard, C., R{\oe}lly, S., Zambrini, J.-C., et~al. (2014).
\newblock Reciprocal processes. a measure-theoretical point of view.
\newblock {\em Probability Surveys}, 11:237--269.

\bibitem[Lipman et~al., 2023]{lipman_flow_2022}
Lipman, Y., Chen, R. T.~Q., {Ben-Hamu}, H., Nickel, M., and Le, M. (2023).
\newblock Flow matching for generative modeling.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Liu et~al., 2022]{liu2022deep}
Liu, G.-H., Chen, T., So, O., and Theodorou, E.~A. (2022).
\newblock Deep generalized {S}chr\"odinger bridge.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Liu et~al., 2023a]{liu2023I2SB}
Liu, G.-H., Vahdat, A., Huang, D.-A., Theodorou, E.~A., Nie, W., and
  Anandkumar, A. (2023a).
\newblock I2sb: image-to-image {S}chr{\"o}dinger bridge.
\newblock In {\em International Conference on Machine Learning}.

\bibitem[Liu, 2022]{liu2022rectified}
Liu, Q. (2022).
\newblock Rectified flow: A marginal preserving approach to optimal transport.
\newblock {\em arXiv preprint arXiv:2209.14577}.

\bibitem[Liu et~al., 2023b]{liu_flow_2023}
Liu, X., Gong, C., and Liu, Q. (2023b).
\newblock Flow straight and fast: Learning to generate and transfer data with
  rectified flow.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Masip et~al., 2023]{masip2023continual}
Masip, S., Rodriguez, P., Tuytelaars, T., and van~de Ven, G.~M. (2023).
\newblock Continual learning of diffusion models with generative distillation.
\newblock {\em arXiv preprint arXiv:2311.14028}.

\bibitem[Mnih et~al., 2015]{mnih2015human}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
  (2015).
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529--533.

\bibitem[Neal and Hinton, 1998]{neal1998view}
Neal, R.~M. and Hinton, G.~E. (1998).
\newblock A view of the {EM} algorithm that justifies incremental, sparse, and
  other variants.
\newblock In {\em Learning in Graphical Models}, pages 355--368. Springer.

\bibitem[Neklyudov et~al., 2023a]{neklyudov2023action}
Neklyudov, K., Brekelmans, R., Severo, D., and Makhzani, A. (2023a).
\newblock Action matching: Learning stochastic dynamics from samples.
\newblock In {\em International Conference on Machine Learning}.

\bibitem[Neklyudov et~al., 2023b]{neklyudov2023computational}
Neklyudov, K., Brekelmans, R., Tong, A., Atanackovic, L., Liu, Q., and
  Makhzani, A. (2023b).
\newblock A computational framework for solving {W}asserstein {L}agrangian
  flows.
\newblock {\em arXiv preprint arXiv:2310.10649}.

\bibitem[Nichol and Dhariwal, 2021]{nichol2021improved}
Nichol, A.~Q. and Dhariwal, P. (2021).
\newblock Improved denoising diffusion probabilistic models.
\newblock In {\em International Conference on Machine Learning}.

\bibitem[Parisi et~al., 2019]{parisi2019continual}
Parisi, G.~I., Kemker, R., Part, J.~L., Kanan, C., and Wermter, S. (2019).
\newblock Continual lifelong learning with neural networks: A review.
\newblock {\em Neural networks}, 113:54--71.

\bibitem[Pavon et~al., 2021]{pavon2018data}
Pavon, M., Trigila, G., and Tabak, E.~G. (2021).
\newblock The data-driven {S}chr{\"o}dinger bridge.
\newblock {\em Communications on Pure and Applied Mathematics}, 74:1545--1573.

\bibitem[Peluchetti, 2021]{peluchettinon}
Peluchetti, S. (2021).
\newblock Non-denoising forward-time diffusions.
\newblock \url{https://openreview.net/forum?id=oVfIKuhqfC}.

\bibitem[Peluchetti, 2023]{peluchetti_diffusion_2023}
Peluchetti, S. (2023).
\newblock Diffusion bridge mixture transports, {Schr\"odinger} bridge problems
  and generative modeling.
\newblock {\em Journal of Machine Learning Research}, 24:1--51.

\bibitem[Perez et~al., 2018]{perez2018film}
Perez, E., Strub, F., de~Vries, H., Dumoulin, V., and Courville, A.~C. (2018).
\newblock Film: Visual reasoning with a general conditioning layer.
\newblock In {\em AAAI}.

\bibitem[Peyr{\'e} et~al., 2019]{peyre2019computational}
Peyr{\'e}, G., Cuturi, M., et~al. (2019).
\newblock Computational optimal transport: With applications to data science.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  11(5-6):355--607.

\bibitem[Pooladian et~al., 2023]{pooladian_2023_multisample}
Pooladian, A.-A., Ben-Hamu, H., Domingo-Enrich, C., Amos, B., Lipman, Y., and
  Chen, R.~T. (2023).
\newblock Multisample flow matching: Straightening flows with minibatch
  couplings.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Rafailov et~al., 2024]{rafailov2024direct}
Rafailov, R., Sharma, A., Mitchell, E., Manning, C.~D., Ermon, S., and Finn, C.
  (2024).
\newblock Direct preference optimization: Your language model is secretly a
  reward model.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[R{\oe}lly, 2013]{roelly2013reciprocal}
R{\oe}lly, S. (2013).
\newblock Reciprocal processes: a stochastic analysis approach.
\newblock In {\em Modern Stochastics and Applications}, pages 53--67. Springer.

\bibitem[Ronneberger et~al., 2015]{unet}
Ronneberger, O., Fischer, P., and Brox, T. (2015).
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In Navab, N., Hornegger, J., Wells, W.~M., and Frangi, A.~F.,
  editors, {\em Medical Image Computing and Computer-Assisted Intervention --
  MICCAI 2015}, pages 234--241, Cham. Springer International Publishing.

\bibitem[Schr{\"o}dinger, 1932]{schrodinger1932theorie}
Schr{\"o}dinger, E. (1932).
\newblock Sur la th{\'e}orie relativiste de l'{\'e}lectron et
  l'interpr{\'e}tation de la m{\'e}canique quantique.
\newblock {\em Annales de l'Institut Henri Poincar{\'e}}, 2(4):269--310.

\bibitem[Shi et~al., 2023]{shi2023DSBM}
Shi, Y., De~Bortoli, V., Campbell, A., and Doucet, A. (2023).
\newblock Diffusion {S}chr{\"o}dinger bridge matching.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Shi et~al., 2022]{shi2022conditional}
Shi, Y., De~Bortoli, V., Deligiannidis, G., and Doucet, A. (2022).
\newblock Conditional simulation using diffusion {S}chr{\"o}dinger bridges.
\newblock In {\em Uncertainty in Artificial Intelligence}.

\bibitem[Smith et~al., 2023]{smith2023continual}
Smith, J.~S., Hsu, Y.-C., Zhang, L., Hua, T., Kira, Z., Shen, Y., and Jin, H.
  (2023).
\newblock Continual diffusion: Continual customization of text-to-image
  diffusion with c-lora.
\newblock {\em arXiv preprint arXiv:2304.06027}.

\bibitem[Sommerfeld et~al., 2019]{sommerfeld2019optimal}
Sommerfeld, M., Schrieber, J., Zemel, Y., and Munk, A. (2019).
\newblock Optimal transport: {F}ast probabilistic approximation with exact
  solvers.
\newblock {\em Journal of Machine Learning Research}, 20(105):1--23.

\bibitem[Somnath et~al., 2023]{somnath2023aligned}
Somnath, V.~R., Pariset, M., Hsieh, Y.-P., Martinez, M.~R., Krause, A., and
  Bunne, C. (2023).
\newblock Aligned diffusion {S}chr{\"o}dinger bridges.
\newblock In {\em Uncertainty in Artificial Intelligence}.

\bibitem[Song et~al., 2021a]{song_denoising_2021}
Song, J., Meng, C., and Ermon, S. (2021a).
\newblock Denoising diffusion implicit models.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Song and Ermon, 2020]{song_improved_2020}
Song, Y. and Ermon, S. (2020).
\newblock Improved techniques for training score-based generative models.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Song et~al., 2021b]{song2020score}
Song, Y., Sohl{-}Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole,
  B. (2021b).
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Su et~al., 2023]{su2022dual}
Su, X., Song, J., Meng, C., and Ermon, S. (2023).
\newblock Dual diffusion implicit bridges for image-to-image translation.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Tamir et~al., 2023]{tamir2023transport}
Tamir, E., Trapp, M., and Solin, A. (2023).
\newblock Transport with support: Data-conditional diffusion bridges.
\newblock {\em Transactions on Machine Learning Research}.

\bibitem[Thornton et~al., 2022]{thornton2022riemannian}
Thornton, J., Hutchinson, M., Mathieu, E., De~Bortoli, V., Teh, Y.~W., and
  Doucet, A. (2022).
\newblock Riemannian diffusion {S}chr\"odinger bridge.
\newblock {\em arXiv preprint arXiv:2207.03024}.

\bibitem[Tong et~al., 2024a]{tong_conditional_2023}
Tong, A., Fatras, K., Malkin, N., Huguet, G., Zhang, Y., {Rector-Brooks}, J.,
  Wolf, G., and Bengio, Y. (2024a).
\newblock Improving and generalizing flow-based generative models with
  minibatch optimal transport.
\newblock {\em Transactions on Machine Learning Research}.

\bibitem[Tong et~al., 2024b]{tong2024simulationfree}
Tong, A., Malkin, N., Fatras, K., Atanackovic, L., Zhang, Y., Huguet, G., Wolf,
  G., and Bengio, Y. (2024b).
\newblock Simulation-free {Schr\"odinger} bridges via score and flow matching.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}.

\bibitem[Vargas et~al., 2024]{vargas2023transport}
Vargas, F., Padhy, S., Blessing, D., and N{\"u}sken, N. (2024).
\newblock Transport meets variational inference: Controlled {M}onte {C}arlo
  diffusions.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Vargas et~al., 2021]{vargas2021solving}
Vargas, F., Thodoroff, P., Lamacraft, A., and Lawrence, N. (2021).
\newblock Solving {S}chr{\"o}dinger bridges via maximum likelihood.
\newblock {\em Entropy}, 23(9):1134.

\bibitem[Yang et~al., 2023]{yang2023using}
Yang, K., Tao, J., Lyu, J., Ge, C., Chen, J., Li, Q., Shen, W., Zhu, X., and
  Li, X. (2023).
\newblock Using human feedback to fine-tune diffusion models without any reward
  model.
\newblock {\em arXiv preprint arXiv:2311.13231}.

\bibitem[Zaj{\k{a}}c et~al., 2023]{zajkac2023exploring}
Zaj{\k{a}}c, M., Deja, K., Kuzina, A., Tomczak, J.~M., Trzci{\'n}ski, T.,
  Shkurti, F., and Mi{\l}o{\'s}, P. (2023).
\newblock Exploring continual learning of diffusion models.
\newblock {\em arXiv preprint arXiv:2303.15342}.

\bibitem[Zhang et~al., 2018]{zhang2018unreasonable}
Zhang, R., Isola, P., Efros, A.~A., Shechtman, E., and Wang, O. (2018).
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In {\em Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pages 586--595.

\bibitem[Zhou et~al., 2022]{zhou2022rethinking}
Zhou, T., Wang, W., Konukoglu, E., and Van~Gool, L. (2022).
\newblock Rethinking semantic segmentation: A prototype view.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}.

\end{thebibliography}
