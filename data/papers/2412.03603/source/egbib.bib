@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(AAAI = {ICML})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {{ECCV} submission ID 00324, supplied as supplemental material {\tt 00324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{luo2024diff,
  title={Diff-foley: Synchronized video-to-audio synthesis with latent diffusion models},
  author={Luo, Simian and Yan, Chuanhao and Hu, Chenxu and Zhao, Hang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@ARTICLE{Hung2022,
  title={A Large TV Dataset for Speech and Music Activity Detection},
  author={Hung, Yun-Ning and Wu, Chih-Wei and Orife, Iroro and Hipple, Aaron and Wolcott, William and Lerch, Alexander},
  journal={EURASIP Journal on Audio, Speech, and Music Processing},
  volume={2022},
  number={1},
  pages={21},
  year={2022},
  publisher={Springer}
}

@article{haji2024taming,
  title={Taming data and transformers for audio generation},
  author={Haji-Ali, Moayed and Menapace, Willi and Siarohin, Aliaksandr and Balakrishnan, Guha and Tulyakov, Sergey and Ordonez, Vicente},
  journal={arXiv preprint arXiv:2406.19388},
  year={2024}
}

@article{kong2020hifi,
  title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17022--17033},
  year={2020}
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@book{ECCV2022,
    editor = {Shai Avidan and Gabriel Brostow and Moustapha Cissé and Giovanni Maria Farinella and Tal Hassner},
    title = {Computer Vision – ECCV 2022},
    year = {2022},
    publisher = {Springer},
    doi = {10.1007/978-3-031-19769-7}
}

@article{zhou2023maskdiffusion,
  title={Maskdiffusion: Boosting text-to-image consistency with conditional mask},
  author={Zhou, Yupeng and Zhou, Daquan and Zhu, Zuo-Liang and Wang, Yaxing and Hou, Qibin and Feng, Jiashi},
  journal={arXiv preprint},
  year={2023}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={MICCAI 2015},
  year={2015}
}

@article{feng2022training,
  title={Training-free structured diffusion guidance for compositional text-to-image synthesis},
  author={Feng, Weixi and He, Xuehai and Fu, Tsu-Jui and Jampani, Varun and Akula, Arjun and Narayana, Pradyumna and Basu, Sugato and Wang, Xin Eric and Wang, William Yang},
  journal={ICLR},
  year={2023}
}

@article{zhou2023magicvideo,
    title={MagicVideo: Efficient Video Generation With Latent Diffusion Models}, 
    author={Daquan Zhou and Weimin Wang and Hanshu Yan and Weiwei Lv and Yizhe Zhu and Jiashi Feng},
    journal={arXiv preprint},
    year={2023},
}


 @inproceedings{Zeng2022lion,  
 title={LION: Latent Point Diffusion Models for 3D Shape Generation}, 
 author={Zeng, Xiaohui and Vahdat, Arash and Williams, Francis and Gojcic, Zan and Litany, Or and Fidler, Sanja and Kreis, Karsten}, 
 year={2022}, 
 booktitle = NIPS
 }

 @inproceedings{Zhou2021shape3d,  
 title={3D Shape Generation and Completion through Point-Voxel Diffusion}, 
 booktitle=ICCV, 
 author={Zhou, Linqi and Du, Yilun and Wu, Jiajun}, 
 year={2021}
 }


@inproceedings{li2023open,
  title={Open-vocabulary object segmentation with diffusion models},
  author={Li, Ziyi and Zhou, Qinye and Zhang, Xiaoyun and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},
  booktitle=ICCV,
  year={2023}
}

@article{amit2021segdiff,
  title={Segdiff: Image segmentation with diffusion probabilistic models},
  author={Amit, Tomer and Shaharbany, Tal and Nachmani, Eliya and Wolf, Lior},
  journal={arXiv preprint},
  year={2021}
}

@inproceedings{rombach2022high,
    title={High-resolution image synthesis with latent diffusion models},
    author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
    booktitle=CVPR,
    year={2022}
}


@article{saharia2022photorealistic,
    title={Photorealistic text-to-image diffusion models with deep language understanding},
    author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
    journal=NIPS,
    year={2022}
}

@inproceedings{ho2020denoising,
    title = {Denoising Diffusion Probabilistic Models},
    author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
    booktitle = NIPS,
    year = {2020}
}

@inproceedings{hong2023improving,
  title={Improving sample quality of diffusion models using self-attention guidance},
  author={Hong, Susung and Lee, Gyuseong and Jang, Wooseok and Kim, Seungryong},
  booktitle=ICCV,
  year={2023}
}

@article{chefer2023attend,
  title={Attend-and-excite: Attention-based semantic guidance for text-to-image diffusion models},
  author={Chefer, Hila and Alaluf, Yuval and Vinker, Yael and Wolf, Lior and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  year={2023}
}

@article{brock2018large,
  title={Large scale GAN training for high fidelity natural image synthesis},
  author={Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  journal={arXiv preprint arXiv:1809.11096},
  year={2018}
}

@article{genau,
  title={Taming data and transformers for audio generation},
  author={Haji-Ali, Moayed and Menapace, Willi and Siarohin, Aliaksandr and Balakrishnan, Guha and Tulyakov, Sergey and Ordonez, Vicente},
  journal={arXiv preprint arXiv:2406.19388},
  year={2024}
}

@article{lp-music-caps,
  title={Lp-musiccaps: Llm-based pseudo music captioning},
  author={Doh, SeungHeon and Choi, Keunwoo and Lee, Jongpil and Nam, Juhan},
  journal={arXiv preprint arXiv:2307.16372},
  year={2023}
}

@article{hifigan,
  title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal=NIPS,
  volume={33},
  pages={17022--17033},
  year={2020}
}

@inproceedings{blattmann2023align,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle=CVPR,
  year={2023}
}

@article{wang2024instantid,
  title={Instantid: Zero-shot identity-preserving generation in seconds},
  author={Wang, Qixun and Bai, Xu and Wang, Haofan and Qin, Zekui and Chen, Anthony},
  journal={arXiv preprint},
  year={2024}
}

@article{ramesh2022hierarchical,
    title={Hierarchical text-conditional image generation with clip latents},
    author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
    journal={arXiv preprint},
    year={2022}
}

@article{Peebles2022DiT,
    title={Scalable Diffusion Models with Transformers},
    author={William Peebles and Saining Xie},
    journal={arXiv preprint},
    year={2022},
}

@inproceedings{bain2021frozen,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  booktitle=ICCV,
  year={2021}
}

@article{guo2023sparsectrl,
  title={Sparsectrl: Adding sparse controls to text-to-video diffusion models},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  journal={arXiv preprint},
  year={2023}
}

@article{chen2023seine,
title={SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction},
author={Chen, Xinyuan and Wang, Yaohui and Zhang, Lingjun and Zhuang, Shaobin and Ma, Xin and Yu, Jiashuo and Wang, Yali and Lin, Dahua and Qiao, Yu and Liu, Ziwei},
journal={arXiv preprint},
year={2023}
}

@article{gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint},
  year={2022}
}

@inproceedings{ruiz2023dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  booktitle=CVPR,
  year={2023}
}

@inproceedings{kumari2023multi,
  title={Multi-concept customization of text-to-image diffusion},
  author={Kumari, Nupur and Zhang, Bingliang and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},
  booktitle=CVPR,
  year={2023}
}
@article{Song2021score,  
title={Score-Based Generative Modeling through Stochastic Differential Equations}, 
journal=ICLR, 
author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, DiederikP. and Kumar, Abhishek and Ermon, Stefano and Poole, Ben}, 
year={2021}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={ICML},
  year={2015}
}

@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint},
  year={2020}
}

@article{lu2022dpm,
  title={Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps},
  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
  journal=NIPS,
  year={2022}
}

@article{zhang2022fast,
  title={Fast Sampling of Diffusion Models with Exponential Integrator},
  author={Zhang, Qinsheng and Chen, Yongxin},
  journal=ICLR,
  year={2023}
}


@article{wang2023exploiting,
  title={Exploiting Diffusion Prior for Real-World Image Super-Resolution},
  author={Wang, Jianyi and Yue, Zongsheng and Zhou, Shangchen and Chan, Kelvin CK and Loy, Chen Change},
  journal={arXiv preprint},
  year={2023}
}

@inproceedings{Lugmayr_2022_CVPR,
    author    = {Lugmayr, Andreas and Danelljan, Martin and Romero, Andres and Yu, Fisher and Timofte, Radu and Van Gool, Luc},
    title     = {RePaint: Inpainting Using Denoising Diffusion Probabilistic Models},
    booktitle = CVPR,
    year      = {2022},
}

@article{xie2022smartbrush,
    title={SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Model}, 
    author={Shaoan Xie and Zhifei Zhang and Zhe Lin and Tobias Hinz and Kun Zhang},
    journal={arXiv preprint},
    year={2022},
}

@article{saharia2021image,
    title={Image super-resolution via iterative refinement},
    author={Saharia, Chitwan and Ho, Jonathan and Chan, William and Salimans, Tim and Fleet, David J. and Norouzi, Mohammad},
    journal=PAMI, 
    year={2023},
}

@article{ho2022video,
  title={Video diffusion models. arXiv 2022},
  author={Ho, J and Salimans, T and Gritsenko, A and Chan, W and Norouzi, M and Fleet, DJ},
  journal={arXiv preprint},
  year={2022}
}


@article{wang2023modelscope,
  title={Modelscope text-to-video technical report},
  author={Wang, Jiuniu and Yuan, Hangjie and Chen, Dayou and Zhang, Yingya and Wang, Xiang and Zhang, Shiwei},
  journal={arXiv preprint},
  year={2023}
}

@article{ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others},
  journal={arXiv preprint},
  year={2022}
}

@article{podell2023sdxl,
  title={Sdxl:
         Improving latent diffusion models for high-resolution image synthesis},
  author={Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and M{\"u}ller, Jonas and Penna, Joe and Rombach, Robin},
  journal={arXiv preprint},
  year={2023}
}

@article{li2023photomaker,
  title={Photomaker: Customizing realistic human photos via stacked id embedding},
  author={Li, Zhen and Cao, Mingdeng and Wang, Xintao and Qi, Zhongang and Cheng, Ming-Ming and Shan, Ying},
  journal={arXiv preprint},
  year={2023}
}

@article{ye2023ip,
  title={Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models},
  author={Ye, Hu and Zhang, Jun and Liu, Sibo and Han, Xiao and Yang, Wei},
  journal={arXiv preprint},
  year={2023}
}

@article{xu2023magicanimate,
  title={Magicanimate: Temporally consistent human image animation using diffusion model},
  author={Xu, Zhongcong and Zhang, Jianfeng and Liew, Jun Hao and Yan, Hanshu and Liu, Jia-Wei and Zhang, Chenxu and Feng, Jiashi and Shou, Mike Zheng},
  journal={arXiv preprint},
  year={2023}
}


@article{hu2023animate,
  title={Animate anyone: Consistent and controllable image-to-video synthesis for character animation},
  author={Hu, Li and Gao, Xin and Zhang, Peng and Sun, Ke and Zhang, Bang and Bo, Liefeng},
  journal={arXiv preprint},
  year={2023}
}

@article{blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint},
  year={2023}
}

@article{guo2023animatediff,
  title={AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  journal=ICLR,
  year={2024}
}

@article{jiang2023text2performer,
  title={Text2Performer: Text-Driven Human Video Generation},
  author={Jiang, Yuming and Yang, Shuai and Koh, Tong Liang and Wu, Wayne and Loy, Chen Change and Liu, Ziwei},
  journal={arXiv preprint},
  year={2023}
}

@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint},
  year={2022}
}

@article{wang2023lavie,
  title={Lavie: High-quality video generation with cascaded latent diffusion models},
  author={Wang, Yaohui and Chen, Xinyuan and Ma, Xin and Zhou, Shangchen and Huang, Ziqi and Wang, Yi and Yang, Ceyuan and He, Yinan and Yu, Jiashuo and Yang, Peiqing and others},
  journal={arXiv preprint},
  year={2023}
}

@article{yang2023probabilistic,
  title={Probabilistic Adaptation of Text-to-Video Models},
  author={Yang, Mengjiao and Du, Yilun and Dai, Bo and Schuurmans, Dale and Tenenbaum, Joshua B and Abbeel, Pieter},
  journal={arXiv preprint},
  year={2023}
}

@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={ICCV},
  year={2023}
}

@article{mou2023t2i,
  title={T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models},
  author={Mou, Chong and Wang, Xintao and Xie, Liangbin and Wu, Yanze and Zhang, Jian and Qi, Zhongang and Shan, Ying and Qie, Xiaohu},
  journal={arXiv preprint},
  year={2023}
}

@article{mao2023training,
  title={Training-Free Location-Aware Text-to-Image Synthesis},
  author={Mao, Jiafeng and Wang, Xueting},
  journal={arXiv preprint},
  year={2023}
}

@inproceedings{feng2023trainingfree,
title={Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis},
author={Weixi Feng and Xuehai He and Tsu-Jui Fu and Varun Jampani and Arjun Reddy Akula and Pradyumna Narayana and Sugato Basu and Xin Eric Wang and William Yang Wang},
booktitle=ICLR,
year={2023}
}

@article{ma2023directed,
  title={Directed diffusion: Direct control of object placement through attention guidance},
  author={Ma, Wan-Duo Kurt and Lewis, JP and Kleijn, W Bastiaan and Leung, Thomas},
  journal={arXiv preprint},
  year={2023}
}

@article{zhao2023motiondirector,
  title={Motiondirector: Motion customization of text-to-video diffusion models},
  author={Zhao, Rui and Gu, Yuchao and Wu, Jay Zhangjie and Zhang, David Junhao and Liu, Jiawei and Wu, Weijia and Keppo, Jussi and Shou, Mike Zheng},
  journal={arXiv preprint},
  year={2023}
}

@article{zhang2023show,
  title={Show-1: Marrying pixel and latent diffusion models for text-to-video generation},
  author={Zhang, David Junhao and Wu, Jay Zhangjie and Liu, Jia-Wei and Zhao, Rui and Ran, Lingmin and Gu, Yuchao and Gao, Difei and Shou, Mike Zheng},
  journal={arXiv preprint},
  year={2023}
}

@article{wu2023lamp,
  title={Lamp: Learn a motion pattern for few-shot-based video generation},
  author={Wu, Ruiqi and Chen, Liangyu and Yang, Tong and Guo, Chunle and Li, Chongyi and Zhang, Xiangyu},
  journal={arXiv preprint},
  year={2023}
}


@article{wang2023disco,
  title={Disco: Disentangled control for referring human dance generation in real world},
  author={Wang, Tan and Li, Linjie and Lin, Kevin and Lin, Chung-Ching and Yang, Zhengyuan and Zhang, Hanwang and Liu, Zicheng and Wang, Lijuan},
  journal={arXiv preprint},
  year={2023}
}


@article{ma2023follow,
  title={Follow Your Pose: Pose-Guided Text-to-Video Generation using Pose-Free Videos},
  author={Ma, Yue and He, Yingqing and Cun, Xiaodong and Wang, Xintao and Shan, Ying and Li, Xiu and Chen, Qifeng},
  journal={arXiv preprint},
  year={2023}
}

@inproceedings{ni2023conditional,
  title={Conditional Image-to-Video Generation with Latent Flow Diffusion Models},
  author={Ni, Haomiao and Shi, Changhao and Li, Kai and Huang, Sharon X and Min, Martin Renqiang},
  booktitle=CVPR,
  year={2023}
}

@article{he2023animate,
  title={Animate-a-story: Storytelling with retrieval-augmented video generation},
  author={He, Yingqing and Xia, Menghan and Chen, Haoxin and Cun, Xiaodong and Gong, Yuan and Xing, Jinbo and Zhang, Yong and Wang, Xintao and Weng, Chao and Shan, Ying and others},
  journal={arXiv preprint},
  year={2023}
}

@inproceedings{zhang2018unreasonable,
  title={The unreasonable effectiveness of deep features as a perceptual metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle=CVPR,
  year={2018}
}

@article{tian2023diffuse,
  title={Diffuse, attend, and segment: Unsupervised zero-shot segmentation using stable diffusion},
  author={Tian, Junjiao and Aggarwal, Lavisha and Colaco, Andrea and Kira, Zsolt and Gonzalez-Franco, Mar},
  journal={arXiv preprint},
  year={2023}
}


@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021}
}

@inproceedings{cherti2023reproducible,
  title={Reproducible scaling laws for contrastive language-image learning},
  author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{wu2023tune,
  title={Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation},
  author={Wu, Jay Zhangjie and Ge, Yixiao and Wang, Xintao and Lei, Stan Weixian and Gu, Yuchao and Shi, Yufei and Hsu, Wynne and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{cao2023masactrl,
  title={Masactrl: Tuning-free mutual self-attention control for consistent image synthesis and editing},
  author={Cao, Mingdeng and Wang, Xintao and Qi, Zhongang and Shan, Ying and Qie, Xiaohu and Zheng, Yinqiang},
  booktitle={ICCV},
  year={2023}
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint},
  year={2022}
}


@inproceedings{avrahami2024chosen,
  title={The chosen one: Consistent characters in text-to-image diffusion models},
  author={Avrahami, Omri and Hertz, Amir and Vinker, Yael and Arar, Moab and Fruchter, Shlomi and Fried, Ohad and Cohen-Or, Daniel and Lischinski, Dani},
  booktitle={ACM SIGGRAPH 2024 conference papers},
  pages={1--12},
  year={2024}
}

@article{tewel2024training,
  title={Training-free consistent text-to-image generation},
  author={Tewel, Yoad and Kaduri, Omri and Gal, Rinon and Kasten, Yoni and Wolf, Lior and Chechik, Gal and Atzmon, Yuval},
  journal={ACM Transactions on Graphics (TOG)},
  volume={43},
  number={4},
  pages={1--18},
  year={2024},
  publisher={ACM New York, NY, USA}
}

@article{jeong2023zero,
  title={Zero-shot generation of coherent storybook from plain text story using diffusion models},
  author={Jeong, Hyeonho and Kwon, Gihyun and Ye, Jong Chul},
  journal={arXiv preprint arXiv:2302.03900},
  year={2023}
}



%%%%%%%%%%%%%%%%%%%%

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@article{videoworldsimulators2024,
  title={Video generation models as world simulators},
  author={Tim Brooks and Bill Peebles and Connor Homes and Will DePue and Yufei Guo and Li Jing and David Schnurr and Joe Taylor and Troy Luhman and Eric Luhman and Clarence Wing Yin Ng and Ricky Wang and Aditya Ramesh},
  year={2024},
  url={https://openai.com/research/video-generation-models-as-world-simulators},
}

# Movie Gen
@article{polyak2024movie,
  title={Movie gen: A cast of media foundation models},
  author={Polyak, Adam and Zohar, Amit and Brown, Andrew and Tjandra, Andros and Sinha, Animesh and Lee, Ann and Vyas, Apoorv and Shi, Bowen and Ma, Chih-Yao and Chuang, Ching-Yao and others},
  journal={arXiv preprint arXiv:2410.13720},
  year={2024}
}

# Dover
@inproceedings{wu2023exploring,
  title={Exploring video quality assessment on user generated contents from aesthetic and technical perspectives},
  author={Wu, Haoning and Zhang, Erli and Liao, Liang and Chen, Chaofeng and Hou, Jingwen and Wang, Annan and Sun, Wenxiu and Yan, Qiong and Lin, Weisi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20144--20154},
  year={2023}
}

# TransNet v2
@article{souvcek2020transnet,
  title={Transnet v2: An effective deep network architecture for fast shot transition detection},
  author={Sou{\v{c}}ek, Tom{\'a}{\v{s}} and Loko{\v{c}}, Jakub},
  journal={arXiv preprint arXiv:2008.04838},
  year={2020}
}

# pyscene
@article{pyscene,
  title={PySceneDetect},
  author={PySceneDetect Developers},
  journal={https://www.scenedetect.com/}
}

# opencv
@article{opencv,
  title={OpenCV},
  author={OpenCV Developers},
  journal={https://opencv.org/}
}

# k-means
@inproceedings{macqueen1967some,
  title={Some methods for classification and analysis of multivariate observations},
  author={MacQueen, J},
  booktitle={Proceedings of 5-th Berkeley Symposium on Mathematical Statistics and Probability/University of California Press},
  year={1967}
}

# Yolox
@article{ge2021yolox,
  title={Yolox: Exceeding yolo series in 2021},
  author={Ge, Z},
  journal={arXiv preprint arXiv:2107.08430},
  year={2021}
}

@article{yang2024cogvideox,
  title={Cogvideox: Text-to-video diffusion models with an expert transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}

@article{yu2023language,
  title={Language Model Beats Diffusion--Tokenizer is Key to Visual Generation},
  author={Yu, Lijun and Lezama, Jos{\'e} and Gundavarapu, Nitesh B and Versari, Luca and Sohn, Kihyuk and Minnen, David and Cheng, Yong and Birodkar, Vighnesh and Gupta, Agrim and Gu, Xiuye and others},
  journal={arXiv preprint arXiv:2310.05737},
  year={2023}
}

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021}
}

@article{chen2024od,
  title={Od-vae: An omni-dimensional video compressor for improving latent video diffusion model},
  author={Chen, Liuhan and Li, Zongjian and Lin, Bin and Zhu, Bin and Wang, Qian and Yuan, Shenghai and Zhou, Xing and Cheng, Xinghua and Yuan, Li},
  journal={arXiv preprint arXiv:2409.01199},
  year={2024}
}

@article{zhou2024allegro,
  title={Allegro: Open the Black Box of Commercial-Level Video Generation Model},
  author={Zhou, Yuan and Wang, Qiuyue and Cai, Yuxuan and Yang, Huan},
  journal={arXiv preprint arXiv:2410.15458},
  year={2024}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{anil2023palm,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}

@inproceedings{li2024scalability,
  title={On the scalability of diffusion-based text-to-image generation},
  author={Li, Hao and Zou, Yang and Wang, Ying and Majumder, Orchid and Xie, Yusheng and Manmatha, R and Swaminathan, Ashwin and Tu, Zhuowen and Ermon, Stefano and Soatto, Stefano},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9400--9409},
  year={2024}
}

@article{kilian2024computational,
  title={Computational Tradeoffs in Image Synthesis: Diffusion, Masked-Token, and Next-Token Prediction},
  author={Kilian, Maciej and Japan, Varun and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2405.13218},
  year={2024}
}

@software{opensora,
  author = {Zangwei Zheng and Xiangyu Peng and Tianji Yang and Chenhui Shen and Shenggui Li and Hongxin Liu and Yukun Zhou and Tianyi Li and Yang You},
  title = {Open-Sora: Democratizing Efficient Video Production for All},
  month = {March},
  year = {2024},
  url = {https://github.com/hpcaitech/Open-Sora}
}

@article{betker2023improving,
  title={Improving image generation with better captions},
  author={Betker, James and Goh, Gabriel and Jing, Li and Brooks, Tim and Wang, Jianfeng and Li, Linjie and Ouyang, Long and Zhuang, Juntang and Lee, Joyce and Guo, Yufei and others},
  journal={Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf},
  volume={2},
  number={3},
  pages={8},
  year={2023}
}

@misc{sun2024hunyuanlargeopensourcemoemodel,
      title={Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent}, 
      author={Xingwu Sun and Yanfeng Chen and Yiqing Huang and Ruobing Xie and Jiaqi Zhu and Kai Zhang and Shuaipeng Li and Zhen Yang and Jonny Han and Xiaobo Shu and Jiahao Bu and Zhongzhi Chen and Xuemeng Huang and Fengzong Lian and Saiyong Yang and Jianfeng Yan and Yuyuan Zeng and Xiaoqin Ren and Chao Yu and Lulu Wu and Yue Mao and Tao Yang and Suncong Zheng and Kan Wu and Dian Jiao and Jinbao Xue and Xipeng Zhang and Decheng Wu and Kai Liu and Dengpeng Wu and Guanghui Xu and Shaohua Chen and Shuang Chen and Xiao Feng and Yigeng Hong and Junqiang Zheng and Chengcheng Xu and Zongwei Li and Xiong Kuang and Jianglu Hu and Yiqi Chen and Yuchi Deng and Guiyang Li and Ao Liu and Chenchen Zhang and Shihui Hu and Zilong Zhao and Zifan Wu and Yao Ding and Weichao Wang and Han Liu and Roberts Wang and Hao Fei and Peijie She and Ze Zhao and Xun Cao and Hai Wang and Fusheng Xiang and Mengyuan Huang and Zhiyuan Xiong and Bin Hu and Xuebin Hou and Lei Jiang and Jiajia Wu and Yaping Deng and Yi Shen and Qian Wang and Weijie Liu and Jie Liu and Meng Chen and Liang Dong and Weiwen Jia and Hu Chen and Feifei Liu and Rui Yuan and Huilin Xu and Zhenxiang Yan and Tengfei Cao and Zhichao Hu and Xinhua Feng and Dong Du and Tinghao She and Yangyu Tao and Feng Zhang and Jianchen Zhu and Chengzhong Xu and Xirui Li and Chong Zha and Wen Ouyang and Yinben Xia and Xiang Li and Zekun He and Rongpeng Chen and Jiawei Song and Ruibin Chen and Fan Jiang and Chongqing Zhao and Bo Wang and Hao Gong and Rong Gan and Winston Hu and Zhanhui Kang and Yong Yang and Yuhong Liu and Di Wang and Jie Jiang},
      year={2024},
      eprint={2411.02265},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.02265}, 
}

@misc{kim2024reex,
    title={Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses},
    author={Juyeon Kim and Jeongeun Lee and Yoonho Chang and Chanyeol Choi and Junseong Kim and Jy-yong Sohn},
    year={2024},
    eprint={2402.17097},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{investopedia_gdpr,
  author = {Investopedia},
  title = {General Data Protection Regulation (GDPR)},
  year = {n.d.},
  url = {https://www.investopedia.com/terms/g/general-data-protection-regulation-gdpr.asp},
  note = {Accessed October 10, 2023}
}

@inproceedings{Chen_2024,
   title={Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers},
   url={http://dx.doi.org/10.1109/CVPR52733.2024.01265},
   DOI={10.1109/cvpr52733.2024.01265},
   booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={Chen, Tsai-Shien and Siarohin, Aliaksandr and Menapace, Willi and Deyneka, Ekaterina and Chao, Hsiang-Wei and Jeon, Byung Eun and Fang, Yuwei and Lee, Hsin-Ying and Ren, Jian and Yang, Ming-Hsuan and Tulyakov, Sergey},
   year={2024},
   month=jun, pages={13320–13331} 
}

@article{chen2024sharegpt4video,
  title={ShareGPT4Video: Improving Video Understanding and Generation with Better Captions},
  author={Chen, Lin and Wei, Xilin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and Zang, Yuhang and Chen, Zehui and Duan, Haodong and Lin, Bin and Tang, Zhenyu and others},
  journal={arXiv preprint arXiv:2406.04325},
  year={2024}
}

@article{chen2023sharegpt4v,
  title={ShareGPT4V: Improving Large Multi-Modal Models with Better Captions},
  author={Chen, Lin and Li, Jisong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
  journal={arXiv preprint arXiv:2311.12793},
  year={2023}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@misc{li2024hunyuandit,
    title={Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding},
    author={Zhimin Li and Jianwei Zhang and Qin Lin and Jiangfeng Xiong and Yanxin Long and Xinchi Deng and Yingfang Zhang and Xingchao Liu and Minbin Huang and Zedong Xiao and Dayou Chen and Jiajun He and Jiahao Li and Wenyue Li and Chen Zhang and Rongwei Quan and Jianxiang Lu and Jiabin Huang and Xiaoyan Yuan and Xiaoxiao Zheng and Yixuan Li and Jihong Zhang and Chao Zhang and Meng Chen and Jie Liu and Zheng Fang and Weiyan Wang and Jinbao Xue and Yangyu Tao and Jianchen Zhu and Kai Liu and Sihuan Lin and Yifu Sun and Yun Li and Dongdong Wang and Mingtao Chen and Zhichao Hu and Xiao Xiao and Yan Chen and Yuhong Liu and Wei Liu and Di Wang and Yong Yang and Jie Jiang and Qinglin Lu},
    year={2024},
    eprint={2405.08748},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}



@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{lipman2022flow,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  journal={arXiv preprint arXiv:2210.02747},
  year={2022}
}

@inproceedings{esser2024scaling,
  title={Scaling rectified flow transformers for high-resolution image synthesis},
  author={Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Ricky TQ and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@software{pku_yuan_lab_and_tuzhan_ai_etc_2024_10948109,
  author       = {PKU-Yuan Lab and Tuzhan AI etc.},
  title        = {Open-Sora-Plan},
  month        = apr,
  year         = 2024,
  publisher    = {GitHub},
  doi          = {10.5281/zenodo.10948109},
  url          = {https://doi.org/10.5281/zenodo.10948109}
}



@misc{genmo2024mochi,
      title={Mochi 1: A new SOTA in open-source video generation},
      author={Genmo Team},
      year={2024},
      publisher = {GitHub},
      journal = {GitHub repository},
      howpublished={\url{https://github.com/genmoai/models}}
}


@inproceedings{meng2023distillation,
  title={On distillation of guided diffusion models},
  author={Meng, Chenlin and Rombach, Robin and Gao, Ruiqi and Kingma, Diederik and Ermon, Stefano and Ho, Jonathan and Salimans, Tim},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14297--14306},
  year={2023}
}


@article{zhao2024real,
  title={Real-time video generation with pyramid attention broadcast},
  author={Zhao, Xuanlei and Jin, Xiaolong and Wang, Kai and You, Yang},
  journal={arXiv preprint arXiv:2408.12588},
  year={2024}
}

@misc{FLUX,
  author = "Black Forest Labs",
  title = "FLUX",
  year = "2024",
  url = "https://blackforestlabs.ai/",
}

@inproceedings{bao2023all,
  title={All are worth words: A vit backbone for diffusion models},
  author={Bao, Fan and Nie, Shen and Xue, Kaiwen and Cao, Yue and Li, Chongxuan and Su, Hang and Zhu, Jun},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={22669--22679},
  year={2023}
}

@article{gao2024lumina,
  title={Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers},
  author={Gao, Peng and Zhuo, Le and Lin, Ziyi and Liu, Chris and Chen, Junsong and Du, Ruoyi and Xie, Enze and Luo, Xu and Qiu, Longtian and Zhang, Yuhang and others},
  journal={arXiv preprint arXiv:2405.05945},
  year={2024}
}

@article{salimans2022progressive,
  title={Progressive distillation for fast sampling of diffusion models},
  author={Salimans, Tim and Ho, Jonathan},
  journal={arXiv preprint arXiv:2202.00512},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{ma2024exploring,
  title={Exploring the Role of Large Language Models in Prompt Encoding for Diffusion Models},
  author={Ma, Bingqi and Zong, Zhuofan and Song, Guanglu and Li, Hongsheng and Liu, Yu},
  journal={arXiv preprint arXiv:2406.11831},
  year={2024}
}

@article{ma2024follow,
  title={Follow-Your-Emoji: Fine-Controllable and Expressive Freestyle Portrait Animation},
  author={Ma, Yue and Liu, Hongyu and Wang, Hongfa and Pan, Heng and He, Yingqing and Yuan, Junkun and Zeng, Ailing and Cai, Chengfei and Shum, Heung-Yeung and Liu, Wei and others},
  journal={arXiv preprint arXiv:2406.01900},
  year={2024}
}

@article{chen2024follow,
  title={Follow-Your-Canvas: Higher-Resolution Video Outpainting with Extensive Content Generation},
  author={Chen, Qihua and Ma, Yue and Wang, Hongfa and Yuan, Junkun and Zhao, Wenzhe and Tian, Qi and Wang, Hongmei and Min, Shaobo and Chen, Qifeng and Liu, Wei},
  journal={arXiv preprint arXiv:2409.01055},
  year={2024}
}

@article{ma2024follow2,
  title={Follow-your-click: Open-domain regional image animation via short prompts},
  author={Ma, Yue and He, Yingqing and Wang, Hongfa and Wang, Andong and Qi, Chenyang and Cai, Chengfei and Li, Xiu and Li, Zhifeng and Shum, Heung-Yeung and Liu, Wei and others},
  journal={arXiv preprint arXiv:2403.08268},
  year={2024}
}

@article{xue2024follow,
  title={Follow-Your-Pose v2: Multiple-Condition Guided Character Image Animation for Stable Pose Control},
  author={Xue, Jingyun and Wang, Hongfa and Tian, Qi and Ma, Yue and Wang, Andong and Zhao, Zhiyuan and Min, Shaobo and Zhao, Wenzhe and Zhang, Kaihao and Shum, Heung-Yeung and others},
  journal={arXiv preprint arXiv:2406.03035},
  year={2024}
}

@article{zhang2022unsupervised,
  title={Unsupervised representation learning from pre-trained diffusion probabilistic models},
  author={Zhang, Zijian and Zhao, Zhou and Lin, Zhijie},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22117--22130},
  year={2022}
}

@inproceedings{zhang2023shiftddpms,
  title={ShiftDDPMs: exploring conditional diffusion models by shifting diffusion trajectories},
  author={Zhang, Zijian and Zhao, Zhou and Yu, Jun and Tian, Qi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  pages={3552--3560},
  year={2023}
}

@misc{cosmos,
  author = "NVIDIA",
  title = "Cosmos-Tokenizer",
  year = "2024",
  url = "https://github.com/NVIDIA/Cosmos-Tokenizer",
}

@article{nie2023angel,
  title={Angel-ptm: A scalable and economical large-scale pre-training system in tencent},
  author={Nie, Xiaonan and Liu, Yi and Fu, Fangcheng and Xue, Jinbao and Jiao, Dian and Miao, Xupeng and Tao, Yangyu and Cui, Bin},
  journal={arXiv preprint arXiv:2303.02868},
  year={2023}
}

@article{2019megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}


@article{2022sequence-parallelism,
  title={Reducing activation recomputation in large transformer models},
  author={Korthikanti, Vijay Anand and Casper, Jared and Lym, Sangkug and McAfee, Lawrence and Andersch, Michael and Shoeybi, Mohammad and Catanzaro, Bryan},
  journal={Proceedings of Machine Learning and Systems},
  volume={5},
  pages={341--353},
  year={2023}
}

@article{2023ring-attention,
  title={Ring Attention with Blockwise Transformers for Near-Infinite Context},
  author={Hao Liu, Matei Zaharia, Pieter Abbeel},
  journal={arXiv preprint arXiv:2310.01889},
  year={2023}
}

@article{2024context-parallelism,
  title={Context parallelism overview},
  author={NVIDIA},
  url = {https://docs.nvidia.com/megatron-core/developer-guide/latest/api-guide/context_parallel.html},
  year={2024}
}

@inproceedings{2024tccl,
  title={TCCL: Co-optimizing Collective Communication and Traffic Routing for GPU-centric Clusters},
  author={Li, Baojia and Wang, Xiaoliang and Wang, Jingzhu and Liu, Yifan and Gong, Yuanyuan and Lu, Hao and Dang, Weizhen and Zhang, Weifeng and Huang, Xiaojie and Chen, Mingzhuo and others},
  booktitle={Proceedings of the 2024 SIGCOMM Workshop on Networks for AI Computing},
  pages={48--53},
  year={2024}
}


@article{doh2023lp,
  title={Lp-musiccaps: Llm-based pseudo music captioning},
  author={Doh, SeungHeon and Choi, Keunwoo and Lee, Jongpil and Nam, Juhan},
  journal={arXiv preprint arXiv:2307.16372},
  year={2023}
}

@article{audioldm2,
  title={Audioldm 2: Learning holistic audio generation with self-supervised pretraining},
  author={Liu, Haohe and Yuan, Yi and Liu, Xubo and Mei, Xinhao and Kong, Qiuqiang and Tian, Qiao and Wang, Yuping and Wang, Wenwu and Wang, Yuxuan and Plumbley, Mark D},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2024},
  publisher={IEEE}
}

@inproceedings{yang2023effective,
  title={Effective whole-body pose estimation with two-stages distillation},
  author={Yang, Zhendong and Zeng, Ailing and Yuan, Chun and Li, Yu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4210--4220},
  year={2023}
}

@article{xu2024vasa,
  title={Vasa-1: Lifelike audio-driven talking faces generated in real time},
  author={Xu, Sicheng and Chen, Guojun and Guo, Yu-Xiao and Yang, Jiaolong and Li, Chong and Zang, Zhenyu and Zhang, Yizhong and Tong, Xin and Guo, Baining},
  journal={arXiv preprint arXiv:2404.10667},
  year={2024}
}



@article{chen2024echomimic,
  title={Echomimic: Lifelike audio-driven portrait animations through editable landmark conditions},
  author={Chen, Zhiyuan and Cao, Jiajiong and Chen, Zhiquan and Li, Yuming and Ma, Chenguang},
  journal={arXiv preprint arXiv:2407.08136},
  year={2024}
}

@article{girdhar2023emu,
  title={Emu video: Factorizing text-to-video generation by explicit image conditioning},
  author={Girdhar, Rohit and Singh, Mannat and Brown, Andrew and Duval, Quentin and Azadi, Samaneh and Rambhatla, Sai Saketh and Shah, Akbar and Yin, Xi and Parikh, Devi and Misra, Ishan},
  journal={arXiv preprint arXiv:2311.10709},
  year={2023}
}

@misc{su2023roformer,
      title={RoFormer: Enhanced Transformer with Rotary Position Embedding}, 
      author={Jianlin Su and Yu Lu and Shengfeng Pan and Ahmed Murtadha and Bo Wen and Yunfeng Liu},
      year={2023},
      eprint={2104.09864},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2104.09864}, 
}

@misc{2023xtuner,
    title={XTuner: A Toolkit for Efficiently Fine-tuning LLM},
    author={XTuner Contributors},
    howpublished = {\url{https://github.com/InternLM/xtuner}},
    year={2023}
}

@misc{glm2024chatglm,
      title={ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools}, 
      author={Team GLM and Aohan Zeng and Bin Xu and Bowen Wang and Chenhui Zhang and Da Yin and Diego Rojas and Guanyu Feng and Hanlin Zhao and Hanyu Lai and Hao Yu and Hongning Wang and Jiadai Sun and Jiajie Zhang and Jiale Cheng and Jiayi Gui and Jie Tang and Jing Zhang and Juanzi Li and Lei Zhao and Lindong Wu and Lucen Zhong and Mingdao Liu and Minlie Huang and Peng Zhang and Qinkai Zheng and Rui Lu and Shuaiqi Duan and Shudan Zhang and Shulin Cao and Shuxun Yang and Weng Lam Tam and Wenyi Zhao and Xiao Liu and Xiao Xia and Xiaohan Zhang and Xiaotao Gu and Xin Lv and Xinghan Liu and Xinyi Liu and Xinyue Yang and Xixuan Song and Xunkai Zhang and Yifan An and Yifan Xu and Yilin Niu and Yuantao Yang and Yueyan Li and Yushi Bai and Yuxiao Dong and Zehan Qi and Zhaoyu Wang and Zhen Yang and Zhengxiao Du and Zhenyu Hou and Zihan Wang},
      year={2024},
      eprint={2406.12793},
      archivePrefix={arXiv}
}

@misc{ye2024mimic,
      title={MimicTalk: Mimicking a personalized and expressive 3D talking face in minutes}, 
      author={Zhenhui Ye and Tianyun Zhong and Yi Ren and Ziyue Jiang and Jiawei Huang and Rongjie Huang and Jinglin Liu and Jinzheng He and Chen Zhang and Zehan Wang and Xize Chen and Xiang Yin and Zhou Zhao},
      year={2024},
      eprint={2410.06734},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.06734}, 
}

@misc{tian2024emo,
      title={EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions}, 
      author={Linrui Tian and Qi Wang and Bang Zhang and Liefeng Bo},
      year={2024},
      eprint={2402.17485},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.17485}, 
}

@misc{xu2024hallo,
      title={Hallo: Hierarchical Audio-Driven Visual Synthesis for Portrait Image Animation}, 
      author={Mingwang Xu and Hui Li and Qingkun Su and Hanlin Shang and Liwei Zhang and Ce Liu and Jingdong Wang and Yao Yao and Siyu Zhu},
      year={2024},
      eprint={2406.08801},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.08801}, 
}

@inproceedings{prajwal2020lip,
  title={A lip sync expert is all you need for speech to lip generation in the wild},
  author={Prajwal, KR and Mukhopadhyay, Rudrabha and Namboodiri, Vinay P and Jawahar, CV},
  booktitle={Proceedings of the 28th ACM international conference on multimedia},
  pages={484--492},
  year={2020}
}

@inproceedings{zhang2023dinet,
  title={Dinet: Deformation inpainting network for realistic face visually dubbing on high resolution video},
  author={Zhang, Zhimeng and Hu, Zhipeng and Deng, Wenjin and Fan, Changjie and Lv, Tangjie and Ding, Yu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={3},
  pages={3543--3551},
  year={2023}
}