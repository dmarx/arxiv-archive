\begin{thebibliography}{100}

\bibitem{achiam2023gpt}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock {\em arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{anil2023palm}
Rohan Anil, Andrew~M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et~al.
\newblock Palm 2 technical report.
\newblock {\em arXiv preprint arXiv:2305.10403}, 2023.

\bibitem{bao2023all}
Fan Bao, Shen Nie, Kaiwen Xue, Yue Cao, Chongxuan Li, Hang Su, and Jun Zhu.
\newblock All are worth words: A vit backbone for diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 22669--22679, 2023.

\bibitem{betker2023improving}
James Betker, Gabriel Goh, Li~Jing, Tim Brooks, Jianfeng Wang, Linjie Li, Long Ouyang, Juntang Zhuang, Joyce Lee, Yufei Guo, et~al.
\newblock Improving image generation with better captions.
\newblock {\em Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf}, 2(3):8, 2023.

\bibitem{blattmann2023stable}
Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, et~al.
\newblock Stable video diffusion: Scaling latent video diffusion models to large datasets.
\newblock {\em arXiv preprint}, 2023.

\bibitem{brock2018large}
Andrew Brock, Jeff Donahue, and Karen Simonyan.
\newblock Large scale gan training for high fidelity natural image synthesis.
\newblock {\em arXiv preprint arXiv:1809.11096}, 2018.

\bibitem{videoworldsimulators2024}
Tim Brooks, Bill Peebles, Connor Homes, Will DePue, Yufei Guo, Li~Jing, David Schnurr, Joe Taylor, Troy Luhman, Eric Luhman, Clarence Wing~Yin Ng, Ricky Wang, and Aditya Ramesh.
\newblock Video generation models as world simulators.
\newblock 2024.

\bibitem{brown2020language}
Tom~B Brown.
\newblock Language models are few-shot learners.
\newblock {\em arXiv preprint arXiv:2005.14165}, 2020.

\bibitem{chen2023sharegpt4v}
Lin Chen, Jisong Li, Xiaoyi Dong, Pan Zhang, Conghui He, Jiaqi Wang, Feng Zhao, and Dahua Lin.
\newblock Sharegpt4v: Improving large multi-modal models with better captions.
\newblock {\em arXiv preprint arXiv:2311.12793}, 2023.

\bibitem{chen2024sharegpt4video}
Lin Chen, Xilin Wei, Jinsong Li, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Zehui Chen, Haodong Duan, Bin Lin, Zhenyu Tang, et~al.
\newblock Sharegpt4video: Improving video understanding and generation with better captions.
\newblock {\em arXiv preprint arXiv:2406.04325}, 2024.

\bibitem{chen2024od}
Liuhan Chen, Zongjian Li, Bin Lin, Bin Zhu, Qian Wang, Shenghai Yuan, Xing Zhou, Xinghua Cheng, and Li~Yuan.
\newblock Od-vae: An omni-dimensional video compressor for improving latent video diffusion model.
\newblock {\em arXiv preprint arXiv:2409.01199}, 2024.

\bibitem{chen2024follow}
Qihua Chen, Yue Ma, Hongfa Wang, Junkun Yuan, Wenzhe Zhao, Qi~Tian, Hongmei Wang, Shaobo Min, Qifeng Chen, and Wei Liu.
\newblock Follow-your-canvas: Higher-resolution video outpainting with extensive content generation.
\newblock {\em arXiv preprint arXiv:2409.01055}, 2024.

\bibitem{chen2018neural}
Ricky~TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David~K Duvenaud.
\newblock Neural ordinary differential equations.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{Chen_2024}
Tsai-Shien Chen, Aliaksandr Siarohin, Willi Menapace, Ekaterina Deyneka, Hsiang-Wei Chao, Byung~Eun Jeon, Yuwei Fang, Hsin-Ying Lee, Jian Ren, Ming-Hsuan Yang, and Sergey Tulyakov.
\newblock Panda-70m: Captioning 70m videos with multiple cross-modality teachers.
\newblock In {\em 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, page 13320â€“13331. IEEE, June 2024.

\bibitem{chen2023seine}
Xinyuan Chen, Yaohui Wang, Lingjun Zhang, Shaobin Zhuang, Xin Ma, Jiashuo Yu, Yali Wang, Dahua Lin, Yu~Qiao, and Ziwei Liu.
\newblock Seine: Short-to-long video diffusion model for generative transition and prediction.
\newblock {\em arXiv preprint}, 2023.

\bibitem{chen2024echomimic}
Zhiyuan Chen, Jiajiong Cao, Zhiquan Chen, Yuming Li, and Chenguang Ma.
\newblock Echomimic: Lifelike audio-driven portrait animations through editable landmark conditions.
\newblock {\em arXiv preprint arXiv:2407.08136}, 2024.

\bibitem{2023xtuner}
XTuner Contributors.
\newblock Xtuner: A toolkit for efficiently fine-tuning llm.
\newblock \url{https://github.com/InternLM/xtuner}, 2023.

\bibitem{opencv}
OpenCV Developers.
\newblock Opencv.
\newblock {\em https://opencv.org/}.

\bibitem{pyscene}
PySceneDetect Developers.
\newblock Pyscenedetect.
\newblock {\em https://www.scenedetect.com/}.

\bibitem{doh2023lp}
SeungHeon Doh, Keunwoo Choi, Jongpil Lee, and Juhan Nam.
\newblock Lp-musiccaps: Llm-based pseudo music captioning.
\newblock {\em arXiv preprint arXiv:2307.16372}, 2023.

\bibitem{esser2024scaling}
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas M{\"u}ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et~al.
\newblock Scaling rectified flow transformers for high-resolution image synthesis.
\newblock In {\em Forty-first International Conference on Machine Learning}, 2024.

\bibitem{esser2021taming}
Patrick Esser, Robin Rombach, and Bjorn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 12873--12883, 2021.

\bibitem{gao2024lumina}
Peng Gao, Le~Zhuo, Ziyi Lin, Chris Liu, Junsong Chen, Ruoyi Du, Enze Xie, Xu~Luo, Longtian Qiu, Yuhang Zhang, et~al.
\newblock Lumina-t2x: Transforming text into any modality, resolution, and duration via flow-based large diffusion transformers.
\newblock {\em arXiv preprint arXiv:2405.05945}, 2024.

\bibitem{ge2021yolox}
Z~Ge.
\newblock Yolox: Exceeding yolo series in 2021.
\newblock {\em arXiv preprint arXiv:2107.08430}, 2021.

\bibitem{girdhar2023emu}
Rohit Girdhar, Mannat Singh, Andrew Brown, Quentin Duval, Samaneh Azadi, Sai~Saketh Rambhatla, Akbar Shah, Xi~Yin, Devi Parikh, and Ishan Misra.
\newblock Emu video: Factorizing text-to-video generation by explicit image conditioning.
\newblock {\em arXiv preprint arXiv:2311.10709}, 2023.

\bibitem{glm2024chatglm}
Team GLM, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da~Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, Hao Yu, Hongning Wang, Jiadai Sun, Jiajie Zhang, Jiale Cheng, Jiayi Gui, Jie Tang, Jing Zhang, Juanzi Li, Lei Zhao, Lindong Wu, Lucen Zhong, Mingdao Liu, Minlie Huang, Peng Zhang, Qinkai Zheng, Rui Lu, Shuaiqi Duan, Shudan Zhang, Shulin Cao, Shuxun Yang, Weng~Lam Tam, Wenyi Zhao, Xiao Liu, Xiao Xia, Xiaohan Zhang, Xiaotao Gu, Xin Lv, Xinghan Liu, Xinyi Liu, Xinyue Yang, Xixuan Song, Xunkai Zhang, Yifan An, Yifan Xu, Yilin Niu, Yuantao Yang, Yueyan Li, Yushi Bai, Yuxiao Dong, Zehan Qi, Zhaoyu Wang, Zhen Yang, Zhengxiao Du, Zhenyu Hou, and Zihan Wang.
\newblock Chatglm: A family of large language models from glm-130b to glm-4 all tools, 2024.

\bibitem{guo2023sparsectrl}
Yuwei Guo, Ceyuan Yang, Anyi Rao, Maneesh Agrawala, Dahua Lin, and Bo~Dai.
\newblock Sparsectrl: Adding sparse controls to text-to-video diffusion models.
\newblock {\em arXiv preprint}, 2023.

\bibitem{guo2023animatediff}
Yuwei Guo, Ceyuan Yang, Anyi Rao, Zhengyang Liang, Yaohui Wang, Yu~Qiao, Maneesh Agrawala, Dahua Lin, and Bo~Dai.
\newblock Animatediff: Animate your personalized text-to-image diffusion models without specific tuning.
\newblock {\em ICLR}, 2024.

\bibitem{haji2024taming}
Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Guha Balakrishnan, Sergey Tulyakov, and Vicente Ordonez.
\newblock Taming data and transformers for audio generation.
\newblock {\em arXiv preprint arXiv:2406.19388}, 2024.

\bibitem{2023ring-attention}
Pieter~Abbeel Hao~Liu, Matei~Zaharia.
\newblock Ring attention with blockwise transformers for near-infinite context.
\newblock {\em arXiv preprint arXiv:2310.01889}, 2023.

\bibitem{he2023animate}
Yingqing He, Menghan Xia, Haoxin Chen, Xiaodong Cun, Yuan Gong, Jinbo Xing, Yong Zhang, Xintao Wang, Chao Weng, Ying Shan, et~al.
\newblock Animate-a-story: Storytelling with retrieval-augmented video generation.
\newblock {\em arXiv preprint}, 2023.

\bibitem{ho2022video}
J~Ho, T~Salimans, A~Gritsenko, W~Chan, M~Norouzi, and DJ~Fleet.
\newblock Video diffusion models. arxiv 2022.
\newblock {\em arXiv preprint}, 2022.

\bibitem{ho2022imagen}
Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik~P Kingma, Ben Poole, Mohammad Norouzi, David~J Fleet, et~al.
\newblock Imagen video: High definition video generation with diffusion models.
\newblock {\em arXiv preprint}, 2022.

\bibitem{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In {\em NeurIPS}, 2020.

\bibitem{ho2022classifier}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock {\em arXiv preprint}, 2022.

\bibitem{hoffmann2022training}
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de~Las Casas, Lisa~Anne Hendricks, Johannes Welbl, Aidan Clark, et~al.
\newblock Training compute-optimal large language models.
\newblock {\em arXiv preprint arXiv:2203.15556}, 2022.

\bibitem{hu2023animate}
Li~Hu, Xin Gao, Peng Zhang, Ke~Sun, Bang Zhang, and Liefeng Bo.
\newblock Animate anyone: Consistent and controllable image-to-video synthesis for character animation.
\newblock {\em arXiv preprint}, 2023.

\bibitem{Hung2022}
Yun-Ning Hung, Chih-Wei Wu, Iroro Orife, Aaron Hipple, William Wolcott, and Alexander Lerch.
\newblock A large tv dataset for speech and music activity detection.
\newblock {\em EURASIP Journal on Audio, Speech, and Music Processing}, 2022(1):21, 2022.

\bibitem{investopedia_gdpr}
Investopedia.
\newblock General data protection regulation (gdpr), n.d.
\newblock Accessed October 10, 2023.

\bibitem{jiang2023text2performer}
Yuming Jiang, Shuai Yang, Tong~Liang Koh, Wayne Wu, Chen~Change Loy, and Ziwei Liu.
\newblock Text2performer: Text-driven human video generation.
\newblock {\em arXiv preprint}, 2023.

\bibitem{kaplan2020scaling}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
\newblock Scaling laws for neural language models.
\newblock {\em arXiv preprint arXiv:2001.08361}, 2020.

\bibitem{kilian2024computational}
Maciej Kilian, Varun Japan, and Luke Zettlemoyer.
\newblock Computational tradeoffs in image synthesis: Diffusion, masked-token, and next-token prediction.
\newblock {\em arXiv preprint arXiv:2405.13218}, 2024.

\bibitem{kim2024reex}
Juyeon Kim, Jeongeun Lee, Yoonho Chang, Chanyeol Choi, Junseong Kim, and Jy~yong Sohn.
\newblock Re-ex: Revising after explanation reduces the factual errors in llm responses, 2024.

\bibitem{kong2020hifi}
Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae.
\newblock Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis.
\newblock {\em Advances in neural information processing systems}, 33:17022--17033, 2020.

\bibitem{2022sequence-parallelism}
Vijay~Anand Korthikanti, Jared Casper, Sangkug Lym, Lawrence McAfee, Michael Andersch, Mohammad Shoeybi, and Bryan Catanzaro.
\newblock Reducing activation recomputation in large transformer models.
\newblock {\em Proceedings of Machine Learning and Systems}, 5:341--353, 2023.

\bibitem{pku_yuan_lab_and_tuzhan_ai_etc_2024_10948109}
PKU-Yuan Lab and Tuzhan~AI etc.
\newblock Open-sora-plan, April 2024.

\bibitem{FLUX}
Black~Forest Labs.
\newblock Flux, 2024.

\bibitem{2024tccl}
Baojia Li, Xiaoliang Wang, Jingzhu Wang, Yifan Liu, Yuanyuan Gong, Hao Lu, Weizhen Dang, Weifeng Zhang, Xiaojie Huang, Mingzhuo Chen, et~al.
\newblock Tccl: Co-optimizing collective communication and traffic routing for gpu-centric clusters.
\newblock In {\em Proceedings of the 2024 SIGCOMM Workshop on Networks for AI Computing}, pages 48--53, 2024.

\bibitem{li2024scalability}
Hao Li, Yang Zou, Ying Wang, Orchid Majumder, Yusheng Xie, R~Manmatha, Ashwin Swaminathan, Zhuowen Tu, Stefano Ermon, and Stefano Soatto.
\newblock On the scalability of diffusion-based text-to-image generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 9400--9409, 2024.

\bibitem{li2022blip}
Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi.
\newblock Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation.
\newblock In {\em International conference on machine learning}, pages 12888--12900. PMLR, 2022.

\bibitem{li2024hunyuandit}
Zhimin Li, Jianwei Zhang, Qin Lin, Jiangfeng Xiong, Yanxin Long, Xinchi Deng, Yingfang Zhang, Xingchao Liu, Minbin Huang, Zedong Xiao, Dayou Chen, Jiajun He, Jiahao Li, Wenyue Li, Chen Zhang, Rongwei Quan, Jianxiang Lu, Jiabin Huang, Xiaoyan Yuan, Xiaoxiao Zheng, Yixuan Li, Jihong Zhang, Chao Zhang, Meng Chen, Jie Liu, Zheng Fang, Weiyan Wang, Jinbao Xue, Yangyu Tao, Jianchen Zhu, Kai Liu, Sihuan Lin, Yifu Sun, Yun Li, Dongdong Wang, Mingtao Chen, Zhichao Hu, Xiao Xiao, Yan Chen, Yuhong Liu, Wei Liu, Di~Wang, Yong Yang, Jie Jiang, and Qinglin Lu.
\newblock Hunyuan-dit: A powerful multi-resolution diffusion transformer with fine-grained chinese understanding, 2024.

\bibitem{lipman2022flow}
Yaron Lipman, Ricky~TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le.
\newblock Flow matching for generative modeling.
\newblock {\em arXiv preprint arXiv:2210.02747}, 2022.

\bibitem{liu2024visual}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock {\em Advances in neural information processing systems}, 36, 2024.

\bibitem{luo2024diff}
Simian Luo, Chuanhao Yan, Chenxu Hu, and Hang Zhao.
\newblock Diff-foley: Synchronized video-to-audio synthesis with latent diffusion models.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{ma2024exploring}
Bingqi Ma, Zhuofan Zong, Guanglu Song, Hongsheng Li, and Yu~Liu.
\newblock Exploring the role of large language models in prompt encoding for diffusion models.
\newblock {\em arXiv preprint arXiv:2406.11831}, 2024.

\bibitem{ma2023follow}
Yue Ma, Yingqing He, Xiaodong Cun, Xintao Wang, Ying Shan, Xiu Li, and Qifeng Chen.
\newblock Follow your pose: Pose-guided text-to-video generation using pose-free videos.
\newblock {\em arXiv preprint}, 2023.

\bibitem{ma2024follow2}
Yue Ma, Yingqing He, Hongfa Wang, Andong Wang, Chenyang Qi, Chengfei Cai, Xiu Li, Zhifeng Li, Heung-Yeung Shum, Wei Liu, et~al.
\newblock Follow-your-click: Open-domain regional image animation via short prompts.
\newblock {\em arXiv preprint arXiv:2403.08268}, 2024.

\bibitem{ma2024follow}
Yue Ma, Hongyu Liu, Hongfa Wang, Heng Pan, Yingqing He, Junkun Yuan, Ailing Zeng, Chengfei Cai, Heung-Yeung Shum, Wei Liu, et~al.
\newblock Follow-your-emoji: Fine-controllable and expressive freestyle portrait animation.
\newblock {\em arXiv preprint arXiv:2406.01900}, 2024.

\bibitem{macqueen1967some}
J~MacQueen.
\newblock Some methods for classification and analysis of multivariate observations.
\newblock In {\em Proceedings of 5-th Berkeley Symposium on Mathematical Statistics and Probability/University of California Press}, 1967.

\bibitem{meng2023distillation}
Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik Kingma, Stefano Ermon, Jonathan Ho, and Tim Salimans.
\newblock On distillation of guided diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 14297--14306, 2023.

\bibitem{ni2023conditional}
Haomiao Ni, Changhao Shi, Kai Li, Sharon~X Huang, and Martin~Renqiang Min.
\newblock Conditional image-to-video generation with latent flow diffusion models.
\newblock In {\em CVPR}, 2023.

\bibitem{nie2023angel}
Xiaonan Nie, Yi~Liu, Fangcheng Fu, Jinbao Xue, Dian Jiao, Xupeng Miao, Yangyu Tao, and Bin Cui.
\newblock Angel-ptm: A scalable and economical large-scale pre-training system in tencent.
\newblock {\em arXiv preprint arXiv:2303.02868}, 2023.

\bibitem{2024context-parallelism}
NVIDIA.
\newblock Context parallelism overview.
\newblock 2024.

\bibitem{cosmos}
NVIDIA.
\newblock Cosmos-tokenizer, 2024.

\bibitem{peebles2023scalable}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4195--4205, 2023.

\bibitem{podell2023sdxl}
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas M{\"u}ller, Joe Penna, and Robin Rombach.
\newblock Sdxl: Improving latent diffusion models for high-resolution image synthesis.
\newblock {\em arXiv preprint}, 2023.

\bibitem{polyak2024movie}
Adam Polyak, Amit Zohar, Andrew Brown, Andros Tjandra, Animesh Sinha, Ann Lee, Apoorv Vyas, Bowen Shi, Chih-Yao Ma, Ching-Yao Chuang, et~al.
\newblock Movie gen: A cast of media foundation models.
\newblock {\em arXiv preprint arXiv:2410.13720}, 2024.

\bibitem{prajwal2020lip}
KR~Prajwal, Rudrabha Mukhopadhyay, Vinay~P Namboodiri, and CV~Jawahar.
\newblock A lip sync expert is all you need for speech to lip generation in the wild.
\newblock In {\em Proceedings of the 28th ACM international conference on multimedia}, pages 484--492, 2020.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em ICML}, 2021.

\bibitem{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em ICML}, pages 8748--8763. PMLR, 2021.

\bibitem{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter~J Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer.
\newblock {\em Journal of machine learning research}, 21(140):1--67, 2020.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em CVPR}, 2022.

\bibitem{salimans2022progressive}
Tim Salimans and Jonathan Ho.
\newblock Progressive distillation for fast sampling of diffusion models.
\newblock {\em arXiv preprint arXiv:2202.00512}, 2022.

\bibitem{2019megatron}
Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro.
\newblock Megatron-lm: Training multi-billion parameter language models using model parallelism.
\newblock {\em arXiv preprint arXiv:1909.08053}, 2019.

\bibitem{singer2022make}
Uriel Singer, Adam Polyak, Thomas Hayes, Xi~Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, et~al.
\newblock Make-a-video: Text-to-video generation without text-video data.
\newblock {\em arXiv preprint}, 2022.

\bibitem{souvcek2020transnet}
Tom{\'a}{\v{s}} Sou{\v{c}}ek and Jakub Loko{\v{c}}.
\newblock Transnet v2: An effective deep network architecture for fast shot transition detection.
\newblock {\em arXiv preprint arXiv:2008.04838}, 2020.

\bibitem{su2023roformer}
Jianlin Su, Yu~Lu, Shengfeng Pan, Ahmed Murtadha, Bo~Wen, and Yunfeng Liu.
\newblock Roformer: Enhanced transformer with rotary position embedding, 2023.

\bibitem{sun2024hunyuanlargeopensourcemoemodel}
Xingwu Sun, Yanfeng Chen, Yiqing Huang, Ruobing Xie, Jiaqi Zhu, Kai Zhang, Shuaipeng Li, Zhen Yang, Jonny Han, Xiaobo Shu, Jiahao Bu, Zhongzhi Chen, Xuemeng Huang, Fengzong Lian, Saiyong Yang, Jianfeng Yan, Yuyuan Zeng, Xiaoqin Ren, Chao Yu, Lulu Wu, Yue Mao, Tao Yang, Suncong Zheng, Kan Wu, Dian Jiao, Jinbao Xue, Xipeng Zhang, Decheng Wu, Kai Liu, Dengpeng Wu, Guanghui Xu, Shaohua Chen, Shuang Chen, Xiao Feng, Yigeng Hong, Junqiang Zheng, Chengcheng Xu, Zongwei Li, Xiong Kuang, Jianglu Hu, Yiqi Chen, Yuchi Deng, Guiyang Li, Ao~Liu, Chenchen Zhang, Shihui Hu, Zilong Zhao, Zifan Wu, Yao Ding, Weichao Wang, Han Liu, Roberts Wang, Hao Fei, Peijie She, Ze~Zhao, Xun Cao, Hai Wang, Fusheng Xiang, Mengyuan Huang, Zhiyuan Xiong, Bin Hu, Xuebin Hou, Lei Jiang, Jiajia Wu, Yaping Deng, Yi~Shen, Qian Wang, Weijie Liu, Jie Liu, Meng Chen, Liang Dong, Weiwen Jia, Hu~Chen, Feifei Liu, Rui Yuan, Huilin Xu, Zhenxiang Yan, Tengfei Cao, Zhichao Hu, Xinhua Feng, Dong Du, Tinghao She, Yangyu Tao, Feng Zhang, Jianchen Zhu,
  Chengzhong Xu, Xirui Li, Chong Zha, Wen Ouyang, Yinben Xia, Xiang Li, Zekun He, Rongpeng Chen, Jiawei Song, Ruibin Chen, Fan Jiang, Chongqing Zhao, Bo~Wang, Hao Gong, Rong Gan, Winston Hu, Zhanhui Kang, Yong Yang, Yuhong Liu, Di~Wang, and Jie Jiang.
\newblock Hunyuan-large: An open-source moe model with 52 billion activated parameters by tencent, 2024.

\bibitem{genmo2024mochi}
Genmo Team.
\newblock Mochi 1: A new sota in open-source video generation.
\newblock \url{https://github.com/genmoai/models}, 2024.

\bibitem{tian2024emo}
Linrui Tian, Qi~Wang, Bang Zhang, and Liefeng Bo.
\newblock Emo: Emote portrait alive -- generating expressive portrait videos with audio2video diffusion model under weak conditions, 2024.

\bibitem{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock {\em arXiv preprint arXiv:2302.13971}, 2023.

\bibitem{wang2023modelscope}
Jiuniu Wang, Hangjie Yuan, Dayou Chen, Yingya Zhang, Xiang Wang, and Shiwei Zhang.
\newblock Modelscope text-to-video technical report.
\newblock {\em arXiv preprint}, 2023.

\bibitem{wang2023disco}
Tan Wang, Linjie Li, Kevin Lin, Chung-Ching Lin, Zhengyuan Yang, Hanwang Zhang, Zicheng Liu, and Lijuan Wang.
\newblock Disco: Disentangled control for referring human dance generation in real world.
\newblock {\em arXiv preprint}, 2023.

\bibitem{wang2023lavie}
Yaohui Wang, Xinyuan Chen, Xin Ma, Shangchen Zhou, Ziqi Huang, Yi~Wang, Ceyuan Yang, Yinan He, Jiashuo Yu, Peiqing Yang, et~al.
\newblock Lavie: High-quality video generation with cascaded latent diffusion models.
\newblock {\em arXiv preprint}, 2023.

\bibitem{wu2023exploring}
Haoning Wu, Erli Zhang, Liang Liao, Chaofeng Chen, Jingwen Hou, Annan Wang, Wenxiu Sun, Qiong Yan, and Weisi Lin.
\newblock Exploring video quality assessment on user generated contents from aesthetic and technical perspectives.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 20144--20154, 2023.

\bibitem{wu2023lamp}
Ruiqi Wu, Liangyu Chen, Tong Yang, Chunle Guo, Chongyi Li, and Xiangyu Zhang.
\newblock Lamp: Learn a motion pattern for few-shot-based video generation.
\newblock {\em arXiv preprint}, 2023.

\bibitem{xu2024hallo}
Mingwang Xu, Hui Li, Qingkun Su, Hanlin Shang, Liwei Zhang, Ce~Liu, Jingdong Wang, Yao Yao, and Siyu Zhu.
\newblock Hallo: Hierarchical audio-driven visual synthesis for portrait image animation, 2024.

\bibitem{xu2024vasa}
Sicheng Xu, Guojun Chen, Yu-Xiao Guo, Jiaolong Yang, Chong Li, Zhenyu Zang, Yizhong Zhang, Xin Tong, and Baining Guo.
\newblock Vasa-1: Lifelike audio-driven talking faces generated in real time.
\newblock {\em arXiv preprint arXiv:2404.10667}, 2024.

\bibitem{xu2023magicanimate}
Zhongcong Xu, Jianfeng Zhang, Jun~Hao Liew, Hanshu Yan, Jia-Wei Liu, Chenxu Zhang, Jiashi Feng, and Mike~Zheng Shou.
\newblock Magicanimate: Temporally consistent human image animation using diffusion model.
\newblock {\em arXiv preprint}, 2023.

\bibitem{xue2024follow}
Jingyun Xue, Hongfa Wang, Qi~Tian, Yue Ma, Andong Wang, Zhiyuan Zhao, Shaobo Min, Wenzhe Zhao, Kaihao Zhang, Heung-Yeung Shum, et~al.
\newblock Follow-your-pose v2: Multiple-condition guided character image animation for stable pose control.
\newblock {\em arXiv preprint arXiv:2406.03035}, 2024.

\bibitem{yang2023probabilistic}
Mengjiao Yang, Yilun Du, Bo~Dai, Dale Schuurmans, Joshua~B Tenenbaum, and Pieter Abbeel.
\newblock Probabilistic adaptation of text-to-video models.
\newblock {\em arXiv preprint}, 2023.

\bibitem{yang2023effective}
Zhendong Yang, Ailing Zeng, Chun Yuan, and Yu~Li.
\newblock Effective whole-body pose estimation with two-stages distillation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4210--4220, 2023.

\bibitem{yang2024cogvideox}
Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, et~al.
\newblock Cogvideox: Text-to-video diffusion models with an expert transformer.
\newblock {\em arXiv preprint arXiv:2408.06072}, 2024.

\bibitem{ye2024mimic}
Zhenhui Ye, Tianyun Zhong, Yi~Ren, Ziyue Jiang, Jiawei Huang, Rongjie Huang, Jinglin Liu, Jinzheng He, Chen Zhang, Zehan Wang, Xize Chen, Xiang Yin, and Zhou Zhao.
\newblock Mimictalk: Mimicking a personalized and expressive 3d talking face in minutes, 2024.

\bibitem{yu2023language}
Lijun Yu, Jos{\'e} Lezama, Nitesh~B Gundavarapu, Luca Versari, Kihyuk Sohn, David Minnen, Yong Cheng, Vighnesh Birodkar, Agrim Gupta, Xiuye Gu, et~al.
\newblock Language model beats diffusion--tokenizer is key to visual generation.
\newblock {\em arXiv preprint arXiv:2310.05737}, 2023.

\bibitem{zhang2023show}
David~Junhao Zhang, Jay~Zhangjie Wu, Jia-Wei Liu, Rui Zhao, Lingmin Ran, Yuchao Gu, Difei Gao, and Mike~Zheng Shou.
\newblock Show-1: Marrying pixel and latent diffusion models for text-to-video generation.
\newblock {\em arXiv preprint}, 2023.

\bibitem{zhang2023dinet}
Zhimeng Zhang, Zhipeng Hu, Wenjin Deng, Changjie Fan, Tangjie Lv, and Yu~Ding.
\newblock Dinet: Deformation inpainting network for realistic face visually dubbing on high resolution video.
\newblock In {\em Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, pages 3543--3551, 2023.

\bibitem{zhang2022unsupervised}
Zijian Zhang, Zhou Zhao, and Zhijie Lin.
\newblock Unsupervised representation learning from pre-trained diffusion probabilistic models.
\newblock {\em Advances in neural information processing systems}, 35:22117--22130, 2022.

\bibitem{zhang2023shiftddpms}
Zijian Zhang, Zhou Zhao, Jun Yu, and Qi~Tian.
\newblock Shiftddpms: exploring conditional diffusion models by shifting diffusion trajectories.
\newblock In {\em Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, pages 3552--3560, 2023.

\bibitem{zhao2023motiondirector}
Rui Zhao, Yuchao Gu, Jay~Zhangjie Wu, David~Junhao Zhang, Jiawei Liu, Weijia Wu, Jussi Keppo, and Mike~Zheng Shou.
\newblock Motiondirector: Motion customization of text-to-video diffusion models.
\newblock {\em arXiv preprint}, 2023.

\bibitem{zhao2024real}
Xuanlei Zhao, Xiaolong Jin, Kai Wang, and Yang You.
\newblock Real-time video generation with pyramid attention broadcast.
\newblock {\em arXiv preprint arXiv:2408.12588}, 2024.

\bibitem{opensora}
Zangwei Zheng, Xiangyu Peng, Tianji Yang, Chenhui Shen, Shenggui Li, Hongxin Liu, Yukun Zhou, Tianyi Li, and Yang You.
\newblock Open-sora: Democratizing efficient video production for all, March 2024.

\bibitem{zhou2023magicvideo}
Daquan Zhou, Weimin Wang, Hanshu Yan, Weiwei Lv, Yizhe Zhu, and Jiashi Feng.
\newblock Magicvideo: Efficient video generation with latent diffusion models.
\newblock {\em arXiv preprint}, 2023.

\bibitem{zhou2024allegro}
Yuan Zhou, Qiuyue Wang, Yuxuan Cai, and Huan Yang.
\newblock Allegro: Open the black box of commercial-level video generation model.
\newblock {\em arXiv preprint arXiv:2410.15458}, 2024.

\end{thebibliography}
