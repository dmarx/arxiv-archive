{
  "arxivId": "1506.06579",
  "title": "Understanding Neural Networks Through Deep Visualization",
  "authors": "Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, Hod Lipson",
  "abstract": "Recent years have produced great advances in training large, deep neural\nnetworks (DNNs), including notable successes in training convolutional neural\nnetworks (convnets) to recognize natural images. However, our understanding of\nhow these models work, especially what computations they perform at\nintermediate layers, has lagged behind. Progress in the field will be further\naccelerated by the development of better tools for visualizing and interpreting\nneural nets. We introduce two such tools here. The first is a tool that\nvisualizes the activations produced on each layer of a trained convnet as it\nprocesses an image or video (e.g. a live webcam stream). We have found that\nlooking at live activations that change in response to user input helps build\nvaluable intuitions about how convnets work. The second tool enables\nvisualizing features at each layer of a DNN via regularized optimization in\nimage space. Because previous versions of this idea produced less recognizable\nimages, here we introduce several new regularization methods that combine to\nproduce qualitatively clearer, more interpretable visualizations. Both tools\nare open source and work on a pre-trained convnet with minimal setup.",
  "url": "http://arxiv.org/abs/1506.06579v1",
  "issue_number": 214,
  "issue_url": "https://github.com/dmarx/arxiv-archive/issues/214",
  "created_at": "2024-12-24T03:19:07.555285",
  "state": "open",
  "labels": [
    "paper",
    "rating:novote"
  ],
  "total_reading_time_seconds": 0,
  "last_read": null
}