\section{Conclusion}
We propose a novel video variational autoencoder (VAE) to address high-fidelity video autoencoding and compression, especially for videos with large motion. 
Our approach extends pre-trained image VAEs to the video domain by decoupling spatial and temporal compression, mitigating motion blur and detail loss. 
We design a temporal-aware spatial encoder and a lightweight motion compression model to enhance motion modeling, temporal consistency, and detail preservation. 
To improve reconstruction quality and versatility, we leverage detailed captions and employ joint image-video training. Extensive experiments on challenging datasets demonstrate superior performance over state-of-the-art baselines. 
Our model sets a new standard for video compression by efficiently handling spatiotemporal compression while benefiting from cross-modal learning and joint training.