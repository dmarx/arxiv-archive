@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@article{videoworldsimulators2024,
  title={Video generation models as world simulators},
  author={Tim Brooks and Bill Peebles and Connor Holmes and Will DePue and Yufei Guo and Li Jing and David Schnurr and Joe Taylor and Troy Luhman and Eric Luhman and Clarence Ng and Ricky Wang and Aditya Ramesh},
  year={2024},
  url={https://openai.com/research/video-generation-models-as-world-simulators},
}

@article{metamoviegen,
  title={Movie Gen: A Cast of Media Foundation Models},
  author={The Movie Gen team @ Meta},
  year={2024},
  url={https://ai.meta.com/static-resource/movie-gen-research-paper},
}

@inproceedings{guoanimatediff,
  title={AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  booktitle={The Twelfth International Conference on Learning Representations}
}

@article{wang2024videocomposer,
  title={Videocomposer: Compositional video synthesis with motion controllability},
  author={Wang, Xiang and Yuan, Hangjie and Zhang, Shiwei and Chen, Dayou and Wang, Jiuniu and Zhang, Yingya and Shen, Yujun and Zhao, Deli and Zhou, Jingren},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{ma2024latte,
  title={Latte: Latent diffusion transformer for video generation},
  author={Ma, Xin and Wang, Yaohui and Jia, Gengyun and Chen, Xinyuan and Liu, Ziwei and Li, Yuan-Fang and Chen, Cunjian and Qiao, Yu},
  journal={arXiv preprint arXiv:2401.03048},
  year={2024}
}

@inproceedings{qing2024hierarchical,
  title={Hierarchical spatio-temporal decoupling for text-to-video generation},
  author={Qing, Zhiwu and Zhang, Shiwei and Wang, Jiayu and Wang, Xiang and Wei, Yujie and Zhang, Yingya and Gao, Changxin and Sang, Nong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6635--6645},
  year={2024}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@article{kingma2014auto,
  title={Auto-Encoding Variational Bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={stat},
  volume={1050},
  pages={1},
  year={2014}
}

@article{blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

@article{podell2023sdxl,
  title={Sdxl: Improving latent diffusion models for high-resolution image synthesis},
  author={Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and M{\"u}ller, Jonas and Penna, Joe and Rombach, Robin},
  journal={arXiv preprint arXiv:2307.01952},
  year={2023}
}

@article{yan2021videogpt,
  title={Videogpt: Video generation using vq-vae and transformers},
  author={Yan, Wilson and Zhang, Yunzhi and Abbeel, Pieter and Srinivas, Aravind},
  journal={arXiv preprint arXiv:2104.10157},
  year={2021}
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{ge2022long,
  title={Long video generation with time-agnostic vqgan and time-sensitive transformer},
  author={Ge, Songwei and Hayes, Thomas and Yang, Harry and Yin, Xi and Pang, Guan and Jacobs, David and Huang, Jia-Bin and Parikh, Devi},
  booktitle={European Conference on Computer Vision},
  pages={102--118},
  year={2022},
  organization={Springer}
}

@inproceedings{yu2023magvit,
  title={Magvit: Masked generative video transformer},
  author={Yu, Lijun and Cheng, Yong and Sohn, Kihyuk and Lezama, Jos{\'e} and Zhang, Han and Chang, Huiwen and Hauptmann, Alexander G and Yang, Ming-Hsuan and Hao, Yuan and Essa, Irfan and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10459--10469},
  year={2023}
}

@article{yu2023language,
  title={Language Model Beats Diffusion--Tokenizer is Key to Visual Generation},
  author={Yu, Lijun and Lezama, Jos{\'e} and Gundavarapu, Nitesh B and Versari, Luca and Sohn, Kihyuk and Minnen, David and Cheng, Yong and Gupta, Agrim and Gu, Xiuye and Hauptmann, Alexander G and others},
  journal={International Conference on Learning Representations},
  year={2024}
}

@software{opensora,
  author = {Zangwei Zheng and Xiangyu Peng and Tianji Yang and Chenhui Shen and Shenggui Li and Hongxin Liu and Yukun Zhou and Tianyi Li and Yang You},
  title = {Open-Sora: Democratizing Efficient Video Production for All},
  month = {March},
  year = {2024},
  url = {https://github.com/hpcaitech/Open-Sora}
}

@software{cosmos_token,
  author = {NVIDIA},
  title = {Cosmos Tokenizer: A suite of image and video neural tokenizers},
  month = {November},
  year = {2024},
  url = {https://github.com/NVIDIA/Cosmos-Tokenizer}
}

@software{pku_yuan_lab_and_tuzhan_ai_etc_2024_10948109,
  author       = {PKU-Yuan Lab and Tuzhan AI etc.},
  title        = {Open-Sora-Plan},
  month        = apr,
  year         = 2024,
  publisher    = {GitHub},
  doi          = {10.5281/zenodo.10948109},
  url          = {https://doi.org/10.5281/zenodo.10948109}
}

@article{bao2024vidu,
  title={Vidu: a highly consistent, dynamic and skilled text-to-video generator with diffusion models},
  author={Bao, Fan and Xiang, Chendong and Yue, Gang and He, Guande and Zhu, Hongzhou and Zheng, Kaiwen and Zhao, Min and Liu, Shilong and Wang, Yaole and Zhu, Jun},
  journal={arXiv preprint arXiv:2405.04233},
  year={2024}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

\cite{@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@article{zhao2024cv,
  title={CV-VAE: A Compatible Video VAE for Latent Generative Video Models},
  author={Zhao, Sijie and Zhang, Yong and Cun, Xiaodong and Yang, Shaoshu and Niu, Muyao and Li, Xiaoyu and Hu, Wenbo and Shan, Ying},
  journal={arXiv preprint arXiv:2405.20279},
  year={2024}
}

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021}
}

@inproceedings{bain2021frozen,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1728--1738},
  year={2021}
}

@inproceedings{chen2024panda,
  title={Panda-70m: Captioning 70m videos with multiple cross-modality teachers},
  author={Chen, Tsai-Shien and Siarohin, Aliaksandr and Menapace, Willi and Deyneka, Ekaterina and Chao, Hsiang-wei and Jeon, Byung Eun and Fang, Yuwei and Lee, Hsin-Ying and Ren, Jian and Yang, Ming-Hsuan and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13320--13331},
  year={2024}
}

@article{soomro2012dataset,
  title={A dataset of 101 human action classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={Center for Research in Computer Vision},
  volume={2},
  number={11},
  pages={1--7},
  year={2012}
}

@inproceedings{xiong2018learning,
  title={Learning to generate time-lapse videos using multi-stage dynamic generative adversarial networks},
  author={Xiong, Wei and Luo, Wenhan and Ma, Lin and Liu, Wei and Luo, Jiebo},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2364--2373},
  year={2018}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{chen2023end,
  title={End-to-end XY Separation for Single Image Blind Deblurring},
  author={Chen, Liuhan and Wang, Yirou and Chen, Yongyong},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={1273--1282},
  year={2023}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={International Conference on Learning Representations},
  year={2015}
}

@article{wang2004image,
  title={Image quality assessment: from error visibility to structural similarity},
  author={Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
  journal={IEEE transactions on image processing},
  volume={13},
  number={4},
  pages={600--612},
  year={2004},
  publisher={IEEE}
}

@inproceedings{hore2010image,
  title={Image quality metrics: PSNR vs. SSIM},
  author={Hore, Alain and Ziou, Djemel},
  booktitle={2010 20th international conference on pattern recognition},
  pages={2366--2369},
  year={2010},
  organization={IEEE}
}

@inproceedings{zhang2018unreasonable,
  title={The unreasonable effectiveness of deep features as a perceptual metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={586--595},
  year={2018}
}

@inproceedings{skorokhodov2022stylegan,
  title={Stylegan-v: A continuous video generator with the price, image quality and perks of stylegan2},
  author={Skorokhodov, Ivan and Tulyakov, Sergey and Elhoseiny, Mohamed},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3626--3636},
  year={2022}
}

@article{unterthiner2018towards,
  title={Towards accurate generative models of video: A new metric \& challenges},
  author={Unterthiner, Thomas and Van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Raphael and Michalski, Marcin and Gelly, Sylvain},
  journal={arXiv preprint arXiv:1812.01717},
  year={2018}
}

@article{saito2020train,
  title={Train sparsely, generate densely: Memory-efficient unsupervised training of high-resolution temporal gan},
  author={Saito, Masaki and Saito, Shunta and Koyama, Masanori and Kobayashi, Sosuke},
  journal={International Journal of Computer Vision},
  volume={128},
  number={10},
  pages={2586--2606},
  year={2020},
  publisher={Springer}
}

@inproceedings{tran2015learning,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4489--4497},
  year={2015}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{magictime,
  title={MagicTime: Time-lapse Video Generation Models as Metamorphic Simulators},
  author={Yuan, Shenghai and Huang, Jinfa and Shi, Yujun and Xu, Yongqi and Zhu, Ruijie and Lin, Bin and Cheng, Xinhua and Yuan, Li and Luo, Jiebo},
  journal={arXiv preprint arXiv:2404.05014},
  year={2024}
}

@article{ChronoMagic-Bench,
  title={ChronoMagic-Bench: A Benchmark for Metamorphic Evaluation of Text-to-Time-lapse Video Generation},
  author={Yuan, Shenghai and Huang, Jinfa and Xu, Yongqi and Liu, Yaoyang and Zhang, Shaofeng and Shi, Yujun and Zhu, Ruijie and Cheng, Xinhua and Luo, Jiebo and Yuan, Li},
  journal={arXiv preprint arXiv:2406.18522},
  year={2024}
}

@inproceedings{Prompt2Poster,
  title={Prompt2Poster: Automatically Artistic Chinese Poster Creation from Prompt Only},
  author={Wang, Shaodong and Ge, Yunyang and Chen, Liuhan and Zhou, Haiyang and Wang, Qian and Cheng, Xinhua and Yuan, Li},
  booktitle={ACM Multimedia 2024}
}

@inproceedings{clh2023end,
  title={End-to-end XY Separation for Single Image Blind Deblurring},
  author={Chen, Liuhan and Wang, Yirou and Chen, Yongyong},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={1273--1282},
  year={2023}
}

@misc{he2023latentvideodiffusionmodels,
      title={Latent Video Diffusion Models for High-Fidelity Long Video Generation}, 
      author={Yingqing He and Tianyu Yang and Yong Zhang and Ying Shan and Qifeng Chen},
      year={2023},
      eprint={2211.13221},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2211.13221}, 
}

@misc{xu2024easyanimatehighperformancelongvideo,
      title={EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture}, 
      author={Jiaqi Xu and Xinyi Zou and Kunzhe Huang and Yunkuo Chen and Bo Liu and MengLi Cheng and Xing Shi and Jun Huang},
      year={2024},
      eprint={2405.18991},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.18991}, 
}

@misc{chen2024odvaeomnidimensionalvideocompressor,
      title={OD-VAE: An Omni-dimensional Video Compressor for Improving Latent Video Diffusion Model}, 
      author={Liuhan Chen and Zongjian Li and Bin Lin and Bin Zhu and Qian Wang and Shenghai Yuan and Xing Zhou and Xinhua Cheng and Li Yuan},
      year={2024},
      eprint={2409.01199},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.01199}, 
}

@misc{chen2024videocrafter2overcomingdatalimitations,
      title={VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models}, 
      author={Haoxin Chen and Yong Zhang and Xiaodong Cun and Menghan Xia and Xintao Wang and Chao Weng and Ying Shan},
      year={2024},
      eprint={2401.09047},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2401.09047}, 
}

@misc{yang2024cogvideox,
      title={CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer}, 
      author={Zhuoyi Yang and Jiayan Teng and Wendi Zheng and Ming Ding and Shiyu Huang and Jiazheng Xu and Yuanming Yang and Wenyi Hong and Xiaohan Zhang and Guanyu Feng and Da Yin and Xiaotao Gu and Yuxuan Zhang and Weihan Wang and Yean Cheng and Ting Liu and Bin Xu and Yuxiao Dong and Jie Tang},
      year={2024},
      eprint={2408.06072},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.06072}, 
}

@misc{xing2023dynamicrafter,
      title={DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors}, 
      author={Jinbo Xing and Menghan Xia and Yong Zhang and Haoxin Chen and Wangbo Yu and Hanyuan Liu and Xintao Wang and Tien-Tsin Wong and Ying Shan},
      year={2023},
      eprint={2310.12190},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2310.12190}, 
}

@misc{singer2022makeavideo,
      title={Make-A-Video: Text-to-Video Generation without Text-Video Data}, 
      author={Uriel Singer and Adam Polyak and Thomas Hayes and Xi Yin and Jie An and Songyang Zhang and Qiyuan Hu and Harry Yang and Oron Ashual and Oran Gafni and Devi Parikh and Sonal Gupta and Yaniv Taigman},
      year={2022},
      eprint={2209.14792},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2209.14792}, 
}

@misc{he2015deepresidual,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1512.03385}, 
}

@article{inter4K,
title={AdaPool: Exponential Adaptive Pooling for Information-Retaining Downsampling},
author={Stergiou, Alexandros and Poppe, Ronald},
journal={arXiv preprint},
year={2021}}

@inproceedings{chen2024panda70m,
  title     = {Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers},
  author    = {Chen, Tsai-Shien and Siarohin, Aliaksandr and Menapace, Willi and Deyneka, Ekaterina and Chao, Hsiang-wei and Jeon, Byung Eun and Fang, Yuwei and Lee, Hsin-Ying and Ren, Jian and Yang, Ming-Hsuan and Tulyakov, Sergey},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year      = {2024}
}

@misc{chi2024mmtrailmultimodaltrailervideo,
      title={MMTrail: A Multimodal Trailer Video Dataset with Language and Music Descriptions}, 
      author={Xiaowei Chi and Yatian Wang and Aosong Cheng and Pengjun Fang and Zeyue Tian and Yingqing He and Zhaoyang Liu and Xingqun Qi and Jiahao Pan and Rongyu Zhang and Mengfei Li and Ruibin Yuan and Yanbing Jiang and Wei Xue and Wenhan Luo and Qifeng Chen and Shanghang Zhang and Qifeng Liu and Yike Guo},
      year={2024},
      eprint={2407.20962},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.20962}, 
}


@misc{sd35,
  title={Stable Diffusion 3.5 Large},
  author={Stability AI},
  year={2023},
  url={https://huggingface.co/stabilityai/stable-diffusion-3.5-large}
}

@article{t5,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={70},
  pages={1--53},
  year={2024}
}
@article{he-llm-survey,
  title={LLMs Meet Multimodal Generation and Editing: A Survey},
  author={He, Yingqing and Liu, Zhaoyang and Chen, Jingye and Tian, Zeyue and Liu, Hongyu and Chi, Xiaowei and Liu, Runtao and Yuan, Ruibin and Xing, Yazhou and Wang, Wenhai and others},
  journal={arXiv preprint arXiv:2405.19334},
  year={2024}
}
@article{he-lvdm,
  title={Latent Video Diffusion Models for High-Fidelity Video Generation with Arbitrary Lengths},
  author={He, Yingqing and Yang, Tianyu and Zhang, Yong and Shan, Ying and Chen, Qifeng},
  journal={arXiv preprint arXiv:2211.13221},
  year={2022}
}
@article{he-videocrafter1,
  title={Videocrafter1: Open diffusion models for high-quality video generation},
  author={Chen, Haoxin and Xia, Menghan and He, Yingqing and Zhang, Yong and Cun, Xiaodong and Yang, Shaoshu and Xing, Jinbo and Liu, Yaofang and Chen, Qifeng and Wang, Xintao and others},
  journal={arXiv preprint arXiv:2310.19512},
  year={2023}
}

@article{he-animate-a-story,
  title={Animate-a-story: Storytelling with retrieval-augmented video generation},
  author={He, Yingqing and Xia, Menghan and Chen, Haoxin and Cun, Xiaodong and Gong, Yuan and Xing, Jinbo and Zhang, Yong and Wang, Xintao and Weng, Chao and Shan, Ying and others},
  journal={arXiv preprint arXiv:2307.06940},
  year={2023}
}
@inproceedings{he-scalecrafter,
  title={Scalecrafter: Tuning-free higher-resolution visual generation with diffusion models},
  author={He, Yingqing and Yang, Shaoshu and Chen, Haoxin and Cun, Xiaodong and Xia, Menghan and Zhang, Yong and Wang, Xintao and He, Ran and Chen, Qifeng and Shan, Ying},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}
@inproceedings{he-shadow-removal,
  title={Unsupervised portrait shadow removal via generative priors},
  author={He, Yingqing and Xing, Yazhou and Zhang, Tianjia and Chen, Qifeng},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={236--244},
  year={2021}
}
@inproceedings{he-seeing-and-hearing,
  title={Seeing and hearing: Open-domain visual-audio generation with diffusion latent aligners},
  author={Xing, Yazhou and He, Yingqing and Tian, Zeyue and Wang, Xintao and Chen, Qifeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7151--7161},
  year={2024}
}
@article{he-hiprompt,
  title={HiPrompt: Tuning-free Higher-Resolution Generation with Hierarchical MLLM Prompts},
  author={Liu, Xinyu and He, Yingqing and Guo, Lanqing and Li, Xiang and Jin, Bu and Li, Peng and Li, Yan and Chan, Chi-Min and Chen, Qifeng and Xue, Wei and others},
  journal={arXiv preprint arXiv:2409.02919},
  year={2024}
}
@inproceedings{he-make-cheap-scaling,
  title={Make a cheap scaling: A self-cascade diffusion model for higher-resolution adaptation},
  author={Guo, Lanqing and He, Yingqing and Chen, Haoxin and Xia, Menghan and Cun, Xiaodong and Wang, Yufei and Huang, Siyu and Zhang, Yong and Wang, Xintao and Chen, Qifeng and others},
  booktitle={European Conference on Computer Vision},
  pages={39--55},
  year={2025},
  organization={Springer}
}
@inproceedings{follow-your-pose,
  title={Follow your pose: Pose-guided text-to-video generation using pose-free videos},
  author={Ma, Yue and He, Yingqing and Cun, Xiaodong and Wang, Xintao and Chen, Siran and Li, Xiu and Chen, Qifeng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={5},
  pages={4117--4125},
  year={2024}
}
@article{follow-your-click,
  title={Follow-your-click: Open-domain regional image animation via short prompts},
  author={Ma, Yue and He, Yingqing and Wang, Hongfa and Wang, Andong and Qi, Chenyang and Cai, Chengfei and Li, Xiu and Li, Zhifeng and Shum, Heung-Yeung and Liu, Wei and others},
  journal={arXiv preprint arXiv:2403.08268},
  year={2024}
}
@article{follow-your-emoji,
  title={Follow-Your-Emoji: Fine-Controllable and Expressive Freestyle Portrait Animation},
  author={Ma, Yue and Liu, Hongyu and Wang, Hongfa and Pan, Heng and He, Yingqing and Yuan, Junkun and Zeng, Ailing and Cai, Chengfei and Shum, Heung-Yeung and Liu, Wei and others},
  journal={arXiv preprint arXiv:2406.01900},
  year={2024}
}
@article{mmtrail,
  title={MMTrail: A Multimodal Trailer Video Dataset with Language and Music Descriptions},
  author={Chi, Xiaowei and Wang, Yatian and Cheng, Aosong and Fang, Pengjun and Tian, Zeyue and He, Yingqing and Liu, Zhaoyang and Qi, Xingqun and Pan, Jiahao and Zhang, Rongyu and others},
  journal={arXiv preprint arXiv:2407.20962},
  year={2024}
}


@article{zhou2022magicvideo,
  title={Magicvideo: Efficient video generation with latent diffusion models},
  author={Zhou, Daquan and Wang, Weimin and Yan, Hanshu and Lv, Weiwei and Zhu, Yizhe and Feng, Jiashi},
  journal={arXiv preprint arXiv:2211.11018},
  year={2022}
}

@inproceedings{lpips,
  title={The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={CVPR},
  year={2018}
}
@inproceedings{blattmann2023align,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22563--22575},
  year={2023}
}
@article{kong2024hunyuanvideo,
  title={HunyuanVideo: A Systematic Framework For Large Video Generative Models},
  author={Kong, Weijie and Tian, Qi and Zhang, Zijian and Min, Rox and Dai, Zuozhuo and Zhou, Jin and Xiong, Jiangfeng and Li, Xin and Wu, Bo and Zhang, Jianwei and others},
  journal={arXiv preprint arXiv:2412.03603},
  year={2024}
}