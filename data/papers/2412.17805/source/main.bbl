\begin{thebibliography}{36}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[AI(2023)]{sd35}
Stability AI.
\newblock Stable diffusion 3.5 large, 2023.

\bibitem[Bain et~al.(2021)Bain, Nagrani, Varol, and Zisserman]{bain2021frozen}
Max Bain, Arsha Nagrani, G{\"u}l Varol, and Andrew Zisserman.
\newblock Frozen in time: A joint video and image encoder for end-to-end retrieval.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 1728--1738, 2021.

\bibitem[Bao et~al.(2024)Bao, Xiang, Yue, He, Zhu, Zheng, Zhao, Liu, Wang, and Zhu]{bao2024vidu}
Fan Bao, Chendong Xiang, Gang Yue, Guande He, Hongzhou Zhu, Kaiwen Zheng, Min Zhao, Shilong Liu, Yaole Wang, and Jun Zhu.
\newblock Vidu: a highly consistent, dynamic and skilled text-to-video generator with diffusion models.
\newblock \emph{arXiv preprint arXiv:2405.04233}, 2024.

\bibitem[Blattmann et~al.(2023{\natexlab{a}})Blattmann, Dockhorn, Kulal, Mendelevitch, Kilian, Lorenz, Levi, English, Voleti, Letts, et~al.]{blattmann2023stable}
Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, et~al.
\newblock Stable video diffusion: Scaling latent video diffusion models to large datasets.
\newblock \emph{arXiv preprint arXiv:2311.15127}, 2023{\natexlab{a}}.

\bibitem[Blattmann et~al.(2023{\natexlab{b}})Blattmann, Rombach, Ling, Dockhorn, Kim, Fidler, and Kreis]{blattmann2023align}
Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung~Wook Kim, Sanja Fidler, and Karsten Kreis.
\newblock Align your latents: High-resolution video synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 22563--22575, 2023{\natexlab{b}}.

\bibitem[Brooks et~al.(2024)Brooks, Peebles, Holmes, DePue, Guo, Jing, Schnurr, Taylor, Luhman, Luhman, Ng, Wang, and Ramesh]{videoworldsimulators2024}
Tim Brooks, Bill Peebles, Connor Holmes, Will DePue, Yufei Guo, Li Jing, David Schnurr, Joe Taylor, Troy Luhman, Eric Luhman, Clarence Ng, Ricky Wang, and Aditya Ramesh.
\newblock Video generation models as world simulators.
\newblock 2024.

\bibitem[Chen et~al.(2023)Chen, Xia, He, Zhang, Cun, Yang, Xing, Liu, Chen, Wang, et~al.]{he-videocrafter1}
Haoxin Chen, Menghan Xia, Yingqing He, Yong Zhang, Xiaodong Cun, Shaoshu Yang, Jinbo Xing, Yaofang Liu, Qifeng Chen, Xintao Wang, et~al.
\newblock Videocrafter1: Open diffusion models for high-quality video generation.
\newblock \emph{arXiv preprint arXiv:2310.19512}, 2023.

\bibitem[Chen et~al.(2024{\natexlab{a}})Chen, Zhang, Cun, Xia, Wang, Weng, and Shan]{chen2024videocrafter2overcomingdatalimitations}
Haoxin Chen, Yong Zhang, Xiaodong Cun, Menghan Xia, Xintao Wang, Chao Weng, and Ying Shan.
\newblock Videocrafter2: Overcoming data limitations for high-quality video diffusion models, 2024{\natexlab{a}}.

\bibitem[Chen et~al.(2024{\natexlab{b}})Chen, Li, Lin, Zhu, Wang, Yuan, Zhou, Cheng, and Yuan]{chen2024odvaeomnidimensionalvideocompressor}
Liuhan Chen, Zongjian Li, Bin Lin, Bin Zhu, Qian Wang, Shenghai Yuan, Xing Zhou, Xinhua Cheng, and Li Yuan.
\newblock Od-vae: An omni-dimensional video compressor for improving latent video diffusion model, 2024{\natexlab{b}}.

\bibitem[Chen et~al.(2024{\natexlab{c}})Chen, Siarohin, Menapace, Deyneka, Chao, Jeon, Fang, Lee, Ren, Yang, et~al.]{chen2024panda}
Tsai-Shien Chen, Aliaksandr Siarohin, Willi Menapace, Ekaterina Deyneka, Hsiang-wei Chao, Byung~Eun Jeon, Yuwei Fang, Hsin-Ying Lee, Jian Ren, Ming-Hsuan Yang, et~al.
\newblock Panda-70m: Captioning 70m videos with multiple cross-modality teachers.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 13320--13331, 2024{\natexlab{c}}.

\bibitem[Chi et~al.(2024)Chi, Wang, Cheng, Fang, Tian, He, Liu, Qi, Pan, Zhang, Li, Yuan, Jiang, Xue, Luo, Chen, Zhang, Liu, and Guo]{chi2024mmtrailmultimodaltrailervideo}
Xiaowei Chi, Yatian Wang, Aosong Cheng, Pengjun Fang, Zeyue Tian, Yingqing He, Zhaoyang Liu, Xingqun Qi, Jiahao Pan, Rongyu Zhang, Mengfei Li, Ruibin Yuan, Yanbing Jiang, Wei Xue, Wenhan Luo, Qifeng Chen, Shanghang Zhang, Qifeng Liu, and Yike Guo.
\newblock Mmtrail: A multimodal trailer video dataset with language and music descriptions, 2024.

\bibitem[Chung et~al.(2024)Chung, Hou, Longpre, Zoph, Tay, Fedus, Li, Wang, Dehghani, Brahma, et~al.]{t5}
Hyung~Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et~al.
\newblock Scaling instruction-finetuned language models.
\newblock \emph{Journal of Machine Learning Research}, 25\penalty0 (70):\penalty0 1--53, 2024.

\bibitem[Guo et~al.()Guo, Yang, Rao, Liang, Wang, Qiao, Agrawala, Lin, and Dai]{guoanimatediff}
Yuwei Guo, Ceyuan Yang, Anyi Rao, Zhengyang Liang, Yaohui Wang, Yu Qiao, Maneesh Agrawala, Dahua Lin, and Bo Dai.
\newblock Animatediff: Animate your personalized text-to-image diffusion models without specific tuning.
\newblock In \emph{The Twelfth International Conference on Learning Representations}.

\bibitem[He et~al.(2022)He, Yang, Zhang, Shan, and Chen]{he-lvdm}
Yingqing He, Tianyu Yang, Yong Zhang, Ying Shan, and Qifeng Chen.
\newblock Latent video diffusion models for high-fidelity video generation with arbitrary lengths.
\newblock \emph{arXiv preprint arXiv:2211.13221}, 2022.

\bibitem[He et~al.(2023)He, Xia, Chen, Cun, Gong, Xing, Zhang, Wang, Weng, Shan, et~al.]{he-animate-a-story}
Yingqing He, Menghan Xia, Haoxin Chen, Xiaodong Cun, Yuan Gong, Jinbo Xing, Yong Zhang, Xintao Wang, Chao Weng, Ying Shan, et~al.
\newblock Animate-a-story: Storytelling with retrieval-augmented video generation.
\newblock \emph{arXiv preprint arXiv:2307.06940}, 2023.

\bibitem[He et~al.(2024)He, Liu, Chen, Tian, Liu, Chi, Liu, Yuan, Xing, Wang, et~al.]{he-llm-survey}
Yingqing He, Zhaoyang Liu, Jingye Chen, Zeyue Tian, Hongyu Liu, Xiaowei Chi, Runtao Liu, Ruibin Yuan, Yazhou Xing, Wenhai Wang, et~al.
\newblock Llms meet multimodal generation and editing: A survey.
\newblock \emph{arXiv preprint arXiv:2405.19334}, 2024.

\bibitem[Kingma and Welling(2014)]{kingma2014auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{stat}, 1050:\penalty0 1, 2014.

\bibitem[Kong et~al.(2024)Kong, Tian, Zhang, Min, Dai, Zhou, Xiong, Li, Wu, Zhang, et~al.]{kong2024hunyuanvideo}
Weijie Kong, Qi Tian, Zijian Zhang, Rox Min, Zuozhuo Dai, Jin Zhou, Jiangfeng Xiong, Xin Li, Bo Wu, Jianwei Zhang, et~al.
\newblock Hunyuanvideo: A systematic framework for large video generative models.
\newblock \emph{arXiv preprint arXiv:2412.03603}, 2024.

\bibitem[Lab and etc.(2024)]{pku_yuan_lab_and_tuzhan_ai_etc_2024_10948109}
PKU-Yuan Lab and Tuzhan~AI etc.
\newblock Open-sora-plan, 2024.

\bibitem[Ma et~al.(2024{\natexlab{a}})Ma, Wang, Jia, Chen, Liu, Li, Chen, and Qiao]{ma2024latte}
Xin Ma, Yaohui Wang, Gengyun Jia, Xinyuan Chen, Ziwei Liu, Yuan-Fang Li, Cunjian Chen, and Yu Qiao.
\newblock Latte: Latent diffusion transformer for video generation.
\newblock \emph{arXiv preprint arXiv:2401.03048}, 2024{\natexlab{a}}.

\bibitem[Ma et~al.(2024{\natexlab{b}})Ma, He, Cun, Wang, Chen, Li, and Chen]{follow-your-pose}
Yue Ma, Yingqing He, Xiaodong Cun, Xintao Wang, Siran Chen, Xiu Li, and Qifeng Chen.
\newblock Follow your pose: Pose-guided text-to-video generation using pose-free videos.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, pages 4117--4125, 2024{\natexlab{b}}.

\bibitem[Ma et~al.(2024{\natexlab{c}})Ma, Liu, Wang, Pan, He, Yuan, Zeng, Cai, Shum, Liu, et~al.]{follow-your-emoji}
Yue Ma, Hongyu Liu, Hongfa Wang, Heng Pan, Yingqing He, Junkun Yuan, Ailing Zeng, Chengfei Cai, Heung-Yeung Shum, Wei Liu, et~al.
\newblock Follow-your-emoji: Fine-controllable and expressive freestyle portrait animation.
\newblock \emph{arXiv preprint arXiv:2406.01900}, 2024{\natexlab{c}}.

\bibitem[NVIDIA(2024)]{cosmos_token}
NVIDIA.
\newblock Cosmos tokenizer: A suite of image and video neural tokenizers, 2024.

\bibitem[Podell et~al.(2023)Podell, English, Lacey, Blattmann, Dockhorn, M{\"u}ller, Penna, and Rombach]{podell2023sdxl}
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas M{\"u}ller, Joe Penna, and Robin Rombach.
\newblock Sdxl: Improving latent diffusion models for high-resolution image synthesis.
\newblock \emph{arXiv preprint arXiv:2307.01952}, 2023.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem[Stergiou and Poppe(2021)]{inter4K}
Alexandros Stergiou and Ronald Poppe.
\newblock Adapool: Exponential adaptive pooling for information-retaining downsampling.
\newblock \emph{arXiv preprint}, 2021.

\bibitem[team @~Meta(2024)]{metamoviegen}
The Movie~Gen team @~Meta.
\newblock Movie gen: A cast of media foundation models.
\newblock 2024.

\bibitem[Xing et~al.(2023)Xing, Xia, Zhang, Chen, Yu, Liu, Wang, Wong, and Shan]{xing2023dynamicrafter}
Jinbo Xing, Menghan Xia, Yong Zhang, Haoxin Chen, Wangbo Yu, Hanyuan Liu, Xintao Wang, Tien-Tsin Wong, and Ying Shan.
\newblock Dynamicrafter: Animating open-domain images with video diffusion priors, 2023.

\bibitem[Xing et~al.(2024)Xing, He, Tian, Wang, and Chen]{he-seeing-and-hearing}
Yazhou Xing, Yingqing He, Zeyue Tian, Xintao Wang, and Qifeng Chen.
\newblock Seeing and hearing: Open-domain visual-audio generation with diffusion latent aligners.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7151--7161, 2024.

\bibitem[Xu et~al.(2024)Xu, Zou, Huang, Chen, Liu, Cheng, Shi, and Huang]{xu2024easyanimatehighperformancelongvideo}
Jiaqi Xu, Xinyi Zou, Kunzhe Huang, Yunkuo Chen, Bo Liu, MengLi Cheng, Xing Shi, and Jun Huang.
\newblock Easyanimate: A high-performance long video generation method based on transformer architecture, 2024.

\bibitem[Yang et~al.(2024)Yang, Teng, Zheng, Ding, Huang, Xu, Yang, Hong, Zhang, Feng, Yin, Gu, Zhang, Wang, Cheng, Liu, Xu, Dong, and Tang]{yang2024cogvideox}
Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, Da Yin, Xiaotao Gu, Yuxuan Zhang, Weihan Wang, Yean Cheng, Ting Liu, Bin Xu, Yuxiao Dong, and Jie Tang.
\newblock Cogvideox: Text-to-video diffusion models with an expert transformer, 2024.

\bibitem[Yu et~al.(2024)Yu, Lezama, Gundavarapu, Versari, Sohn, Minnen, Cheng, Gupta, Gu, Hauptmann, et~al.]{yu2023language}
Lijun Yu, Jos{\'e} Lezama, Nitesh~B Gundavarapu, Luca Versari, Kihyuk Sohn, David Minnen, Yong Cheng, Agrim Gupta, Xiuye Gu, Alexander~G Hauptmann, et~al.
\newblock Language model beats diffusion--tokenizer is key to visual generation.
\newblock \emph{International Conference on Learning Representations}, 2024.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and Wang]{lpips}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual metric.
\newblock In \emph{CVPR}, 2018.

\bibitem[Zhao et~al.(2024)Zhao, Zhang, Cun, Yang, Niu, Li, Hu, and Shan]{zhao2024cv}
Sijie Zhao, Yong Zhang, Xiaodong Cun, Shaoshu Yang, Muyao Niu, Xiaoyu Li, Wenbo Hu, and Ying Shan.
\newblock Cv-vae: A compatible video vae for latent generative video models.
\newblock \emph{arXiv preprint arXiv:2405.20279}, 2024.

\bibitem[Zheng et~al.(2024)Zheng, Peng, Yang, Shen, Li, Liu, Zhou, Li, and You]{opensora}
Zangwei Zheng, Xiangyu Peng, Tianji Yang, Chenhui Shen, Shenggui Li, Hongxin Liu, Yukun Zhou, Tianyi Li, and Yang You.
\newblock Open-sora: Democratizing efficient video production for all, 2024.

\bibitem[Zhou et~al.(2022)Zhou, Wang, Yan, Lv, Zhu, and Feng]{zhou2022magicvideo}
Daquan Zhou, Weimin Wang, Hanshu Yan, Weiwei Lv, Yizhe Zhu, and Jiashi Feng.
\newblock Magicvideo: Efficient video generation with latent diffusion models.
\newblock \emph{arXiv preprint arXiv:2211.11018}, 2022.

\end{thebibliography}
