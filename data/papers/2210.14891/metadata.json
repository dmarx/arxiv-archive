{
  "arxivId": "2210.14891",
  "title": "Broken Neural Scaling Laws",
  "authors": "Ethan Caballero, Kshitij Gupta, Irina Rish, David Krueger",
  "abstract": "We present a smoothly broken power law functional form (that we refer to as a\nBroken Neural Scaling Law (BNSL)) that accurately models & extrapolates the\nscaling behaviors of deep neural networks (i.e. how the evaluation metric of\ninterest varies as amount of compute used for training (or inference), number\nof model parameters, training dataset size, model input size, number of\ntraining steps, or upstream performance varies) for various architectures & for\neach of various tasks within a large & diverse set of upstream & downstream\ntasks, in zero-shot, prompted, & finetuned settings. This set includes\nlarge-scale vision, language, audio, video, diffusion, generative modeling,\nmultimodal learning, contrastive learning, AI alignment, AI capabilities,\nrobotics, out-of-distribution (OOD) generalization, continual learning,\ntransfer learning, uncertainty estimation / calibration, OOD detection,\nadversarial robustness, distillation, sparsity, retrieval, quantization,\npruning, fairness, molecules, computer programming/coding, math word problems,\n\"emergent phase transitions\", arithmetic, supervised learning,\nunsupervised/self-supervised learning, & reinforcement learning (single agent &\nmulti-agent). When compared to other functional forms for neural scaling, this\nfunctional form yields extrapolations of scaling behavior that are considerably\nmore accurate on this set. Moreover, this functional form accurately models &\nextrapolates scaling behavior that other functional forms are incapable of\nexpressing such as the nonmonotonic transitions present in the scaling behavior\nof phenomena such as double descent & the delayed, sharp inflection points\npresent in the scaling behavior of tasks such as arithmetic. Lastly, we use\nthis functional form to glean insights about the limit of the predictability of\nscaling behavior. Code is available at\nhttps://github.com/ethancaballero/broken_neural_scaling_laws",
  "url": "https://arxiv.org/abs/2210.14891",
  "issue_number": 85,
  "issue_url": "https://github.com/dmarx/arxiv-archive/issues/85",
  "created_at": "2024-12-25T08:53:08.561080",
  "state": "open",
  "labels": [
    "paper",
    "rating:downvote"
  ],
  "total_reading_time_seconds": 0,
  "last_read": null,
  "last_visited": "2024-12-21T05:51:08.748Z"
}