\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading mlsafety_neurips_2022


% ready for submission
\usepackage[final]{mlsafety_neurips_2022}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{mlsafety_neurips_2022}


% to compile a camera-ready version, add the [final] option, e.g.:
%\usepackage[final]{mlsafety_neurips_2022}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{mlsafety_neurips_2022}




\usepackage{booktabs} % for professional tables

%for removing columns
\usepackage{array}
\newcolumntype{H}{>{\setbox0=\hbox\bgroup}c<{\egroup}@{}}
\newcolumntype{Z}{>{\setbox0=\hbox\bgroup}c<{\egroup}@{\hspace*{-\tabcolsep}}}


% added by IR
\newcommand{\ir}[1]		{{ \textcolor{blue} { #1}}}
\newcommand{\dk}[1]		{{ \textcolor{red} { #1}}}
\newcommand{\kg}[1]		{{ \textcolor{purple} { #1}}}
%\newcommand{\notice}[1]		{{ \textcolor{purple} { #1}}}
\usepackage[colorinlistoftodos]{todonotes}
\newcommand{\highlight}[1]{\colorbox{blue!10}{#1}}
\newcommand{\squeezeup}{\vspace{-2.5mm}}
% \usepackage{graphicx}
\usepackage{amsfonts, amsmath, amsthm}       % blackboard math symbols, proofs
\usepackage{verbatim}

\newtheorem{proposition}{Proposition}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors


\title{Broken Neural Scaling Laws}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{Ethan Caballero
\\ Mila, McGill University
\\ \texttt{ethan.victor.caballero@gmail.com}
\\ \texttt{ethan.caballero@mila.quebec}
%\\ \texttt{https://twitter.com/ethancaballero}
\And
Kshitij Gupta
\\ Mila, University of Montreal
\And%\AND
Irina Rish 
\\ Mila, University of Montreal
\And
\hspace{123pt}
David Krueger
\\ \hspace{123pt} University of Cambridge
}


\begin{document}

\maketitle


\begin{comment}
\begin{abstract}
DK ABSTRACT:
\dk{Neural scaling laws can be used to predict the results of large-scale training runs from smaller, cheaper experiments.  
A number of works have found that training loss scales smoothly and predictably as a function of data set size, parameter count, and training time.  
However, this masks a major limitation of existing scaling laws: they are not able to predict ``downstream'' performance of a model evaluated on new tasks or specific subsets of the training data, which often exhibits striking discontinuities} \ir{ not sure we should call the nonlinearities "discontinuities" - they are still continuous curves} \dk{, and can even decrease with scale.
Downstream performance is important as it can reflect particularly important properties of a model, such as TODO or truthfulness.
Our work proposes a new form of scaling law capable of fitting Todo discontinuities, ``inverse scaling'', and even double descent curves.
Traditional scaling laws are modified power laws, i.e.\ log(performance) is a linear function of log(scale).
Our new family of \textbf{broken neural scaling laws (BNSL)} are instead (roughly) \textit{piecewise} linear on a log-log plot.
% We show how to overcome optimization obstacles encountered when fitting such functions to empirical scaling data.
Our experiments demonstrate that this simple modification produces state-of-the-art extrapolations of both large scale and synthetic empirical scaling data.}
%\dk{Scaling laws matter because they predict performance, but predicting behavior is harder and also matters.  For that, we need }
\end{abstract}
\end{comment}

\begin{comment}
\begin{abstract}
%\ir{Training state-of-the-art deep networks becomes highly expensive as the data and model size increase. Reliable prediction of their performance at scale is essential for selecting the most promising/cost-efficient architectures and algorithms. This triggered a recent surge in the literature on neural scaling laws that attempt to capture the performance (as well as other behaviors)   However, while the upstream (test set) performance typically follows a power law, no unifying scaling law were proposed yet for the downstream performance, which sometimes tends to exhibit non-linearities and sharp transitions (inflection points). }
% Why scaling laws?
IR abstract: \ir{Neural scaling laws aim to predict the behavior of large-scale models  from smaller, cheaper experiments, allowing to focus on the best-scaling architectures, algorithms, datasets, and so on. The upstream/in-distribution test loss typically (but not always!) falls off  as a power law with increasing  data, model size and compute. However, the downstream/out-of-distribution performance, and other evaluation metrics of interest (e.g., truthfulness in language models, etc) are often less predictable, exhibiting  nonlinear (e.g., sharp transitions, or ``grokking") and non-monotonic (inverse scaling, double descent etc) behaviors. Discovering {\it universal  scaling laws} that accurately model a wide range of potentially unexpected behaviors is clearly important not only for identifying that which scales best, but also for AI safety.
In this paper, we consider a {\it broken neural scaling laws (BNSL)} functional form that generalizes power laws (linear in  log-log plot) %, $\log(y)$=a$\log(x) + b)$)  
to ``smoothly broken" power laws, i.e. smoothly connected piecewise linear function in log-log plot.  An extensive empirical evaluation demonstrates that BNSL accurately model scaling behaviors of each task across a large and diverse set of both upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set includes large-scale unsupervised language and vision tasks, arithmetic, and reinforcement learning (rl). This functional form yields extrapolations of scaling behavior that often are an order of magnitude more accurate then those achieved by several previously proposed functional forms for neural scaling. It captures well the non-monotonic transitions present in the scaling behavior of phenomena such as double descent and the delayed, sharp transitions present in the scaling behavior of tasks such as arithmetic.}
\end{abstract}
\end{comment}

\begin{abstract}
%Ethan's version:\\
% We present a smoothly broken power law function %functional form 
% that accurately models the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, or training dataset size varies) for  a  large and diverse set of upstream and downstream tasks, in  zero-shot, prompted, and fine-tuned settings. This set includes     large-scale vision and unsupervised language tasks, arithmetic, and reinforcement learning. The proposed functional form yields extrapolations of scaling behavior that often are an order of magnitude more accurate than the ones obtained by previously proposed  functional forms for neural scaling behavior. Moreover, this functional form accurately models the non-monotonic transitions present in the scaling behavior of phenomena such as double descent and the delayed, sharp transitions present in the scaling behavior of tasks such as arithmetic.
% w/DK tweeks:
We present a smoothly broken power law functional form that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, training dataset size, or upstream performance varies) for each task within a large and diverse set of upstream and downstream tasks, in  zero-shot, prompted, and fine-tuned settings. This set includes large-scale vision and unsupervised language tasks, diffusion generative modeling of images, arithmetic, and reinforcement learning. When compared to other functional forms for neural scaling behavior, this functional form yields extrapolations of scaling behavior that are considerably more accurate (root mean squared log error of its extrapolations are 0.86 times that of previous state-of-the-art on average) on this set. Moreover, this functional form accurately models and extrapolates scaling behavior that other functional forms are incapable of expressing such as the non-monotonic transitions present in the scaling behavior of phenomena such as double descent and the delayed, sharp inflection points present in the scaling behavior of tasks such as arithmetic. Code is available at \url{https://github.com/ethancaballero/broken_neural_scaling_laws}
    
\end{abstract}


%\input{sec_intro}

\section{Introduction}
The amount of compute used for training, number of model parameters, and training dataset size of the most capable artificial neural networks keeps increasing and will probably keep rapidly increasing for the foreseeable future. However, no organization currently has direct access to these larger resources of the future; and it has been empirically verified  many times  that methods which perform best at smaller scales often are no longer the best performing methods at larger scales (e.g., one of such examples can be seen in  Figure 2 (right) of \cite{tolstikhin2021mlp}). To work on, identify, and steer the methods that are most probable to stand the test-of-time as these larger resources come online, one needs a way to predict how all relevant performance evaluation metrics of artificial neural networks vary in all relevant settings as scale increases. 

%%% david's intro
%In the largest scale regimes of modern deep learning, it seems that increasing the number of model parameters, amount of compute used for training, or training dataset size (almost) always yields better results. 
% TODO: reference other results like double descent?  Or probably that should come later...
%In fact, scaling up deep learning seems to yield predictable performance improvements, which can be modeled using neural scaling laws.
%Remarkably, the same simple functional form, a modified power law, applies equally well to data, parameters, and compute, the three axes along which scaling is measured.
%, provided that none of the three is a bottleneck (TODO: more details on that?). Ethan: It works fine even if bottlenecked.

%Currently, the main practical value of neural scaling laws is in forecasting the performance of larger models and datasets without needing to train or collect them.  
%Indeed, several works have shown that models that underperform at smaller scales can be predicted to reach state of the art performance at larger scales \citep{}, although such predictions have not always held up \citep{}.
%However, it is difficult to translate predictions about performance metrics such as negative log likelihood into predictions about qualitative behaviors and capabilities.
%For instance, \citet{GPT} famously document the emergence of in-context meta-learning in large-scale language models.
%``Downstream'' performance, i.e.\ that which is measured on metrics other than the training loss, reveals striking discontinuities as a function of scale. % TODO: note that it's not all downstream, and discuss fine-tuning vs. 0-shot
%Models suddenly go from near-chance level to state-of-the-art performance on tasks such as TODO once a critical scale is reached.
%TODO: say something more here about how we crush it 

%Predicting the emergence of novel capabilities at scale could prove crucial to responsibly developing and deploying increasingly advanced AI systems. % TODO: say more, e.g. mention deception or something? Doing so requires methods of identifying and measuring relevant capabilities, and scaling laws that can accurately forecast how these capabilities develop at scale. % of modelling their learning dynamics. However, the functional forms of scaling laws applied in prior work are not up to this challenge.

%One salient defect is that they can only represent monotonic functions. They thus fail to model the striking phenomena of double-descent \citep{}, where increased scale temporarily decreases test performance before ultimately leading to further improvements. %, and grokking \citep{}, where test performance remains near chance levels  They also lack the expressive power to model inflection points, which can be observed empirically for many downstream tasks, and even some upstream tasks, such as our $N$-digit arithmetic task, or the modular arithmetic task introduced by \citet{grokking} in their work on ``grokking''. 
%For this task, test performance remains near chance levels long after training accuracy has reached 100\% before eventually climbing towards 100\% as well on synthetic arithmetic tasks.
%, and grokking \citep{}, where test performance remains near chance levels long after training accuracy has reached 100\% before eventually climbing towards 100\% as well on synthetic arithmetic tasks.
%Such discontinuities can sometimes even be observed on the ``upstream'' test loss; for instance, we observe them in a simple $N$-digit arithmetic task.
%Another striking phenomena of modern deep learning that 

%also fail to fit the striking phenomena of double-descent \citep{}, where increased scale temporarily decreases test performance before ultimately leading to further improvements.%, and grokking \citep{}, where test performance remains near chance levels long after training accuracy has reached 100\% before eventually climbing towards 100\% as well on synthetic arithmetic tasks.
%Modelling, predicting, and ultimately understanding these phenomena will 
%Our work presents a functional form capable of modeling all of these diverse behaviors, and empirically validates it's effectiveness in extrapolating scaling behavior.
%%%% david's intro


Neural scaling laws \cite{cortes1994learning,2017arXiv171200409H,DBLP:journals/corr/abs-1909-12673,icm2020arXiv200108361K,DBLP:journals/corr/abs-2106-04560,abnar2021exploring,Alabdulmohsi2022revisiting, brown2020language} aim to predict the behavior of large-scale models from smaller, cheaper experiments, allowing to focus on the best-scaling architectures and algorithms. The upstream/in-distribution test loss typically (but not always!) falls off  as a power law with increasing  data, model size and compute. However, the downstream/out-of-distribution performance, and other evaluation metrics of interest (even upstream/in-distribution evaluation metrics) %(e.g., truthfulness in language models, etc) 
are often less predictable, sometimes exhibiting inflection points (on a linear-linear plot) and non-monotonic behaviors. Discovering {\it universal  scaling laws} that accurately model a wide range of potentially unexpected behaviors is clearly important not only for identifying that which scales best, but also for AI safety, as predicting the emergence of novel capabilities at scale could prove crucial to responsibly developing and deploying increasingly advanced AI systems. % TODO: say more, e.g. mention deception or something?
%Doing so requires methods of identifying and measuring relevant capabilities, and scaling laws that can accurately forecast how these capabilities develop at scale. % of modelling their learning dynamics.
%However, the functional forms of scaling laws proposed so far may not be fully up to this challenge.
%The functional forms of many existing scaling laws are not up to this challenge.
The functional forms of scaling laws evaluated in previous work are not up to this challenge.

% Ok, that works
% \great!

% @david, I commented out because it uses the word propose 
% so what? it's not "we propose"

% thus far implies we are about propose something. Also, smoothly broken power laws are already propoesed by others technically
% Better?
% its all, not many... 


One salient defect is that they can only represent monotonic functions.
They thus fail to model the striking phenomena of double-descent \citep{nakkiran2021deep}, where increased scale temporarily decreases test performance before ultimately leading to further improvements. %, and grokking \citep{}, where test performance remains near chance levels 
They also lack the expressive power to model inflection points (on a linear-linear plot), which can be observed empirically for many downstream tasks, and even some upstream tasks, such as our $N$-digit arithmetic task, or the modular arithmetic task introduced by \citet{power2022grokking} in their work on ``grokking".

To overcome the above limitations,  we present {\it broken neural scaling laws (BNSL)} - a functional form that generalizes power laws (linear in  log-log plot) %, $\log(y)$=a$\log(x) + b)$)  
to ``smoothly broken" power laws, i.e. a smoothly connected piecewise (approximately) linear function in a log-log plot.  An extensive empirical evaluation demonstrates that BNSL accurately model  scaling behaviors across a large and diverse set of both upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set includes large-scale unsupervised language and vision tasks, arithmetic, and reinforcement learning. 
%This functional form yields more accurate (often by an order of magnitude) extrapolations of scaling behavior then those achieved by several previously proposed functional forms for neural scaling. 
This functional form yields more accurate (often by an order of magnitude) extrapolations of scaling behavior then those achieved in any previous work. %by several previously proposed functional forms for neural scaling. 
It captures well the non-monotonic transitions present in the scaling behavior of phenomena such as double descent and the delayed, sharp transitions present in the scaling behavior of tasks such as arithmetic.


%\todo[inline]{don't copy the abstract (exactly), paraphrase}
%To address this need, we present a smoothly broken power law functional form, referred to by us as a \textbf{broken neural scaling law (BNSL)}, that accurately models the scaling behaviors of artificial neural networks for each task from a very large and diverse set of upstream and downstream (i.e. zero-shot, prompted, and fine-tuned) tasks. These tasks include large-scale vision tasks, large-scale unsupervised language tasks, arithmetic, and reinforcement learning. This functional form yields extrapolations of scaling behavior that often are an order of magnitude more accurate than previous functional forms for modeling the scaling behavior of artificial neural networks. Moreover, this functional form accurately models the non-monotonic transitions present in the scaling behavior of phenomena such as double descent and the delayed, sharp transitions present in the scaling behavior of tasks such as arithmetic.

%One collects some experimental data in the smaller (compute, data, or number of parameters) regime, and then fits a neural scaling law functional form (e.g. via a curve fitting library such as SciPy \cite{virtanen2020scipy}.

%Currently variants of power laws branded as neural scaling laws are main means one uses to make such predictions. One collects some experimental data in the smaller (compute, data, or number of parameters) regime, and then fits a neural scaling law functional form (e.g. via a curve fitting library such as SciPy \cite{virtanen2020scipy}.

%Neural Scaling Laws as they currently are used have some issues. (TODO: this is tricky to phrase because scaling laws for transfer exists and is equivalent to ours)

%\iffalse

\begin{comment}
\section{DK Introduction}
\label{sec:intro}

%\todo[inline]{TODO: this needs references all over the place}


%Conventional wisdom and machine learning has long held that more data is always better, but there is a sweet spot for the number of parameters or amount of training: too much of either risks overfitting.
%For modern deep learning, however it seems that more is (almost) always better. % TODO: reference other results like double descent?  Or probably that should come later...
In the largest scale regimes of modern deep learning, it seems that increasing the number of model parameters, amount of compute used for training, or training dataset size (almost) always yields better results. % TODO: reference other results like double descent?  Or probably that should come later...
In fact, scaling up deep learning seems to yield predictable performance improvements, which can be modeled using neural scaling laws.
Remarkably, the same simple functional form, a modified power law, applies equally well to data, parameters, and compute, the three axes along which scaling is measured.
%, provided that none of the three is a bottleneck (TODO: more details on that?). Ethan: It works fine even if bottlenecked.

Currently, the main practical value of neural scaling laws is in forecasting the performance of larger models and datasets without needing to train or collect them.  
Indeed, several works have shown that models that underperform at smaller scales can be predicted to reach state of the art performance at larger scales \citep{}, although such predictions have not always held up \citep{}.
However, it is difficult to translate predictions about performance metrics such as negative log likelihood into predictions about qualitative behaviors and capabilities.
For instance, \citet{GPT} famously document the emergence of in-context meta-learning in large-scale language models.
``Downstream'' performance, i.e.\ that which is measured on metrics other than the training loss, reveals striking discontinuities as a function of scale. % TODO: note that it's not all downstream, and discuss fine-tuning vs. 0-shot
Models suddenly go from near-chance level to state-of-the-art performance on tasks such as TODO once a critical scale is reached.

%TODO: say something more here about how we crush it 

Predicting the emergence of novel capabilities at scale could prove crucial to responsibly developing and deploying increasingly advanced AI systems. % TODO: say more, e.g. mention deception or something?
Doing so requires methods of identifying and measuring relevant capabilities, and scaling laws that can accurately forecast how these capabilities develop at scale. % of modelling their learning dynamics.
However, the functional forms of scaling laws applied in prior work are not up to this challenge.

One salient defect is that they can only represent monotonic functions.
They thus fail to model the striking phenomena of double-descent \citep{}, where increased scale temporarily decreases test performance before ultimately leading to further improvements. %, and grokking \citep{}, where test performance remains near chance levels 
They also lack the expressive power to model inflection points, which can be observed empirically for many downstream tasks, and even some upstream tasks, such as our $N$-digit arithmetic task, or the modular arithmetic task introduced by \citet{grokking} in their work on ``grokking''. 
%For this task, test performance remains near chance levels long after training accuracy has reached 100\% before eventually climbing towards 100\% as well on synthetic arithmetic tasks.
%, and grokking \citep{}, where test performance remains near chance levels long after training accuracy has reached 100\% before eventually climbing towards 100\% as well on synthetic arithmetic tasks.
%Such discontinuities can sometimes even be observed on the ``upstream'' test loss; for instance, we observe them in a simple $N$-digit arithmetic task.
%Another striking phenomena of modern deep learning that 

%also fail to fit the striking phenomena of double-descent \citep{}, where increased scale temporarily decreases test performance before ultimately leading to further improvements.%, and grokking \citep{}, where test performance remains near chance levels long after training accuracy has reached 100\% before eventually climbing towards 100\% as well on synthetic arithmetic tasks.
%Modelling, predicting, and ultimately understanding these phenomena will 
Our work presents a functional form capable of modeling all of these diverse behaviors, and empirically validates it's effectiveness in extrapolating scaling behavior.
%Besides the qualitative di
%TODO: last 2 sentences above are now a bit out of place...
TODO: say something more here about how we crush it (i.e. enumerate all the scaling data we fit).

%\fi

%TODO:  Say something like: "Sometimes the non-broken Scaling laws don't even work upstream when you have weird stuff like Grokking or double descent or unusual data sets like our N-digit addition".
\end{comment}




\iffalse
\subsection{old Introduction}


%\textbf{\texttt{http://icml.cc/}}
\todo[inline]{motivation: why scaling laws?}
%Machine learning involves optimizing an upstream training objective and evaluating downstream metric(s).

%The endgame of machine learning is going to involve training models with more parameters than the human brain on the entire internet. To make claims today about what machine learning methods will be most effective during the endgame, we must rely on forecasts because no organization currently has enough compute to run these future workloads empirically. The measurement that makes the most sense to forecast is downstream task performance scaling because TODO

One of the principal goals of deep learning research is to find a functional form that characterizes the relationship between performance and scale in all settings. Such a functional form would allow one to better predict that which scales best on all the evaluations that one cares about. TODO: Revisiting NSL had pretty good list of why to care about scaling laws. In pursuit of this goal, we present some key results.

%In this paper, we focus on the 190 downstream task scaling evaluations reported in the GPT-3 arXiv paper because it reports the downstream scaling information for the largest number of tasks of any paper we are aware of.

%The endgame of machine learning is going to involve training models with more parameters than the human brain on the entire internet. To make claims today about what machine learning methods will be most effective during the endgame, we must rely on forecasts because no organization currently has enough compute to run these future workloads empirically. The measurement that makes the most sense to forecast is downstream task performance scaling because TODO

%One of the principal goals of deep learning research is to find a single functional form that characterizes the relationship between performance and scale in all settings. In pursuit of this goal, we present some key results.  %% IR: a bit controversial statement about finding a single functional form as one of the principal goals of DL.

%In this paper, we focus on the 190 downstream task scaling evaluations reported in the GPT-3 arXiv paper because it reports the downstream scaling information for the largest number of tasks of any paper we are aware of.
%----
\fi

%\input{sec_bnsl_form}
\section{The Functional Form of Broken Neural Scaling Laws }
\label{section:bnsl}
\vspace{-0.05in}

\begin{figure*}[h]%tbp]
    \centering


%\includegraphics[width=0.7\textwidth]{figures/figure_1/figure_1.png}
\hspace*{-.04cm}\includegraphics[width=0.786\textwidth]{figures/figure_1/figure_1__wide.png}

    \caption{
    A Broken Neural Scaling Law (BNSL) (dark black solid line) with 3 breaks (where purple dotted lines intersect with dark black solid line) decomposed into the individual power laws (dashed lines that are yellow, blue, red, and green) that it is composed of overlaid on top of it. The 1st and 2nd break are very smooth; the 3rd break is very sharp. See Section \ref{section:bnsl} for more details. 
    }
    \label{fig:figure_1}
\end{figure*}

%\todo[inline]{TODO: Add figure 1 from \url{https://colab.research.google.com/drive/1V7PdLqRoiJGyNT0UBOq3_PuDxg2OJXv0}}

%\todo[inline]{maybe replace c and $g_i$ with $c_0$ and $c_i$ respectively}

The general functional form of a broken neural scaling law (BNSL) is given as follows:
%\begin{equation}
%y = \left(\frac{a}{x}\right)^b \left(1 + %\left(\frac{x}{c}\right)^d\right)^{-f} + g
%\label{eq:BNSL}
%\end{equation}
% \begin{equation}
% y = \left(\frac{a}{x}\right)^b \left(1 + \left(\frac{x}{c}\right)^d\right)^{-f} \left(1 + \left(\frac{x}{c}\right)^d\right)^{-f} + g
% \label{eq:BNSL}
% \end{equation}
%\todo[inline]{ How to best communicate that elements of equation 1 are added and removed based on number of breaks (see below)}
\begin{equation}
\vspace{-0.05in}
%y =  a + \left(\frac{b}{x}\right)^c \prod_{i=1}^n \left(1 + \left(\frac{x}{d_i}\right)^{f_i}\right)^{-g_i},
%original version
%y =  a + \bigg(bx^{-c}\bigg) \prod_{i=1}^n \left(1 + \left(\frac{x}{d_i}\right)^{f_i}\right)^{-g_i},
%y =  a + \bigg(bx^{-c}\bigg) \prod_{i=1}^n \left(1 + \left(\frac{x}{d_i}\right)^{1/f_i}\right)^{-g_i * f_i},
y =  a + \bigg(bx^{-c_0}\bigg) \prod_{i=1}^n \left(1 + \left(\frac{x}{d_i}\right)^{1/f_i}\right)^{-c_i * f_i},
%y =  a + \Big(bx^{-c}\Big) \prod_{i=1}^n \left(1 + \left(\frac{x}{d_i}\right)^{f_i}\right)^{-g_i},
\label{eq:BNSL}
%\vspace{-0.05in}
\end{equation}
\begin{comment}
\iffalse
When $a = 0$, applying logarithms to both sides yields:
\begin{equation}
\log (y) =  c \log (b) - c \log(x) -  \sum_{i=1}^n g_i \log\left(1 + \left(\frac{x}{d_i}\right)^{f_i}\right).
%\label{eq:BNSL}
\end{equation}
TODO: I (David) made the above to try and get more intuition on this.  I guess it's not actually piece-wise linear (hence the SMOOTHLY broken)?
\fi
\end{comment}
%\begin{equation}
%y =  a + b^{-c} \prod_{i=1}^n \left(1 + {d_i}{x}^{-f_i}\right)^{-g_i}
%\label{eq:BNSL}
%\end{equation}
%In equation \ref{eq:BNSL}, 
where $y$ represents the performance evaluation metric (e.g. prediction error, cross entropy, BLEU score percentage, F1 score percentage, reward, Elo rating, or FID score) (downstream or upstream) and $x$ represents a quantity that is being scaled (e.g. number of model parameters, amount of compute used for training, training dataset size, or upstream performance). The remaining  parameters %variables 
%$a, b, c, d_1 ...  d_n, f_1 ... f_n, g_1 ... g_n$
$a, b, c_0, c_1 ... c_n, d_1 ...  d_n, f_1 ... f_n$
are unknown constants that must be estimated by fitting the above functional form to the $(x,y)$ data points. (In our experiments,  SciPy curve-fitting library \citep{virtanen2020scipy} was used.) 
%are all constants that are fit via curve fitting libraries such as SciPy \cite{virtanen2020scipy}.

\iffalse
When $a = 0$, applying logarithms to both sides yields:
\begin{equation}
\log (y) =  c \log (b) - c \log(x) -  \sum_{i=1}^n g_i \log\left(1 + \left(\frac{x}{d_i}\right)^{f_i}\right).
%\label{eq:BNSL}
\end{equation}
TODO: I (David) made the above to try and get more intuition on this.  I guess it's not actually piece-wise linear (hence the SMOOTHLY broken)?
\fi

The constants in equation \ref{eq:BNSL} are interpreted as follows. Constant $n$ represents the number of (smooth) ``breaks" (i.e. transitions) between $n+1$ consecutive approximately linear (on a log-log plot) segments, for a total of $n+1$  approximately linear segments (on a log-log plot). 
%Namely, this function is approximately piece-wise linear, since the  transitions between the linear segment are smoothly interpolated, unlike the non-smooth break points in  standard piece-wise linear functions.  
%A ``break" is defined as a transition between an interval that forms a straight line on a log-log plot and another interval that forms a straight line on a log-log plot.
%The graph of this function (in a log-log plot) is not exactly piece-wise linear; instead, it smoothly interpolates between the different approximately linear regions. 
%\todo{why is that good? possible answer: intuitively, any  smooth function (in log-log) can be approximated by a piece-wise linear function with a sufficient number of smoothly connected segments - the challenge is to find how many are needed.}
%Most of our experiments use $n=1$, but we also show that 
%TODO: explain that there are varying number of variables $d_i, f_i, g_i$ depending on the number of breaks in the functional form.
Constant $a$ represents the limit as to how far the value of $y$ (performance evaluation metric) can be reduced (or maximized) even if $x$ (the quantity being scaled) goes to infinity. Constant $b$ represents the offset of functional form on a log-log plot (analogous to the intercept $b$ in $y=mx+b$ on a linear-linear plot). Constant $c_0$ represents the slope of the first approximately linear region on a log-log plot. Constant $c_i$ represents the difference in slope of the $(i)$th approximately linear region and $(i+1)$th approximately linear region on a log-log plot. Constant $d_i$ represents where on the x-axis the break between the $(i)$th and the $(i+1)$th approximately linear region (on a log-log plot) occurs. %Constant $f_i$ represents the slope of the $(i+1)$th linear region on a log-log plot. Constant $g_i$ represents the sharpness of break between the $(i)$th and the $(i+1)$th linear region on a log-log plot.
Constant $f_i$ represents the sharpness of break between the $(i)$th and the $(i+1)$th approximately linear region on a log-log plot; smaller (nonnegative) values of $f_i$ yield a sharper break and intervals (before and after the $(i)$th break) that are more linear on a log-log plot; larger values of $f_i$ yield a smoother break and intervals (before and after the $(i)$th break) that are less linear on a log-log plot.

Note that, while an intuition for using such  approximately piece-wise linear (in log-log plot) function was that, with enough segments, it could fit well any smooth univariate scaling function, it remained unclear whether BNSL would also {\em extrapolate} well; as we demonstrate below,  it does extrapolate quite accurately in all our experiments. Additionally, we find that the number of breaks needed to accurately model an entire scaling behavior is often quite small.

%TODO: note that equation \ref{eq:BNSL} works fine for upstream scaling too; we just name paper downstream scaling to emphasize the scenarios (i.e. downstream scaling) in which all its terms become necessary.

%\be
%\label{eq:PowerLawPlusConstant}
%L(x) = L_\infty + \left( \frac{x_0}{x}  \right)^{\alpha_x} 
%\ee

% \todo[inline]{this paragraph goes elsewhere} 
% We show mathematically and empirically that previous functional forms are unable to express inflection points, and we show mathematically and empirically that our functional form is able to express inflection points.



%We show that the functional form $y=a+(b/(x+c))^d$ (equation 1) very accurately fits 75\% of downstream tasks from the GPT-3 arXiv paper.


%When the best fit of equation 1 converges to values of d much larger than 1, the functional form equation 1 seems to not be sufficient and will probably need to be replaced with a new functional form.

%We find that the functional form $y=a+(b/((1+h)^x+c))^d$ (equation 2) is capable of fitting a subset of the downstream tasks (the downstream tasks for which equation 1 converges to values of d much larger than 1). However, equation 2 is much harder to fit due to small changes in h drastically changing y.


\iffalse
\begin{figure*}[t!]
\centering
\includegraphics[width=1.0\columnwidth]{figures/inflection_points/Two_Digit_Addition_Zero-Shot_Zoom.png}
\includegraphics[width=1.0\columnwidth]{figures/inflection_points/Two_Digit_Addition_Zero-Shot.png}
\caption{
Black points are test errors at various model sizes (numbers of parameters). Red line is functional form from equation \ref{eq:BNSL} fit to the black points. Left figure is zoomed in version of right figure. Task is Downstream Two Digit Addition (Zero-Shot) from \citet{brown2020language}. %\citet{2020arXiv200514165B}. 
All plots axes are \textbf{linear-linear} (not log-log).
}
\label{fig:Inflection_Point_example}
\end{figure*}
\fi


\iffalse
Our downstream forecasts show that an infinitely large (simultaneously infinitely deep and infinitely wide) GPT trained using the same 300 billion tokens as GPT-3 does not surpass human performance on any downstream task when using the few-shot in-context learning methodology from GPT-3 paper.
The one exception is fake news generation, for which our downstream forecast shows that humans would rate news articles generated by the model to be better than human written news articles 54.37\% of the time.

We perform ablations on the number of points and supremum of the points used for the fitting the scaling law functional form. These ablations provide some intuitions for how much to trust our forecasts.
\fi


%\input{sec_related}
\section{Related Work}
To the best of our knowledge, \citet{cortes1994learning} was the first paper to model the scaling of multilayer neural network's performance as a power law (also known as a scaling law) (plus a constant)
%(also known as a scaling law) (plus a constant) \ir{[I would delete both those phrases in ()] } 
of the form $y=ax^b + c$ in which $x$ refers to training dataset size and $y$ refers to test error.
\citet{2017arXiv171200409H} showed that this functional form holds over many orders of magnitude. \citet{DBLP:journals/corr/abs-1909-12673} demonstrated  that the same functional form applies when $x$ refers to model size (number of parameters). \citet{icm2020arXiv200108361K} brought ``neural" scaling laws to the mainstream and showed that there is an additional scaling law with respect to compute. \citet{DBLP:journals/corr/abs-2106-04560} introduced the functional form $y=a(x+d)^b + c$, where  d represents the scale at which the performance starts to improve beyond the  random guess loss (a constant) and transitions to a  power law scaling regime. \citet{abnar2021exploring} proposed a functional form that relates downstream performance to upstream performance. \citet{Alabdulmohsi2022revisiting} proposed functional form $(y - \epsilon_{\infty}) / ((\epsilon_{0} - y)^a) = bx^c$, where  $\epsilon_{\infty}$ is irreducible entropy of the data distribution and $\epsilon_{0}$ is random guess performance, for relating scale to performance and released a scaling laws benchmark dataset that we use in our experiments. %in section 

%\todo[inline]{NEED TO TALK ABOUT HOW EQUATION 6.1 OF SCALING LAWS FOR TRANSFER (plus a trivial constant for irreducible entropy) IS MATHEMATICALLY EQUIVALENT TO BNSL}

%\citet{2021arXiv210201293H}  - this has full list of authors/too long/not the format used in biblio for a conference
%\citet{brown2020language}
\citet{2021arXiv210201293H} described a smoothly broken power law functional form (consisting of 5 constants after reducing redundant variables) in equation 6.1 of their paper, when relating scale and downstream performance. 
While that form is mathematically equivalent to our BNSL with a single break, it is important to note that (i) \citet{2021arXiv210201293H}  uses this form  only in the specific context, when exploring how  fine-tuning combined with transfer learning scales as a function of the model size - thus, their functional form contains a break only with respect to the number of model parameters but not with respect to the dataset size (which we do explore); (ii) \citet{2021arXiv210201293H} only mentioned this equation in passing, without trying to fit this functional form to any data; (iii) they arrived at it simply via combining the scaling law for transfer (that was the focus of their work) with a scaling law for pretraining data; (iv) they did not identify it as a smoothly broken power law, or note any qualitative advantages of this functional form; (v) they did not discuss the family of functional forms with multiple breaks. 

Finally, we would like to mention that smoothly broken power law functional forms, equivalent to equation \ref{eq:BNSL}, are commonly used in the astrophysics literature (e.g. \cite{dampe2017direct}) as they happen  to  model well a variety of physical phenomena. %This inspired us to investigate their applicability to a wide range of deep neural scaling phenomena as well.

%but to the best of our knowledge have never been mentioned or utilized in any literature that involves artificial neural networks.


%TODO: Maybe mention "Limits of Large-Scale Training" Function
%TODO: mention that \citet{DBLP:journals/corr/abs-1909-12673} attempts to model transition from random guessing to power law
%TODO: explain why a,b,c,d are all non-negative.


%\input{sec_theory}

%\FloatBarrier
%\begin{tiny}



%Figure \ref{fig:Inflection_Point_example} is an example of this inflection point present in experimental data from a real world downstream task, Two Digit Addition (Zero-Shot) from \citet{brown2020language}. %\citet{2020arXiv200514165B}. 
%In the small scale regime, the function is concave downward as it transitions from random guessing performance to starting to learn the task. As the scale increases past the small scale regime, an inflection point is reached and the function becomes concave upward as power law scaling behaviour takes over.



% % M3: (need d>0) 
% M3: $f(x) = a(x^{-1} + d)^{-b} + c$ 
% $$
%  f'(x) = \frac{a b }{x (1 + d x)(d + 1/x)^{b}} 
% $$
% $$
%  f''(x) = a b x^{(b-2)} (1 + d x)^{(-2 - b)} (b -1 - 2 d x) 
% $$
% The above expression does not have a root for $a,b,d,x>0; b < 1$: the first two terms are strictly positive, meaning we would need $b = 2dx + 1 \geq 1$.

% "also M3?": $f(x)=a(x+d)^b + c$
% $$
% f'(x) = a b (d + x)^{(b-1)}
% $$
% $$
% f''(x) = a (-1 + b) b (d + x)^{(b-2)}
% $$
% Neither of the above expressions have roots because they are a product of non-zero constants and expressions of the form $m^n$.


%M2: $y = ax^b +c$


% \subsection{SCRAPS}

% % TODO: convert this to same form as M2
% \begin{proposition}
%     Functions of the form $f(x) = a + \left(\frac{b}{x}\right)^c$ are necessarily monotonic for $a,b,c>0$ in the range $x>0$.
% \end{proposition}
% \begin{proof}
%     A sufficient condition for monotonicity is that $f'(x)$ does not change sign.  
%     In our case, we have 
%     $$
%     f'(x) = - bc \left(\frac{b}{x}\right)^{(c-1)}.
%     $$
%     Since $b$ and $x$ are both positive, so is the ratio $\frac{b}{x}$.  
%     And since a positive number taken to any power is also positive, the entire expression is guaranteed to be negative for all values of $a,b,c,x>0$.
% \end{proof}

% %TODO: rename this section to "Math Proofs" and also prove that other functional forms can't express non-monotonic behavior

% \begin{proposition}
%     Functions of the form $f(x) = a + \left(\frac{b}{x}\right)^c$ cannot contain an inflection point for $a,b,c>0$ in the range $x>0$.
% \end{proposition}
% \begin{proof}
% The second derivative is:
% $$
% f''(x) = 
% \frac{(c (1 + c) (b/x)^c)}{x^2}.
% $$
% Since $b$, $c$ and $x$ are all positive, all of the multiplicands of $f''(x)$ are positive, and thus so is $f''(x)$, but an inflection point must have $f''(x)=0$.
% \end{proof}

% \subsection{SCRAPS}

% An inflection point is a point of a curve at which the second order derivative (i.e.\ curvature) changes signs. 
% Empirically, the function relating the performance evaluation metric (e.g. prediction error) to the quantity being scaled (e.g.\ model size) often has an inflection point. 
% Figure \ref{fig:Inflection_Point_example} is an example of this inflection point present in experimental data from a real world downstream task, Two Digit Addition (Zero-Shot) from \citet{brown2020language}. %\citet{2020arXiv200514165B}. 
% In the small scale regime, the function is concave downward as it transitions from random guessing performance to starting to learn the task. 
% As the scale increases past the small scale regime, an inflection point is reached and the function becomes concave upward as power law scaling behaviour takes over.

% However, \textbf{Proposition:} typical functional form cannot have an inflection point.
% \textbf{Proof:}
% %https://www.wolframalpha.com/input?i=d%5E2%2Fdx%5E2+%28a+%2B+%28b%2Fx%29**c%29+
% An inflection point is a point of a curve at which the second order derivative (i.e.\ curvature) changes signs. 
% The second derivative of this function is:
% $$
% f''(x) = 
% \frac{(c (1 + c) (b/x)^c)}{x^2}.
% $$
% Since $b$, $c$ and $x$ are all positive, all of the multiplicands of $f''(x)$ are positive, and thus so is $f''(x)$, but an inflection point must have $f''(x)=0$.
% % https://www.wolframalpha.com/input?i=d%5E2%2Fdx%5E2+%28a+%2B+%28b%2Fx%29**c+%281+%2F+%28x%2Bd%29%5Ef%29%29

% Note that inflection points often appear in scaling curves, which are typically plotted on log/log axes, and existing scaling laws can fit those inflection points (TODO: is this right?  I thought they were just linear on a log/log plot?).
% Inflection points are less common but still sometimes present in a linear/linear plot; These are the inflection points that existing scaling laws cannot capture.

% TODO: do we get the same result for all of M1 through M4?

% All the functional forms:

% M1: $y = ax^b$

% M2: $y = ax^b +c$

% M3: $y = a(x^{-1} + d)^{-b} + c$ 

% also M3?: $y=a(x+d)^b + c$

% M4: $(y - \epsilon_{\infty}) / ((\epsilon_{0} - y)^a) = bx$ 

% $\epsilon_{\infty}$ is irreducible loss, and $\epsilon_{0}$ is performance of random guessing.

% Equation 6.1 of "scaling laws for transfer" paper: $y = (ax^b + cx^d)^f + g$

% I (Ethan) just now have realized that this equation 6.1 above is a smoothly broken power law (i.e. mathematically equivalent to ours I think) too so we have to change the narrative of the paper now:  
% \url{https://math.stackexchange.com/a/2427151}

% \url{https://colab.research.google.com/drive/1QP81soNf1DDV_Q6iimN8sb-hZHaZeMyW}

% Also, I think "scaling laws for transfer" paper may/might have been unaware that its equation 6.1 is a thing called a smoothly broken power law.

% Broken Neural Scaling Law: $y =  a + \left(\frac{b}{x}\right)^c \prod_{i=1}^n \left(1 + \left(\frac{x}{d_i}\right)^{f_i}\right)^{-g_i}$



% TODO: remove this section?
% TODO: replace it with section about breaks rather than inflection points


%This inflection point at the transition from constant random guessing performance in the small scale regime to 
%When the performance evaluation metric (e.g. prediction error) is plotted on y-axis and the quantity being scaled (e.g. model size) is plotted on x-axis, the plotted data has an inflection point at the transition from constant random guessing performance in the small scale regime to 
% Figure \ref{fig:Inflection_Point_example} is an example of this inflection point present in experimental data from a real world downstream task, Two Digit Addition (Zero-Shot) from \citet{brown2020language}. %\citet{2020arXiv200514165B}. 
%In the small scale regime, the function is concave downward as it transitions from random guessing performance to starting to learn the task. As the scale increases past the small scale regime, an inflection point is reached and the function becomes concave upward as power law scaling behaviour takes over.

% \todo[inline]{math proofs}

% 1. proof that shows $y=a/(x^b+d)+c$ has inflection point for all functions in which $a$ $!=0$, $b>1$, and $d>0$ are simultaneously true

% 2. proof that shows $y=a(x+d)^b + c$ never has inflection point


%\input{sec_experiments}
\section{Empirical Results: Fits and Extrapolations of Functional Forms}

\label{section:functional_form_fits}

We now show the fits and/or extrapolations of various functional forms. In all plots here and in the quite large appendix, black points are points used for fitting a functional form, green points are held-out points used for evaluating extrapolation of a functional form fit to the black points, and a red line is BNSL that has been fit to the black points. All the extrapolation evaluations reported in the tables are reported in terms of root mean squared log error (RMSLE\footnote{RMSLE = $ \sqrt{(\sum_{i=1}^{n} (log(y_{i})-log(\hat{y}_{i}))^2)/n}$}) ± root standard log error. See Appendix \ref{section:definition_of_Root_Standard_Log_Error} for definition of root standard log error. Unless stated otherwise, every BNSL we fit only has one break. Please refer to Appendix Section \ref{section:BNSL_fit_details} for further experimental details on fitting BNSL. All non-math task results (e.g. vision, language, rl, and double descent) are in the appendix.

%In the tables and elsewhere, 
%\begin{itemize}
%    \item M1 refers to functional form $y = ax^b$
%    \item M2 refers to functional form $y = ax^b +c$
%    \item M3 refers to functional form $y = a(x^{-1} %+ d)^{-b} + c$
%    \item M4 refers to functional form $(y - %\epsilon_{\infty}) / ((\epsilon_{0} - y)^a) = bx^c$
%\end{itemize}

In the tables and elsewhere, 
M1 refers to functional form $y = ax^b$,
M2 refers to functional form $y = ax^b +c$,
M3 refers to functional form $y = a(x^{-1} + d)^{-b} + c$, and
M4 refers to functional form $(y - \epsilon_{\infty}) / ((\epsilon_{0} - y)^a) = bx^c$ .


%All the extrapolation evaluations reported in the tables are reported in terms of root mean squared log error (RMSLE\footnote{RMSLE = $ \sqrt{(\sum_{i=1}^{n} (log(y_{i})-log(\hat{y}_{i}))^2)/n}$}) ± root standard log error. See Appendix \ref{section:definition_of_Root_Standard_Log_Error} for definition of root standard log error.


% \end{center}

\FloatBarrier

\subsection{Table summarizing results on large-scale scaling laws benchmark of \cite{Alabdulmohsi2022revisiting}}
\label{section:scaling_benchmark__summary}

\FloatBarrier

% \begin{center}

% \begin{center}
\begin{table}[hbt!]
    \centering
    \begin{tabular}{ |cH|c|c|c|c|c| } 
\hline
Domain & \hspace{.9cm}Task & M1 $\uparrow$ & M2 $\uparrow$ & M3 $\uparrow$ & M4 $\uparrow$ & BNSL $\uparrow$ \\
 \hline
 %IC & Birds 200 & 0 & 0 & 0 & 5.56 & \highlight{94.44}\\ 
 %IC & Caltech101 & 0 & 0 & 5.56 & 5.56 & \highlight{88.89}\\ 
 %IC & CIFAR-100 & 0 & 5.56 & 5.56 & 5.56 & \highlight{83.33}\\
 %IC & ImageNet & 0 & 0 & 11.11 & 0 & \highlight{88.89}\\
 
 %version where Ibrahim had error %Downstream Image Classification & All & 0\% & 1.39\% & 5.56\% & 4.17\% & \bfseries 88.89\%\\
 %Downstream Image Classification & All & 0\% & 1.39\% & 5.56\% & 1.39\% & \bfseries 91.67\%\\
 Downstream Image Classification & All & 2.78\% & 5.56\% & 13.89\% & 13.89\% & \bfseries 63.89\%\\
 %version where Ibrahim had error %Language & All & 5\% & 10\% & 15\% & 25\% & \bfseries 45\%\\
 %Language & All & 5\% & 10\% & 15\% & 5\% & \bfseries 65\%\\
 %Language & All & 10\% & 10\% & 25\% & 20\% & \bfseries 35\%\\
 Language & All & 10\% & 10\% & 25\% & 0\% & \bfseries 55\%\\
 \hline
\end{tabular}
    \caption{
    Percentage of tasks by domain where each functional form is the best for extrapolation of scaling behavior. Numbers for M1, M2, M3, and M4 were obtained via correspondence with authors of \cite{Alabdulmohsi2022revisiting}. See Sections \ref{section:scaling_benchmark__vision} and \ref{section:scaling_benchmark__language} for more details.
    }
    \label{table:scaling_laws_benchmark_dataset__summary}
\end{table}
% \end{center}

\FloatBarrier


\subsection{Inflection Points}
\label{section:Inflection_Points}

We show that BNSL is capable of modeling and extrapolating the scaling behavior of tasks that have an inflection point on a linear-linear plot such as the task of arithmetic (4-digit addition). Here we model and extrapolate the scaling behavior of a transformer model (\cite{vaswani2017attention}) with respect to the dataset size on the 4-digit addition task. Other functional forms are mathematically incapable of expressing inflection points on a linear-linear plot (as shown in Section \ref{section:math_proofs}) and as a result, are mathematically incapable of expressing and modeling inflection points (on a linear-linear plot) that are present in the scaling behavior of 4-digit addition. In Figure \ref{fig:arithmetic} left, we show that BNSL expresses and accurately models the inflection point present in the scaling behavior of 4-digit addition and as a result accurately extrapolates the scaling behavior of 4 digit addition. For further details about the hyperparameters please refer to the Appendix Section \ref{section:Inflection_points_experimental}. Fit of M3 to 4-digit addition task is also available in Figure \ref{fig:M3_addition_failure} of the Appendix for comparison purposes. We also show a fit of BNSL to Large-Scale BIG-Bench \cite{srivastava2022beyond} 3-shot arithmetic task with number of parameters on the x-axis in Figure \ref{fig:arithmetic_big_bench} in Appendix \ref{figure:arithmetic_big_bench}.

%\FloatBarrier
\begin{figure*}[htbp]
    \centering


\includegraphics[width=0.48\textwidth]{figures/arithmetic/4_digit_addition__dataset_size.png}
%\includegraphics[width=0.48\textwidth]{figures/arithmetic/4_digit_addition__dataset_size__very_first_version.png}
\includegraphics[width=0.48\textwidth]{figures/arithmetic/4_digit_addition__dataset_size__very_first_version__simulation_limit.png}

    \caption{
    4 Digit Addition. Note that these plots are linear-linear. Each point in the left plot is the mean of greater than 1000 seeds at that dataset size. In the left plot, each point is gathered from a model trained to do the task of 4-digit addition. In the right plot, each point is gathered from a noiseless simulation of the BNSL of the task of 4-digit addition.
    }
    \label{fig:arithmetic}
\end{figure*}

%\FloatBarrier

\subsection{The Limit of the Predictability of Scaling Behavior}
\label{section:limit_of_agi_superforecasting}
We use BNSL to glean insights about the limit of the predictability of scaling behavior. Recent papers \citep{ganguli2022predictability, wei2022emergent} have advertised many tasks as having ``unpredictable" scaling behavior, the most famous of which is the task of arithmetic. In the previous section and in Figure \ref{fig:arithmetic} left, we successfully predicted (i.e. extrapolated) the scaling behavior of 4-digit addition (arithmetic). However, we are only able to accurately extrapolate the scaling behavior if given some points from training runs with a training dataset size of at least 720, and the break in which the scaling behavior of 4-digit addition transitions from one power law to another steeper power-law happens at around training dataset size of 415. Ideally, one would like to be able to extrapolate the entire scaling behavior by fitting only points from before the break. In Figure \ref{fig:arithmetic} right, we use a noiseless simulation of the BNSL of 4-digit addition to show what would happen if one had infinitely many training runs / seeds to average out all the noisy deviation between runs such that one could recover (i.e. learn via a curve-fitting library such as SciPy \cite{virtanen2020scipy}) the learned constant of the BNSL as well as possible. When using this noiseless simulation, we find that we are only able to accurately extrapolate the scaling behavior if given some points from training runs with a training dataset size of at least 415, which is very close to the break. This implies that very near to the break there is limit as to how small the supremum of the x-axis of the points used for fitting can be if one wants to perfectly extrapolate the scaling behavior, even if one has infinitely many seeds / training runs. 
%TODO: Mention it is a one break-point simulation. Mention how the simulation is done.

%\subsection{BIG Bench Emergent}
%Probably will just finish it for rebuttals


%\input{sec_conclusions}
\section{Conclusions}
We have presented a smoothly broken power law functional form that accurately models the scaling behaviors of artificial neural networks for each task from a very large and diverse set of upstream and downstream tasks. These tasks include large-scale vision tasks, large-scale unsupervised language tasks, arithmetic, and reinforcement learning. This functional form yields extrapolations of scaling behavior that often are an order of magnitude more accurate than other functional forms for modeling the scaling behavior of artificial neural networks. Additionally, this functional form accurately models many scaling behaviors that other functional forms are mathematically incapable of expressing such as non-monotonic transitions present in the scaling behavior of phenomena such as double descent and delayed, sharp inflection points present in the scaling behavior of tasks such as arithmetic. Finally, we used this functional form to obtain insights about the limit of the predictability of scaling behavior.
%\noindent{\bf Limitations.} A limitation of the current approach is the potential need to collect enough samples of the system's performance (i.e. the (x,y) points required for estimating the scaling laws parameters). A small number of samples may not be sufficient to accurately fit and extrapolate the BNSL functional form, and obtaining a large number of such samples can sometimes be costly.
%\noindent{\bf Limitations.} Among the most significant limitations of the current approach is the potential need for an effective algorithm that allows to collect enough samples of system's performance (i.e. the (x,y) points required for estimating the scaling laws parameters). A small number of samples may not be sufficient to accurately fit and extrapolate the BNSL functional form, but obtaining a large number of such samples can sometimes be costly. %Thus, we need to develop an algorithm for finding cost-efficient sampling trade-off. This is one of the immediate next steps in our future work plans.
%\noindent{\bf Ethical considerations.} An ethical concern one might have about our work is that revealing BNSL might differentially \citep{hendrycks2022x} improve AI capabilities progress relative to AI safety/alignment progress. 
%A counter-argument is that BNSL will also allow the AI safety/alignment field to extrapolate the scaling behaviors of its methods for aligning AI system and as a result will also accelerate alignment/safety progress.

Existing scaling laws besides BNSL struggle especially to model downstream performance, e.g.\ on safety-relevant evaluations; we believe our work could differentially \citep{hendrycks2022x} help in forecasting emergence of novel capabilities (such as reasoning \citep{wei2022chain} ) or behaviors (such as deception or dishonesty \citep{evans2021truthful,lin2021truthfulqa}), and thus help avoid unpleasant surprises.

%\noindent{\bf Future work.}

\newpage

%\subsubsection*{Author Contributions}
%If you'd like to, you may include  a section for author contributions as is done in many journals. This is optional and at the discretion of the authors.

%\subsubsection*{Acknowledgments}
%Use unnumbered third level headings for the acknowledgments. All acknowledgments, including those to funding agencies, go at the end of the paper.

\bibliographystyle{apalike}
%\bibliography{iclr2023/iclr2023_conference.bib}
\bibliography{iclr2023_conference.bib}
%\bibliography{main}
%\usepackage[style=apa,sorting=nyt,natbib=true]{biblatex}
%\addbibresource{iclr2023_conference.bib}
%\bibliographystyle{iclr2023_conference}

% This pushes the appendix to next page
\clearpage 
\appendix
%\input{sec_appendix}
\section{Appendix}

\section{Theoretical Limitations of Previously Proposed Scaling Laws}
\label{section:math_proofs}

%\todo[inline]{I'm not sure it's worth including any propositions in the main text.  The proofs are just basic calculus and algebra.}

%\todo[inline]{This is for M2.  Need to do M3 (and maybe M4) case as well.  Also need to know which one(s) to consider "standard" for framing.}

Our use of BNSLs is inspired by the observation that scaling is not always well predicted by a simple power law;
nor are many of the modifications which have been applied in previous works sufficient to capture the qualitative properties of empirical scaling curves.  
% In effect, the most sophisticated form common in previous work is a power law modified to incorporate a minimum achievable loss, representing irreducible entropy, and TODO.
Here we show mathematically two qualitative defects of these functional forms:
\begin{enumerate}
    \item They are strictly monotonic (first-order derivative does not change its sign) and thus unable to fit double descent phenomena.
    \item They cannot express inflection points (second-order derivative does not change its sign), which are frequently observed empirically.  An exception to this is M4, proposed by \citet{Alabdulmohsi2022revisiting}. %, which can model a single inflection point.
\end{enumerate}
Note that these functional forms \textit{can} exhibit inflection points on the log-log axes which are commonly used for plotting scaling data (as it was observed in several prior works).
However, for inflection points on a \textit{linear-linear} plot, the extra expressiveness of broken neural scaling laws appears to be necessary (and sufficient).
Figure~\ref{fig:double_descent} and Figure~\ref{fig:arithmetic}, provide examples of BNSLs producing non-monotonic behavior and inflection points, respectively, establishing the capacity of this functional form to model these phenomena that occur in real scaling behavior.

\begin{table}[h]
\centering
\footnotesize
\begin{tabular}{c|c|c|c}
name & $f(x)$ & $f'(x)$ & $f''(x)$ \\
\midrule
M1  & $ax^b$ & $abx^{b-1}$ & $ab(b-1)x^{b-2}$ \\
\midrule
M2  & $ax^b + c$ & $abx^{b-1}$ & $ab(b-1)x^{b-2}$ \\
%M2  & $f(x)$ & $f'(x)$ & $\frac{(c (1 + c) (b/x)^c)}{x^2}$ \\
\midrule
M3  & $a(x^{-1} + d)^{-b} + c$  & 
$\frac{a b }{x (1 + d x)(d + 1/x)^{b}}$  & $a b x^{(b-2)} (1 + d x)^{(-2 - b)} (b -1 - 2 d x) $ \\
%$~~f(x) = g^{-1}(x)$  &   & & \\ 
%$x:=g(y)$
% \midrule
% M3' & $f(x)$ & $f'(x)$ & $f''(x)$ \\
%\midrule
%M4 &  $(y - \epsilon_{\infty}) / ((\epsilon_{0} - y)^a) = bx$ &  $f'(x)$ & $f''(x)$ \\
% M3' & $f(x)$ & $f'(x)$ & $f''(x)$ \\
%The above expression does not have a root for $a,b,d,x>0; b < 1$: the first two terms are strictly positive, meaning we would need $b = 2dx + 1 \geq 1$.
\end{tabular}
\caption{
    Previously proposed functional forms M1, M2, M3 and their (first and second order) derivatives.  See Equation~\ref{eqn:M4} for M4.
    %For $d,x>0$, $b<0$, the expressions for each of the derivatives is a product of non-zero multiplicands, and thus none of these functional forms can express functions that are non-monotonic or have inflection points.
    %The above expression does not have a root for $a,b,d,x>0; b < 1$: the first two terms are strictly positive, meaning we would need $b = 2dx + 1 \geq 1$.
 }
\label{tab:math}
\end{table}


% \begin{table}[h]
% \centering
% \footnotesize
% \begin{tabular}{c|c|c|c}
% \midrule
% $f(x) = g^{-1}(x)$ & $g(y)$ & $g'(y)$ & $g''(y)$ \\
% \midrule
% M4  & $\frac{1}{b}\big(\frac{y - \epsilon_{\infty}}{(\epsilon_{0} - y)^a}\big)^{1/c}$ &  
% $\frac{((\epsilon_0 - y)^{-a} + a (\epsilon_0 - y)^{-1 - a} (y - \epsilon_{\infty})) ((\epsilon_0 - y)^{-a} (y - \epsilon_{\infty}))^{1/c - 1})}{b c}$ &  \\
% %$\frac{-a (y - \epsilon_{0})^{(-a - 2)} (\epsilon_{\infty} + a \epsilon_{\infty} - 2 \epsilon_{0} + y - a y)}{b}$ \\
% \end{tabular}
% \caption{
%     Previously proposed functional forms and their (first and second order) derivatives.  
%     %For $d,x>0$, $b<0$, the expressions for each of the derivatives is a product of non-zero multiplicands, and thus none of these functional forms can express functions that are non-monotonic or have inflection points.
%     %The above expression does not have a root for $a,b,d,x>0; b < 1$: the first two terms are strictly positive, meaning we would need $b = 2dx + 1 \geq 1$.
%  }
% \label{tab:math}
% \end{table}
%\end{tiny}
%\FloatBarrier

%\todo[inline]{TODO: fix claims of this section; and make sure claims everywhere in paper agree with claims here}

\noindent{\bf M1, M2, M3 functional forms cannot model non-monotonic behavior or inflection points:}  %We now explain why standard functional forms are incapable of exhibiting either behavior.
First, recall that expressions of the form $m^n$ can only take the value $0$ if $m=0$. 
We now examine the expressions for the first and second derivatives of M1, M2, M3, %M3',
provided in Table~\ref{tab:math}, and observe that they are all continuous and do not have roots over the relevant ranges of their variables, i.e.\ $x>0$ in general and $b<0$ in the case of M3 
%(we require $x > 0$ because the scaling variable (such as model size, dataset size, or amount of compute used) is always non-negative).
(we require $x > 0$ because model size, dataset size, and compute are always non-negative).
This implies that, for any valid settings of the parameters $a,b,c,d,x$, these functional forms are monotonic (as the first derivative never changes sign), and that they lack inflection points (since an inflection point must have $f''(x)=0$).

\noindent{\bf M4 functional form cannot model non-monotonic behavior.}  %We now 
The case of M4 is a bit different, since the relationship between $y$ and $x$ in this case is expressed as an inverse function, i.e.
\begin{align}
\label{eqn:M4}
x = g(y) = \left(\frac{y - \epsilon_{\infty}} {b(\epsilon_{0} - y)^a}\right)^{1/c}
\end{align}
However, non-monotonicity of $y$ as an inverse function $y = g^{-1}(x)$ is ruled out, since that would imply two different values of $x=g(y)$ can be obtained for the single value of $y$ -- this is impossible, since $f(y)$ maps each $y$ deterministically to a single value of $x$. As a result, M4 cannot express non-monotonic functions.
%As to the possibility of modeling an inflection point, we were yet not able to determine whether M4 has this capability or not.
%$a, b,c,e_0,e_{inf} = 1, 1, -2, .75, .25.$

\noindent{\bf M4 functional form can model inflection points.}  %We now 
%M4 is capable of expressive inflection points, however. 
It is easy to see that if $y=g^{-1}(x)$ had an inflection point, then $x = g(y)$ would have it as well. This is because an inflection point is defined as a point $x$ where $f(x)$ changes from concave to convex, which implies that $g(y)$ changes from convex to concave, since the inverse of a convex function is concave; the root(s) of $g''(y)$ are the point(s) at which this change occurs.
Using Wolfram Alpha\footnote{\href{https://www.wolframalpha.com/}{https://www.wolframalpha.com/}} and matplotlib \citep{Hunter:2007}, we observe that M4 is able to express inflection points, e.g.\ $(a,b,c,\epsilon_0, \epsilon_{\infty}, x, y) = (1,1,-2,3/4,1/4,1/\sqrt3, 5/8$), or $(a,b,c,\epsilon_0, \epsilon_{\infty}, x, y) = (2,1,-3,2/3,1/3,(-5/6 + \sqrt3/2)^{1/3}, 1/\sqrt3)$. % TODO: double check these (ideally someone else does that, to be extra sure)



% meaning M4 is capable of expressing an inflection point.
% Note also that when $a=1$, we can solve for M4 for $y$ in closed form, yielding the expression $y = \frac{h + j(bx)^c} {1 + (bx)^c}$.

%For $g''(y)$ to have a root we would need $y = (1-a) ((1+a)\epsilon_\infty - 2 \epsilon_0) =0 $; This can be achieved for $a=2, \epsilon_\infty=2/3, \epsilon_0=1$. 


% but this is impossible because we have $0 <\epsilon_\infty \leq \epsilon_0  < 1$ and $0<a<1$.
%However, it is easy to show via simple algebraic computation that  second derivative $g''(y)$ never equals zero, thus ruling out the possibility of inflection points with this functional form as well.

%\FloatBarrier
%\begin{tiny}



%Figure \ref{fig:Inflection_Point_example} is an example of this inflection point present in experimental data from a real world downstream task, Two Digit Addition (Zero-Shot) from \citet{brown2020language}. %\citet{2020arXiv200514165B}. 
%In the small scale regime, the function is concave downward as it transitions from random guessing performance to starting to learn the task. As the scale increases past the small scale regime, an inflection point is reached and the function becomes concave upward as power law scaling behaviour takes over.



% % M3: (need d>0) 
% M3: $f(x) = a(x^{-1} + d)^{-b} + c$ 
% $$
%  f'(x) = \frac{a b }{x (1 + d x)(d + 1/x)^{b}} 
% $$
% $$
%  f''(x) = a b x^{(b-2)} (1 + d x)^{(-2 - b)} (b -1 - 2 d x) 
% $$
% The above expression does not have a root for $a,b,d,x>0; b < 1$: the first two terms are strictly positive, meaning we would need $b = 2dx + 1 \geq 1$.

% "also M3?": $f(x)=a(x+d)^b + c$
% $$
% f'(x) = a b (d + x)^{(b-1)}
% $$
% $$
% f''(x) = a (-1 + b) b (d + x)^{(b-2)}
% $$
% Neither of the above expressions have roots because they are a product of non-zero constants and expressions of the form $m^n$.


%M2: $y = ax^b +c$


% \subsection{SCRAPS}

% % TODO: convert this to same form as M2
% \begin{proposition}
%     Functions of the form $f(x) = a + \left(\frac{b}{x}\right)^c$ are necessarily monotonic for $a,b,c>0$ in the range $x>0$.
% \end{proposition}
% \begin{proof}
%     A sufficient condition for monotonicity is that $f'(x)$ does not change sign.  
%     In our case, we have 
%     $$
%     f'(x) = - bc \left(\frac{b}{x}\right)^{(c-1)}.
%     $$
%     Since $b$ and $x$ are both positive, so is the ratio $\frac{b}{x}$.  
%     And since a positive number taken to any power is also positive, the entire expression is guaranteed to be negative for all values of $a,b,c,x>0$.
% \end{proof}

% %TODO: rename this section to "Math Proofs" and also prove that other functional forms can't express non-monotonic behavior

% \begin{proposition}
%     Functions of the form $f(x) = a + \left(\frac{b}{x}\right)^c$ cannot contain an inflection point for $a,b,c>0$ in the range $x>0$.
% \end{proposition}
% \begin{proof}
% The second derivative is:
% $$
% f''(x) = 
% \frac{(c (1 + c) (b/x)^c)}{x^2}.
% $$
% Since $b$, $c$ and $x$ are all positive, all of the multiplicands of $f''(x)$ are positive, and thus so is $f''(x)$, but an inflection point must have $f''(x)=0$.
% \end{proof}

% \subsection{SCRAPS}

% An inflection point is a point of a curve at which the second order derivative (i.e.\ curvature) changes signs. 
% Empirically, the function relating the performance evaluation metric (e.g. prediction error) to the quantity being scaled (e.g.\ model size) often has an inflection point. 
% Figure \ref{fig:Inflection_Point_example} is an example of this inflection point present in experimental data from a real world downstream task, Two Digit Addition (Zero-Shot) from \citet{brown2020language}. %\citet{2020arXiv200514165B}. 
% In the small scale regime, the function is concave downward as it transitions from random guessing performance to starting to learn the task. 
% As the scale increases past the small scale regime, an inflection point is reached and the function becomes concave upward as power law scaling behaviour takes over.

% However, \textbf{Proposition:} typical functional form cannot have an inflection point.
% \textbf{Proof:}
% %https://www.wolframalpha.com/input?i=d%5E2%2Fdx%5E2+%28a+%2B+%28b%2Fx%29**c%29+
% An inflection point is a point of a curve at which the second order derivative (i.e.\ curvature) changes signs. 
% The second derivative of this function is:
% $$
% f''(x) = 
% \frac{(c (1 + c) (b/x)^c)}{x^2}.
% $$
% Since $b$, $c$ and $x$ are all positive, all of the multiplicands of $f''(x)$ are positive, and thus so is $f''(x)$, but an inflection point must have $f''(x)=0$.
% % https://www.wolframalpha.com/input?i=d%5E2%2Fdx%5E2+%28a+%2B+%28b%2Fx%29**c+%281+%2F+%28x%2Bd%29%5Ef%29%29

% Note that inflection points often appear in scaling curves, which are typically plotted on log/log axes, and existing scaling laws can fit those inflection points (TODO: is this right?  I thought they were just linear on a log/log plot?).
% Inflection points are less common but still sometimes present in a linear/linear plot; These are the inflection points that existing scaling laws cannot capture.

% TODO: do we get the same result for all of M1 through M4?

% All the functional forms:

% M1: $y = ax^b$

% M2: $y = ax^b +c$

% M3: $y = a(x^{-1} + d)^{-b} + c$ 

% also M3?: $y=a(x+d)^b + c$

% M4: $(y - \epsilon_{\infty}) / ((\epsilon_{0} - y)^a) = bx$ 

% $\epsilon_{\infty}$ is irreducible loss, and $\epsilon_{0}$ is performance of random guessing.

% Equation 6.1 of "scaling laws for transfer" paper: $y = (ax^b + cx^d)^f + g$

% I (Ethan) just now have realized that this equation 6.1 above is a smoothly broken power law (i.e. mathematically equivalent to ours I think) too so we have to change the narrative of the paper now:  
% \url{https://math.stackexchange.com/a/2427151}

% \url{https://colab.research.google.com/drive/1QP81soNf1DDV_Q6iimN8sb-hZHaZeMyW}

% Also, I think "scaling laws for transfer" paper may/might have been unaware that its equation 6.1 is a thing called a smoothly broken power law.

% Broken Neural Scaling Law: $y =  a + \left(\frac{b}{x}\right)^c \prod_{i=1}^n \left(1 + \left(\frac{x}{d_i}\right)^{f_i}\right)^{-g_i}$



% TODO: remove this section?
% TODO: replace it with section about breaks rather than inflection points


%This inflection point at the transition from constant random guessing performance in the small scale regime to 
%When the performance evaluation metric (e.g. prediction error) is plotted on y-axis and the quantity being scaled (e.g. model size) is plotted on x-axis, the plotted data has an inflection point at the transition from constant random guessing performance in the small scale regime to 
% Figure \ref{fig:Inflection_Point_example} is an example of this inflection point present in experimental data from a real world downstream task, Two Digit Addition (Zero-Shot) from \citet{brown2020language}. %\citet{2020arXiv200514165B}. 
%In the small scale regime, the function is concave downward as it transitions from random guessing performance to starting to learn the task. As the scale increases past the small scale regime, an inflection point is reached and the function becomes concave upward as power law scaling behaviour takes over.

% \todo[inline]{math proofs}

% 1. proof that shows $y=a/(x^b+d)+c$ has inflection point for all functions in which $a$ $!=0$, $b>1$, and $d>0$ are simultaneously true

% 2. proof that shows $y=a(x+d)^b + c$ never has inflection point



\section{Additional Empirical Results: Additional Fits and Extrapolations of Functional Forms}
\label{section:additional_functional_form_fits}



\subsection{Fit of M3 (functional form that can't express inflection point) to 4 digit addition}
\label{section:M3_addition_failure}

\FloatBarrier

\begin{figure*}[htbp]
    \centering
%\includegraphics[width=0.48\textwidth]{figures/arithmetic/4_digit_addition__dataset_size.png}
\includegraphics[width=0.48\textwidth]{figures/arithmetic/4_digit_addition__dataset_size__very_first_version__M3.png}

    \caption{
    4 Digit Addition. Fit of M3 (functional form that can't express inflection point) to 4 digit addition.
    }
    \label{fig:M3_addition_failure}
\end{figure*}

\FloatBarrier

\iffalse

\subsection{Fit of M3 to BIG-Bench Arithmetic}
\label{section:M3_addition_failure}

\begin{figure*}[htbp]
    \centering
\includegraphics[width=0.48\textwidth]{figures/arithmetic/arithmetic__BIG-G_T=0__2-shot__M3.png}

    \caption{
    Fit of M3 to BIG-Bench Arithmetic.
    }
    \label{fig:M3_arithmetic_failure}
\end{figure*}

\fi

\subsection{Fit and Extrapolation of BNSL on BIG-Bench Arithmetic}
\label{figure:arithmetic_big_bench}

\begin{figure*}[htbp]
    \centering
\includegraphics[width=0.48\textwidth]{figures/arithmetic/arithmetic__BIG-G_T=0__3-shot__BNSL.png}

    \caption{
    Large-Scale BIG-Bench Arithmetic. Extrapolation yielded by BNSL on BIG-Bench 3-shot Arithmetic task with number of parameters on the x-axis. This experimental data is obtained from the \cite{srivastava2022beyond} release.
    }
    \label{fig:arithmetic_big_bench}
\end{figure*}



\subsection{Vision}
\label{section:scaling_benchmark__vision}

% (TODO: this sentence is repeated in language section)

Using the scaling laws benchmark of \cite{Alabdulmohsi2022revisiting}, we evaluate how well various functional forms extrapolate performance on vision tasks as training dataset size increases. In this vision subset of the benchmark, the tasks that are evaluated are error rate on each of various few-shot downstream image classification (IC) tasks; the downstream tasks are: Birds 200 \cite{welinder2010caltech}, Caltech101 \cite{fei2004learning}, CIFAR-100 \cite{krizhevsky2009learning}, and ImageNet \cite{deng2009imagenet}. The following architectures of various sizes are pretrained on subsets of JFT-300M: big-transfer residual neural networks (BiT) \cite{kolesnikov2020big}, MLP mixers (MiX) \cite{tolstikhin2021mlp}, and vision transformers (ViT) \cite{dosovitskiy2020image}. As can be seen in Tables  \ref{table:scaling_laws_benchmark_dataset__summary} and \ref{table:scaling_laws_benchmark_dataset__Vision},BNSL yields extrapolations with the lowest RMSLE (Root Mean Squared Logarithmic Error) for 63.89\% of tasks of any of the functional forms, while the next best functional form performs the best on only 13.89\% of the tasks.

To view all plots of the BNSL on each of these tasks, see figures
\ref{fig:scaling_laws_benchmark_dataset__birds},
\ref{fig:scaling_laws_benchmark_dataset__cifar_100},
\ref{fig:scaling_laws_benchmark_dataset__caltech},
\ref{fig:scaling_laws_benchmark_dataset__ImageNet} in Appendix \ref{section:Plots_of_BNSL_Extrapolations}. To view all plots of M1, M2, M3, and M4 on each of these tasks, see Appendix A.4 of \cite{Alabdulmohsi2022revisiting}.

\iffalse

\begin{wraptable}{r}{9}
\tiny
% \fontsize{8}{8}\selectfont
% \setlength\tabcolsep{3.1pt} 
\begin{tabular}
{p{.205\textwidth}p{.111\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}}
%\begin{tabular}{llllrrrrrrrrrrrrl}
\hspace{.9cm}Task & Model & M1 $\downarrow$ & M2 $\downarrow$ & M3 $\downarrow$ & M4 $\downarrow$ & BNSL $\downarrow$ \\
\hline
Birds 200 10-shot & BiT/101/3 & 9.13e-2 & 9.13e-2 & 9.13e-2 & 2.49e-2 & \highlight{3.79e-3} \\
Birds 200 10-shot & BiT/50/1 & 6.88e-2 & 6.88e-2 & 5.24e-2 & 2.48e-2 & \highlight{4.96e-3} \\
Birds 200 10-shot & MiX/B/16 & 9.15e-2 & 9.15e-2 & 3.95e-2 & 4.14e-2 & \highlight{9.98e-3} \\
Birds 200 10-shot & MiX/L/16 & 5.51e-2 & 5.51e-2 & 5.51e-2 & 4.59e-2 & \highlight{8.41e-3} \\
Birds 200 10-shot & ViT/B/16 & 6.77e-2 & 6.77e-2 & 3.52e-2 & 1.87e-2 & \highlight{9.81e-3} \\
Birds 200 10-shot & ViT/S/16 & 3.95e-2 & 3.95e-2 & 3.74e-2 & \highlight{9.81e-3} & 1.51e-2 \\
Birds 200 25-shot & BiT/101/3 & 9.41e-2 & 9.41e-2 & 9.41e-2 & 5.09e-2 & \highlight{7.24e-3} \\
Birds 200 25-shot & BiT/50/1 & 1.10e-1 & 7.29e-2 & 1.52e-2 & 1.63e-2 & \highlight{8.00e-3} \\
Birds 200 25-shot & MiX/B/16 & 1.40e-1 & 1.40e-1 & 6.93e-2 & 1.85e-2 & \highlight{5.02e-3} \\
Birds 200 25-shot & MiX/L/16 & 1.12e-1 & 1.12e-1 & 1.12e-1 & 4.88e-2 & \highlight{1.05e-2} \\
Birds 200 25-shot & ViT/B/16 & 9.02e-2 & 9.02e-2 & 3.75e-2 & 1.52e-2 & \highlight{5.87e-3} \\
Birds 200 25-shot & ViT/S/16 & 5.06e-2 & 5.06e-2 & 4.96e-2 & 3.28e-2 & \highlight{1.21e-2} \\
Birds 200 5-shot & BiT/101/3 & 8.17e-2 & 8.17e-2 & 8.17e-2 & 3.00e-2 & \highlight{6.08e-3} \\
Birds 200 5-shot & BiT/50/1 & 5.44e-2 & 5.44e-2 & 5.44e-2 & 2.63e-2 & \highlight{5.79e-3} \\
Birds 200 5-shot & MiX/B/16 & 8.27e-2 & 8.27e-2 & 5.49e-2 & 1.86e-2 & \highlight{5.74e-3} \\
Birds 200 5-shot & MiX/L/16 & 5.68e-2 & 5.68e-2 & 5.68e-2 & 2.65e-2 & \highlight{5.06e-3} \\
Birds 200 5-shot & ViT/B/16 & 3.40e-2 & 3.40e-2 & 3.40e-2 & 1.26e-2 & \highlight{6.32e-3} \\
Birds 200 5-shot & ViT/S/16 & 2.75e-2 & 2.75e-2 & 2.75e-2 & 1.56e-2 & \highlight{6.93e-3} \\
\hline
CIFAR-100 10-shot & BiT/101/3 & 8.57e-2 & 8.57e-2 & 8.25e-2 & 9.28e-2 & \highlight{1.53e-2} \\
CIFAR-100 10-shot & BiT/50/1 & 7.44e-2 & 1.24e-2 & 2.08e-2 & 1.23e-2 & \highlight{9.74e-3} \\
CIFAR-100 10-shot & MiX/B/16 & 8.77e-2 & 8.77e-2 & 2.71e-2 & 2.60e-2 & \highlight{8.61e-3} \\
CIFAR-100 10-shot & MiX/L/16 & 1.05e-1 & 1.05e-1 & 4.85e-2 & 4.76e-2 & \highlight{1.55e-2} \\
CIFAR-100 10-shot & ViT/B/16 & 8.98e-2 & 8.98e-2 & 8.98e-2 & 5.60e-2 & \highlight{1.73e-2} \\
CIFAR-100 10-shot & ViT/S/16 & 6.84e-2 & 2.11e-2 & 3.35e-2 & 2.47e-2 & \highlight{1.15e-2} \\
CIFAR-100 25-shot & BiT/101/3 & 8.77e-2 & 8.77e-2 & 4.44e-2 & 4.29e-2 & \highlight{9.32e-3} \\
CIFAR-100 25-shot & BiT/50/1 & 7.31e-2 & 2.35e-2 & 3.65e-2 & 2.36e-2 & \highlight{2.00e-2} \\
CIFAR-100 25-shot & MiX/B/16 & 1.08e-1 & 4.75e-2 & 2.10e-2 & 2.08e-2 & \highlight{8.15e-3} \\
CIFAR-100 25-shot & MiX/L/16 & 9.79e-2 & 9.79e-2 & 3.67e-2 & 2.79e-2 & \highlight{8.47e-3} \\
CIFAR-100 25-shot & ViT/B/16 & 1.07e-1 & 1.07e-1 & 6.54e-2 & \highlight{4.81e-2} & 1.20e-1 \\
CIFAR-100 25-shot & ViT/S/16 & 8.03e-2 & 2.19e-2 & 3.13e-2 & 2.19e-2 & \highlight{1.34e-2} \\
CIFAR-100 5-shot & BiT/101/3 & 5.94e-2 & 5.94e-2 & 5.94e-2 & 4.57e-2 & \highlight{1.58e-2} \\
CIFAR-100 5-shot & BiT/50/1 & 4.87e-2 & 4.87e-2 & \highlight{1.69e-2} & 4.91e-2 & 1.95e-2 \\
CIFAR-100 5-shot & MiX/B/16 & 7.07e-2 & 7.07e-2 & 2.78e-2 & 2.05e-2 & \highlight{6.77e-3} \\
CIFAR-100 5-shot & MiX/L/16 & 7.06e-2 & 7.06e-2 & 4.17e-2 & 3.14e-2 & \highlight{1.18e-2} \\
CIFAR-100 5-shot & ViT/B/16 & 6.27e-2 & 6.27e-2 & 6.27e-2 & 5.11e-2 & \highlight{1.19e-2} \\
CIFAR-100 5-shot & ViT/S/16 & 6.93e-2 & \highlight{2.84e-2} & 3.88e-2 & 3.09e-2 & 6.40e-2 \\
\hline
Caltech101 10-shot & BiT/101/3 & 3.07e-1 & 3.07e-1 & 1.51e-1 & 3.54e-2 & \highlight{6.42e-3} \\
Caltech101 10-shot & BiT/50/1 & 3.29e-1 & 7.68e-2 & 1.13e-1 & 6.31e-2 & \highlight{5.37e-3} \\
Caltech101 10-shot & MiX/B/16 & 1.35e-1 & 1.35e-1 & 1.35e-1 & 2.11e-1 & \highlight{3.72e-2} \\
Caltech101 10-shot & MiX/L/16 & 1.25e-1 & 1.25e-1 & 1.25e-1 & 1.92e-1 & \highlight{3.73e-2} \\
Caltech101 10-shot & ViT/B/16 & 7.76e-2 & 7.76e-2 & 3.11e-2 & 5.54e-2 & \highlight{1.67e-2} \\
Caltech101 10-shot & ViT/S/16 & 1.95e-1 & 3.41e-2 & \highlight{2.40e-2} & 3.95e-2 & 3.31e-2 \\
Caltech101 25-shot & BiT/101/3 & 1.15e-1 & 1.15e-1 & 1.15e-1 & 5.23e-2 & \highlight{1.13e-2} \\
Caltech101 25-shot & BiT/50/1 & 3.60e-1 & 8.80e-2 & 1.43e-1 & 5.95e-2 & \highlight{2.13e-3} \\
Caltech101 25-shot & MiX/B/16 & 8.28e-2 & 8.28e-2 & 8.28e-2 & 1.74e-1 & \highlight{2.83e-2} \\
Caltech101 25-shot & MiX/L/16 & 9.66e-2 & 9.66e-2 & 9.66e-2 & 1.03e-1 & \highlight{1.98e-2} \\
Caltech101 25-shot & ViT/B/16 & 1.03e-1 & 3.33e-2 & 4.46e-2 & 4.24e-2 & \highlight{6.37e-3} \\
Caltech101 25-shot & ViT/S/16 & 1.77e-1 & 3.79e-2 & 2.80e-2 & \highlight{2.35e-2} & 2.38e-2 \\
Caltech101 5-shot & BiT/101/3 & 2.12e-1 & 2.12e-1 & 2.12e-1 & 8.82e-2 & \highlight{3.17e-3} \\
Caltech101 5-shot & BiT/50/1 & 2.34e-1 & 4.13e-2 & 1.61e-2 & 4.49e-2 & \highlight{1.33e-2} \\
Caltech101 5-shot & MiX/B/16 & 2.43e-1 & 2.43e-1 & 2.35e-1 & 1.23e-1 & \highlight{3.59e-3} \\
Caltech101 5-shot & MiX/L/16 & 1.38e-1 & 1.38e-1 & 1.38e-1 & 3.19e-2 & \highlight{3.19e-2} \\
Caltech101 5-shot & ViT/B/16 & 1.10e-1 & 1.10e-1 & 6.02e-2 & 6.59e-2 & \highlight{2.33e-2} \\
Caltech101 5-shot & ViT/S/16 & 1.90e-1 & 3.82e-2 & 5.04e-2 & 4.06e-2 & \highlight{2.47e-2} \\
\hline
ImageNet 10-shot & BiT/101/3 & 1.27e-1 & 1.27e-1 & 7.36e-2 & 2.13e-2 & \highlight{5.95e-3} \\
ImageNet 10-shot & BiT/50/1 & 9.54e-2 & 9.54e-2 & \highlight{5.75e-3} & 1.77e-2 & 8.93e-3 \\
ImageNet 10-shot & MiX/B/16 & 9.34e-2 & 9.34e-2 & 3.37e-2 & 1.80e-2 & \highlight{5.88e-3} \\
ImageNet 10-shot & MiX/L/16 & 9.83e-2 & 9.83e-2 & 9.83e-2 & 9.48e-3 & \highlight{3.81e-3} \\
ImageNet 10-shot & ViT/B/16 & 4.62e-2 & 4.62e-2 & 4.62e-2 & 3.43e-2 & \highlight{2.85e-3} \\
ImageNet 10-shot & ViT/S/16 & 4.74e-2 & 4.74e-2 & 1.66e-2 & 1.14e-2 & \highlight{1.97e-3} \\
ImageNet 25-shot & BiT/101/3 & 1.42e-1 & 1.42e-1 & 6.67e-2 & 2.18e-2 & \highlight{4.86e-3} \\
ImageNet 25-shot & BiT/50/1 & 1.17e-1 & 1.17e-1 & \highlight{4.06e-3} & 1.70e-2 & 8.14e-3 \\
ImageNet 25-shot & MiX/B/16 & 9.59e-2 & 9.59e-2 & 5.39e-2 & 1.47e-2 & \highlight{2.86e-3} \\
ImageNet 25-shot & MiX/L/16 & 1.03e-1 & 1.03e-1 & 1.03e-1 & 6.09e-3 & \highlight{1.94e-3} \\
ImageNet 25-shot & ViT/B/16 & 5.17e-2 & 5.17e-2 & 5.17e-2 & 3.26e-2 & \highlight{6.91e-3} \\
ImageNet 25-shot & ViT/S/16 & 5.52e-2 & 4.12e-2 & 9.65e-3 & 1.16e-2 & \highlight{3.09e-3} \\
ImageNet 5-shot & BiT/101/3 & 9.24e-2 & 9.24e-2 & 9.24e-2 & 1.01e-2 & \highlight{2.55e-3} \\
ImageNet 5-shot & BiT/50/1 & 8.95e-2 & 8.95e-2 & 1.53e-2 & 1.03e-2 & \highlight{4.00e-3} \\
ImageNet 5-shot & MiX/B/16 & 9.09e-2 & 9.09e-2 & 3.01e-2 & 1.45e-2 & \highlight{3.57e-3} \\
ImageNet 5-shot & MiX/L/16 & 7.99e-2 & 7.99e-2 & 7.99e-2 & 5.66e-3 & \highlight{1.63e-3} \\
ImageNet 5-shot & ViT/B/16 & 4.11e-2 & 4.11e-2 & 4.11e-2 & 2.88e-2 & \highlight{4.97e-3} \\
ImageNet 5-shot & ViT/S/16 & 4.20e-2 & 4.20e-2 & 2.40e-2 & 1.44e-2 & \highlight{3.00e-3} \\
\end{tabular}
    \caption{
    Extrapolation Results for Vision Tasks. See Section \ref{section:scaling_benchmark__vision} for more details. Numbers for M1, M2, M3, and M4 obtained via correspondence with authors of \cite{Alabdulmohsi2022revisiting}. 
    }
    \label{table:scaling_laws_benchmark_dataset__Vision_old}
\end{wraptable}
\FloatBarrier

\begin{table}[htbp]
\setlength\tabcolsep{2.1pt} 
\begin{adjustwidth}{-2.2cm}{-1cm}
\fontsize{8}{10}\selectfont
% \setlength\tabcolsep{3.1pt} 
\begin{tabular}
{|p{.165\textwidth} c c c c c || p{.165\textwidth} c c c c c |}
%{p{.02\textwidth}p{.165\textwidth}p{.095\textwidth}p{.01\textwidth}p{.01\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}}
% {p{.165\textwidth}p{.070\textwidth}p{.070\textwidth}p{.080\textwidth}p{.080\textwidth}p{.080\textwidth}p{.165\textwidth}p{.080\textwidth}p{.080\textwidth}p{.080\textwidth}p{.080\textwidth}p{.080\textwidth}}
%\begin{tabular}{llllrrrrrrrrrrrrl}
%\hline
%\multicolumn{6}{c}{Sum of Extracted Bits}
\hline
\hspace{.9cm}Task & M1 $\downarrow$ & M2 $\downarrow$ & M3 $\downarrow$ & M4 $\downarrow$ & BNSL $\downarrow$ & \hspace{.9cm}Task & M1 $\downarrow$ & M2 $\downarrow$ & M3 $\downarrow$ & M4 $\downarrow$ & BNSL $\downarrow$\\
\hline
Birds 200 10-shot & 9.13e-2 & 9.13e-2 & 9.13e-2 & 2.49e-2 & \highlight{3.79e-3} & CIFAR-100 10-shot & 8.57e-2 & 8.57e-2 & 8.25e-2 & 9.28e-2 & \highlight{1.53e-2} \\
Birds 200 10-shot & 6.88e-2 & 6.88e-2 & 5.24e-2 & 2.48e-2 & \highlight{4.96e-3} & CIFAR-100 10-shot & 7.44e-2 & 1.24e-2 & 2.08e-2 & 1.23e-2 & \highlight{9.74e-3} \\
Birds 200 10-shot & 9.15e-2 & 9.15e-2 & 3.95e-2 & 4.14e-2 & \highlight{9.98e-3} & CIFAR-100 10-shot & 8.77e-2 & 8.77e-2 & 2.71e-2 & 2.60e-2 & \highlight{8.61e-3} \\
Birds 200 10-shot & 5.51e-2 & 5.51e-2 & 5.51e-2 & 4.59e-2 & \highlight{8.41e-3} & CIFAR-100 10-shot & 1.05e-1 & 1.05e-1 & 4.85e-2 & 4.76e-2 & \highlight{1.55e-2} \\
Birds 200 10-shot & 6.77e-2 & 6.77e-2 & 3.52e-2 & 1.87e-2 & \highlight{9.81e-3} & CIFAR-100 10-shot & 8.98e-2 & 8.98e-2 & 8.98e-2 & 5.60e-2 & \highlight{1.73e-2} \\
Birds 200 10-shot & 3.95e-2 & 3.95e-2 & 3.74e-2 & \highlight{9.81e-3} & 1.51e-2 & CIFAR-100 10-shot & 6.84e-2 & 2.11e-2 & 3.35e-2 & 2.47e-2 & \highlight{1.15e-2} \\
Birds 200 25-shot & 9.41e-2 & 9.41e-2 & 9.41e-2 & 5.09e-2 & \highlight{7.24e-3} & CIFAR-100 25-shot & 8.77e-2 & 8.77e-2 & 4.44e-2 & 4.29e-2 & \highlight{9.32e-3} \\
Birds 200 25-shot & 1.10e-1 & 7.29e-2 & 1.52e-2 & 1.63e-2 & \highlight{8.00e-3} & CIFAR-100 25-shot & 7.31e-2 & 2.35e-2 & 3.65e-2 & 2.36e-2 & \highlight{2.00e-2} \\
Birds 200 25-shot & 1.40e-1 & 1.40e-1 & 6.93e-2 & 1.85e-2 & \highlight{5.02e-3} & CIFAR-100 25-shot & 1.08e-1 & 4.75e-2 & 2.10e-2 & 2.08e-2 & \highlight{8.15e-3} \\
Birds 200 25-shot & 1.12e-1 & 1.12e-1 & 1.12e-1 & 4.88e-2 & \highlight{1.05e-2} & CIFAR-100 25-shot & 9.79e-2 & 9.79e-2 & 3.67e-2 & 2.79e-2 & \highlight{8.47e-3} \\
Birds 200 25-shot & 9.02e-2 & 9.02e-2 & 3.75e-2 & 1.52e-2 & \highlight{5.87e-3} & CIFAR-100 25-shot & 1.07e-1 & 1.07e-1 & 6.54e-2 & \highlight{4.81e-2} & 1.20e-1 \\
Birds 200 25-shot & 5.06e-2 & 5.06e-2 & 4.96e-2 & 3.28e-2 & \highlight{1.21e-2} & CIFAR-100 25-shot & 8.03e-2 & 2.19e-2 & 3.13e-2 & 2.19e-2 & \highlight{1.34e-2} \\
Birds 200 5-shot & 8.17e-2 & 8.17e-2 & 8.17e-2 & 3.00e-2 & \highlight{6.08e-3} & CIFAR-100 5-shot & 5.94e-2 & 5.94e-2 & 5.94e-2 & 4.57e-2 & \highlight{1.58e-2} \\
Birds 200 5-shot & 5.44e-2 & 5.44e-2 & 5.44e-2 & 2.63e-2 & \highlight{5.79e-3} & CIFAR-100 5-shot & 4.87e-2 & 4.87e-2 & \highlight{1.69e-2} & 4.91e-2 & 1.95e-2 \\
Birds 200 5-shot & 8.27e-2 & 8.27e-2 & 5.49e-2 & 1.86e-2 & \highlight{5.74e-3} & CIFAR-100 5-shot & 7.07e-2 & 7.07e-2 & 2.78e-2 & 2.05e-2 & \highlight{6.77e-3} \\
Birds 200 5-shot & 5.68e-2 & 5.68e-2 & 5.68e-2 & 2.65e-2 & \highlight{5.06e-3} & CIFAR-100 5-shot & 7.06e-2 & 7.06e-2 & 4.17e-2 & 3.14e-2 & \highlight{1.18e-2} \\
Birds 200 5-shot & 3.40e-2 & 3.40e-2 & 3.40e-2 & 1.26e-2 & \highlight{6.32e-3} & CIFAR-100 5-shot & 6.27e-2 & 6.27e-2 & 6.27e-2 & 5.11e-2 & \highlight{1.19e-2} \\
Birds 200 5-shot & 2.75e-2 & 2.75e-2 & 2.75e-2 & 1.56e-2 & \highlight{6.93e-3} & CIFAR-100 5-shot & 6.93e-2 & \highlight{2.84e-2} & 3.88e-2 & 3.09e-2 & 6.40e-2 \\
\hline
\hline
Caltech101 10-shot & 3.07e-1 & 3.07e-1 & 1.51e-1 & 3.54e-2 & \highlight{6.42e-3} & ImageNet 10-shot & 1.27e-1 & 1.27e-1 & 7.36e-2 & 2.13e-2 & \highlight{5.95e-3} \\
Caltech101 10-shot & 3.29e-1 & 7.68e-2 & 1.13e-1 & 6.31e-2 & \highlight{5.37e-3} & ImageNet 10-shot & 9.54e-2 & 9.54e-2 & \highlight{5.75e-3} & 1.77e-2 & 8.93e-3 \\
Caltech101 10-shot & 1.35e-1 & 1.35e-1 & 1.35e-1 & 2.11e-1 & \highlight{3.72e-2} & ImageNet 10-shot & 9.34e-2 & 9.34e-2 & 3.37e-2 & 1.80e-2 & \highlight{5.88e-3} \\
Caltech101 10-shot & 1.25e-1 & 1.25e-1 & 1.25e-1 & 1.92e-1 & \highlight{3.73e-2} & ImageNet 10-shot & 9.83e-2 & 9.83e-2 & 9.83e-2 & 9.48e-3 & \highlight{3.81e-3} \\
Caltech101 10-shot & 7.76e-2 & 7.76e-2 & 3.11e-2 & 5.54e-2 & \highlight{1.67e-2} & ImageNet 10-shot & 4.62e-2 & 4.62e-2 & 4.62e-2 & 3.43e-2 & \highlight{2.85e-3} \\
Caltech101 10-shot & 1.95e-1 & 3.41e-2 & \highlight{2.40e-2} & 3.95e-2 & 3.31e-2 & ImageNet 10-shot & 4.74e-2 & 4.74e-2 & 1.66e-2 & 1.14e-2 & \highlight{1.97e-3} \\
Caltech101 25-shot & 1.15e-1 & 1.15e-1 & 1.15e-1 & 5.23e-2 & \highlight{1.13e-2} & ImageNet 25-shot & 1.42e-1 & 1.42e-1 & 6.67e-2 & 2.18e-2 & \highlight{4.86e-3} \\
Caltech101 25-shot & 3.60e-1 & 8.80e-2 & 1.43e-1 & 5.95e-2 & \highlight{2.13e-3} & ImageNet 25-shot & 1.17e-1 & 1.17e-1 & \highlight{4.06e-3} & 1.70e-2 & 8.14e-3 \\
Caltech101 25-shot & 8.28e-2 & 8.28e-2 & 8.28e-2 & 1.74e-1 & \highlight{2.83e-2} & ImageNet 25-shot & 9.59e-2 & 9.59e-2 & 5.39e-2 & 1.47e-2 & \highlight{2.86e-3} \\
Caltech101 25-shot & 9.66e-2 & 9.66e-2 & 9.66e-2 & 1.03e-1 & \highlight{1.98e-2} & ImageNet 25-shot & 1.03e-1 & 1.03e-1 & 1.03e-1 & 6.09e-3 & \highlight{1.94e-3} \\
Caltech101 25-shot & 1.03e-1 & 3.33e-2 & 4.46e-2 & 4.24e-2 & \highlight{6.37e-3} & ImageNet 25-shot & 5.17e-2 & 5.17e-2 & 5.17e-2 & 3.26e-2 & \highlight{6.91e-3} \\
Caltech101 25-shot & 1.77e-1 & 3.79e-2 & 2.80e-2 & \highlight{2.35e-2} & 2.38e-2 & ImageNet 25-shot & 5.52e-2 & 4.12e-2 & 9.65e-3 & 1.16e-2 & \highlight{3.09e-3} \\
Caltech101 5-shot & 2.12e-1 & 2.12e-1 & 2.12e-1 & 8.82e-2 & \highlight{3.17e-3} & ImageNet 5-shot & 9.24e-2 & 9.24e-2 & 9.24e-2 & 1.01e-2 & \highlight{2.55e-3} \\
Caltech101 5-shot & 2.34e-1 & 4.13e-2 & 1.61e-2 & 4.49e-2 & \highlight{1.33e-2} & ImageNet 5-shot & 8.95e-2 & 8.95e-2 & 1.53e-2 & 1.03e-2 & \highlight{4.00e-3} \\
Caltech101 5-shot & 2.43e-1 & 2.43e-1 & 2.35e-1 & 1.23e-1 & \highlight{3.59e-3} & ImageNet 5-shot & 9.09e-2 & 9.09e-2 & 3.01e-2 & 1.45e-2 & \highlight{3.57e-3} \\
Caltech101 5-shot & 1.38e-1 & 1.38e-1 & 1.38e-1 & 3.19e-2 & \highlight{3.19e-2} & ImageNet 5-shot & 7.99e-2 & 7.99e-2 & 7.99e-2 & 5.66e-3 & \highlight{1.63e-3} \\
Caltech101 5-shot & 1.10e-1 & 1.10e-1 & 6.02e-2 & 6.59e-2 & \highlight{2.33e-2} & ImageNet 5-shot & 4.11e-2 & 4.11e-2 & 4.11e-2 & 2.88e-2 & \highlight{4.97e-3} \\
Caltech101 5-shot & 1.90e-1 & 3.82e-2 & 5.04e-2 & 4.06e-2 & \highlight{2.47e-2} & ImageNet 5-shot & 4.20e-2 & 4.20e-2 & 2.40e-2 & 1.44e-2 & \highlight{3.00e-3} \\
\hline
\end{tabular}
    \caption{
    Extrapolation Results for Vision Tasks. See Section \ref{section:scaling_benchmark__vision} for more details. Numbers for M1, M2, M3, and M4 obtained via correspondence with authors of \cite{Alabdulmohsi2022revisiting}. 
    }
    \label{table:scaling_laws_benchmark_dataset__Vision_old}
\end{adjustwidth}
\end{table}
\FloatBarrier

\fi

\begin{table}[]
%\tiny
%\footnotesize
\scriptsize
\setlength\tabcolsep{3.1pt} 
\setlength{\extrarowheight}{0.4pt}
\begin{tabular}
%{p{.021\textwidth}p{.165\textwidth}p{.111\textwidth}p{.028\textwidth}p{.022\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}}
%{Hp{.21\textwidth}p{.111\textwidth}HHp{.165\textwidth}p{.165\textwidth}p{.165\textwidth}p{.165\textwidth}p{.165\textwidth}}
%{Hp{.15\textwidth}p{.08\textwidth}HHp{.13\textwidth}p{.13\textwidth}p{.13\textwidth}p{.13\textwidth}p{.13\textwidth}}
{Hp{.14\textwidth}p{.08\textwidth}HH|p{.13\textwidth}|p{.13\textwidth}|p{.13\textwidth}|p{.13\textwidth}|p{.13\textwidth}}
%\begin{tabular}{llllrrrrrrrrrrrrl}
Domain & Task & Model & Train Points & Test Points & M1 $\downarrow$ & M2 $\downarrow$ & M3 $\downarrow$ & M4 $\downarrow$ & BNSL $\downarrow$ \\
\hline
IC & Birds 200 10-shot & BiT/101/3 & 57 & 107 & 9.13e-2 ± 2.8e-3 & 9.13e-2 ± 2.8e-3 & 9.13e-2 ± 2.8e-3 & 2.95e-2 ± 1.3e-3 & \bfseries 1.76e-2 ± 1.1e-3 \\
IC & Birds 200 10-shot & BiT/50/1 & 70 & 469 & 6.88e-2 ± 7.5e-4 & 6.88e-2 ± 7.5e-4 & 5.24e-2 ± 6.2e-4 & 2.66e-2 ± 5.3e-4 & \bfseries 1.39e-2 ± 3.9e-4 \\
IC & Birds 200 10-shot & MiX/B/16 & 69 & 383 & 9.15e-2 ± 1.1e-3 & 9.15e-2 ± 1.1e-3 & 3.95e-2 ± 7.0e-4 & 4.62e-2 ± 8.2e-4 & \bfseries 3.16e-2 ± 7.0e-4 \\
IC & Birds 200 10-shot & MiX/L/16 & 63 & 211 & 5.51e-2 ± 1.4e-3 & 5.51e-2 ± 1.4e-3 & 5.51e-2 ± 1.4e-3 & 5.15e-2 ± 1.7e-3 & \bfseries 3.46e-2 ± 1.3e-3 \\
IC & Birds 200 10-shot & ViT/B/16 & 65 & 316 & 6.77e-2 ± 1.1e-3 & 6.77e-2 ± 1.1e-3 & 3.52e-2 ± 8.1e-4 & \bfseries 1.51e-2 ± 6.2e-4 & 2.43e-2 ± 8.1e-4 \\
IC & Birds 200 10-shot & ViT/S/16 & 54 & 133 & 3.95e-2 ± 1.2e-3 & 3.95e-2 ± 1.2e-3 & 3.74e-2 ± 1.1e-3 & \bfseries 1.85e-2 ± 7.9e-4 & 2.35e-2 ± 8.4e-4 \\
IC & Birds 200 25-shot & BiT/101/3 & 53 & 78 & 9.41e-2 ± 3.2e-3 & 9.41e-2 ± 3.2e-3 & 9.41e-2 ± 3.2e-3 & 6.38e-2 ± 2.0e-3 & \bfseries 3.94e-2 ± 1.6e-3 \\
IC & Birds 200 25-shot & BiT/50/1 & 69 & 452 & 1.10e-1 ± 1.0e-3 & 7.29e-2 ± 8.0e-4 & \bfseries 1.52e-2 ± 4.9e-4 & 1.97e-2 ± 5.6e-4 & 2.73e-2 ± 6.1e-4 \\
IC & Birds 200 25-shot & MiX/B/16 & 67 & 293 & 1.40e-1 ± 1.9e-3 & 1.40e-1 ± 1.9e-3 & 6.93e-2 ± 1.2e-3 & 2.11e-2 ± 6.9e-4 & \bfseries 1.83e-2 ± 6.2e-4 \\
IC & Birds 200 25-shot & MiX/L/16 & 63 & 196 & 1.12e-1 ± 2.0e-3 & 1.12e-1 ± 2.0e-3 & 1.12e-1 ± 2.0e-3 & 5.44e-2 ± 1.8e-3 & \bfseries 5.04e-2 ± 1.7e-3 \\
IC & Birds 200 25-shot & ViT/B/16 & 64 & 271 & 9.02e-2 ± 1.6e-3 & 9.02e-2 ± 1.6e-3 & 3.75e-2 ± 1.0e-3 & \bfseries 1.51e-2 ± 5.7e-4 & 1.62e-2 ± 6.1e-4 \\
IC & Birds 200 25-shot & ViT/S/16 & 51 & 100 & 5.06e-2 ± 1.4e-3 & 5.06e-2 ± 1.4e-3 & 4.96e-2 ± 1.4e-3 & 4.02e-2 ± 1.2e-3 & \bfseries 2.02e-2 ± 8.5e-4 \\
IC & Birds 200 5-shot & BiT/101/3 & 62 & 180 & 8.17e-2 ± 2.0e-3 & 8.17e-2 ± 2.0e-3 & 8.17e-2 ± 2.0e-3 & 3.38e-2 ± 1.3e-3 & \bfseries 2.47e-2 ± 1.1e-3 \\
IC & Birds 200 5-shot & BiT/50/1 & 71 & 517 & 5.44e-2 ± 5.6e-4 & 5.44e-2 ± 5.6e-4 & 5.44e-2 ± 5.6e-4 & 2.59e-2 ± 5.4e-4 & \bfseries 1.34e-2 ± 3.7e-4 \\
IC & Birds 200 5-shot & MiX/B/16 & 71 & 494 & 8.27e-2 ± 1.0e-3 & 8.27e-2 ± 1.0e-3 & 5.49e-2 ± 7.8e-4 & 2.14e-2 ± 5.3e-4 & \bfseries 1.60e-2 ± 4.7e-4 \\
IC & Birds 200 5-shot & MiX/L/16 & 67 & 326 & 5.68e-2 ± 1.4e-3 & 5.68e-2 ± 1.4e-3 & 5.68e-2 ± 1.4e-3 & 3.20e-2 ± 9.7e-4 & \bfseries 1.85e-2 ± 6.4e-4 \\
IC & Birds 200 5-shot & ViT/B/16 & 65 & 284 & 3.40e-2 ± 8.9e-4 & 3.40e-2 ± 8.9e-4 & 3.40e-2 ± 8.9e-4 & 1.65e-2 ± 6.7e-4 & \bfseries 1.36e-2 ± 5.8e-4 \\
IC & Birds 200 5-shot & ViT/S/16 & 57 & 150 & 2.75e-2 ± 7.9e-4 & 2.75e-2 ± 7.9e-4 & 2.75e-2 ± 7.9e-4 & 1.20e-2 ± 5.2e-4 & \bfseries 1.00e-2 ± 4.8e-4 \\
IC & CIFAR-100 10-shot & BiT/101/3 & 37 & 60 & 8.57e-2 ± 3.8e-3 & 8.57e-2 ± 3.8e-3 & 8.25e-2 ± 3.7e-3 & 4.77e-2 ± 3.0e-3 & \bfseries 3.41e-2 ± 2.7e-3 \\
IC & CIFAR-100 10-shot & BiT/50/1 & 52 & 192 & 7.44e-2 ± 1.5e-3 & 1.24e-2 ± 5.8e-4 & 2.08e-2 ± 7.2e-4 & \bfseries 1.24e-2 ± 5.8e-4 & 1.25e-2 ± 5.8e-4 \\
IC & CIFAR-100 10-shot & MiX/B/16 & 45 & 248 & 8.77e-2 ± 1.9e-3 & 8.77e-2 ± 1.9e-3 & 2.71e-2 ± 1.2e-3 & 2.37e-2 ± 9.9e-4 & \bfseries 2.36e-2 ± 9.4e-4 \\
IC & CIFAR-100 10-shot & MiX/L/16 & 57 & 313 & 1.05e-1 ± 3.1e-3 & 1.05e-1 ± 3.1e-3 & \bfseries 4.85e-2 ± 2.6e-3 & 4.97e-2 ± 1.6e-3 & 5.03e-2 ± 1.6e-3 \\
IC & CIFAR-100 10-shot & ViT/B/16 & 40 & 354 & 8.98e-2 ± 2.0e-3 & 8.98e-2 ± 2.0e-3 & 8.98e-2 ± 2.0e-3 & 4.98e-2 ± 1.7e-3 & \bfseries 3.71e-2 ± 1.4e-3 \\
IC & CIFAR-100 10-shot & ViT/S/16 & 67 & 450 & 6.84e-2 ± 1.1e-3 & \bfseries 2.11e-2 ± 6.6e-4 & 3.35e-2 ± 8.6e-4 & 2.54e-2 ± 7.5e-4 & 2.57e-2 ± 7.5e-4 \\
IC & CIFAR-100 25-shot & BiT/101/3 & 14 & 38 & 8.77e-2 ± 5.6e-3 & 8.77e-2 ± 5.6e-3 & 4.44e-2 ± 3.5e-3 & 3.40e-2 ± 2.7e-3 & \bfseries 2.49e-2 ± 2.2e-3 \\
IC & CIFAR-100 25-shot & BiT/50/1 & 35 & 109 & 7.31e-2 ± 2.0e-3 & 2.35e-2 ± 1.5e-3 & 3.65e-2 ± 1.8e-3 & 2.35e-2 ± 1.5e-3 & \bfseries 1.89e-2 ± 1.1e-3 \\
IC & CIFAR-100 25-shot & MiX/B/16 & 64 & 202 & 1.08e-1 ± 2.3e-3 & 4.75e-2 ± 1.6e-3 & \bfseries 2.10e-2 ± 9.4e-4 & 2.24e-2 ± 9.9e-4 & 2.67e-2 ± 1.1e-3 \\
IC & CIFAR-100 25-shot & MiX/L/16 & 52 & 185 & 9.79e-2 ± 2.2e-3 & 9.79e-2 ± 2.2e-3 & 3.67e-2 ± 1.7e-3 & \bfseries 2.98e-2 ± 1.4e-3 & 3.19e-2 ± 1.5e-3 \\
IC & CIFAR-100 25-shot & ViT/B/16 & 46 & 355 & 1.07e-1 ± 1.9e-3 & 1.07e-1 ± 1.9e-3 & 6.54e-2 ± 1.6e-3 & 4.80e-2 ± 1.4e-3 & \bfseries 2.97e-2 ± 1.9e-3 \\
IC & CIFAR-100 25-shot & ViT/S/16 & 66 & 416 & 8.03e-2 ± 1.2e-3 & \bfseries 2.19e-2 ± 7.4e-4 & 3.13e-2 ± 8.4e-4 & 2.27e-2 ± 7.1e-4 & 3.24e-2 ± 8.5e-4 \\
IC & CIFAR-100 5-shot & BiT/101/3 & 37 & 59 & 5.94e-2 ± 3.2e-3 & 5.94e-2 ± 3.2e-3 & 5.94e-2 ± 3.2e-3 & 3.30e-2 ± 2.4e-3 & \bfseries 2.35e-2 ± 2.0e-3 \\
IC & CIFAR-100 5-shot & BiT/50/1 & 37 & 98 & 4.87e-2 ± 1.3e-3 & 4.87e-2 ± 1.3e-3 & 1.69e-2 ± 8.8e-4 & 1.87e-2 ± 8.9e-4 & \bfseries 1.45e-2 ± 8.7e-4 \\
IC & CIFAR-100 5-shot & MiX/B/16 & 66 & 304 & 7.07e-2 ± 1.2e-3 & 7.07e-2 ± 1.2e-3 & 2.78e-2 ± 8.4e-4 & 1.76e-2 ± 6.6e-4 & \bfseries 1.70e-2 ± 6.3e-4 \\
IC & CIFAR-100 5-shot & MiX/L/16 & 57 & 312 & 7.06e-2 ± 1.6e-3 & 7.06e-2 ± 1.6e-3 & 4.17e-2 ± 1.4e-3 & 3.32e-2 ± 1.2e-3 & \bfseries 3.03e-2 ± 1.1e-3 \\
IC & CIFAR-100 5-shot & ViT/B/16 & 57 & 352 & 6.27e-2 ± 1.6e-3 & 6.27e-2 ± 1.6e-3 & 6.27e-2 ± 1.6e-3 & 4.30e-2 ± 1.3e-3 & \bfseries 2.86e-2 ± 1.1e-3 \\
IC & CIFAR-100 5-shot & ViT/S/16 & 43 & 710 & 6.93e-2 ± 1.2e-3 & \bfseries 2.84e-2 ± 8.2e-4 & 3.88e-2 ± 8.0e-4 & 3.16e-2 ± 7.5e-4 & 3.49e-2 ± 7.7e-4 \\
IC & Caltech101 10-shot & BiT/101/3 & 21 & 14 & 3.07e-1 ± 2.0e-2 & 3.07e-1 ± 2.0e-2 & 1.51e-1 ± 1.3e-2 & 1.00e-1 ± 1.1e-2 & \bfseries 4.97e-2 ± 5.8e-3 \\
IC & Caltech101 10-shot & BiT/50/1 & 30 & 16 & 3.29e-1 ± 1.6e-2 & 7.68e-2 ± 5.0e-3 & 1.13e-1 ± 6.0e-3 & 6.01e-2 ± 4.4e-3 & \bfseries 1.77e-2 ± 2.5e-3 \\
IC & Caltech101 10-shot & MiX/B/16 & 14 & 12 & \bfseries 1.35e-1 ± 1.4e-2 & 1.35e-1 ± 1.4e-2 & 1.35e-1 ± 1.4e-2 & 1.92e-1 ± 1.6e-2 & 2.04e-1 ± 9.7e-3 \\
IC & Caltech101 10-shot & MiX/L/16 & 12 & 11 & 1.25e-1 ± 1.3e-2 & 1.25e-1 ± 1.3e-2 & \bfseries 1.25e-1 ± 1.3e-2 & 1.30e-1 ± 1.2e-2 & 2.13e-1 ± 1.5e-2 \\
IC & Caltech101 10-shot & ViT/B/16 & 25 & 33 & 7.76e-2 ± 4.3e-3 & 7.76e-2 ± 4.3e-3 & \bfseries 3.11e-2 ± 3.0e-3 & 5.75e-2 ± 4.4e-3 & 4.02e-2 ± 3.9e-3 \\
IC & Caltech101 10-shot & ViT/S/16 & 35 & 55 & 1.95e-1 ± 6.0e-3 & 3.41e-2 ± 2.9e-3 & \bfseries 2.40e-2 ± 2.0e-3 & 3.41e-2 ± 2.9e-3 & 2.40e-2 ± 2.0e-3 \\
IC & Caltech101 25-shot & BiT/101/3 & 10 & 3 & 1.15e-1 ± 6.5e-3 & 1.15e-1 ± 6.5e-3 & 1.15e-1 ± 6.5e-3 & 1.15e-1 ± 6.5e-3 & \bfseries 9.86e-2 ± 8.0e-3 \\
IC & Caltech101 25-shot & BiT/50/1 & 28 & 16 & 3.60e-1 ± 1.9e-2 & 8.80e-2 ± 5.5e-3 & 1.43e-1 ± 7.6e-3 & 4.76e-2 ± 3.6e-3 & \bfseries 1.55e-2 ± 1.6e-3 \\
IC & Caltech101 25-shot & MiX/B/16 & 13 & 11 & \bfseries 8.28e-2 ± 1.2e-2 & 8.28e-2 ± 1.2e-2 & 8.28e-2 ± 1.2e-2 & 1.65e-1 ± 1.7e-2 & 1.93e-1 ± 1.3e-2 \\
IC & Caltech101 25-shot & MiX/L/16 & 12 & 12 & 9.66e-2 ± 1.0e-2 & 9.66e-2 ± 1.0e-2 & 9.66e-2 ± 1.0e-2 & \bfseries 9.66e-2 ± 1.0e-2 & 1.49e-1 ± 1.3e-2 \\
IC & Caltech101 25-shot & ViT/B/16 & 27 & 28 & 1.03e-1 ± 5.6e-3 & \bfseries 3.33e-2 ± 2.5e-3 & 4.46e-2 ± 3.6e-3 & 3.33e-2 ± 2.5e-3 & 3.95e-2 ± 5.4e-3 \\
IC & Caltech101 25-shot & ViT/S/16 & 15 & 54 & 1.77e-1 ± 5.4e-3 & 3.79e-2 ± 3.1e-3 & \bfseries 2.80e-2 ± 1.8e-3 & 3.79e-2 ± 3.1e-3 & 3.29e-2 ± 2.1e-3 \\
IC & Caltech101 5-shot & BiT/101/3 & 16 & 13 & 2.12e-1 ± 1.2e-2 & 2.12e-1 ± 1.2e-2 & 2.12e-1 ± 1.2e-2 & 1.65e-1 ± 9.4e-3 & \bfseries 1.87e-2 ± 4.3e-3 \\
IC & Caltech101 5-shot & BiT/50/1 & 35 & 54 & 2.34e-1 ± 6.1e-3 & 4.13e-2 ± 2.1e-3 & \bfseries 1.61e-2 ± 1.3e-3 & 4.69e-2 ± 2.1e-3 & 4.10e-2 ± 2.1e-3 \\
IC & Caltech101 5-shot & MiX/B/16 & 24 & 19 & 2.43e-1 ± 1.2e-2 & 2.43e-1 ± 1.2e-2 & 2.35e-1 ± 1.1e-2 & 7.28e-2 ± 4.3e-3 & \bfseries 1.92e-2 ± 1.9e-3 \\
IC & Caltech101 5-shot & MiX/L/16 & 14 & 13 & 1.38e-1 ± 9.7e-3 & 1.38e-1 ± 9.7e-3 & 1.38e-1 ± 9.7e-3 & \bfseries 1.37e-1 ± 9.9e-3 & 1.63e-1 ± 1.1e-2 \\
IC & Caltech101 5-shot & ViT/B/16 & 25 & 41 & 1.10e-1 ± 6.3e-3 & 1.10e-1 ± 6.3e-3 & 6.02e-2 ± 4.7e-3 & 6.81e-2 ± 4.8e-3 & \bfseries 3.87e-2 ± 3.4e-3 \\
IC & Caltech101 5-shot & ViT/S/16 & 40 & 82 & 1.90e-1 ± 4.7e-3 & 3.82e-2 ± 2.6e-3 & 5.04e-2 ± 2.9e-3 & 3.82e-2 ± 2.6e-3 & \bfseries 2.78e-2 ± 1.8e-3 \\
IC & ImageNet 10-shot & BiT/101/3 & 60 & 118 & 1.27e-1 ± 2.0e-3 & 1.27e-1 ± 2.0e-3 & 7.36e-2 ± 1.1e-3 & 3.06e-2 ± 7.0e-4 & \bfseries 2.08e-2 ± 5.5e-4 \\
IC & ImageNet 10-shot & BiT/50/1 & 68 & 262 & 9.54e-2 ± 7.2e-4 & 9.54e-2 ± 7.2e-4 & \bfseries 5.75e-3 ± 2.0e-4 & 1.86e-2 ± 2.8e-4 & 1.97e-2 ± 2.7e-4 \\
IC & ImageNet 10-shot & MiX/B/16 & 69 & 329 & 9.34e-2 ± 7.9e-4 & 9.34e-2 ± 7.9e-4 & 3.37e-2 ± 2.9e-4 & 2.32e-2 ± 3.0e-4 & \bfseries 1.68e-2 ± 2.5e-4 \\
IC & ImageNet 10-shot & MiX/L/16 & 66 & 249 & 9.83e-2 ± 1.3e-3 & 9.83e-2 ± 1.3e-3 & 9.83e-2 ± 1.3e-3 & \bfseries 4.01e-3 ± 1.9e-4 & 1.44e-2 ± 2.9e-4 \\
IC & ImageNet 10-shot & ViT/B/16 & 67 & 289 & 4.62e-2 ± 7.1e-4 & 4.62e-2 ± 7.1e-4 & 4.62e-2 ± 7.1e-4 & 1.44e-2 ± 3.0e-4 & \bfseries 7.73e-3 ± 2.7e-4 \\
IC & ImageNet 10-shot & ViT/S/16 & 65 & 310 & 4.74e-2 ± 5.6e-4 & 4.74e-2 ± 5.6e-4 & 1.66e-2 ± 2.5e-4 & 7.18e-3 ± 2.0e-4 & \bfseries 3.71e-3 ± 1.4e-4 \\
IC & ImageNet 25-shot & BiT/101/3 & 57 & 100 & 1.42e-1 ± 2.3e-3 & 1.42e-1 ± 2.3e-3 & 6.67e-2 ± 9.1e-4 & 3.31e-2 ± 8.7e-4 & \bfseries 1.85e-2 ± 6.2e-4 \\
IC & ImageNet 25-shot & BiT/50/1 & 68 & 263 & 1.17e-1 ± 9.2e-4 & 1.17e-1 ± 9.2e-4 & \bfseries 4.06e-3 ± 1.7e-4 & 1.84e-2 ± 2.6e-4 & 1.96e-2 ± 2.4e-4 \\
IC & ImageNet 25-shot & MiX/B/16 & 68 & 284 & 9.59e-2 ± 9.3e-4 & 9.59e-2 ± 9.3e-4 & 5.39e-2 ± 4.9e-4 & 2.04e-2 ± 3.1e-4 & \bfseries 8.56e-3 ± 2.3e-4 \\
IC & ImageNet 25-shot & MiX/L/16 & 66 & 226 & 1.03e-1 ± 1.3e-3 & 1.03e-1 ± 1.3e-3 & 1.03e-1 ± 1.3e-3 & \bfseries 6.33e-3 ± 2.2e-4 & 7.60e-3 ± 2.6e-4 \\
IC & ImageNet 25-shot & ViT/B/16 & 67 & 289 & 5.17e-2 ± 8.8e-4 & 5.17e-2 ± 8.8e-4 & 5.17e-2 ± 8.8e-4 & \bfseries 1.52e-2 ± 3.8e-4 & 1.98e-2 ± 4.3e-4 \\
IC & ImageNet 25-shot & ViT/S/16 & 65 & 311 & 5.52e-2 ± 4.4e-4 & 4.12e-2 ± 3.4e-4 & 9.65e-3 ± 2.3e-4 & 7.78e-3 ± 2.1e-4 & \bfseries 6.11e-3 ± 2.4e-4 \\
IC & ImageNet 5-shot & BiT/101/3 & 60 & 124 & 9.24e-2 ± 1.4e-3 & 9.24e-2 ± 1.4e-3 & 9.24e-2 ± 1.4e-3 & 2.09e-2 ± 7.9e-4 & \bfseries 8.05e-3 ± 5.0e-4 \\
IC & ImageNet 5-shot & BiT/50/1 & 69 & 305 & 8.95e-2 ± 6.7e-4 & 8.95e-2 ± 6.7e-4 & 1.53e-2 ± 2.2e-4 & 1.11e-2 ± 2.3e-4 & \bfseries 7.94e-3 ± 2.1e-4 \\
IC & ImageNet 5-shot & MiX/B/16 & 70 & 394 & 9.09e-2 ± 7.2e-4 & 9.09e-2 ± 7.2e-4 & 3.01e-2 ± 2.8e-4 & 1.95e-2 ± 2.7e-4 & \bfseries 9.60e-3 ± 2.3e-4 \\
IC & ImageNet 5-shot & MiX/L/16 & 67 & 240 & 7.99e-2 ± 9.7e-4 & 7.99e-2 ± 9.7e-4 & 7.99e-2 ± 9.7e-4 & 9.92e-3 ± 4.5e-4 & \bfseries 5.68e-3 ± 2.4e-4 \\
IC & ImageNet 5-shot & ViT/B/16 & 68 & 361 & 4.11e-2 ± 6.3e-4 & 4.11e-2 ± 6.3e-4 & 4.11e-2 ± 6.3e-4 & 1.55e-2 ± 2.8e-4 & \bfseries 1.29e-2 ± 2.7e-4 \\
IC & ImageNet 5-shot & ViT/S/16 & 66 & 323 & 4.20e-2 ± 4.1e-4 & 4.20e-2 ± 4.1e-4 & 2.40e-2 ± 2.6e-4 & 8.02e-3 ± 1.9e-4 & \bfseries 5.51e-3 ± 1.7e-4 \\
\end{tabular}
    \caption{
    Extrapolation Results on scaling behavior of Downstream Vision Tasks. See Section \ref{section:scaling_benchmark__vision} for more details. Numbers for M1, M2, M3, and M4 obtained via correspondence with authors of \cite{Alabdulmohsi2022revisiting}. 
    }
    \label{table:scaling_laws_benchmark_dataset__Vision}
\end{table}
\FloatBarrier

\iffalse

%\small is default
%\tiny, \scriptsize, \footnotesize, \small, \normalsize, \large, \Large, \LARGE, \huge, and \Huge
%\begin{table}[hbt!]
\begin{table}[]
%\tiny
%\footnotesize
\scriptsize
\setlength\tabcolsep{3.1pt} 
\setlength{\extrarowheight}{0.4pt}
\begin{tabular}
%{p{.021\textwidth}p{.165\textwidth}p{.111\textwidth}p{.028\textwidth}p{.022\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}}
%{Hp{.21\textwidth}p{.111\textwidth}HHp{.165\textwidth}p{.165\textwidth}p{.165\textwidth}p{.165\textwidth}p{.165\textwidth}}
%{Hp{.15\textwidth}p{.08\textwidth}HHp{.13\textwidth}p{.13\textwidth}p{.13\textwidth}p{.13\textwidth}p{.13\textwidth}}
{Hp{.14\textwidth}p{.08\textwidth}HH|p{.13\textwidth}|p{.13\textwidth}|p{.13\textwidth}|p{.13\textwidth}|p{.13\textwidth}}
%\begin{tabular}{llllrrrrrrrrrrrrl}
Domain & Task & Model & Train Points & Test Points & M1 $\downarrow$ & M2 $\downarrow$ & M3 $\downarrow$ & M4 $\downarrow$ & BNSL $\downarrow$ \\
\hline
IC & Birds 200 10-shot & BiT/101/3 & 57 & 107 & 9.13e-2 ± 2.8e-3 & 9.13e-2 ± 2.8e-3 & 9.13e-2 ± 2.8e-3 & 2.49e-2 ± 1.2e-3 & \bfseries 3.79e-3 ± 1.1e-3 \\
IC & Birds 200 10-shot & BiT/50/1 & 70 & 469 & 6.88e-2 ± 7.5e-4 & 6.88e-2 ± 7.5e-4 & 5.24e-2 ± 6.2e-4 & 2.48e-2 ± 5.1e-4 & \bfseries 4.96e-3 ± 3.9e-4 \\
IC & Birds 200 10-shot & MiX/B/16 & 69 & 383 & 9.15e-2 ± 1.1e-3 & 9.15e-2 ± 1.1e-3 & 3.95e-2 ± 7.0e-4 & 4.14e-2 ± 7.8e-4 & \bfseries 9.98e-3 ± 7.0e-4 \\
IC & Birds 200 10-shot & MiX/L/16 & 63 & 211 & 5.51e-2 ± 1.4e-3 & 5.51e-2 ± 1.4e-3 & 5.51e-2 ± 1.4e-3 & 4.59e-2 ± 1.6e-3 & \bfseries 8.41e-3 ± 1.3e-3 \\
IC & Birds 200 10-shot & ViT/B/16 & 65 & 316 & 6.77e-2 ± 1.1e-3 & 6.77e-2 ± 1.1e-3 & 3.52e-2 ± 8.1e-4 & 1.87e-2 ± 7.2e-4 & \bfseries 9.81e-3 ± 8.1e-4 \\
IC & Birds 200 10-shot & ViT/S/16 & 54 & 133 & 3.95e-2 ± 1.2e-3 & 3.95e-2 ± 1.2e-3 & 3.74e-2 ± 1.1e-3 & \bfseries 9.81e-3 ± 5.4e-4 & 1.51e-2 ± 8.4e-4 \\
IC & Birds 200 25-shot & BiT/101/3 & 53 & 78 & 9.41e-2 ± 3.2e-3 & 9.41e-2 ± 3.2e-3 & 9.41e-2 ± 3.2e-3 & 5.09e-2 ± 1.8e-3 & \bfseries 7.24e-3 ± 1.6e-3 \\
IC & Birds 200 25-shot & BiT/50/1 & 69 & 452 & 1.10e-1 ± 1.0e-3 & 7.29e-2 ± 8.0e-4 & 1.52e-2 ± 4.9e-4 & 1.63e-2 ± 5.1e-4 & \bfseries 8.00e-3 ± 6.1e-4 \\
IC & Birds 200 25-shot & MiX/B/16 & 67 & 293 & 1.40e-1 ± 1.9e-3 & 1.40e-1 ± 1.9e-3 & 6.93e-2 ± 1.2e-3 & 1.85e-2 ± 6.3e-4 & \bfseries 5.02e-3 ± 6.2e-4 \\
IC & Birds 200 25-shot & MiX/L/16 & 63 & 196 & 1.12e-1 ± 2.0e-3 & 1.12e-1 ± 2.0e-3 & 1.12e-1 ± 2.0e-3 & 4.88e-2 ± 1.8e-3 & \bfseries 1.05e-2 ± 1.7e-3 \\
IC & Birds 200 25-shot & ViT/B/16 & 64 & 271 & 9.02e-2 ± 1.6e-3 & 9.02e-2 ± 1.6e-3 & 3.75e-2 ± 1.0e-3 & 1.52e-2 ± 5.8e-4 & \bfseries 5.87e-3 ± 6.1e-4 \\
IC & Birds 200 25-shot & ViT/S/16 & 51 & 100 & 5.06e-2 ± 1.4e-3 & 5.06e-2 ± 1.4e-3 & 4.96e-2 ± 1.4e-3 & 3.28e-2 ± 1.1e-3 & \bfseries 1.21e-2 ± 8.5e-4 \\
IC & Birds 200 5-shot & BiT/101/3 & 62 & 180 & 8.17e-2 ± 2.0e-3 & 8.17e-2 ± 2.0e-3 & 8.17e-2 ± 2.0e-3 & 3.00e-2 ± 1.2e-3 & \bfseries 6.08e-3 ± 1.1e-3 \\
IC & Birds 200 5-shot & BiT/50/1 & 71 & 517 & 5.44e-2 ± 5.6e-4 & 5.44e-2 ± 5.6e-4 & 5.44e-2 ± 5.6e-4 & 2.63e-2 ± 5.4e-4 & \bfseries 5.79e-3 ± 3.7e-4 \\
IC & Birds 200 5-shot & MiX/B/16 & 71 & 494 & 8.27e-2 ± 1.0e-3 & 8.27e-2 ± 1.0e-3 & 5.49e-2 ± 7.8e-4 & 1.86e-2 ± 5.0e-4 & \bfseries 5.74e-3 ± 4.7e-4 \\
IC & Birds 200 5-shot & MiX/L/16 & 67 & 326 & 5.68e-2 ± 1.4e-3 & 5.68e-2 ± 1.4e-3 & 5.68e-2 ± 1.4e-3 & 2.65e-2 ± 9.0e-4 & \bfseries 5.06e-3 ± 6.4e-4 \\
IC & Birds 200 5-shot & ViT/B/16 & 65 & 284 & 3.40e-2 ± 8.9e-4 & 3.40e-2 ± 8.9e-4 & 3.40e-2 ± 8.9e-4 & 1.26e-2 ± 5.3e-4 & \bfseries 6.32e-3 ± 5.8e-4 \\
IC & Birds 200 5-shot & ViT/S/16 & 57 & 150 & 2.75e-2 ± 7.9e-4 & 2.75e-2 ± 7.9e-4 & 2.75e-2 ± 7.9e-4 & 1.56e-2 ± 5.9e-4 & \bfseries 6.93e-3 ± 4.8e-4 \\
IC & CIFAR-100 10-shot & BiT/101/3 & 47 & 60 & 8.57e-2 ± 3.8e-3 & 8.57e-2 ± 3.8e-3 & 8.25e-2 ± 3.7e-3 & 9.28e-2 ± 3.9e-3 & \bfseries 1.53e-2 ± 2.9e-3 \\
IC & CIFAR-100 10-shot & BiT/50/1 & 62 & 192 & 7.44e-2 ± 1.5e-3 & 1.24e-2 ± 5.8e-4 & 2.08e-2 ± 7.2e-4 & 1.23e-2 ± 5.7e-4 & \bfseries 9.74e-3 ± 7.1e-4 \\
IC & CIFAR-100 10-shot & MiX/B/16 & 65 & 248 & 8.77e-2 ± 1.9e-3 & 8.77e-2 ± 1.9e-3 & 2.71e-2 ± 1.2e-3 & 2.60e-2 ± 1.2e-3 & \bfseries 8.61e-3 ± 9.5e-4 \\
IC & CIFAR-100 10-shot & MiX/L/16 & 67 & 313 & 1.05e-1 ± 3.1e-3 & 1.05e-1 ± 3.1e-3 & 4.85e-2 ± 2.6e-3 & 4.76e-2 ± 1.7e-3 & \bfseries 1.55e-2 ± 1.6e-3 \\
IC & CIFAR-100 10-shot & ViT/B/16 & 67 & 354 & 8.98e-2 ± 2.0e-3 & 8.98e-2 ± 2.0e-3 & 8.98e-2 ± 2.0e-3 & 5.60e-2 ± 1.8e-3 & \bfseries 1.73e-2 ± 1.8e-3 \\
IC & CIFAR-100 10-shot & ViT/S/16 & 67 & 450 & 6.84e-2 ± 1.1e-3 & 2.11e-2 ± 6.6e-4 & 3.35e-2 ± 8.6e-4 & 2.47e-2 ± 7.4e-4 & \bfseries 1.15e-2 ± 7.5e-4 \\
IC & CIFAR-100 25-shot & BiT/101/3 & 41 & 38 & 8.77e-2 ± 5.6e-3 & 8.77e-2 ± 5.6e-3 & 4.44e-2 ± 3.5e-3 & 4.29e-2 ± 3.4e-3 & \bfseries 9.32e-3 ± 3.0e-3 \\
IC & CIFAR-100 25-shot & BiT/50/1 & 55 & 109 & 7.31e-2 ± 2.0e-3 & 2.35e-2 ± 1.5e-3 & 3.65e-2 ± 1.8e-3 & 2.36e-2 ± 1.5e-3 & \bfseries 2.00e-2 ± 1.8e-3 \\
IC & CIFAR-100 25-shot & MiX/B/16 & 64 & 202 & 1.08e-1 ± 2.3e-3 & 4.75e-2 ± 1.6e-3 & 2.10e-2 ± 9.4e-4 & 2.08e-2 ± 9.3e-4 & \bfseries 8.15e-3 ± 1.1e-3 \\
IC & CIFAR-100 25-shot & MiX/L/16 & 62 & 185 & 9.79e-2 ± 2.2e-3 & 9.79e-2 ± 2.2e-3 & 3.67e-2 ± 1.7e-3 & 2.79e-2 ± 1.3e-3 & \bfseries 8.47e-3 ± 1.6e-3 \\
IC & CIFAR-100 25-shot & ViT/B/16 & 66 & 355 & 1.07e-1 ± 1.9e-3 & 1.07e-1 ± 1.9e-3 & 6.54e-2 ± 1.6e-3 & \bfseries 4.81e-2 ± 1.4e-3 & 1.20e-1 ± 1.4e-3 \\
IC & CIFAR-100 25-shot & ViT/S/16 & 66 & 416 & 8.03e-2 ± 1.2e-3 & 2.19e-2 ± 7.4e-4 & 3.13e-2 ± 8.4e-4 & 2.19e-2 ± 7.0e-4 & \bfseries 1.34e-2 ± 8.5e-4 \\
IC & CIFAR-100 5-shot & BiT/101/3 & 47 & 59 & 5.94e-2 ± 3.2e-3 & 5.94e-2 ± 3.2e-3 & 5.94e-2 ± 3.2e-3 & 4.57e-2 ± 2.8e-3 & \bfseries 1.58e-2 ± 2.6e-3 \\
IC & CIFAR-100 5-shot & BiT/50/1 & 57 & 98 & 4.87e-2 ± 1.3e-3 & 4.87e-2 ± 1.3e-3 & \bfseries 1.69e-2 ± 8.8e-4 & 4.91e-2 ± 1.3e-3 & 1.95e-2 ± 1.0e-3 \\
IC & CIFAR-100 5-shot & MiX/B/16 & 66 & 304 & 7.07e-2 ± 1.2e-3 & 7.07e-2 ± 1.2e-3 & 2.78e-2 ± 8.4e-4 & 2.05e-2 ± 7.4e-4 & \bfseries 6.77e-3 ± 6.3e-4 \\
IC & CIFAR-100 5-shot & MiX/L/16 & 67 & 312 & 7.06e-2 ± 1.6e-3 & 7.06e-2 ± 1.6e-3 & 4.17e-2 ± 1.4e-3 & 3.14e-2 ± 1.1e-3 & \bfseries 1.18e-2 ± 1.3e-3 \\
IC & CIFAR-100 5-shot & ViT/B/16 & 67 & 352 & 6.27e-2 ± 1.6e-3 & 6.27e-2 ± 1.6e-3 & 6.27e-2 ± 1.6e-3 & 5.11e-2 ± 1.4e-3 & \bfseries 1.19e-2 ± 1.2e-3 \\
IC & CIFAR-100 5-shot & ViT/S/16 & 70 & 710 & 6.93e-2 ± 1.2e-3 & \bfseries 2.84e-2 ± 8.2e-4 & 3.88e-2 ± 8.0e-4 & 3.09e-2 ± 7.5e-4 & 6.40e-2 ± 7.7e-4 \\
IC & Caltech101 10-shot & BiT/101/3 & 21 & 14 & 3.07e-1 ± 2.0e-2 & 3.07e-1 ± 2.0e-2 & 1.51e-1 ± 1.3e-2 & 3.54e-2 ± 6.3e-3 & \bfseries 6.42e-3 ± 5.8e-3 \\
IC & Caltech101 10-shot & BiT/50/1 & 33 & 16 & 3.29e-1 ± 1.6e-2 & 7.68e-2 ± 5.0e-3 & 1.13e-1 ± 6.0e-3 & 6.31e-2 ± 4.4e-3 & \bfseries 5.37e-3 ± 2.2e-3 \\
IC & Caltech101 10-shot & MiX/B/16 & 14 & 12 & 1.35e-1 ± 1.4e-2 & 1.35e-1 ± 1.4e-2 & 1.35e-1 ± 1.4e-2 & 2.11e-1 ± 1.7e-2 & \bfseries 3.72e-2 ± 9.7e-3 \\
IC & Caltech101 10-shot & MiX/L/16 & 12 & 11 & 1.25e-1 ± 1.3e-2 & 1.25e-1 ± 1.3e-2 & 1.25e-1 ± 1.3e-2 & 1.92e-1 ± 1.6e-2 & \bfseries 3.73e-2 ± 1.5e-2 \\
IC & Caltech101 10-shot & ViT/B/16 & 34 & 33 & 7.76e-2 ± 4.3e-3 & 7.76e-2 ± 4.3e-3 & 3.11e-2 ± 3.0e-3 & 5.54e-2 ± 4.3e-3 & \bfseries 1.67e-2 ± 5.4e-3 \\
IC & Caltech101 10-shot & ViT/S/16 & 43 & 55 & 1.95e-1 ± 6.0e-3 & 3.41e-2 ± 2.9e-3 & \bfseries 2.40e-2 ± 2.0e-3 & 3.95e-2 ± 3.1e-3 & 3.31e-2 ± 5.3e-3 \\
IC & Caltech101 25-shot & BiT/101/3 & 10 & 3 & 1.15e-1 ± 6.5e-3 & 1.15e-1 ± 6.5e-3 & 1.15e-1 ± 6.5e-3 & 5.23e-2 ± 2.7e-3 & \bfseries 1.13e-2 ± 8.0e-3 \\
IC & Caltech101 25-shot & BiT/50/1 & 28 & 16 & 3.60e-1 ± 1.9e-2 & 8.80e-2 ± 5.5e-3 & 1.43e-1 ± 7.6e-3 & 5.95e-2 ± 4.1e-3 & \bfseries 2.13e-3 ± 1.6e-3 \\
IC & Caltech101 25-shot & MiX/B/16 & 13 & 11 & 8.28e-2 ± 1.2e-2 & 8.28e-2 ± 1.2e-2 & 8.28e-2 ± 1.2e-2 & 1.74e-1 ± 1.7e-2 & \bfseries 2.83e-2 ± 1.3e-2 \\
IC & Caltech101 25-shot & MiX/L/16 & 12 & 12 & 9.66e-2 ± 1.0e-2 & 9.66e-2 ± 1.0e-2 & 9.66e-2 ± 1.0e-2 & 1.03e-1 ± 9.5e-3 & \bfseries 1.98e-2 ± 1.3e-2 \\
IC & Caltech101 25-shot & ViT/B/16 & 27 & 28 & 1.03e-1 ± 5.6e-3 & 3.33e-2 ± 2.5e-3 & 4.46e-2 ± 3.6e-3 & 4.24e-2 ± 3.6e-3 & \bfseries 6.37e-3 ± 5.4e-3 \\
IC & Caltech101 25-shot & ViT/S/16 & 41 & 54 & 1.77e-1 ± 5.4e-3 & 3.79e-2 ± 3.1e-3 & 2.80e-2 ± 1.8e-3 & \bfseries 2.35e-2 ± 2.3e-3 & 2.38e-2 ± 4.7e-3 \\
IC & Caltech101 5-shot & BiT/101/3 & 16 & 13 & 2.12e-1 ± 1.2e-2 & 2.12e-1 ± 1.2e-2 & 2.12e-1 ± 1.2e-2 & 8.82e-2 ± 5.0e-3 & \bfseries 3.17e-3 ± 4.3e-3 \\
IC & Caltech101 5-shot & BiT/50/1 & 46 & 54 & 2.34e-1 ± 6.1e-3 & 4.13e-2 ± 2.1e-3 & 1.61e-2 ± 1.3e-3 & 4.49e-2 ± 2.1e-3 & \bfseries 1.33e-2 ± 2.2e-3 \\
IC & Caltech101 5-shot & MiX/B/16 & 24 & 19 & 2.43e-1 ± 1.2e-2 & 2.43e-1 ± 1.2e-2 & 2.35e-1 ± 1.1e-2 & 1.23e-1 ± 6.0e-3 & \bfseries 3.59e-3 ± 1.9e-3 \\
IC & Caltech101 5-shot & MiX/L/16 & 14 & 13 & 1.38e-1 ± 9.7e-3 & 1.38e-1 ± 9.7e-3 & 1.38e-1 ± 9.7e-3 & 3.19e-2 ± 2.6e-3 & \bfseries 3.19e-2 ± 1.1e-2 \\
IC & Caltech101 5-shot & ViT/B/16 & 38 & 41 & 1.10e-1 ± 6.3e-3 & 1.10e-1 ± 6.3e-3 & 6.02e-2 ± 4.7e-3 & 6.59e-2 ± 4.7e-3 & \bfseries 2.33e-2 ± 6.0e-3 \\
IC & Caltech101 5-shot & ViT/S/16 & 49 & 82 & 1.90e-1 ± 4.7e-3 & 3.82e-2 ± 2.6e-3 & 5.04e-2 ± 2.9e-3 & 4.06e-2 ± 2.7e-3 & \bfseries 2.47e-2 ± 3.8e-3 \\
IC & ImageNet 10-shot & BiT/101/3 & 60 & 118 & 1.27e-1 ± 2.0e-3 & 1.27e-1 ± 2.0e-3 & 7.36e-2 ± 1.1e-3 & 2.13e-2 ± 5.8e-4 & \bfseries 5.95e-3 ± 5.5e-4 \\
IC & ImageNet 10-shot & BiT/50/1 & 68 & 262 & 9.54e-2 ± 7.2e-4 & 9.54e-2 ± 7.2e-4 & \bfseries 5.75e-3 ± 2.0e-4 & 1.77e-2 ± 2.7e-4 & 8.93e-3 ± 2.7e-4 \\
IC & ImageNet 10-shot & MiX/B/16 & 69 & 329 & 9.34e-2 ± 7.9e-4 & 9.34e-2 ± 7.9e-4 & 3.37e-2 ± 2.9e-4 & 1.80e-2 ± 2.7e-4 & \bfseries 5.88e-3 ± 2.5e-4 \\
IC & ImageNet 10-shot & MiX/L/16 & 66 & 249 & 9.83e-2 ± 1.3e-3 & 9.83e-2 ± 1.3e-3 & 9.83e-2 ± 1.3e-3 & 9.48e-3 ± 2.4e-4 & \bfseries 3.81e-3 ± 2.9e-4 \\
IC & ImageNet 10-shot & ViT/B/16 & 67 & 289 & 4.62e-2 ± 7.1e-4 & 4.62e-2 ± 7.1e-4 & 4.62e-2 ± 7.1e-4 & 3.43e-2 ± 4.4e-4 & \bfseries 2.85e-3 ± 2.7e-4 \\
IC & ImageNet 10-shot & ViT/S/16 & 65 & 310 & 4.74e-2 ± 5.6e-4 & 4.74e-2 ± 5.6e-4 & 1.66e-2 ± 2.5e-4 & 1.14e-2 ± 2.4e-4 & \bfseries 1.97e-3 ± 1.4e-4 \\
IC & ImageNet 25-shot & BiT/101/3 & 57 & 100 & 1.42e-1 ± 2.3e-3 & 1.42e-1 ± 2.3e-3 & 6.67e-2 ± 9.1e-4 & 2.18e-2 ± 7.0e-4 & \bfseries 4.86e-3 ± 6.2e-4 \\
IC & ImageNet 25-shot & BiT/50/1 & 68 & 263 & 1.17e-1 ± 9.2e-4 & 1.17e-1 ± 9.2e-4 & \bfseries 4.06e-3 ± 1.7e-4 & 1.70e-2 ± 2.5e-4 & 8.14e-3 ± 2.4e-4 \\
IC & ImageNet 25-shot & MiX/B/16 & 68 & 284 & 9.59e-2 ± 9.3e-4 & 9.59e-2 ± 9.3e-4 & 5.39e-2 ± 4.9e-4 & 1.47e-2 ± 2.7e-4 & \bfseries 2.86e-3 ± 2.3e-4 \\
IC & ImageNet 25-shot & MiX/L/16 & 66 & 226 & 1.03e-1 ± 1.3e-3 & 1.03e-1 ± 1.3e-3 & 1.03e-1 ± 1.3e-3 & 6.09e-3 ± 2.5e-4 & \bfseries 1.94e-3 ± 2.6e-4 \\
IC & ImageNet 25-shot & ViT/B/16 & 67 & 289 & 5.17e-2 ± 8.8e-4 & 5.17e-2 ± 8.8e-4 & 5.17e-2 ± 8.8e-4 & 3.26e-2 ± 5.4e-4 & \bfseries 6.91e-3 ± 4.3e-4 \\
IC & ImageNet 25-shot & ViT/S/16 & 65 & 311 & 5.52e-2 ± 4.4e-4 & 4.12e-2 ± 3.4e-4 & 9.65e-3 ± 2.3e-4 & 1.16e-2 ± 2.2e-4 & \bfseries 3.09e-3 ± 2.4e-4 \\
IC & ImageNet 5-shot & BiT/101/3 & 60 & 124 & 9.24e-2 ± 1.4e-3 & 9.24e-2 ± 1.4e-3 & 9.24e-2 ± 1.4e-3 & 1.01e-2 ± 5.3e-4 & \bfseries 2.55e-3 ± 5.0e-4 \\
IC & ImageNet 5-shot & BiT/50/1 & 69 & 305 & 8.95e-2 ± 6.7e-4 & 8.95e-2 ± 6.7e-4 & 1.53e-2 ± 2.2e-4 & 1.03e-2 ± 2.3e-4 & \bfseries 4.00e-3 ± 2.1e-4 \\
IC & ImageNet 5-shot & MiX/B/16 & 70 & 394 & 9.09e-2 ± 7.2e-4 & 9.09e-2 ± 7.2e-4 & 3.01e-2 ± 2.8e-4 & 1.45e-2 ± 2.5e-4 & \bfseries 3.57e-3 ± 2.3e-4 \\
IC & ImageNet 5-shot & MiX/L/16 & 67 & 240 & 7.99e-2 ± 9.7e-4 & 7.99e-2 ± 9.7e-4 & 7.99e-2 ± 9.7e-4 & 5.66e-3 ± 3.1e-4 & \bfseries 1.63e-3 ± 2.4e-4 \\
IC & ImageNet 5-shot & ViT/B/16 & 68 & 361 & 4.11e-2 ± 6.3e-4 & 4.11e-2 ± 6.3e-4 & 4.11e-2 ± 6.3e-4 & 2.88e-2 ± 3.6e-4 & \bfseries 4.97e-3 ± 2.7e-4 \\
IC & ImageNet 5-shot & ViT/S/16 & 66 & 323 & 4.20e-2 ± 4.1e-4 & 4.20e-2 ± 4.1e-4 & 2.40e-2 ± 2.6e-4 & 1.44e-2 ± 2.2e-4 & \bfseries 3.00e-3 ± 1.7e-4 \\
\end{tabular}
    \caption{
    Extrapolation Results for Vision Tasks. See Section \ref{section:scaling_benchmark__vision} for more details. Numbers for M1, M2, M3, and M4 obtained via correspondence with authors of \cite{Alabdulmohsi2022revisiting}. 
    }
    \label{table:scaling_laws_benchmark_dataset__Vision}
\end{table}
\FloatBarrier

\fi

\subsection{Language}
\label{section:scaling_benchmark__language}
Using the scaling laws benchmark of \cite{Alabdulmohsi2022revisiting}, we evaluate how well various functional forms extrapolate performance on language tasks as the training dataset size increases. In this language subset of the benchmark, the tasks that are evaluated are error rates on each of the various downstream tasks from the BIG-Bench (BB) \cite{srivastava2022beyond} benchmark and upstream test cross-entropy of various models trained to do language modeling (LM) and neural machine translation (NMT). All LM and BB tasks use a decoder-only language model. As can be seen in Table \ref{table:scaling_laws_benchmark_dataset__summary} and \ref{table:scaling_laws_benchmark_dataset__language}, BNSL yields extrapolations with the lowest RMSLE (Root Mean Squared Logarithmic Error) for 55\% of tasks of any of the functional forms, while the next best functional form performs the best on only 25\% of the tasks.

% TODO: Should these sentence be removed.
% The one task subset where the extrapolations of BNSL are comparable (rather than significantly better) is upstream cross entropy of language modeling because in that task the RMSLE is already very low (i.e. lower than 1e-3) such that there is not much headroom to improve further. Sentence about 

To view all plots of the BNSL on each of these tasks, see Figures
\ref{fig:scaling_laws_benchmark_dataset__big_bench},
\ref{fig:scaling_laws_benchmark_dataset__nmt},
\ref{fig:scaling_laws_benchmark_dataset__language_modeling} in Appendix \ref{section:Plots_of_BNSL_Extrapolations}.

To view plots of M1, M2, M3, and M4 on these tasks, see Figure 8 of \cite{Alabdulmohsi2022revisiting}.

%While all of their functional forms tend to underestimate loss, ours has more of a tendency to overestimate loss, 
%^Ethan says: nah, this isn't a general trend from what I've seen.

\iffalse

\FloatBarrier
\begin{table}[htbp]

\tiny
\setlength\tabcolsep{3.1pt} 
\begin{tabular}
%{p{.02\textwidth}p{.165\textwidth}p{.095\textwidth}p{.01\textwidth}p{.01\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}}
{p{.021\textwidth}p{.165\textwidth}p{.111\textwidth}p{.028\textwidth}p{.025\textwidth}p{.11\textwidth}p{.11\textwidth}p{.11\textwidth}p{.11\textwidth}p{.11\textwidth}}
%\begin{tabular}{llllrrrrrrrrrrrrl}
Domain & \hspace{.9cm}Task & Model & Train Points & Test Points & M1 $\downarrow$ & M2 $\downarrow$ & M3 $\downarrow$ & M4 $\downarrow$ & BNSL $\downarrow$ \\
\hline
BB & date understanding, 1-shot & 2.62e+8 Param & 19 & 24 & 3.19e-2 ± 9.6e-4 & 3.09e-2 ± 9.2e-4 & \highlight{4.67e-3 ± 1.4e-4} & 1.49e-2 ± 5.9e-4 & 4.96e-3 ± 4.8e-5 \\
BB & date understanding, 2-shot & 2.62e+8 Param & 19 & 24 & 2.86e-2 ± 6.2e-4 & 2.44e-2 ± 5.6e-4 & 4.83e-3 ± 4.1e-4 & 1.58e-2 ± 5.0e-4 & \highlight{2.55e-3 ± 6.2e-4} \\
BB & linguistic mappings, 1-shot & 2.62e+8 Param & 19 & 24 & 1.66e-2 ± 5.5e-4 & \highlight{1.41e-2 ± 4.7e-4} & 1.66e-2 ± 5.5e-4 & 1.57e-2 ± 4.8e-4 & 2.22e-2 ± 8.2e-4 \\
BB & linguistic mappings, 2-shot & 2.62e+8 Param & 19 & 24 & 1.70e-2 ± 6.5e-4 & 1.30e-2 ± 5.4e-4 & 1.70e-2 ± 6.5e-4 & 9.25e-3 ± 5.1e-4 & \highlight{8.09e-3 ± 5.1e-4} \\
BB & mult data wrangling, 1-shot & 2.62e+8 Param & 19 & 24 & 1.07e-2 ± 1.0e-3 & 6.71e-3 ± 7.6e-4 & 1.07e-2 ± 1.0e-3 & 8.27e-3 ± 8.4e-4 & \highlight{6.17e-3 ± 8.4e-4} \\
BB & mult data wrangling, 2-shot & 2.62e+8 Param & 19 & 24 & 1.57e-2 ± 1.5e-3 & 7.22e-3 ± 8.9e-4 & 1.57e-2 ± 1.5e-3 & \highlight{5.01e-3 ± 5.0e-4} & 5.45e-3 ± 9.2e-4 \\
BB & qa wikidata, 1-shot & 2.62e+8 Param & 19 & 24 & \highlight{4.27e-3 ± 8.9e-4} & 5.14e-3 ± 5.3e-4 & 4.27e-3 ± 8.9e-4 & 5.05e-3 ± 5.6e-4 & 4.34e-3 ± 6.1e-4 \\
BB & qa wikidata, 2-shot & 2.62e+8 Param & 19 & 24 & 4.39e-3 ± 7.0e-4 & 7.35e-3 ± 6.1e-4 & 4.39e-3 ± 7.0e-4 & 7.12e-3 ± 6.0e-4 & \highlight{4.20e-3 ± 6.0e-4} \\
BB & unit conversion, 1-shot & 2.62e+8 Param & 19 & 24 & 8.30e-3 ± 4.4e-4 & 6.77e-3 ± 4.0e-4 & \highlight{1.48e-3 ± 2.7e-4} & 2.32e-3 ± 2.3e-4 & 6.32e-3 ± 2.5e-4 \\
BB & unit conversion, 2-shot & 2.62e+8 Param & 19 & 24 & 1.07e-2 ± 4.4e-4 & 9.15e-3 ± 4.7e-4 & 7.50e-3 ± 5.5e-4 & \highlight{2.83e-3 ± 4.8e-4} & 5.21e-3 ± 5.2e-4 \\
LM & upstream test cross-entropy& 1.07e+9 Param & 44 & 40 & 1.71e-2 ± 6.0e-4 & 1.02e-3 ± 3.5e-5 & 4.50e-3 ± 5.9e-5 & \highlight{3.79e-4 ± 4.0e-5} & 8.26e-4 ± 3.2e-5 \\
LM & upstream test cross-entropy& 4.53e+8 Param & 44 & 40 & 1.65e-2 ± 6.6e-4 & 6.47e-4 ± 8.5e-5 & 6.58e-4 ± 6.6e-5 & 8.54e-4 ± 4.7e-5 & \highlight{5.10e-4 ± 7.7e-5} \\
LM & upstream test cross-entropy& 2.62e+8 Param & 156 & 20 & 1.55e-2 ± 7.2e-4 & 1.01e-3 ± 9.4e-5 & 3.97e-3 ± 1.3e-4 & \highlight{9.37e-4 ± 9.7e-5} & 1.80e-3 ± 5.6e-5 \\
LM & upstream test cross-entropy& 1.34e+8 Param & 48 & 48 & 1.43e-2 ± 4.8e-4 & 1.33e-3 ± 6.5e-5 & \highlight{6.46e-4 ± 5.1e-5} & 8.14e-4 ± 5.3e-5 & 8.09e-4 ± 5.5e-5 \\
LM & upstream test cross-entropy& 1.68e+7 Param & 236 & 240 & 6.37e-3 ± 9.4e-5 & \highlight{3.08e-4 ± 1.3e-5} & 1.24e-3 ± 3.2e-5 & 3.27e-4 ± 1.5e-5 & 4.05e-4 ± 1.8e-5 \\
NMT & upstream test cross-entropy & 28 Enc, 6 Dec & 9 & 1 & 1.71e-1 ± 0 & 5.63e-2 ± 0 & 3.37e-2 ± 0 & 1.50e-2 ± 0 & \highlight{5.13e-3 ± 0} \\
NMT & upstream test cross-entropy & 6 Enc, 28 Dec & 10 & 1 & 2.34e-1 ± 0 & 5.27e-2 ± 0 & 1.65e-2 ± 0 & 3.21e-2 ± 0 & \highlight{9.81e-3 ± 0} \\
NMT & upstream test cross-entropy & 6 Enc, 6 Dec & 10 & 1 & 2.62e-1 ± 0 & 3.84e-2 ± 0 & 8.92e-2 ± 0 & \highlight{1.05e-2 ± 0} & 1.41e-2 ± 0 \\
NMT & upstream test cross-entropy & Dec-only, LM & 10 & 1 & 2.52e-1 ± 0 & 1.03e-2 ± 0 & 3.28e-2 ± 0 & 8.88e-3 ± 0 & \highlight{2.79e-3 ± 0} \\
NMT & upstream test cross-entropy & Trans-E, LSTM-D & 9 & 1 & 1.90e-1 ± 0 & 1.26e-2 ± 0 & 6.32e-2 ± 0 & 1.31e-2 ± 0 & \highlight{3.08e-3 ± 0} \\    
\end{tabular}
    \caption{
    Extrapolation Results for Language Tasks. See Section \ref{section:scaling_benchmark__language} for more details. Numbers for M1, M2, M3, and M4 were obtained via correspondence with authors of \cite{Alabdulmohsi2022revisiting}.
    }
    \label{table:scaling_laws_benchmark_dataset__language}
\end{table}
\FloatBarrier

\fi

\FloatBarrier
\begin{table}[htbp]

%\tiny
\scriptsize
\setlength\tabcolsep{2.1pt} 
\setlength{\extrarowheight}{0.4pt}
%\setlength{\columnseprule}{0.4pt}
\begin{tabular}
%{p{.021\textwidth}p{.165\textwidth}p{.111\textwidth}p{.028\textwidth}p{.022\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}}
%{p{.021\textwidth}p{.165\textwidth}p{.111\textwidth}HHp{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}}
%{p{.025\textwidth}p{.193\textwidth}p{.131\textwidth}HHp{.115\textwidth}p{.115\textwidth}p{.115\textwidth}p{.115\textwidth}p{.115\textwidth}}
{p{.031\textwidth}p{.192\textwidth}p{.106\textwidth}HH|p{.115\textwidth}|p{.115\textwidth}|p{.115\textwidth}|p{.115\textwidth}|p{.115\textwidth}}
%\begin{tabular}{llllrrrrrrrrrrrrl}
Domain & \hspace{.9cm}Task & Model & Train Points & Test Points & M1 $\downarrow$ & M2 $\downarrow$ & M3 $\downarrow$ & M4 $\downarrow$ & BNSL $\downarrow$ \\
\hline
BB & date understanding, 1-shot & 2.62e+8 Param & 16 & 24 & 3.19e-2 ± 9.6e-4 & 3.19e-2 ± 9.6e-4 & \bfseries 4.67e-3 ± 1.4e-4 & 3.19e-2 ± 9.6e-4 & 1.81e-2 ± 3.9e-4 \\
BB & date understanding, 2-shot & 2.62e+8 Param & 14 & 24 & 2.86e-2 ± 6.2e-4 & 2.86e-2 ± 6.2e-4 & \bfseries 4.83e-3 ± 4.1e-4 & 2.86e-2 ± 6.2e-4 & 5.41e-3 ± 1.0e-3 \\
BB & linguistic mappings, 1-shot & 2.62e+8 Param & 10 & 24 & 1.66e-2 ± 5.5e-4 & 1.62e-2 ± 5.4e-4 & 1.66e-2 ± 5.5e-4 & 1.33e-2 ± 3.8e-4 & \bfseries 1.13e-2 ± 2.2e-4 \\
BB & linguistic mappings, 2-shot & 2.62e+8 Param & 19 & 24 & 1.70e-2 ± 6.5e-4 & 1.70e-2 ± 6.5e-4 & 1.70e-2 ± 6.5e-4 & 1.06e-2 ± 5.1e-4 & \bfseries 9.51e-3 ± 5.1e-4 \\
BB & mult data wrangling, 1-shot & 2.62e+8 Param & 11 & 24 & 1.07e-2 ± 1.0e-3 & 1.07e-2 ± 1.0e-3 & 1.07e-2 ± 1.0e-3 & 6.66e-3 ± 7.3e-4 & \bfseries 6.39e-3 ± 4.6e-4 \\
BB & mult data wrangling, 2-shot & 2.62e+8 Param & 10 & 24 & 1.57e-2 ± 1.5e-3 & 1.57e-2 ± 1.5e-3 & 1.57e-2 ± 1.5e-3 & 5.79e-3 ± 7.0e-4 & \bfseries 2.67e-3 ± 2.7e-4 \\
BB & qa wikidata, 1-shot & 2.62e+8 Param & 16 & 24 & \bfseries 4.27e-3 ± 8.9e-4 & 4.32e-3 ± 8.2e-4 & 4.27e-3 ± 8.9e-4 & 4.32e-3 ± 8.2e-4 & 4.68e-3 ± 7.3e-4 \\
BB & qa wikidata, 2-shot & 2.62e+8 Param & 16 & 24 & \bfseries 4.39e-3 ± 7.0e-4 & 4.66e-3 ± 6.4e-4 & 4.39e-3 ± 7.0e-4 & 9.02e-3 ± 6.9e-4 & 8.05e-3 ± 7.3e-4 \\
BB & unit conversion, 1-shot & 2.62e+8 Param & 12 & 24 & 8.30e-3 ± 4.4e-4 & 8.30e-3 ± 4.4e-4 & \bfseries 1.48e-3 ± 2.7e-4 & 4.79e-3 ± 3.4e-4 & 5.73e-2 ± 4.6e-3 \\
BB & unit conversion, 2-shot & 2.62e+8 Param & 12 & 24 & 1.07e-2 ± 4.4e-4 & 1.07e-2 ± 4.4e-4 & \bfseries 7.50e-3 ± 5.5e-4 & 7.55e-3 ± 5.1e-4 & 7.74e-2 ± 5.7e-3 \\
LM & upstream test cross-entropy& 1.07e+9 Param & 44 & 40 & 1.71e-2 ± 6.0e-4 & 1.66e-3 ± 5.1e-5 & 4.50e-3 ± 5.9e-5 & 1.28e-3 ± 3.9e-5 & \bfseries 9.71e-4 ± 3.2e-5 \\
LM & upstream test cross-entropy& 1.34e+8 Param & 48 & 48 & 1.43e-2 ± 4.8e-4 & 1.46e-3 ± 6.8e-5 & \bfseries 6.46e-4 ± 5.1e-5 & 1.46e-3 ± 6.8e-5 & 9.01e-4 ± 5.5e-5 \\
LM & upstream test cross-entropy& 1.68e+7 Param & 236 & 240 & 6.37e-3 ± 9.4e-5 & \bfseries 3.03e-4 ± 1.2e-5 & 1.56e-3 ± 3.5e-5 & 3.03e-4 ± 1.2e-5 & 4.34e-4 ± 1.8e-5 \\
LM & upstream test cross-entropy& 2.62e+8 Param & 156 & 20 & 1.55e-2 ± 7.2e-4 & \bfseries 9.20e-4 ± 9.7e-5 & 3.97e-3 ± 1.3e-4 & 9.20e-4 ± 9.7e-5 & 2.05e-3 ± 5.6e-5 \\
LM & upstream test cross-entropy& 4.53e+8 Param & 44 & 40 & 1.65e-2 ± 6.6e-4 & 7.41e-4 ± 9.8e-5 & 6.58e-4 ± 6.6e-5 & 7.41e-4 ± 9.8e-5 & \bfseries 5.86e-4 ± 7.7e-5 \\
NMT & upstream test cross-entropy & 28 Enc, 6 Dec & 9 & 1 & 1.71e-1 ± 0 & 5.64e-2 ± 0 & 3.37e-2 ± 0 & 1.81e-2 ± 0 & \bfseries 1.69e-2 ± 0 \\
NMT & upstream test cross-entropy & 6 Enc, 28 Dec & 10 & 1 & 2.34e-1 ± 0 & 5.27e-2 ± 0 & 1.65e-2 ± 0 & 4.44e-2 ± 0 & \bfseries 1.56e-2 ± 0 \\
NMT & upstream test cross-entropy & 6 Enc, 6 Dec & 10 & 1 & 2.62e-1 ± 0 & 3.84e-2 ± 0 & 8.92e-2 ± 0 & 2.05e-2 ± 0 & \bfseries 1.37e-3 ± 0 \\
NMT & upstream test cross-entropy & Dec-only, LM & 10 & 1 & 2.52e-1 ± 0 & 1.03e-2 ± 0 & 3.28e-2 ± 0 & 8.43e-3 ± 0 & \bfseries 7.33e-3 ± 0 \\
NMT & upstream test cross-entropy & Transformer-Enc, LSTM-Dec & 9 & 1 & 1.90e-1 ± 0 & 1.26e-2 ± 0 & 6.32e-2 ± 0 & 1.26e-2 ± 0 & \bfseries 8.30e-3 ± 0 \\
\end{tabular}
    \caption{
    Extrapolation Results on scaling behavior of Language Tasks. See Section \ref{section:scaling_benchmark__language} for more details. Numbers for M1, M2, M3, and M4 were obtained via correspondence with authors of \cite{Alabdulmohsi2022revisiting}. BB stands for BIG-Bench \citep{srivastava2022beyond}. NMT stands for Neural Machine Translation. LM stands for Language Modeling.
    }
    \label{table:scaling_laws_benchmark_dataset__language}
\end{table}
\FloatBarrier

%LM & upstream test cross-entropy& 1.07e+9 Param & 44 & 40 & 1.71e-2 ± 6.0e-4 & 1.02e-3 ± 3.5e-5 & 4.50e-3 ± 5.9e-5 & \bfseries 3.79e-4 ± 4.0e-5 & \bfseries 8.26e-4 ± 3.2e-5 \\
%LM & upstream test cross-entropy& 1.34e+8 Param & 48 & 48 & 1.43e-2 ± 4.8e-4 & 1.33e-3 ± 6.5e-5 & \bfseries 6.46e-4 ± 5.1e-5 & \bfseries 8.14e-4 ± 5.3e-5 & \bfseries 8.09e-4 ± 5.5e-5 \\
%LM & upstream test cross-entropy& 1.68e+7 Param & 236 & 240 & 6.37e-3 ± 9.4e-5 & \bfseries 3.08e-4 ± 1.3e-5 & 1.24e-3 ± 3.2e-5 & \bfseries 3.27e-4 ± 1.5e-5 & \bfseries 4.05e-4 ± 1.8e-5 \\
%LM & upstream test cross-entropy& 2.62e+8 Param & 156 & 20 & 1.55e-2 ± 7.2e-4 & 1.01e-3 ± 9.4e-5 & 3.97e-3 ± 1.3e-4 & \bfseries 9.37e-4 ± 9.7e-5 & 1.80e-3 ± 5.6e-5 \\
%LM & upstream test cross-entropy& 4.53e+8 Param & 44 & 40 & 1.65e-2 ± 6.6e-4 & \bfseries 6.47e-4 ± 8.5e-5 & \bfseries 6.58e-4 ± 6.6e-5 & \bfseries 8.54e-4 ± 4.7e-5 & \bfseries 5.10e-4 ± 7.7e-5 \\
%\end{tabular}
%    \caption{
%    Extrapolation Results for Language Tasks. See Section \ref{section:scaling_benchmark__language} for more details. Numbers for M1, M2, M3, and M4 obtained via correspondence with authors of \cite{Alabdulmohsi2022revisiting}. Bolded if lowest in row or below 1e-3.
%    }
%    \label{table:scaling_laws_benchmark_dataset__language}
%\end{table}

\subsection{Non-Monotonic Scaling}


\FloatBarrier

\label{section:non-monotonic_scaling}
We show that BNSL accurately models and extrapolates non-monotonic scaling behaviors that are exhibited by Transformers (\cite{vaswani2017attention}) in double descent \citep{nakkiran2021deep} in Figure \ref{fig:double_descent}. Various other functional forms are mathematically incapable of expressing non-monotonic behaviors (as shown in Section \ref{section:math_proofs}).

%TODO: mention that transformer was used

\FloatBarrier
\begin{figure*}[h]%tbp]
    \centering


\includegraphics[width=0.42\textwidth]{figures/double_descent/double_descent__model_size.png}
\includegraphics[width=0.42\textwidth]{figures/double_descent/double_descent__dataset_size_1.png}

    \caption{
    Extrapolation of BNSL on Double Descent. Both plots are of transformers trained to do neural machine translation via minimizing cross-entropy. Experimental data of left figure is obtained from Figure 8 top of \cite{nakkiran2021deep}; ``Model Width" on the x-axis refers to embedding dimension $d_{model}$ of the transformer. Experimental data of the right figure is obtained from Figure 11b of \cite{nakkiran2021deep}. The plot on the left contains two breaks of a BNSL fit to the black points. See Section \ref{section:non-monotonic_scaling} for more details.
    }
    \label{fig:double_descent}
\end{figure*}
%\FloatBarrier

\FloatBarrier

\subsection{Reinforcement Learning}

\label{section:reinforcement_learning}

\FloatBarrier

We show that BNSL accurately models and extrapolates the scaling behaviors of various multi-agent and single-agent reinforcement learning algorithms trained in various environments. In the top left plot and top right plot and bottom left plot of Figure \ref{fig:rl_scaling}, BNSL accurately models and extrapolates the scaling behavior of the AlphaZero algorithm trained to play the game Connect Four from Figure 4 and Figure 5 and Figure 3 respectively of \cite{neumann2022scaling}; the x-axes respectively are compute (FLOPs) used for training, training dataset size (states), and number of model parameters. In Figure \ref{fig:rl_scaling} bottom right, BNSL accurately models and extrapolates the scaling behavior of the Proximal Policy Optimization (PPO) algorithm \cite{schulman2017proximal} trained to play the Procgen \citep{cobbe2020leveraging} game called Heist.


\begin{figure*}[hhh]%tbp]
    \centering


%\includegraphics[width=0.45\textwidth]{figures/rl/reanalyze/reanalyze__ms_pacman_dataset_size__fit.png}
%\includegraphics[height=0.345\textwidth]{figures/rl/procgen/Procgen_Heist.png}

\includegraphics[width=.42\textwidth]{figures/rl/connect_four/connect_four__compute.png}
\includegraphics[width=.42\textwidth]{figures/rl/connect_four/connect_four__data.png}

\includegraphics[width=.42\textwidth]{figures/rl/connect_four/connect_four__parameters.png}
\includegraphics[width=.42\textwidth]{figures/rl/procgen/Procgen_Heist.png}
    \caption{
    %Fit of BNSL to Reinforcement Learning Scaling Data. Experimental Data of the left plot is from Figure 1 of \cite{schrittwieser2021online}. Experimental Data of the right plot is from Figure 2 of \cite{cobbe2020leveraging}.
    Extrapolation of BNSL on Reinforcement Learning Scaling Experimental Data. Experimental data of the top left plot and top right plot and bottom left plot is from Figure 4 and Figure 5 and Figure 3 respectively of \cite{neumann2022scaling}. Experimental Data of the bottom right plot is from Figure 2 of \cite{cobbe2020leveraging}. Top left plot is the compute-optimal Pareto frontier. See Section \ref{section:reinforcement_learning} for more details.
    % 3 params
    % 4 compute
    % 5 data
    }
    \label{fig:rl_scaling}
\end{figure*}
\FloatBarrier

\subsection{Definition of Root Standard Log Error}
\label{section:definition_of_Root_Standard_Log_Error}

\[error = (log(y_{i})-log(\hat{y}_{i}))^2)\] 
\[\mu_{error} = \frac{1}{N}\sum_{i=1}^N error\]
\[\sigma_{error} = \sqrt{\frac{1}{N-1}\sum_{i=1}^N(error_i-\mu_{error})^2}\]
\[Root\_Standard\_Log\_Error = \sqrt{\mu_{error} + \frac{\sigma_{error}}{\sqrt{len(\hat{y})}}} - \sqrt{\mu_{error}}\] 

% how root standard log error is calculated
%error = (np.log(yp) - np.log(y)) ** 2
%errmu = np.mean(error)
%rstderr = np.sqrt(errmu + np.std(error) / (len(yp)**0.5)) - np.sqrt(errmu)

\subsection{Experimental details of Section \ref{section:Inflection_Points}}
\label{section:Inflection_points_experimental}
We perform an extensive set of experiments to model and extrapolate the scaling behavior for the 4-digit arithmetic addition task with respect to the training dataset size. Our code is based on the minGPT implementation \cite{Karpathy2020}. We set the batch size equal to the training dataset size. We do not use dropout or a learning rate decay here. Each experiment was run on a single V100 GPU and each run took less than 2 hours. For our experiments we train the transformer model using the following set of hyperparameters:
\begin{table}[hbt!]
    \centering
    \begin{tabular}{c|c}
         $D_{model}$ & 128 \\
         $D_{MLP}$ & 512 \\
         Number of heads & 2 \\
         Number of transformer blocks (i.e. layers) & 1 \\
         Learning rate & 0.0001\\
         Weight Decay & 0.1\\
         Dropout Probability & 0.0\\
         Dataset sizes & 144-1008 \\
         Vocab Size & 10 \\
         
         % Test set size & 1000\\
    \end{tabular}
    \caption{Hyperparameters for 4-digit addition task}
    \label{tab:my_label}
\end{table}

\subsection{Experimental details of fitting BNSL}
\label{section:BNSL_fit_details}
We fit BNSL as follows:
We first use scipy.optimize.brute to do a grid search of the values of the constants ($a, b, c, d_1 ...  d_n, f_1 ... f_n, g_1 ... g_n$) of BNSL that best minimize the mean squared log error (MSLE) between the real data and the output of BNSL.
We then use the values obtained from the grid search as the initialization of the non-linear least squares algorithm of scipy.optimize.curve\_fit.
We then use the non-linear least squares algorithm of scipy.optimize.curve\_fit to minimize the mean squared log error (MSLE) between the real data and the output of BNSL.

The version of MSLE we use for such optimization is the following numerically stable variant:

\[Numerically\_Stable\_MSLE = \sum_{i=1}^{n} ((log(y_{i}+1)-log(\hat{y}_{i}+1))^2)/n\] 
\clearpage
% \subsection{Tables on the Scaling Laws Benchmark}
% \label{all_scaling_laws}

% % \subsection{Table of Extrapolations}

% % \FloatBarrier

% \begin{table}[!hbt]
% \tiny
% \setlength\tabcolsep{3.1pt} 
% \begin{tabular}
% %{p{.02\textwidth}p{.165\textwidth}p{.095\textwidth}p{.01\textwidth}p{.01\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}}
% {p{.021\textwidth}p{.165\textwidth}p{.111\textwidth}p{.028\textwidth}p{.022\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}}
% %\begin{tabular}{llllrrrrrrrrrrrrl}
% Domain & \hspace{.9cm}Task & Model & Train Points & Test Points & M1 $\downarrow$ & M2 $\downarrow$ & M3 $\downarrow$ & M4 $\downarrow$ & BNSL $\downarrow$ \\
% \hline
% IC & Birds 200 10-shot & BiT/101/3 & 57 & 107 & 9.13e-2 ± 2.8e-3 & 9.13e-2 ± 2.8e-3 & 9.13e-2 ± 2.8e-3 & 2.49e-2 ± 1.2e-3 & \bfseries 3.79e-3 ± 1.1e-3 \\
% IC & Birds 200 10-shot & BiT/50/1 & 70 & 469 & 6.88e-2 ± 7.5e-4 & 6.88e-2 ± 7.5e-4 & 5.24e-2 ± 6.2e-4 & 2.48e-2 ± 5.1e-4 & \bfseries 4.96e-3 ± 3.9e-4 \\
% IC & Birds 200 10-shot & MiX/B/16 & 69 & 383 & 9.15e-2 ± 1.1e-3 & 9.15e-2 ± 1.1e-3 & 3.95e-2 ± 7.0e-4 & 4.14e-2 ± 7.8e-4 & \bfseries 9.98e-3 ± 7.0e-4 \\
% IC & Birds 200 10-shot & MiX/L/16 & 63 & 211 & 5.51e-2 ± 1.4e-3 & 5.51e-2 ± 1.4e-3 & 5.51e-2 ± 1.4e-3 & 4.59e-2 ± 1.6e-3 & \bfseries 8.41e-3 ± 1.3e-3 \\
% IC & Birds 200 10-shot & ViT/B/16 & 65 & 316 & 6.77e-2 ± 1.1e-3 & 6.77e-2 ± 1.1e-3 & 3.52e-2 ± 8.1e-4 & 1.87e-2 ± 7.2e-4 & \bfseries 9.81e-3 ± 8.1e-4 \\
% IC & Birds 200 10-shot & ViT/S/16 & 54 & 133 & 3.95e-2 ± 1.2e-3 & 3.95e-2 ± 1.2e-3 & 3.74e-2 ± 1.1e-3 & \bfseries 9.81e-3 ± 5.4e-4 & 1.51e-2 ± 8.4e-4 \\
% IC & Birds 200 25-shot & BiT/101/3 & 53 & 78 & 9.41e-2 ± 3.2e-3 & 9.41e-2 ± 3.2e-3 & 9.41e-2 ± 3.2e-3 & 5.09e-2 ± 1.8e-3 & \bfseries 7.24e-3 ± 1.6e-3 \\
% IC & Birds 200 25-shot & BiT/50/1 & 69 & 452 & 1.10e-1 ± 1.0e-3 & 7.29e-2 ± 8.0e-4 & 1.52e-2 ± 4.9e-4 & 1.63e-2 ± 5.1e-4 & \bfseries 8.00e-3 ± 6.1e-4 \\
% IC & Birds 200 25-shot & MiX/B/16 & 67 & 293 & 1.40e-1 ± 1.9e-3 & 1.40e-1 ± 1.9e-3 & 6.93e-2 ± 1.2e-3 & 1.85e-2 ± 6.3e-4 & \bfseries 5.02e-3 ± 6.2e-4 \\
% IC & Birds 200 25-shot & MiX/L/16 & 63 & 196 & 1.12e-1 ± 2.0e-3 & 1.12e-1 ± 2.0e-3 & 1.12e-1 ± 2.0e-3 & 4.88e-2 ± 1.8e-3 & \bfseries 1.05e-2 ± 1.7e-3 \\
% IC & Birds 200 25-shot & ViT/B/16 & 64 & 271 & 9.02e-2 ± 1.6e-3 & 9.02e-2 ± 1.6e-3 & 3.75e-2 ± 1.0e-3 & 1.52e-2 ± 5.8e-4 & \bfseries 5.87e-3 ± 6.1e-4 \\
% IC & Birds 200 25-shot & ViT/S/16 & 51 & 100 & 5.06e-2 ± 1.4e-3 & 5.06e-2 ± 1.4e-3 & 4.96e-2 ± 1.4e-3 & 3.28e-2 ± 1.1e-3 & \bfseries 1.21e-2 ± 8.5e-4 \\
% IC & Birds 200 5-shot & BiT/101/3 & 62 & 180 & 8.17e-2 ± 2.0e-3 & 8.17e-2 ± 2.0e-3 & 8.17e-2 ± 2.0e-3 & 3.00e-2 ± 1.2e-3 & \bfseries 6.08e-3 ± 1.1e-3 \\
% IC & Birds 200 5-shot & BiT/50/1 & 71 & 517 & 5.44e-2 ± 5.6e-4 & 5.44e-2 ± 5.6e-4 & 5.44e-2 ± 5.6e-4 & 2.63e-2 ± 5.4e-4 & \bfseries 5.79e-3 ± 3.7e-4 \\
% IC & Birds 200 5-shot & MiX/B/16 & 71 & 494 & 8.27e-2 ± 1.0e-3 & 8.27e-2 ± 1.0e-3 & 5.49e-2 ± 7.8e-4 & 1.86e-2 ± 5.0e-4 & \bfseries 5.74e-3 ± 4.7e-4 \\
% IC & Birds 200 5-shot & MiX/L/16 & 67 & 326 & 5.68e-2 ± 1.4e-3 & 5.68e-2 ± 1.4e-3 & 5.68e-2 ± 1.4e-3 & 2.65e-2 ± 9.0e-4 & \bfseries 5.06e-3 ± 6.4e-4 \\
% IC & Birds 200 5-shot & ViT/B/16 & 65 & 284 & 3.40e-2 ± 8.9e-4 & 3.40e-2 ± 8.9e-4 & 3.40e-2 ± 8.9e-4 & 1.26e-2 ± 5.3e-4 & \bfseries 6.32e-3 ± 5.8e-4 \\
% IC & Birds 200 5-shot & ViT/S/16 & 57 & 150 & 2.75e-2 ± 7.9e-4 & 2.75e-2 ± 7.9e-4 & 2.75e-2 ± 7.9e-4 & 1.56e-2 ± 5.9e-4 & \bfseries 6.93e-3 ± 4.8e-4 \\
% IC & CIFAR-100 10-shot & BiT/101/3 & 47 & 60 & 8.57e-2 ± 3.8e-3 & 8.57e-2 ± 3.8e-3 & 8.25e-2 ± 3.7e-3 & 9.28e-2 ± 3.9e-3 & \bfseries 1.53e-2 ± 2.9e-3 \\
% IC & CIFAR-100 10-shot & BiT/50/1 & 62 & 192 & 7.44e-2 ± 1.5e-3 & 1.24e-2 ± 5.8e-4 & 2.08e-2 ± 7.2e-4 & 1.23e-2 ± 5.7e-4 & \bfseries 9.74e-3 ± 7.1e-4 \\
% IC & CIFAR-100 10-shot & MiX/B/16 & 65 & 248 & 8.77e-2 ± 1.9e-3 & 8.77e-2 ± 1.9e-3 & 2.71e-2 ± 1.2e-3 & 2.60e-2 ± 1.2e-3 & \bfseries 8.61e-3 ± 9.5e-4 \\
% IC & CIFAR-100 10-shot & MiX/L/16 & 67 & 313 & 1.05e-1 ± 3.1e-3 & 1.05e-1 ± 3.1e-3 & 4.85e-2 ± 2.6e-3 & 4.76e-2 ± 1.7e-3 & \bfseries 1.55e-2 ± 1.6e-3 \\
% IC & CIFAR-100 10-shot & ViT/B/16 & 67 & 354 & 8.98e-2 ± 2.0e-3 & 8.98e-2 ± 2.0e-3 & 8.98e-2 ± 2.0e-3 & 5.60e-2 ± 1.8e-3 & \bfseries 1.73e-2 ± 1.8e-3 \\
% IC & CIFAR-100 10-shot & ViT/S/16 & 67 & 450 & 6.84e-2 ± 1.1e-3 & 2.11e-2 ± 6.6e-4 & 3.35e-2 ± 8.6e-4 & 2.47e-2 ± 7.4e-4 & \bfseries 1.15e-2 ± 7.5e-4 \\
% IC & CIFAR-100 25-shot & BiT/101/3 & 41 & 38 & 8.77e-2 ± 5.6e-3 & 8.77e-2 ± 5.6e-3 & 4.44e-2 ± 3.5e-3 & 4.29e-2 ± 3.4e-3 & \bfseries 9.32e-3 ± 3.0e-3 \\
% IC & CIFAR-100 25-shot & BiT/50/1 & 55 & 109 & 7.31e-2 ± 2.0e-3 & 2.35e-2 ± 1.5e-3 & 3.65e-2 ± 1.8e-3 & 2.36e-2 ± 1.5e-3 & \bfseries 2.00e-2 ± 1.8e-3 \\
% IC & CIFAR-100 25-shot & MiX/B/16 & 64 & 202 & 1.08e-1 ± 2.3e-3 & 4.75e-2 ± 1.6e-3 & 2.10e-2 ± 9.4e-4 & 2.08e-2 ± 9.3e-4 & \bfseries 8.15e-3 ± 1.1e-3 \\
% IC & CIFAR-100 25-shot & MiX/L/16 & 62 & 185 & 9.79e-2 ± 2.2e-3 & 9.79e-2 ± 2.2e-3 & 3.67e-2 ± 1.7e-3 & 2.79e-2 ± 1.3e-3 & \bfseries 8.47e-3 ± 1.6e-3 \\
% IC & CIFAR-100 25-shot & ViT/B/16 & 66 & 355 & 1.07e-1 ± 1.9e-3 & 1.07e-1 ± 1.9e-3 & 6.54e-2 ± 1.6e-3 & \bfseries 4.81e-2 ± 1.4e-3 & 1.20e-1 ± 1.4e-3 \\
% IC & CIFAR-100 25-shot & ViT/S/16 & 66 & 416 & 8.03e-2 ± 1.2e-3 & 2.19e-2 ± 7.4e-4 & 3.13e-2 ± 8.4e-4 & 2.19e-2 ± 7.0e-4 & \bfseries 1.34e-2 ± 8.5e-4 \\
% IC & CIFAR-100 5-shot & BiT/101/3 & 47 & 59 & 5.94e-2 ± 3.2e-3 & 5.94e-2 ± 3.2e-3 & 5.94e-2 ± 3.2e-3 & 4.57e-2 ± 2.8e-3 & \bfseries 1.58e-2 ± 2.6e-3 \\
% IC & CIFAR-100 5-shot & BiT/50/1 & 57 & 98 & 4.87e-2 ± 1.3e-3 & 4.87e-2 ± 1.3e-3 & \bfseries 1.69e-2 ± 8.8e-4 & 4.91e-2 ± 1.3e-3 & 1.95e-2 ± 1.0e-3 \\
% IC & CIFAR-100 5-shot & MiX/B/16 & 66 & 304 & 7.07e-2 ± 1.2e-3 & 7.07e-2 ± 1.2e-3 & 2.78e-2 ± 8.4e-4 & 2.05e-2 ± 7.4e-4 & \bfseries 6.77e-3 ± 6.3e-4 \\
% IC & CIFAR-100 5-shot & MiX/L/16 & 67 & 312 & 7.06e-2 ± 1.6e-3 & 7.06e-2 ± 1.6e-3 & 4.17e-2 ± 1.4e-3 & 3.14e-2 ± 1.1e-3 & \bfseries 1.18e-2 ± 1.3e-3 \\
% IC & CIFAR-100 5-shot & ViT/B/16 & 67 & 352 & 6.27e-2 ± 1.6e-3 & 6.27e-2 ± 1.6e-3 & 6.27e-2 ± 1.6e-3 & 5.11e-2 ± 1.4e-3 & \bfseries 1.19e-2 ± 1.2e-3 \\
% IC & CIFAR-100 5-shot & ViT/S/16 & 70 & 710 & 6.93e-2 ± 1.2e-3 & \bfseries 2.84e-2 ± 8.2e-4 & 3.88e-2 ± 8.0e-4 & 3.09e-2 ± 7.5e-4 & 6.40e-2 ± 7.7e-4 \\
% IC & Caltech101 10-shot & BiT/101/3 & 21 & 14 & 3.07e-1 ± 2.0e-2 & 3.07e-1 ± 2.0e-2 & 1.51e-1 ± 1.3e-2 & 3.54e-2 ± 6.3e-3 & \bfseries 6.42e-3 ± 5.8e-3 \\
% IC & Caltech101 10-shot & BiT/50/1 & 33 & 16 & 3.29e-1 ± 1.6e-2 & 7.68e-2 ± 5.0e-3 & 1.13e-1 ± 6.0e-3 & 6.31e-2 ± 4.4e-3 & \bfseries 5.37e-3 ± 2.2e-3 \\
% IC & Caltech101 10-shot & MiX/B/16 & 14 & 12 & 1.35e-1 ± 1.4e-2 & 1.35e-1 ± 1.4e-2 & 1.35e-1 ± 1.4e-2 & 2.11e-1 ± 1.7e-2 & \bfseries 3.72e-2 ± 9.7e-3 \\
% IC & Caltech101 10-shot & MiX/L/16 & 12 & 11 & 1.25e-1 ± 1.3e-2 & 1.25e-1 ± 1.3e-2 & 1.25e-1 ± 1.3e-2 & 1.92e-1 ± 1.6e-2 & \bfseries 3.73e-2 ± 1.5e-2 \\
% IC & Caltech101 10-shot & ViT/B/16 & 34 & 33 & 7.76e-2 ± 4.3e-3 & 7.76e-2 ± 4.3e-3 & 3.11e-2 ± 3.0e-3 & 5.54e-2 ± 4.3e-3 & \bfseries 1.67e-2 ± 5.4e-3 \\
% IC & Caltech101 10-shot & ViT/S/16 & 43 & 55 & 1.95e-1 ± 6.0e-3 & 3.41e-2 ± 2.9e-3 & \bfseries 2.40e-2 ± 2.0e-3 & 3.95e-2 ± 3.1e-3 & 3.31e-2 ± 5.3e-3 \\
% IC & Caltech101 25-shot & BiT/101/3 & 10 & 3 & 1.15e-1 ± 6.5e-3 & 1.15e-1 ± 6.5e-3 & 1.15e-1 ± 6.5e-3 & 5.23e-2 ± 2.7e-3 & \bfseries 1.13e-2 ± 8.0e-3 \\
% IC & Caltech101 25-shot & BiT/50/1 & 28 & 16 & 3.60e-1 ± 1.9e-2 & 8.80e-2 ± 5.5e-3 & 1.43e-1 ± 7.6e-3 & 5.95e-2 ± 4.1e-3 & \bfseries 2.13e-3 ± 1.6e-3 \\
% IC & Caltech101 25-shot & MiX/B/16 & 13 & 11 & 8.28e-2 ± 1.2e-2 & 8.28e-2 ± 1.2e-2 & 8.28e-2 ± 1.2e-2 & 1.74e-1 ± 1.7e-2 & \bfseries 2.83e-2 ± 1.3e-2 \\
% IC & Caltech101 25-shot & MiX/L/16 & 12 & 12 & 9.66e-2 ± 1.0e-2 & 9.66e-2 ± 1.0e-2 & 9.66e-2 ± 1.0e-2 & 1.03e-1 ± 9.5e-3 & \bfseries 1.98e-2 ± 1.3e-2 \\
% IC & Caltech101 25-shot & ViT/B/16 & 27 & 28 & 1.03e-1 ± 5.6e-3 & 3.33e-2 ± 2.5e-3 & 4.46e-2 ± 3.6e-3 & 4.24e-2 ± 3.6e-3 & \bfseries 6.37e-3 ± 5.4e-3 \\
% IC & Caltech101 25-shot & ViT/S/16 & 41 & 54 & 1.77e-1 ± 5.4e-3 & 3.79e-2 ± 3.1e-3 & 2.80e-2 ± 1.8e-3 & \bfseries 2.35e-2 ± 2.3e-3 & 2.38e-2 ± 4.7e-3 \\
% IC & Caltech101 5-shot & BiT/101/3 & 16 & 13 & 2.12e-1 ± 1.2e-2 & 2.12e-1 ± 1.2e-2 & 2.12e-1 ± 1.2e-2 & 8.82e-2 ± 5.0e-3 & \bfseries 3.17e-3 ± 4.3e-3 \\
% IC & Caltech101 5-shot & BiT/50/1 & 46 & 54 & 2.34e-1 ± 6.1e-3 & 4.13e-2 ± 2.1e-3 & 1.61e-2 ± 1.3e-3 & 4.49e-2 ± 2.1e-3 & \bfseries 1.33e-2 ± 2.2e-3 \\
% IC & Caltech101 5-shot & MiX/B/16 & 24 & 19 & 2.43e-1 ± 1.2e-2 & 2.43e-1 ± 1.2e-2 & 2.35e-1 ± 1.1e-2 & 1.23e-1 ± 6.0e-3 & \bfseries 3.59e-3 ± 1.9e-3 \\
% IC & Caltech101 5-shot & MiX/L/16 & 14 & 13 & 1.38e-1 ± 9.7e-3 & 1.38e-1 ± 9.7e-3 & 1.38e-1 ± 9.7e-3 & 3.19e-2 ± 2.6e-3 & \bfseries 3.19e-2 ± 1.1e-2 \\
% IC & Caltech101 5-shot & ViT/B/16 & 38 & 41 & 1.10e-1 ± 6.3e-3 & 1.10e-1 ± 6.3e-3 & 6.02e-2 ± 4.7e-3 & 6.59e-2 ± 4.7e-3 & \bfseries 2.33e-2 ± 6.0e-3 \\
% IC & Caltech101 5-shot & ViT/S/16 & 49 & 82 & 1.90e-1 ± 4.7e-3 & 3.82e-2 ± 2.6e-3 & 5.04e-2 ± 2.9e-3 & 4.06e-2 ± 2.7e-3 & \bfseries 2.47e-2 ± 3.8e-3 \\
% IC & ImageNet 10-shot & BiT/101/3 & 60 & 118 & 1.27e-1 ± 2.0e-3 & 1.27e-1 ± 2.0e-3 & 7.36e-2 ± 1.1e-3 & 2.13e-2 ± 5.8e-4 & \bfseries 5.95e-3 ± 5.5e-4 \\
% IC & ImageNet 10-shot & BiT/50/1 & 68 & 262 & 9.54e-2 ± 7.2e-4 & 9.54e-2 ± 7.2e-4 & \bfseries 5.75e-3 ± 2.0e-4 & 1.77e-2 ± 2.7e-4 & 8.93e-3 ± 2.7e-4 \\
% IC & ImageNet 10-shot & MiX/B/16 & 69 & 329 & 9.34e-2 ± 7.9e-4 & 9.34e-2 ± 7.9e-4 & 3.37e-2 ± 2.9e-4 & 1.80e-2 ± 2.7e-4 & \bfseries 5.88e-3 ± 2.5e-4 \\
% IC & ImageNet 10-shot & MiX/L/16 & 66 & 249 & 9.83e-2 ± 1.3e-3 & 9.83e-2 ± 1.3e-3 & 9.83e-2 ± 1.3e-3 & 9.48e-3 ± 2.4e-4 & \bfseries 3.81e-3 ± 2.9e-4 \\
% IC & ImageNet 10-shot & ViT/B/16 & 67 & 289 & 4.62e-2 ± 7.1e-4 & 4.62e-2 ± 7.1e-4 & 4.62e-2 ± 7.1e-4 & 3.43e-2 ± 4.4e-4 & \bfseries 2.85e-3 ± 2.7e-4 \\
% IC & ImageNet 10-shot & ViT/S/16 & 65 & 310 & 4.74e-2 ± 5.6e-4 & 4.74e-2 ± 5.6e-4 & 1.66e-2 ± 2.5e-4 & 1.14e-2 ± 2.4e-4 & \bfseries 1.97e-3 ± 1.4e-4 \\
% IC & ImageNet 25-shot & BiT/101/3 & 57 & 100 & 1.42e-1 ± 2.3e-3 & 1.42e-1 ± 2.3e-3 & 6.67e-2 ± 9.1e-4 & 2.18e-2 ± 7.0e-4 & \bfseries 4.86e-3 ± 6.2e-4 \\
% IC & ImageNet 25-shot & BiT/50/1 & 68 & 263 & 1.17e-1 ± 9.2e-4 & 1.17e-1 ± 9.2e-4 & \bfseries 4.06e-3 ± 1.7e-4 & 1.70e-2 ± 2.5e-4 & 8.14e-3 ± 2.4e-4 \\
% IC & ImageNet 25-shot & MiX/B/16 & 68 & 284 & 9.59e-2 ± 9.3e-4 & 9.59e-2 ± 9.3e-4 & 5.39e-2 ± 4.9e-4 & 1.47e-2 ± 2.7e-4 & \bfseries 2.86e-3 ± 2.3e-4 \\
% IC & ImageNet 25-shot & MiX/L/16 & 66 & 226 & 1.03e-1 ± 1.3e-3 & 1.03e-1 ± 1.3e-3 & 1.03e-1 ± 1.3e-3 & 6.09e-3 ± 2.5e-4 & \bfseries 1.94e-3 ± 2.6e-4 \\
% IC & ImageNet 25-shot & ViT/B/16 & 67 & 289 & 5.17e-2 ± 8.8e-4 & 5.17e-2 ± 8.8e-4 & 5.17e-2 ± 8.8e-4 & 3.26e-2 ± 5.4e-4 & \bfseries 6.91e-3 ± 4.3e-4 \\
% IC & ImageNet 25-shot & ViT/S/16 & 65 & 311 & 5.52e-2 ± 4.4e-4 & 4.12e-2 ± 3.4e-4 & 9.65e-3 ± 2.3e-4 & 1.16e-2 ± 2.2e-4 & \bfseries 3.09e-3 ± 2.4e-4 \\
% IC & ImageNet 5-shot & BiT/101/3 & 60 & 124 & 9.24e-2 ± 1.4e-3 & 9.24e-2 ± 1.4e-3 & 9.24e-2 ± 1.4e-3 & 1.01e-2 ± 5.3e-4 & \bfseries 2.55e-3 ± 5.0e-4 \\
% IC & ImageNet 5-shot & BiT/50/1 & 69 & 305 & 8.95e-2 ± 6.7e-4 & 8.95e-2 ± 6.7e-4 & 1.53e-2 ± 2.2e-4 & 1.03e-2 ± 2.3e-4 & \bfseries 4.00e-3 ± 2.1e-4 \\
% IC & ImageNet 5-shot & MiX/B/16 & 70 & 394 & 9.09e-2 ± 7.2e-4 & 9.09e-2 ± 7.2e-4 & 3.01e-2 ± 2.8e-4 & 1.45e-2 ± 2.5e-4 & \bfseries 3.57e-3 ± 2.3e-4 \\
% IC & ImageNet 5-shot & MiX/L/16 & 67 & 240 & 7.99e-2 ± 9.7e-4 & 7.99e-2 ± 9.7e-4 & 7.99e-2 ± 9.7e-4 & 5.66e-3 ± 3.1e-4 & \bfseries 1.63e-3 ± 2.4e-4 \\
% IC & ImageNet 5-shot & ViT/B/16 & 68 & 361 & 4.11e-2 ± 6.3e-4 & 4.11e-2 ± 6.3e-4 & 4.11e-2 ± 6.3e-4 & 2.88e-2 ± 3.6e-4 & \bfseries 4.97e-3 ± 2.7e-4 \\
% IC & ImageNet 5-shot & ViT/S/16 & 66 & 323 & 4.20e-2 ± 4.1e-4 & 4.20e-2 ± 4.1e-4 & 2.40e-2 ± 2.6e-4 & 1.44e-2 ± 2.2e-4 & \bfseries 3.00e-3 ± 1.7e-4 \\
% \end{tabular}
%     \caption{
%     Extrapolation Results for Each of Every Task from Scaling Laws Benchmark Dataset. Numbers for M1, M2, M3, and M4 obtained via correspondence with authors of \cite{Alabdulmohsi2022revisiting}. Bolded if lowest in row or below 1e-3.
%     }
%     \label{table:scaling_laws_benchmark_dataset__All}
% \end{table}
% \clearpage
% \begin{table}
% \tiny
% \setlength\tabcolsep{3.1pt} 
% \begin{tabular}
% %{p{.02\textwidth}p{.165\textwidth}p{.095\textwidth}p{.01\textwidth}p{.01\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}}
% {p{.021\textwidth}p{.165\textwidth}p{.111\textwidth}p{.028\textwidth}p{.022\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}p{.099\textwidth}}
% %\begin{tabular}{llllrrrrrrrrrrrrl}
% Domain & \hspace{.9cm}Task & Model & Train Points & Test Points & M1 $\downarrow$ & M2 $\downarrow$ & M3 $\downarrow$ & M4 $\downarrow$ & BNSL $\downarrow$ \\
% \hline
% BB & date understanding, 1-shot & 2.62e+8 Param & 19 & 24 & 3.19e-2 ± 9.6e-4 & 3.09e-2 ± 9.2e-4 & \bfseries 4.67e-3 ± 1.4e-4 & 1.49e-2 ± 5.9e-4 & 4.96e-3 ± 4.8e-5 \\
% BB & date understanding, 2-shot & 2.62e+8 Param & 19 & 24 & 2.86e-2 ± 6.2e-4 & 2.44e-2 ± 5.6e-4 & 4.83e-3 ± 4.1e-4 & 1.58e-2 ± 5.0e-4 & \bfseries 2.55e-3 ± 6.2e-4 \\
% BB & linguistic mappings, 1-shot & 2.62e+8 Param & 19 & 24 & 1.66e-2 ± 5.5e-4 & \bfseries 1.41e-2 ± 4.7e-4 & 1.66e-2 ± 5.5e-4 & 1.57e-2 ± 4.8e-4 & 2.22e-2 ± 8.2e-4 \\
% BB & linguistic mappings, 2-shot & 2.62e+8 Param & 19 & 24 & 1.70e-2 ± 6.5e-4 & 1.30e-2 ± 5.4e-4 & 1.70e-2 ± 6.5e-4 & 9.25e-3 ± 5.1e-4 & \bfseries 8.09e-3 ± 5.1e-4 \\
% BB & mult data wrangling, 1-shot & 2.62e+8 Param & 19 & 24 & 1.07e-2 ± 1.0e-3 & 6.71e-3 ± 7.6e-4 & 1.07e-2 ± 1.0e-3 & 8.27e-3 ± 8.4e-4 & \bfseries 6.17e-3 ± 8.4e-4 \\
% BB & mult data wrangling, 2-shot & 2.62e+8 Param & 19 & 24 & 1.57e-2 ± 1.5e-3 & 7.22e-3 ± 8.9e-4 & 1.57e-2 ± 1.5e-3 & \bfseries 5.01e-3 ± 5.0e-4 & 5.45e-3 ± 9.2e-4 \\
% BB & qa wikidata, 1-shot & 2.62e+8 Param & 19 & 24 & \bfseries 4.27e-3 ± 8.9e-4 & 5.14e-3 ± 5.3e-4 & 4.27e-3 ± 8.9e-4 & 5.05e-3 ± 5.6e-4 & 4.34e-3 ± 6.1e-4 \\
% BB & qa wikidata, 2-shot & 2.62e+8 Param & 19 & 24 & 4.39e-3 ± 7.0e-4 & 7.35e-3 ± 6.1e-4 & 4.39e-3 ± 7.0e-4 & 7.12e-3 ± 6.0e-4 & \bfseries 4.20e-3 ± 6.0e-4 \\
% BB & unit conversion, 1-shot & 2.62e+8 Param & 19 & 24 & 8.30e-3 ± 4.4e-4 & 6.77e-3 ± 4.0e-4 & \bfseries 1.48e-3 ± 2.7e-4 & 2.32e-3 ± 2.3e-4 & 6.32e-3 ± 2.5e-4 \\
% BB & unit conversion, 2-shot & 2.62e+8 Param & 19 & 24 & 1.07e-2 ± 4.4e-4 & 9.15e-3 ± 4.7e-4 & 7.50e-3 ± 5.5e-4 & \bfseries 2.83e-3 ± 4.8e-4 & 5.21e-3 ± 5.2e-4 \\
% NMT & upstream test cross-entropy & 28 Enc, 6 Dec & 9 & 1 & 1.71e-1 ± 0 & 5.63e-2 ± 0 & 3.37e-2 ± 0 & 1.50e-2 ± 0 & \bfseries 5.13e-3 ± 0 \\
% NMT & upstream test cross-entropy & 6 Enc, 28 Dec & 10 & 1 & 2.34e-1 ± 0 & 5.27e-2 ± 0 & 1.65e-2 ± 0 & 3.21e-2 ± 0 & \bfseries 9.81e-3 ± 0 \\
% NMT & upstream test cross-entropy & 6 Enc, 6 Dec & 10 & 1 & 2.62e-1 ± 0 & 3.84e-2 ± 0 & 8.92e-2 ± 0 & \bfseries 1.05e-2 ± 0 & 1.41e-2 ± 0 \\
% NMT & upstream test cross-entropy & Dec-only, LM & 10 & 1 & 2.52e-1 ± 0 & 1.03e-2 ± 0 & 3.28e-2 ± 0 & 8.88e-3 ± 0 & \bfseries 2.79e-3 ± 0 \\
% NMT & upstream test cross-entropy & Trans-E, LSTM-D & 9 & 1 & 1.90e-1 ± 0 & 1.26e-2 ± 0 & 6.32e-2 ± 0 & 1.31e-2 ± 0 & \bfseries 3.08e-3 ± 0 \\
% LM & upstream test cross-entropy& 1.07e+9 Param & 44 & 40 & 1.71e-2 ± 6.0e-4 & 1.02e-3 ± 3.5e-5 & 4.50e-3 ± 5.9e-5 & \bfseries 3.79e-4 ± 4.0e-5 & 8.26e-4 ± 3.2e-5 \\
% LM & upstream test cross-entropy& 1.34e+8 Param & 48 & 48 & 1.43e-2 ± 4.8e-4 & 1.33e-3 ± 6.5e-5 & \bfseries 6.46e-4 ± 5.1e-5 & 8.14e-4 ± 5.3e-5 & 8.09e-4 ± 5.5e-5 \\
% LM & upstream test cross-entropy& 1.68e+7 Param & 236 & 240 & 6.37e-3 ± 9.4e-5 & \bfseries 3.08e-4 ± 1.3e-5 & 1.24e-3 ± 3.2e-5 & 3.27e-4 ± 1.5e-5 & 4.05e-4 ± 1.8e-5 \\
% LM & upstream test cross-entropy& 2.62e+8 Param & 156 & 20 & 1.55e-2 ± 7.2e-4 & 1.01e-3 ± 9.4e-5 & 3.97e-3 ± 1.3e-4 & \bfseries 9.37e-4 ± 9.7e-5 & 1.80e-3 ± 5.6e-5 \\
% LM & upstream test cross-entropy& 4.53e+8 Param & 44 & 40 & 1.65e-2 ± 6.6e-4 & 6.47e-4 ± 8.5e-5 & 6.58e-4 ± 6.6e-5 & 8.54e-4 ± 4.7e-5 & \bfseries 5.10e-4 ± 7.7e-5 \\
% \end{tabular}
%     \caption{
%     Extrapolation Results for Each of Every Task from Scaling Laws Benchmark Dataset. Numbers for M1, M2, M3, and M4 obtained via correspondence with authors of \cite{Alabdulmohsi2022revisiting}. Bolded if lowest in row or below 1e-3.
%     }
%     \label{table:scaling_laws_benchmark_dataset__All-2}
% \end{table}
% \FloatBarrier
\clearpage
\subsection{Extrapolation Results when Upstream Performance is on the x-axis}
\label{section:downstream_from_upstream}

\begin{figure*}[htbp]
    \centering
%\includegraphics[width=0.48\textwidth]{figures/arithmetic/4_digit_addition__dataset_size.png}
\includegraphics[width=0.48\textwidth]{figures/downstream_from_upstream/Task_ImageNet_20-shot.png}

    \caption{
    Extrapolation Results of BNSL for scaling behavior when Upstream Performance is on the x-axis and Downstream Performance is on the y-axis. Experimental data of scaling behavior obtained from Figure 5 of \cite{abnar2021exploring}. The upstream task is supervised pretraining of ViT \citep{dosovitskiy2020image} on subsets of JFT-300M \citep{sun2017revisiting}. The Downstream Task is 20-shot ImageNet classification. See Section \ref{section:downstream_from_upstream} for more details.
    }
    \label{fig:downstream_from_upstream}
\end{figure*}

In Figure \ref{fig:downstream_from_upstream}, we show that BNSL accurately extrapolates the scaling behavior when upstream performance is on the x-axis and downstream performance is on the y-axis. The upstream task is supervised pretraining of ViT \citep{dosovitskiy2020image} on subsets of JFT-300M \citep{sun2017revisiting}. The downstream task is 20-shot ImageNet classification. The experimental data of this scaling behavior is obtained from Figure 5 of \cite{abnar2021exploring}.

\clearpage

\subsection{Extrapolation Results for Diffusion Generative Models of Images}
\label{section:diffusion}

\begin{figure*}[htbp]
    \centering
%\includegraphics[width=0.48\textwidth]{figures/arithmetic/4_digit_addition__dataset_size.png}
\includegraphics[width=0.48\textwidth]{figures/diffusion/diffusion__fid.png}
\includegraphics[width=0.48\textwidth]{figures/diffusion/diffusion__nll.png}

    \caption{
Extrapolation Results of BNSL for scaling behavior of Diffusion Generative Models of Images. Frechet Inception Distance (FID) score is on the y-axis in the left plot. Negative log-likelihood (NLL) is the y-axis in the right plot. For both plots, compute used for training is on the x-axis and Imagenet 64x64 is the evaluation dataset. Experimental data of scaling behavior obtained from Figure 10 of \cite{nichol2021improved}. See Section \ref{section:diffusion} for more details.
    }
    \label{fig:diffusion_compute_scaling}
\end{figure*}

In Figure \ref{fig:diffusion_compute_scaling}, we show that BNSL accurately extrapolates the scaling behavior of Diffusion Generative Models of Images from Figure 10 of \cite{nichol2021improved} when Negative Log-likelihood (NLL) or Frechet Inception Distance (FID) score is on the y-axis and compute used for training is on the x-axis; compute is scaled in the manner that is Pareto optimal with respect to the performance evaluation metric on the y-axis.

\FloatBarrier

\clearpage
\subsection{Plots of BNSL Extrapolations on Scaling Laws Benchmark of \cite{Alabdulmohsi2022revisiting}}
\label{section:Plots_of_BNSL_Extrapolations}

% \FloatBarrier
\begin{figure*}[!htb]
    \centering

\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_5___BiT_50_1.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_5___BiT_101_3.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_5___MiX_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_5___MiX_L_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_5___ViT_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_5___ViT_S_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_10___BiT_50_1.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_10___BiT_101_3.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_10___MiX_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_10___MiX_L_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_10___ViT_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_10___ViT_S_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_25___BiT_50_1.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_25___BiT_101_3.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_25___MiX_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_25___MiX_L_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_25___ViT_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/birds_25___ViT_S_16.png}
\caption{
    Birds 200
    }
    \label{fig:scaling_laws_benchmark_dataset__birds}
\end{figure*}

\clearpage
\begin{figure*}
    \centering


\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_5___BiT_50_1.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_5___BiT_101_3.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_5___MiX_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_5___MiX_L_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_5___ViT_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_5___ViT_S_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_10___BiT_50_1.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_10___BiT_101_3.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_10___MiX_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_10___MiX_L_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_10___ViT_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_10___ViT_S_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_25___BiT_50_1.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_25___BiT_101_3.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_25___MiX_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_25___MiX_L_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_25___ViT_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/c100_25___ViT_S_16.png}

    \caption{
    CIFAR-100
    }
    \label{fig:scaling_laws_benchmark_dataset__cifar_100}
\end{figure*}


\begin{figure*}
    \centering

\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_5shot___BiT_50_1.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_5shot___BiT_101_3.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_5shot___MiX_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_5shot___MiX_L_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_5shot___ViT_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_5shot___ViT_S_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_10shot___BiT_50_1.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_10shot___BiT_101_3.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_10shot___MiX_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_10shot___MiX_L_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_10shot___ViT_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_10shot___ViT_S_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_25shot___BiT_50_1.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_25shot___BiT_101_3.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_25shot___MiX_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_25shot___MiX_L_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_25shot___ViT_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/caltech_25shot___ViT_S_16.png}

    \caption{
    Caltech101. From eyeballing, we think the subset of Caltech101 with unsatisfactory extrapolations has unsatisfactory extrapolations due to the maximum (along the x-axis) of the black point used for fitting being near or before a break; this is accentuated by not having enough points for fitting for the SciPy fitter to be able to determine whether the break is an actual break or just noisy deviation.
    }
    \label{fig:scaling_laws_benchmark_dataset__caltech}
\end{figure*}


\begin{figure*}
    \centering

\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_5___BiT_50_1.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_5___BiT_101_3.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_5___MiX_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_5___MiX_L_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_5___ViT_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_5___ViT_S_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_10___BiT_50_1.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_10___BiT_101_3.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_10___MiX_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_10___MiX_L_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_10___ViT_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_10___ViT_S_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_25___BiT_50_1.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_25___BiT_101_3.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_25___MiX_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_25___MiX_L_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_25___ViT_B_16.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/few_shot_25___ViT_S_16.png}

    \caption{
    ImageNet
    }
    \label{fig:scaling_laws_benchmark_dataset__ImageNet}
\end{figure*}

\begin{figure*}
    \centering

\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/__date_understanding_,__1-shot_____262M.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/__linguistic_mappings_,__1-shot_____262M.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/__linguistic_mappings_,__2-shot_____262M.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/__mult_data_wrangling_,__1-shot_____262M.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/__mult_data_wrangling_,__2-shot_____262M.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/__qa_wikidata_,__1-shot_____262M.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/__qa_wikidata_,__2-shot_____262M.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/__unit_conversion_,__1-shot_____262M.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/__unit_conversion_,__2-shot_____262M.png}

    \caption{
    BIG-Bench (BB). From eyeballing, we think the subset of BIG-Bench with unsatisfactory extrapolations has unsatisfactory extrapolations due to the maximum (along the x-axis) of the black point used for fitting being near or before a break; this is accentuated by not having enough points for fitting for the SciPy fitter to be able to determine whether the break is an actual break or just noisy deviation.
    }
    \label{fig:scaling_laws_benchmark_dataset__big_bench}
\end{figure*}

\begin{figure*}
    \centering

\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/log_perplexity___6_Enc,_6_Dec.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/log_perplexity___6_Enc,_28_Dec.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/log_perplexity___28_Enc,_6_Dec.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/log_perplexity___Decoder-only,_Language_modeling.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/log_perplexity___Transfomer-Encoder,_LSTM-Decoder.png}

    \caption{
    Neural Machine Translation (NMT)
    }
    \label{fig:scaling_laws_benchmark_dataset__nmt}
\end{figure*}

\begin{figure}
    \centering


\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/validation_loss___1.07e+09.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/validation_loss___1.34e+08.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/validation_loss___1.68e+07.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/validation_loss___2.62e+08.png}
\includegraphics[width=0.245\textwidth]{figures/scaling_laws_benchmark_dataset_plots/validation_loss___4.53e+08.png}

    \caption{
    Language Modeling (LM)
    }
    \label{fig:scaling_laws_benchmark_dataset__language_modeling}
\end{figure}

% \FloatBarrier


\end{document}
