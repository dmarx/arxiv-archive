\section{Theoretical Limitations of Other Scaling Laws}

%\todo[inline]{I'm not sure it's worth including any propositions in the main text.  The proofs are just basic calculus and algebra.}


%\todo[inline]{This is for M2.  Need to do M3 (and maybe M4) case as well.  Also need to know which one(s) to consider "standard" for framing.}

Our use of BNSLs is inspired by the observation that scaling is not always well predicted by a simple power law.
Nor are the modifications which have been applied in previous works sufficient to capture the qualitative properties of empirical scaling curves.  
In effect, the most sophisticated form common in previous work is a power law modified to incorporate a minimum achievable loss, representing irreducible entropy, and TODO.
Here we show mathematically two qualitative defects of these functional forms:
\begin{enumerate}
    \item They are strictly monotonic and thus unable to fit double descent phenomena.
    \item They cannot express inflection points, which are frequently observed empirically.
\end{enumerate}
%This can be seen by observing that thes
Note that these functional forms \textit{can} exhibit inflection points on the log-log axes which are commonly used for plotting scaling data.  
However, on a linear-linear plot, the extra expressiveness of broken neural scaling laws is required (and sufficient).
Figure~\ref{fig:double_descent} and Figure~\ref{fig:arithmetic}, provides examples of BNSLs (with a single break-point, $n=1$) producing double descent and inflection points, respectively, establishing the capacity of this functional form to fit these phenomena.

We now explain why standard functional forms are incapable of exhibiting either behavior.
First, recall that expressions of the form $m^n$ can only take the value $0$ if $m=0$. 
We now examine the expressions for the first and second derivatives of M1, M2, M3, M3', provided in Table~\ref{tab:math}, and observe that they are all continuous and do not have roots over the relevant ranges of $a,b,c,d,x>0$, $b<1$.
This implies that they are monotonic (as the first derivative never changes sign), and that they lack inflection points (since an inflection point must have $f''(x)=0$).

\begin{table}[h]
\centering
\begin{tabular}{c|c|c|c}
name & $f(x)$ & $f'(x)$ & $f''(x)$ \\
\midrule
M1  & $ax^b$ & $abx^{b-1}$ & $ab(b-1)x^{b-2}$ \\
\midrule
M2  & $ax^b + c$ & $abx^{b-1}$ & $ab(b-1)x^{b-2}$ \\
%M2  & $f(x)$ & $f'(x)$ & $\frac{(c (1 + c) (b/x)^c)}{x^2}$ \\
\midrule
M3  & $a(x^{-1} + d)^{-b} + c$  & 
%$\frac{a b }{x (1 + d x)(d + 1/x)^{b}}$  & $a b x^{(b-2)} (1 + d x)^{(-2 - b)} (b -1 - 2 d x) $ \\
$a b  x^{(b-1)} (1 + d x)^{(-1 - b)}$  & $a b x^{(b-2)} (1 + d x)^{(-2 - b)} (b -1 - 2 d x) $ 
% \midrule
% M3' & $f(x)$ & $f'(x)$ & $f''(x)$ \\
%The above expression does not have a root for $a,b,d,x>0; b < 1$: the first two terms are strictly positive, meaning we would need $b = 2dx + 1 \geq 1$.
\label{tab:math}
\end{tabular}
\caption{
    Previously proposed functional forms and their (first and second order) derivatives.  
    For $a,b,c,d,x>0$, $b<1$, the expressions for each of the derivatives is a product of non-zero multiplicands, and thus none of these functional forms can express functions that are non-monotonic or have inflection points.
    %The above expression does not have a root for $a,b,d,x>0; b < 1$: the first two terms are strictly positive, meaning we would need $b = 2dx + 1 \geq 1$.
 }
\end{table}


Figure \ref{fig:Inflection_Point_example} is an example of this inflection point present in experimental data from a real world downstream task, Two Digit Addition (Zero-Shot) from \citet{brown2020language}. %\citet{2020arXiv200514165B}. 
In the small scale regime, the function is concave downward as it transitions from random guessing performance to starting to learn the task. As the scale increases past the small scale regime, an inflection point is reached and the function becomes concave upward as power law scaling behaviour takes over.



% % M3: (need d>0) 
% M3: $f(x) = a(x^{-1} + d)^{-b} + c$ 
% $$
%  f'(x) = \frac{a b }{x (1 + d x)(d + 1/x)^{b}} 
% $$
% $$
%  f''(x) = a b x^{(b-2)} (1 + d x)^{(-2 - b)} (b -1 - 2 d x) 
% $$
% The above expression does not have a root for $a,b,d,x>0; b < 1$: the first two terms are strictly positive, meaning we would need $b = 2dx + 1 \geq 1$.

% "also M3?": $f(x)=a(x+d)^b + c$
% $$
% f'(x) = a b (d + x)^{(b-1)}
% $$
% $$
% f''(x) = a (-1 + b) b (d + x)^{(b-2)}
% $$
% Neither of the above expressions have roots because they are a product of non-zero constants and expressions of the form $m^n$.


%M2: $y = ax^b +c$


% \subsection{SCRAPS}

% % TODO: convert this to same form as M2
% \begin{proposition}
%     Functions of the form $f(x) = a + \left(\frac{b}{x}\right)^c$ are necessarily monotonic for $a,b,c>0$ in the range $x>0$.
% \end{proposition}
% \begin{proof}
%     A sufficient condition for monotonicity is that $f'(x)$ does not change sign.  
%     In our case, we have 
%     $$
%     f'(x) = - bc \left(\frac{b}{x}\right)^{(c-1)}.
%     $$
%     Since $b$ and $x$ are both positive, so is the ratio $\frac{b}{x}$.  
%     And since a positive number taken to any power is also positive, the entire expression is guaranteed to be negative for all values of $a,b,c,x>0$.
% \end{proof}

% %TODO: rename this section to "Math Proofs" and also prove that other functional forms can't express non-monotonic behavior

% \begin{proposition}
%     Functions of the form $f(x) = a + \left(\frac{b}{x}\right)^c$ cannot contain an inflection point for $a,b,c>0$ in the range $x>0$.
% \end{proposition}
% \begin{proof}
% The second derivative is:
% $$
% f''(x) = 
% \frac{(c (1 + c) (b/x)^c)}{x^2}.
% $$
% Since $b$, $c$ and $x$ are all positive, all of the multiplicands of $f''(x)$ are positive, and thus so is $f''(x)$, but an inflection point must have $f''(x)=0$.
% \end{proof}

% \subsection{SCRAPS}

% An inflection point is a point of a curve at which the second order derivative (i.e.\ curvature) changes signs. 
% Empirically, the function relating the performance evaluation metric (e.g. prediction error) to the quantity being scaled (e.g.\ model size) often has an inflection point. 
% Figure \ref{fig:Inflection_Point_example} is an example of this inflection point present in experimental data from a real world downstream task, Two Digit Addition (Zero-Shot) from \citet{brown2020language}. %\citet{2020arXiv200514165B}. 
% In the small scale regime, the function is concave downward as it transitions from random guessing performance to starting to learn the task. 
% As the scale increases past the small scale regime, an inflection point is reached and the function becomes concave upward as power law scaling behaviour takes over.

% However, \textbf{Proposition:} typical functional form cannot have an inflection point.
% \textbf{Proof:}
% %https://www.wolframalpha.com/input?i=d%5E2%2Fdx%5E2+%28a+%2B+%28b%2Fx%29**c%29+
% An inflection point is a point of a curve at which the second order derivative (i.e.\ curvature) changes signs. 
% The second derivative of this function is:
% $$
% f''(x) = 
% \frac{(c (1 + c) (b/x)^c)}{x^2}.
% $$
% Since $b$, $c$ and $x$ are all positive, all of the multiplicands of $f''(x)$ are positive, and thus so is $f''(x)$, but an inflection point must have $f''(x)=0$.
% % https://www.wolframalpha.com/input?i=d%5E2%2Fdx%5E2+%28a+%2B+%28b%2Fx%29**c+%281+%2F+%28x%2Bd%29%5Ef%29%29

% Note that inflection points often appear in scaling curves, which are typically plotted on log/log axes, and existing scaling laws can fit those inflection points (TODO: is this right?  I thought they were just linear on a log/log plot?).
% Inflection points are less common but still sometimes present in a linear/linear plot; These are the inflection points that existing scaling laws cannot capture.

% TODO: do we get the same result for all of M1 through M4?

% All the functional forms:

% M1: $y = ax^b$

% M2: $y = ax^b +c$

% M3: $y = a(x^{-1} + d)^{-b} + c$ 

% also M3?: $y=a(x+d)^b + c$

% M4: $(y - \epsilon_{\infty}) / ((\epsilon_{0} - y)^a) = bx$ 

% $\epsilon_{\infty}$ is irreducible loss, and $\epsilon_{0}$ is performance of random guessing.

% Equation 6.1 of "scaling laws for transfer" paper: $y = (ax^b + cx^d)^f + g$

% I (Ethan) just now have realized that this equation 6.1 above is a smoothly broken power law (i.e. mathematically equivalent to ours I think) too so we have to change the narrative of the paper now:  
% \url{https://math.stackexchange.com/a/2427151}

% \url{https://colab.research.google.com/drive/1QP81soNf1DDV_Q6iimN8sb-hZHaZeMyW}

% Also, I think "scaling laws for transfer" paper may/might have been unaware that its equation 6.1 is a thing called a smoothly broken power law.

% Broken Neural Scaling Law: $y =  a + \left(\frac{b}{x}\right)^c \prod_{i=1}^n \left(1 + \left(\frac{x}{d_i}\right)^{f_i}\right)^{-g_i}$



% TODO: remove this section?
% TODO: replace it with section about breaks rather than inflection points


%This inflection point at the transition from constant random guessing performance in the small scale regime to 
%When the performance evaluation metric (e.g. prediction error) is plotted on y-axis and the quantity being scaled (e.g. model size) is plotted on x-axis, the plotted data has an inflection point at the transition from constant random guessing performance in the small scale regime to 
% Figure \ref{fig:Inflection_Point_example} is an example of this inflection point present in experimental data from a real world downstream task, Two Digit Addition (Zero-Shot) from \citet{brown2020language}. %\citet{2020arXiv200514165B}. 
%In the small scale regime, the function is concave downward as it transitions from random guessing performance to starting to learn the task. As the scale increases past the small scale regime, an inflection point is reached and the function becomes concave upward as power law scaling behaviour takes over.

% \todo[inline]{math proofs}

% 1. proof that shows $y=a/(x^b+d)+c$ has inflection point for all functions in which $a$ $!=0$, $b>1$, and $d>0$ are simultaneously true

% 2. proof that shows $y=a(x+d)^b + c$ never has inflection point