\begin{thebibliography}{36}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Chefer et~al.(2023)Chefer, Alaluf, Vinker, Wolf, and Cohen-Or]{chefer2023attend}
Hila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, and Daniel Cohen-Or.
\newblock Attend-and-excite: Attention-based semantic guidance for text-to-image diffusion models.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 42\penalty0 (4):\penalty0 1--10, 2023.

\bibitem[Dai et~al.(2023)Dai, Hou, Ma, Tsai, Wang, Wang, Zhang, Vandenhende, Wang, Dubey, et~al.]{dai2023emu}
Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang Wang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiaofang Wang, Abhimanyu Dubey, et~al.
\newblock Emu: Enhancing image generation models using photogenic needles in a haystack.
\newblock \emph{arXiv preprint arXiv:2309.15807}, 2023.

\bibitem[Esser et~al.(2024)Esser, Kulal, Blattmann, Entezari, M{\"u}ller, Saini, Levi, Lorenz, Sauer, Boesel, et~al.]{esser2024scaling}
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas M{\"u}ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et~al.
\newblock Scaling rectified flow transformers for high-resolution image synthesis.
\newblock In \emph{Forty-first International Conference on Machine Learning}, 2024.

\bibitem[Feng et~al.(2023)Feng, Zhang, Yu, Fang, Li, Chen, Lu, Liu, Yin, Feng, et~al.]{feng2023ernie}
Zhida Feng, Zhenyu Zhang, Xintong Yu, Yewei Fang, Lanxin Li, Xuyi Chen, Yuxiang Lu, Jiaxiang Liu, Weichong Yin, Shikun Feng, et~al.
\newblock Ernie-vilg 2.0: Improving text-to-image diffusion model with knowledge-enhanced mixture-of-denoising-experts.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 10135--10145, 2023.

\bibitem[Gal et~al.(2022)Gal, Alaluf, Atzmon, Patashnik, Bermano, Chechik, and Cohen-Or]{gal2022image}
Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit~H Bermano, Gal Chechik, and Daniel Cohen-Or.
\newblock An image is worth one word: Personalizing text-to-image generation using textual inversion.
\newblock \emph{arXiv preprint arXiv:2208.01618}, 2022.

\bibitem[He et~al.(2024)He, Li, Zhang, Yan, Si, and Li]{he2024freestyle}
Feihong He, Gang Li, Mengyuan Zhang, Leilei Yan, Lingyu Si, and Fanzhang Li.
\newblock Freestyle: Free lunch for text-guided style transfer using diffusion models.
\newblock \emph{arXiv preprint arXiv:2401.15636}, 2024.

\bibitem[Hu et~al.(2021)Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen]{hu2021lora}
Edward~J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen.
\newblock Lora: Low-rank adaptation of large language models.
\newblock \emph{arXiv preprint arXiv:2106.09685}, 2021.

\bibitem[Kirstain et~al.(2023)Kirstain, Polyak, Singer, Matiana, Penna, and Levy]{kirstain2023pick}
Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland Matiana, Joe Penna, and Omer Levy.
\newblock Pick-a-pic: An open dataset of user preferences for text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2305.01569}, 2023.

\bibitem[Li et~al.(2024)Li, Kamko, Akhgari, Sabet, Xu, and Doshi]{li2024playground}
Daiqing Li, Aleks Kamko, Ehsan Akhgari, Ali Sabet, Linmiao Xu, and Suhail Doshi.
\newblock Playground v2.5: Three insights towards enhancing aesthetic quality in text-to-image generation, 2024.

\bibitem[Liang et~al.(2024)Liang, He, Li, Li, Klimovskiy, Carolan, Sun, Pont-Tuset, Young, Yang, et~al.]{liang2024rich}
Youwei Liang, Junfeng He, Gang Li, Peizhao Li, Arseniy Klimovskiy, Nicholas Carolan, Jiao Sun, Jordi Pont-Tuset, Sarah Young, Feng Yang, et~al.
\newblock Rich human feedback for text-to-image generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 19401--19411, 2024.

\bibitem[Loshchilov and Hutter(2017)]{loshchilov2017decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock \emph{arXiv preprint arXiv:1711.05101}, 2017.

\bibitem[Mou et~al.(2023)Mou, Wang, Xie, Zhang, Qi, Shan, and Qie]{mou2023t2i}
Chong Mou, Xintao Wang, Liangbin Xie, Jian Zhang, Zhongang Qi, Ying Shan, and Xiaohu Qie.
\newblock T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2302.08453}, 2023.

\bibitem[Nichol et~al.(2021)Nichol, Dhariwal, Ramesh, Shyam, Mishkin, McGrew, Sutskever, and Chen]{nichol2021glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock Glide: Towards photorealistic image generation and editing with text-guided diffusion models.
\newblock \emph{arXiv preprint arXiv:2112.10741}, 2021.

\bibitem[Podell et~al.(2023)Podell, English, Lacey, Blattmann, Dockhorn, M{\"u}ller, Penna, and Rombach]{podell2023sdxl}
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas M{\"u}ller, Joe Penna, and Robin Rombach.
\newblock Sdxl: Improving latent diffusion models for high-resolution image synthesis.
\newblock \emph{arXiv preprint arXiv:2307.01952}, 2023.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{ICML}, pages 8748--8763. PMLR, 2021.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li, and Liu]{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter~J Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer.
\newblock \emph{Journal of machine learning research}, 21\penalty0 (140):\penalty0 1--67, 2020.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and Sutskever]{ramesh2021zero}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In \emph{International Conference on Machine Learning}, pages 8821--8831. PMLR, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 1\penalty0 (2):\penalty0 3, 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and Brox]{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{MICCAI}, pages 234--241. Springer, 2015.

\bibitem[Ruiz et~al.(2023)Ruiz, Li, Jampani, Pritch, Rubinstein, and Aberman]{ruiz2023dreambooth}
Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman.
\newblock Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 22500--22510, 2023.

\bibitem[Schuhmann et~al.(2021)Schuhmann, Vencu, Beaumont, Kaczmarczyk, Mullis, Katta, Coombes, Jitsev, and Komatsuzaki]{schuhmann2021laion}
Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran Komatsuzaki.
\newblock Laion-400m: Open dataset of clip-filtered 400 million image-text pairs.
\newblock \emph{arXiv preprint arXiv:2111.02114}, 2021.

\bibitem[Si et~al.(2023)Si, Huang, Jiang, and Liu]{si2023freeu}
Chenyang Si, Ziqi Huang, Yuming Jiang, and Ziwei Liu.
\newblock Freeu: Free lunch in diffusion u-net.
\newblock \emph{arXiv preprint arXiv:2309.11497}, 2023.

\bibitem[Song et~al.(2020)Song, Meng, and Ermon]{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock \emph{arXiv preprint arXiv:2010.02502}, 2020.

\bibitem[Tao et~al.(2022)Tao, Tang, Wu, Jing, Bao, and Xu]{tao2022df}
Ming Tao, Hao Tang, Fei Wu, Xiao-Yuan Jing, Bing-Kun Bao, and Changsheng Xu.
\newblock Df-gan: A simple and effective baseline for text-to-image synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 16515--16525, 2022.

\bibitem[Wallace et~al.(2024)Wallace, Dang, Rafailov, Zhou, Lou, Purushwalkam, Ermon, Xiong, Joty, and Naik]{wallace2024diffusion}
Bram Wallace, Meihua Dang, Rafael Rafailov, Linqi Zhou, Aaron Lou, Senthil Purushwalkam, Stefano Ermon, Caiming Xiong, Shafiq Joty, and Nikhil Naik.
\newblock Diffusion model alignment using direct preference optimization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 8228--8238, 2024.

\bibitem[Wei et~al.(2023)Wei, Zhang, Ji, Bai, Zhang, and Zuo]{wei2023elite}
Yuxiang Wei, Yabo Zhang, Zhilong Ji, Jinfeng Bai, Lei Zhang, and Wangmeng Zuo.
\newblock Elite: Encoding visual concepts into textual embeddings for customized text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2302.13848}, 2023.

\bibitem[Wu et~al.(2023)Wu, Liu, Zhao, Kale, Bui, Yu, Lin, Zhang, and Chang]{wu2023uncovering}
Qiucheng Wu, Yujian Liu, Handong Zhao, Ajinkya Kale, Trung Bui, Tong Yu, Zhe Lin, Yang Zhang, and Shiyu Chang.
\newblock Uncovering the disentanglement capability in text-to-image diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 1900--1910, 2023.

\bibitem[Xu et~al.(2024)Xu, Liu, Wu, Tong, Li, Ding, Tang, and Dong]{xu2024imagereward}
Jiazheng Xu, Xiao Liu, Yuchen Wu, Yuxuan Tong, Qinkai Li, Ming Ding, Jie Tang, and Yuxiao Dong.
\newblock Imagereward: Learning and evaluating human preferences for text-to-image generation.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Xu et~al.(2018)Xu, Zhang, Huang, Zhang, Gan, Huang, and He]{xu2018attngan}
Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, and Xiaodong He.
\newblock Attngan: Fine-grained text to image generation with attentional generative adversarial networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 1316--1324, 2018.

\bibitem[Ye et~al.(2023)Ye, Zhang, Liu, Han, and Yang]{ye2023ip}
Hu Ye, Jun Zhang, Sibo Liu, Xiao Han, and Wei Yang.
\newblock Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2308.06721}, 2023.

\bibitem[Yu et~al.(2022)Yu, Xu, Koh, Luong, Baid, Wang, Vasudevan, Ku, Yang, Ayan, et~al.]{yu2022scaling}
Jiahui Yu, Yuanzhong Xu, Jing~Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu~Karagol Ayan, et~al.
\newblock Scaling autoregressive models for content-rich text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2206.10789}, 2\penalty0 (3):\penalty0 5, 2022.

\bibitem[Yu et~al.(2023)Yu, Shi, Pasunuru, Muller, Golovneva, Wang, Babu, Tang, Karrer, Sheynin, et~al.]{yu2023scaling}
Lili Yu, Bowen Shi, Ramakanth Pasunuru, Benjamin Muller, Olga Golovneva, Tianlu Wang, Arun Babu, Binh Tang, Brian Karrer, Shelly Sheynin, et~al.
\newblock Scaling autoregressive multi-modal models: Pretraining and instruction tuning.
\newblock \emph{arXiv preprint arXiv:2309.02591}, 2023.

\bibitem[Zhang et~al.(2021)Zhang, Koh, Baldridge, Lee, and Yang]{zhang2021cross}
Han Zhang, Jing~Yu Koh, Jason Baldridge, Honglak Lee, and Yinfei Yang.
\newblock Cross-modal contrastive learning for text-to-image generation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 833--842, 2021.

\bibitem[Zhang et~al.(2023)Zhang, Rao, and Agrawala]{zhang2023adding}
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 3836--3847, 2023.

\end{thebibliography}
