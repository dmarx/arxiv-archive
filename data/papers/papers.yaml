'1411.1792':
  abstract: 'Many deep neural networks trained on natural images exhibit a curious

    phenomenon in common: on the first layer they learn features similar to Gabor

    filters and color blobs. Such first-layer features appear not to be specific to

    a particular dataset or task, but general in that they are applicable to many

    datasets and tasks. Features must eventually transition from general to

    specific by the last layer of the network, but this transition has not been

    studied extensively. In this paper we experimentally quantify the generality

    versus specificity of neurons in each layer of a deep convolutional neural

    network and report a few surprising results. Transferability is negatively

    affected by two distinct issues: (1) the specialization of higher layer neurons

    to their original task at the expense of performance on the target task, which

    was expected, and (2) optimization difficulties related to splitting networks

    between co-adapted neurons, which was not expected. In an example network

    trained on ImageNet, we demonstrate that either of these two issues may

    dominate, depending on whether features are transferred from the bottom,

    middle, or top of the network. We also document that the transferability of

    features decreases as the distance between the base task and target task

    increases, but that transferring features even from distant tasks can be better

    than using random features. A final surprising result is that initializing a

    network with transferred features from almost any number of layers can produce

    a boost to generalization that lingers even after fine-tuning to the target

    dataset.'
  arxivId: '1411.1792'
  authors: Jason Yosinski, Jeff Clune, Yoshua Bengio, Hod Lipson
  created_at: '2024-12-24T02:44:32.596984'
  issue_number: 212
  issue_url: https://github.com/dmarx/arxiv-archive/issues/212
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: How transferable are features in deep neural networks?
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/1411.1792v1
'1503.03585':
  abstract: 'A central problem in machine learning involves modeling complex data-sets

    using highly flexible families of probability distributions in which learning,

    sampling, inference, and evaluation are still analytically or computationally

    tractable. Here, we develop an approach that simultaneously achieves both

    flexibility and tractability. The essential idea, inspired by non-equilibrium

    statistical physics, is to systematically and slowly destroy structure in a

    data distribution through an iterative forward diffusion process. We then learn

    a reverse diffusion process that restores structure in data, yielding a highly

    flexible and tractable generative model of the data. This approach allows us to

    rapidly learn, sample from, and evaluate probabilities in deep generative

    models with thousands of layers or time steps, as well as to compute

    conditional and posterior probabilities under the learned model. We

    additionally release an open source reference implementation of the algorithm.'
  arxivId: '1503.03585'
  authors: Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, Surya Ganguli
  created_at: '2024-12-23T05:03:18.844600'
  issue_number: 118
  issue_url: https://github.com/dmarx/arxiv-archive/issues/118
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-23T05:14:17.130560'
  state: open
  title: Deep Unsupervised Learning using Nonequilibrium Thermodynamics
  total_reading_time_seconds: 46
  url: http://arxiv.org/abs/1503.03585v8
'1506.06579':
  abstract: 'Recent years have produced great advances in training large, deep neural

    networks (DNNs), including notable successes in training convolutional neural

    networks (convnets) to recognize natural images. However, our understanding of

    how these models work, especially what computations they perform at

    intermediate layers, has lagged behind. Progress in the field will be further

    accelerated by the development of better tools for visualizing and interpreting

    neural nets. We introduce two such tools here. The first is a tool that

    visualizes the activations produced on each layer of a trained convnet as it

    processes an image or video (e.g. a live webcam stream). We have found that

    looking at live activations that change in response to user input helps build

    valuable intuitions about how convnets work. The second tool enables

    visualizing features at each layer of a DNN via regularized optimization in

    image space. Because previous versions of this idea produced less recognizable

    images, here we introduce several new regularization methods that combine to

    produce qualitatively clearer, more interpretable visualizations. Both tools

    are open source and work on a pre-trained convnet with minimal setup.'
  arxivId: '1506.06579'
  authors: Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, Hod Lipson
  created_at: '2024-12-24T03:19:07.555285'
  issue_number: 214
  issue_url: https://github.com/dmarx/arxiv-archive/issues/214
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: Understanding Neural Networks Through Deep Visualization
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/1506.06579v1
'1705.08926':
  abstract: 'Cooperative multi-agent systems can be naturally used to model many real

    world problems, such as network packet routing and the coordination of

    autonomous vehicles. There is a great need for new reinforcement learning

    methods that can efficiently learn decentralised policies for such systems. To

    this end, we propose a new multi-agent actor-critic method called

    counterfactual multi-agent (COMA) policy gradients. COMA uses a centralised

    critic to estimate the Q-function and decentralised actors to optimise the

    agents'' policies. In addition, to address the challenges of multi-agent credit

    assignment, it uses a counterfactual baseline that marginalises out a single

    agent''s action, while keeping the other agents'' actions fixed. COMA also uses
    a

    critic representation that allows the counterfactual baseline to be computed

    efficiently in a single forward pass. We evaluate COMA in the testbed of

    StarCraft unit micromanagement, using a decentralised variant with significant

    partial observability. COMA significantly improves average performance over

    other multi-agent actor-critic methods in this setting, and the best performing

    agents are competitive with state-of-the-art centralised controllers that get

    access to the full state.'
  arxivId: '1705.08926'
  authors: Jakob Foerster, Gregory Farquhar, Triantafyllos Afouras, Nantas Nardelli,
    Shimon Whiteson
  created_at: '2024-12-23T05:03:45.328469'
  issue_number: 127
  issue_url: https://github.com/dmarx/arxiv-archive/issues/127
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: Counterfactual Multi-Agent Policy Gradients
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/1705.08926v3
'1706.05806':
  abstract: 'We propose a new technique, Singular Vector Canonical Correlation Analysis

    (SVCCA), a tool for quickly comparing two representations in a way that is both

    invariant to affine transform (allowing comparison between different layers and

    networks) and fast to compute (allowing more comparisons to be calculated than

    with previous methods). We deploy this tool to measure the intrinsic

    dimensionality of layers, showing in some cases needless over-parameterization;

    to probe learning dynamics throughout training, finding that networks converge

    to final representations from the bottom up; to show where class-specific

    information in networks is formed; and to suggest new training regimes that

    simultaneously save computation and overfit less. Code:

    https://github.com/google/svcca/'
  arxivId: '1706.05806'
  authors: Maithra Raghu, Justin Gilmer, Jason Yosinski, Jascha Sohl-Dickstein
  created_at: '2024-12-24T03:19:01.559519'
  issue_number: 218
  issue_url: https://github.com/dmarx/arxiv-archive/issues/218
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-24T04:16:45.844292'
  state: open
  title: "SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning\n\
    \  Dynamics and Interpretability"
  total_reading_time_seconds: 20
  url: http://arxiv.org/abs/1706.05806v2
'1710.09412':
  abstract: 'Large deep neural networks are powerful, but exhibit undesirable behaviors

    such as memorization and sensitivity to adversarial examples. In this work, we

    propose mixup, a simple learning principle to alleviate these issues. In

    essence, mixup trains a neural network on convex combinations of pairs of

    examples and their labels. By doing so, mixup regularizes the neural network to

    favor simple linear behavior in-between training examples. Our experiments on

    the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show

    that mixup improves the generalization of state-of-the-art neural network

    architectures. We also find that mixup reduces the memorization of corrupt

    labels, increases the robustness to adversarial examples, and stabilizes the

    training of generative adversarial networks.'
  arxivId: '1710.09412'
  authors: Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, David Lopez-Paz
  created_at: '2024-12-23T05:03:30.511116'
  issue_number: 162
  issue_url: https://github.com/dmarx/arxiv-archive/issues/162
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: 'mixup: Beyond Empirical Risk Minimization'
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/1710.09412v2
'1711.11586':
  abstract: 'Many image-to-image translation problems are ambiguous, as a single input

    image may correspond to multiple possible outputs. In this work, we aim to

    model a \emph{distribution} of possible outputs in a conditional generative

    modeling setting. The ambiguity of the mapping is distilled in a

    low-dimensional latent vector, which can be randomly sampled at test time. A

    generator learns to map the given input, combined with this latent code, to the

    output. We explicitly encourage the connection between output and the latent

    code to be invertible. This helps prevent a many-to-one mapping from the latent

    code to the output during training, also known as the problem of mode collapse,

    and produces more diverse results. We explore several variants of this approach

    by employing different training objectives, network architectures, and methods

    of injecting the latent code. Our proposed method encourages bijective

    consistency between the latent encoding and output modes. We present a

    systematic comparison of our method and other variants on both perceptual

    realism and diversity.'
  arxivId: '1711.11586'
  authors: Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A. Efros,
    Oliver Wang, Eli Shechtman
  created_at: '2024-12-23T05:04:39.348908'
  issue_number: 14
  issue_url: https://github.com/dmarx/arxiv-archive/issues/14
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: Toward Multimodal Image-to-Image Translation
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/1711.11586v4
'1804.08838':
  abstract: 'Many recently trained neural networks employ large numbers of parameters
    to

    achieve good performance. One may intuitively use the number of parameters

    required as a rough gauge of the difficulty of a problem. But how accurate are

    such notions? How many parameters are really needed? In this paper we attempt

    to answer this question by training networks not in their native parameter

    space, but instead in a smaller, randomly oriented subspace. We slowly increase

    the dimension of this subspace, note at which dimension solutions first appear,

    and define this to be the intrinsic dimension of the objective landscape. The

    approach is simple to implement, computationally tractable, and produces

    several suggestive conclusions. Many problems have smaller intrinsic dimensions

    than one might suspect, and the intrinsic dimension for a given dataset varies

    little across a family of models with vastly different sizes. This latter

    result has the profound implication that once a parameter space is large enough

    to solve a problem, extra parameters serve directly to increase the

    dimensionality of the solution manifold. Intrinsic dimension allows some

    quantitative comparison of problem difficulty across supervised, reinforcement,

    and other types of learning where we conclude, for example, that solving the

    inverted pendulum problem is 100 times easier than classifying digits from

    MNIST, and playing Atari Pong from pixels is about as hard as classifying

    CIFAR-10. In addition to providing new cartography of the objective landscapes

    wandered by parameterized models, the method is a simple technique for

    constructively obtaining an upper bound on the minimum description length of a

    solution. A byproduct of this construction is a simple approach for compressing

    networks, in some cases by more than 100 times.'
  arxivId: '1804.08838'
  authors: Chunyuan Li, Heerad Farkhoor, Rosanne Liu, Jason Yosinski
  created_at: '2024-12-24T02:44:47.418353'
  issue_number: 198
  issue_url: https://github.com/dmarx/arxiv-archive/issues/198
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-24T02:44:47.419675'
  state: open
  title: Measuring the Intrinsic Dimension of Objective Landscapes
  total_reading_time_seconds: 26
  url: http://arxiv.org/abs/1804.08838v1
'1810.01588':
  abstract: 'Interpreting the prediction mechanism of complex models is currently
    one of

    the most important tasks in the machine learning field, especially with layered

    neural networks, which have achieved high predictive performance with various

    practical data sets. To reveal the global structure of a trained neural network

    in an interpretable way, a series of clustering methods have been proposed,

    which decompose the units into clusters according to the similarity of their

    inference roles. The main problems in these studies were that (1) we have no

    prior knowledge about the optimal resolution for the decomposition, or the

    appropriate number of clusters, and (2) there was no method with which to

    acquire knowledge about whether the outputs of each cluster have a positive or

    negative correlation with the input and output dimension values. In this paper,

    to solve these problems, we propose a method for obtaining a hierarchical

    modular representation of a layered neural network. The application of a

    hierarchical clustering method to a trained network reveals a tree-structured

    relationship among hidden layer units, based on their feature vectors defined

    by their correlation with the input and output dimension values.'
  arxivId: '1810.01588'
  authors: Chihiro Watanabe
  created_at: '2024-12-24T03:18:52.770781'
  issue_number: 230
  issue_url: https://github.com/dmarx/arxiv-archive/issues/230
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-24T03:18:52.772559'
  state: open
  title: "Interpreting Layered Neural Networks via Hierarchical Modular\n  Representation"
  total_reading_time_seconds: 6
  url: http://arxiv.org/abs/1810.01588v1
'1901.10159':
  abstract: 'To understand the dynamics of optimization in deep neural networks, we

    develop a tool to study the evolution of the entire Hessian spectrum throughout

    the optimization process. Using this, we study a number of hypotheses

    concerning smoothness, curvature, and sharpness in the deep learning

    literature. We then thoroughly analyze a crucial structural feature of the

    spectra: in non-batch normalized networks, we observe the rapid appearance of

    large isolated eigenvalues in the spectrum, along with a surprising

    concentration of the gradient in the corresponding eigenspaces. In batch

    normalized networks, these two effects are almost absent. We characterize these

    effects, and explain how they affect optimization speed through both theory and

    experiments. As part of this work, we adapt advanced tools from numerical

    linear algebra that allow scalable and accurate estimation of the entire

    Hessian spectrum of ImageNet-scale neural networks; this technique may be of

    independent interest in other applications.'
  arxivId: '1901.10159'
  authors: Behrooz Ghorbani, Shankar Krishnan, Ying Xiao
  created_at: '2024-12-24T04:16:42.640297'
  issue_number: 239
  issue_url: https://github.com/dmarx/arxiv-archive/issues/239
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-24T05:13:36.809798'
  state: open
  title: "An Investigation into Neural Net Optimization via Hessian Eigenvalue\n \
    \ Density"
  total_reading_time_seconds: 102
  url: http://arxiv.org/abs/1901.10159v1
'1904.08779':
  abstract: 'We present SpecAugment, a simple data augmentation method for speech

    recognition. SpecAugment is applied directly to the feature inputs of a neural

    network (i.e., filter bank coefficients). The augmentation policy consists of

    warping the features, masking blocks of frequency channels, and masking blocks

    of time steps. We apply SpecAugment on Listen, Attend and Spell networks for

    end-to-end speech recognition tasks. We achieve state-of-the-art performance on

    the LibriSpeech 960h and Swichboard 300h tasks, outperforming all prior work.

    On LibriSpeech, we achieve 6.8% WER on test-other without the use of a language

    model, and 5.8% WER with shallow fusion with a language model. This compares to

    the previous state-of-the-art hybrid system of 7.5% WER. For Switchboard, we

    achieve 7.2%/14.6% on the Switchboard/CallHome portion of the Hub5''00 test set

    without the use of a language model, and 6.8%/14.1% with shallow fusion, which

    compares to the previous state-of-the-art hybrid system at 8.3%/17.3% WER.'
  arxivId: '1904.08779'
  authors: Daniel S. Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph,
    Ekin D. Cubuk, Quoc V. Le
  created_at: '2024-12-23T05:04:33.321756'
  issue_number: 60
  issue_url: https://github.com/dmarx/arxiv-archive/issues/60
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "SpecAugment: A Simple Data Augmentation Method for Automatic Speech\n  Recognition"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/1904.08779v3
'1906.01563':
  abstract: 'Even though neural networks enjoy widespread use, they still struggle
    to

    learn the basic laws of physics. How might we endow them with better inductive

    biases? In this paper, we draw inspiration from Hamiltonian mechanics to train

    models that learn and respect exact conservation laws in an unsupervised

    manner. We evaluate our models on problems where conservation of energy is

    important, including the two-body problem and pixel observations of a pendulum.

    Our model trains faster and generalizes better than a regular neural network.

    An interesting side effect is that our model is perfectly reversible in time.'
  arxivId: '1906.01563'
  authors: Sam Greydanus, Misko Dzamba, Jason Yosinski
  created_at: '2024-12-24T03:19:04.530050'
  issue_number: 216
  issue_url: https://github.com/dmarx/arxiv-archive/issues/216
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: Hamiltonian Neural Networks
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/1906.01563v3
'1906.04358':
  abstract: 'Not all neural network architectures are created equal, some perform
    much

    better than others for certain tasks. But how important are the weight

    parameters of a neural network compared to its architecture? In this work, we

    question to what extent neural network architectures alone, without learning

    any weight parameters, can encode solutions for a given task. We propose a

    search method for neural network architectures that can already perform a task

    without any explicit weight training. To evaluate these networks, we populate

    the connections with a single shared weight parameter sampled from a uniform

    random distribution, and measure the expected performance. We demonstrate that

    our method can find minimal neural network architectures that can perform

    several reinforcement learning tasks without weight training. On a supervised

    learning domain, we find network architectures that achieve much higher than

    chance accuracy on MNIST using random weights. Interactive version of this

    paper at https://weightagnostic.github.io/'
  arxivId: '1906.04358'
  authors: Adam Gaier, David Ha
  created_at: '2024-12-24T04:16:45.841019'
  issue_number: 235
  issue_url: https://github.com/dmarx/arxiv-archive/issues/235
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-24T04:16:45.842903'
  state: open
  title: Weight Agnostic Neural Networks
  total_reading_time_seconds: 20
  url: http://arxiv.org/abs/1906.04358v2
'1906.05433':
  abstract: 'Climate change is one of the greatest challenges facing humanity, and
    we, as

    machine learning experts, may wonder how we can help. Here we describe how

    machine learning can be a powerful tool in reducing greenhouse gas emissions

    and helping society adapt to a changing climate. From smart grids to disaster

    management, we identify high impact problems where existing gaps can be filled

    by machine learning, in collaboration with other fields. Our recommendations

    encompass exciting research questions as well as promising business

    opportunities. We call on the machine learning community to join the global

    effort against climate change.'
  arxivId: '1906.05433'
  authors: David Rolnick, Priya L. Donti, Lynn H. Kaack, Kelly Kochanski, Alexandre
    Lacoste, Kris Sankaran, Andrew Slavin Ross, Nikola Milojevic-Dupont, Natasha Jaques,
    Anna Waldman-Brown, Alexandra Luccioni, Tegan Maharaj, Evan D. Sherwin, S. Karthik
    Mukkavilli, Konrad P. Kording, Carla Gomes, Andrew Y. Ng, Demis Hassabis, John
    C. Platt, Felix Creutzig, Jennifer Chayes, Yoshua Bengio
  created_at: '2024-12-23T05:04:09.536092'
  issue_number: 111
  issue_url: https://github.com/dmarx/arxiv-archive/issues/111
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: Tackling Climate Change with Machine Learning
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/1906.05433v2
'1912.02757':
  abstract: 'Deep ensembles have been empirically shown to be a promising approach
    for

    improving accuracy, uncertainty and out-of-distribution robustness of deep

    learning models. While deep ensembles were theoretically motivated by the

    bootstrap, non-bootstrap ensembles trained with just random initialization also

    perform well in practice, which suggests that there could be other explanations

    for why deep ensembles work well. Bayesian neural networks, which learn

    distributions over the parameters of the network, are theoretically

    well-motivated by Bayesian principles, but do not perform as well as deep

    ensembles in practice, particularly under dataset shift. One possible

    explanation for this gap between theory and practice is that popular scalable

    variational Bayesian methods tend to focus on a single mode, whereas deep

    ensembles tend to explore diverse modes in function space. We investigate this

    hypothesis by building on recent work on understanding the loss landscape of

    neural networks and adding our own exploration to measure the similarity of

    functions in the space of predictions. Our results show that random

    initializations explore entirely different modes, while functions along an

    optimization trajectory or sampled from the subspace thereof cluster within a

    single mode predictions-wise, while often deviating significantly in the weight

    space. Developing the concept of the diversity--accuracy plane, we show that

    the decorrelation power of random initializations is unmatched by popular

    subspace sampling methods. Finally, we evaluate the relative effects of

    ensembling, subspace based methods and ensembles of subspace based methods, and

    the experimental results validate our hypothesis.'
  arxivId: '1912.02757'
  authors: Stanislav Fort, Huiyi Hu, Balaji Lakshminarayanan
  created_at: '2024-12-24T03:18:58.544773'
  issue_number: 224
  issue_url: https://github.com/dmarx/arxiv-archive/issues/224
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-24T03:18:58.545978'
  state: open
  title: 'Deep Ensembles: A Loss Landscape Perspective'
  total_reading_time_seconds: 6
  url: http://arxiv.org/abs/1912.02757v2
'2006.14769':
  abstract: 'We present the Supermasks in Superposition (SupSup) model, capable of

    sequentially learning thousands of tasks without catastrophic forgetting. Our

    approach uses a randomly initialized, fixed base network and for each task

    finds a subnetwork (supermask) that achieves good performance. If task identity

    is given at test time, the correct subnetwork can be retrieved with minimal

    memory usage. If not provided, SupSup can infer the task using gradient-based

    optimization to find a linear superposition of learned supermasks which

    minimizes the output entropy. In practice we find that a single gradient step

    is often sufficient to identify the correct mask, even among 2500 tasks. We

    also showcase two promising extensions. First, SupSup models can be trained

    entirely without task identity information, as they may detect when they are

    uncertain about new data and allocate an additional supermask for the new

    training distribution. Finally the entire, growing set of supermasks can be

    stored in a constant-sized reservoir by implicitly storing them as attractors

    in a fixed-sized Hopfield network.'
  arxivId: '2006.14769'
  authors: Mitchell Wortsman, Vivek Ramanujan, Rosanne Liu, Aniruddha Kembhavi, Mohammad
    Rastegari, Jason Yosinski, Ali Farhadi
  created_at: '2024-12-24T02:44:35.633974'
  issue_number: 210
  issue_url: https://github.com/dmarx/arxiv-archive/issues/210
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: Supermasks in Superposition
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2006.14769v3
'2009.10195':
  abstract: 'Models that perform well on a training domain often fail to generalize
    to

    out-of-domain (OOD) examples. Data augmentation is a common method used to

    prevent overfitting and improve OOD generalization. However, in natural

    language, it is difficult to generate new examples that stay on the underlying

    data manifold. We introduce SSMBA, a data augmentation method for generating

    synthetic training examples by using a pair of corruption and reconstruction

    functions to move randomly on a data manifold. We investigate the use of SSMBA

    in the natural language domain, leveraging the manifold assumption to

    reconstruct corrupted text with masked language models. In experiments on

    robustness benchmarks across 3 tasks and 9 datasets, SSMBA consistently

    outperforms existing data augmentation methods and baseline models on both

    in-domain and OOD data, achieving gains of 0.8% accuracy on OOD Amazon reviews,

    1.8% accuracy on OOD MNLI, and 1.4 BLEU on in-domain IWSLT14 German-English.'
  arxivId: '2009.10195'
  authors: Nathan Ng, Kyunghyun Cho, Marzyeh Ghassemi
  created_at: '2024-12-23T05:04:27.328301'
  issue_number: 98
  issue_url: https://github.com/dmarx/arxiv-archive/issues/98
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving\n\
    \  Out-of-Domain Robustness"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2009.10195v2
'2010.15110':
  abstract: 'In suitably initialized wide networks, small learning rates transform
    deep

    neural networks (DNNs) into neural tangent kernel (NTK) machines, whose

    training dynamics is well-approximated by a linear weight expansion of the

    network at initialization. Standard training, however, diverges from its

    linearization in ways that are poorly understood. We study the relationship

    between the training dynamics of nonlinear deep networks, the geometry of the

    loss landscape, and the time evolution of a data-dependent NTK. We do so

    through a large-scale phenomenological analysis of training, synthesizing

    diverse measures characterizing loss landscape geometry and NTK dynamics. In

    multiple neural architectures and datasets, we find these diverse measures

    evolve in a highly correlated manner, revealing a universal picture of the deep

    learning process. In this picture, deep network training exhibits a highly

    chaotic rapid initial transient that within 2 to 3 epochs determines the final

    linearly connected basin of low loss containing the end point of training.

    During this chaotic transient, the NTK changes rapidly, learning useful

    features from the training data that enables it to outperform the standard

    initial NTK by a factor of 3 in less than 3 to 4 epochs. After this rapid

    chaotic transient, the NTK changes at constant velocity, and its performance

    matches that of full network training in 15% to 45% of training time. Overall,

    our analysis reveals a striking correlation between a diverse set of metrics

    over training time, governed by a rapid chaotic to stable transition in the

    first few epochs, that together poses challenges and opportunities for the

    development of more accurate theories of deep learning.'
  arxivId: '2010.15110'
  authors: Stanislav Fort, Gintare Karolina Dziugaite, Mansheej Paul, Sepideh Kharaghani,
    Daniel M. Roy, Surya Ganguli
  created_at: '2024-12-24T04:16:39.854776'
  issue_number: 245
  issue_url: https://github.com/dmarx/arxiv-archive/issues/245
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "Deep learning versus kernel learning: an empirical study of loss\n  landscape\
    \ geometry and the time evolution of the Neural Tangent Kernel"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2010.15110v1
'2012.13255':
  abstract: 'Although pretrained language models can be fine-tuned to produce

    state-of-the-art results for a very wide range of language understanding tasks,

    the dynamics of this process are not well understood, especially in the low

    data regime. Why can we use relatively vanilla gradient descent algorithms

    (e.g., without strong regularization) to tune a model with hundreds of millions

    of parameters on datasets with only hundreds or thousands of labeled examples?

    In this paper, we argue that analyzing fine-tuning through the lens of

    intrinsic dimension provides us with empirical and theoretical intuitions to

    explain this remarkable phenomenon. We empirically show that common pre-trained

    models have a very low intrinsic dimension; in other words, there exists a low

    dimension reparameterization that is as effective for fine-tuning as the full

    parameter space. For example, by optimizing only 200 trainable parameters

    randomly projected back into the full space, we can tune a RoBERTa model to

    achieve 90\% of the full parameter performance levels on MRPC. Furthermore, we

    empirically show that pre-training implicitly minimizes intrinsic dimension

    and, perhaps surprisingly, larger models tend to have lower intrinsic dimension

    after a fixed number of pre-training updates, at least in part explaining their

    extreme effectiveness. Lastly, we connect intrinsic dimensionality with low

    dimensional task representations and compression based generalization bounds to

    provide intrinsic-dimension-based generalization bounds that are independent of

    the full parameter count.'
  arxivId: '2012.13255'
  authors: Armen Aghajanyan, Luke Zettlemoyer, Sonal Gupta
  created_at: '2024-12-24T02:44:38.463464'
  issue_number: 222
  issue_url: https://github.com/dmarx/arxiv-archive/issues/222
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-24T03:19:07.556630'
  state: open
  title: "Intrinsic Dimensionality Explains the Effectiveness of Language Model\n\
    \  Fine-Tuning"
  total_reading_time_seconds: 7
  url: http://arxiv.org/abs/2012.13255v1
'2105.05720':
  abstract: "Recent trend towards increasing large machine learning models require\
    \ both\ntraining and inference tasks to be distributed. Considering the huge cost\
    \ of\ntraining these models, it is imperative to unlock optimizations in computation\n\
    and communication to obtain best performance. However, current logical\nseparation\
    \ between computation and communication kernels in deep learning\nframeworks misses\
    \ the optimization opportunities across such barrier. Breaking\nthis abstraction\
    \ with a holistic consideration can provide many optimizations\nto provide performance\
    \ improvements in distributed workloads. Manually applying\nthese optimizations\
    \ needs modifications in underlying computation and\ncommunication libraries for\
    \ each scenario, which is time consuming and\nerror-prone.\n  Therefore, we present\
    \ CoCoNeT, with a DSL to express a program with both\ncomputation and communication.\
    \ CoCoNeT contains several machine learning aware\ntransformations to optimize\
    \ a program and a compiler to generate high\nperformance kernels. Providing both\
    \ computation and communication as first\nclass constructs allows users to work\
    \ on a high-level abstraction and apply\npowerful optimizations, such as fusion\
    \ or overlapping of communication and\ncomputation. CoCoNeT enables us to optimize\
    \ data-, model-and pipeline-parallel\nworkloads in large language models with\
    \ only a few lines of code. Experiments\nshow CoCoNeT significantly outperforms\
    \ state-of-the-art distributed machine\nlearning implementations."
  arxivId: '2105.05720'
  authors: Abhinav Jangda, Jun Huang, Guodong Liu, Amir Hossein Nodehi Sabet, Saeed
    Maleki, Youshan Miao, Madanlal Musuvathi, Todd Mytkowicz, Olli Sarikivi
  created_at: '2024-12-23T05:04:48.322668'
  issue_number: 49
  issue_url: https://github.com/dmarx/arxiv-archive/issues/49
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "Breaking the Computation and Communication Abstraction Barrier in\n  Distributed\
    \ Machine Learning Workloads"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2105.05720v5
'2106.04647':
  abstract: 'Adapting large-scale pretrained language models to downstream tasks via

    fine-tuning is the standard method for achieving state-of-the-art performance

    on NLP benchmarks. However, fine-tuning all weights of models with millions or

    billions of parameters is sample-inefficient, unstable in low-resource

    settings, and wasteful as it requires storing a separate copy of the model for

    each task. Recent work has developed parameter-efficient fine-tuning methods,

    but these approaches either still require a relatively large number of

    parameters or underperform standard fine-tuning. In this work, we propose

    Compacter, a method for fine-tuning large-scale language models with a better

    trade-off between task performance and the number of trainable parameters than

    prior work. Compacter accomplishes this by building on top of ideas from

    adapters, low-rank optimization, and parameterized hypercomplex multiplication

    layers. Specifically, Compacter inserts task-specific weight matrices into a

    pretrained model''s weights, which are computed efficiently as a sum of

    Kronecker products between shared "slow" weights and "fast" rank-one matrices

    defined per Compacter layer. By only training 0.047% of a pretrained model''s

    parameters, Compacter performs on par with standard fine-tuning on GLUE and

    outperforms standard fine-tuning on SuperGLUE and low-resource settings. Our

    code is publicly available at~\url{https://github.com/rabeehk/compacter}.'
  arxivId: '2106.04647'
  authors: Rabeeh Karimi Mahabadi, James Henderson, Sebastian Ruder
  created_at: '2024-12-24T02:44:44.394096'
  issue_number: 202
  issue_url: https://github.com/dmarx/arxiv-archive/issues/202
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-24T02:44:44.395207'
  state: open
  title: 'Compacter: Efficient Low-Rank Hypercomplex Adapter Layers'
  total_reading_time_seconds: 3
  url: http://arxiv.org/abs/2106.04647v2
'2203.15556':
  abstract: 'We investigate the optimal model size and number of tokens for training
    a

    transformer language model under a given compute budget. We find that current

    large language models are significantly undertrained, a consequence of the

    recent focus on scaling language models whilst keeping the amount of training

    data constant. By training over 400 language models ranging from 70 million to

    over 16 billion parameters on 5 to 500 billion tokens, we find that for

    compute-optimal training, the model size and the number of training tokens

    should be scaled equally: for every doubling of model size the number of

    training tokens should also be doubled. We test this hypothesis by training a

    predicted compute-optimal model, Chinchilla, that uses the same compute budget

    as Gopher but with 70B parameters and 4$\times$ more more data. Chinchilla

    uniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1

    (178B), and Megatron-Turing NLG (530B) on a large range of downstream

    evaluation tasks. This also means that Chinchilla uses substantially less

    compute for fine-tuning and inference, greatly facilitating downstream usage.

    As a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5%

    on the MMLU benchmark, greater than a 7% improvement over Gopher.'
  arxivId: '2203.15556'
  authors: Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya,
    Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes
    Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den
    Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen,
    Jack W. Rae, Oriol Vinyals, Laurent Sifre
  created_at: '2024-12-23T05:04:30.316093'
  issue_number: 67
  issue_url: https://github.com/dmarx/arxiv-archive/issues/67
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: Training Compute-Optimal Large Language Models
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2203.15556v1
'2209.02740':
  abstract: 'Networks of weakly coupled oscillators had a profound impact on our

    understanding of complex systems. Studies on model reconstruction from data

    have shown prevalent contributions from hypernetworks with triplet and higher

    interactions among oscillators, in spite that such models were originally

    defined as oscillator networks with pairwise interactions. Here, we show that

    hypernetworks can spontaneously emerge even in the presence of pairwise albeit

    nonlinear coupling given certain triplet frequency resonance conditions. The

    results are demonstrated in experiments with electrochemical oscillators and in

    simulations with integrate-and-fire neurons. By developing a comprehensive

    theory, we uncover the mechanism for emergent hypernetworks by identifying

    appearing and forbidden frequency resonant conditions. Furthermore, it is shown

    that microscopic linear (difference) coupling among units results in coupled

    mean fields, which have sufficient nonlinearity to facilitate hypernetworks.

    Our findings shed light on the apparent abundance of hypernetworks and provide

    a constructive way to predict and engineer their emergence.'
  arxivId: '2209.02740'
  authors: Eddie Nijholt, Jorge Luis Ocampo-Espindola, Deniz Eroglu, István Z. Kiss,
    Tiago Pereira
  created_at: '2024-12-23T05:04:21.323306'
  issue_number: 103
  issue_url: https://github.com/dmarx/arxiv-archive/issues/103
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: Emergent hypernetworks in weakly coupled oscillators
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2209.02740v1
'2302.05543':
  abstract: 'We present ControlNet, a neural network architecture to add spatial

    conditioning controls to large, pretrained text-to-image diffusion models.

    ControlNet locks the production-ready large diffusion models, and reuses their

    deep and robust encoding layers pretrained with billions of images as a strong

    backbone to learn a diverse set of conditional controls. The neural

    architecture is connected with "zero convolutions" (zero-initialized

    convolution layers) that progressively grow the parameters from zero and ensure

    that no harmful noise could affect the finetuning. We test various conditioning

    controls, eg, edges, depth, segmentation, human pose, etc, with Stable

    Diffusion, using single or multiple conditions, with or without prompts. We

    show that the training of ControlNets is robust with small (<50k) and large

    (>1m) datasets. Extensive results show that ControlNet may facilitate wider

    applications to control image diffusion models.'
  arxivId: '2302.05543'
  authors: Lvmin Zhang, Anyi Rao, Maneesh Agrawala
  created_at: '2024-12-24T02:44:41.401461'
  issue_number: 205
  issue_url: https://github.com/dmarx/arxiv-archive/issues/205
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-24T03:19:07.557119'
  state: open
  title: Adding Conditional Control to Text-to-Image Diffusion Models
  total_reading_time_seconds: 23
  url: http://arxiv.org/abs/2302.05543v3
'2302.11529':
  abstract: 'Transfer learning has recently become the dominant paradigm of machine

    learning. Pre-trained models fine-tuned for downstream tasks achieve better

    performance with fewer labelled examples. Nonetheless, it remains unclear how

    to develop models that specialise towards multiple tasks without incurring

    negative interference and that generalise systematically to non-identically

    distributed tasks. Modular deep learning has emerged as a promising solution to

    these challenges. In this framework, units of computation are often implemented

    as autonomous parameter-efficient modules. Information is conditionally routed

    to a subset of modules and subsequently aggregated. These properties enable

    positive transfer and systematic generalisation by separating computation from

    routing and updating modules locally. We offer a survey of modular

    architectures, providing a unified view over several threads of research that

    evolved independently in the scientific literature. Moreover, we explore

    various additional purposes of modularity, including scaling language models,

    causal inference, programme induction, and planning in reinforcement learning.

    Finally, we report various concrete applications where modularity has been

    successfully deployed such as cross-lingual and cross-modal knowledge transfer.

    Related talks and projects to this survey, are available at

    https://www.modulardeeplearning.com/.'
  arxivId: '2302.11529'
  authors: Jonas Pfeiffer, Sebastian Ruder, Ivan Vulić, Edoardo Maria Ponti
  created_at: '2024-12-24T03:18:55.545390'
  issue_number: 227
  issue_url: https://github.com/dmarx/arxiv-archive/issues/227
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-24T04:16:45.843769'
  state: open
  title: Modular Deep Learning
  total_reading_time_seconds: 26
  url: http://arxiv.org/abs/2302.11529v2
'2308.10718':
  abstract: "Recent years have witnessed success in AIGC (AI Generated Content). People\n\
    can make use of a pre-trained diffusion model to generate images of high\nquality\
    \ or freely modify existing pictures with only prompts in nature\nlanguage. More\
    \ excitingly, the emerging personalization techniques make it\nfeasible to create\
    \ specific-desired images with only a few images as\nreferences. However, this\
    \ induces severe threats if such advanced techniques\nare misused by malicious\
    \ users, such as spreading fake news or defaming\nindividual reputations. Thus,\
    \ it is necessary to regulate personalization\nmodels (i.e., concept censorship)\
    \ for their development and advancement.\n  In this paper, we focus on the personalization\
    \ technique dubbed Textual\nInversion (TI), which is becoming prevailing for its\
    \ lightweight nature and\nexcellent performance. TI crafts the word embedding\
    \ that contains detailed\ninformation about a specific object. Users can easily\
    \ download the word\nembedding from public websites like Civitai and add it to\
    \ their own stable\ndiffusion model without fine-tuning for personalization. To\
    \ achieve the concept\ncensorship of a TI model, we propose leveraging the backdoor\
    \ technique for good\nby injecting backdoors into the Textual Inversion embeddings.\
    \ Briefly, we\nselect some sensitive words as triggers during the training of\
    \ TI, which will\nbe censored for normal use. In the subsequent generation stage,\
    \ if the triggers\nare combined with personalized embeddings as final prompts,\
    \ the model will\noutput a pre-defined target image rather than images including\
    \ the desired\nmalicious concept.\n  To demonstrate the effectiveness of our approach,\
    \ we conduct extensive\nexperiments on Stable Diffusion, a prevailing open-sourced\
    \ text-to-image model.\nOur code, data, and results are available at\nhttps://concept-censorship.github.io."
  arxivId: '2308.10718'
  authors: Yutong Wu, Jie Zhang, Florian Kerschbaum, Tianwei Zhang
  created_at: '2024-12-23T05:03:36.849082'
  issue_number: 160
  issue_url: https://github.com/dmarx/arxiv-archive/issues/160
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: Backdooring Textual Inversion for Concept Censorship
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2308.10718v2
'2312.00330':
  abstract: 'Text-to-video (T2V) models have shown remarkable capabilities in generating

    diverse videos. However, they struggle to produce user-desired stylized videos

    due to (i) text''s inherent clumsiness in expressing specific styles and (ii)

    the generally degraded style fidelity. To address these challenges, we

    introduce StyleCrafter, a generic method that enhances pre-trained T2V models

    with a style control adapter, enabling video generation in any style by

    providing a reference image. Considering the scarcity of stylized video

    datasets, we propose to first train a style control adapter using style-rich

    image datasets, then transfer the learned stylization ability to video

    generation through a tailor-made finetuning paradigm. To promote content-style

    disentanglement, we remove style descriptions from the text prompt and extract

    style information solely from the reference image using a decoupling learning

    strategy. Additionally, we design a scale-adaptive fusion module to balance the

    influences of text-based content features and image-based style features, which

    helps generalization across various text and style combinations. StyleCrafter

    efficiently generates high-quality stylized videos that align with the content

    of the texts and resemble the style of the reference images. Experiments

    demonstrate that our approach is more flexible and efficient than existing

    competitors.'
  arxivId: '2312.00330'
  authors: Gongye Liu, Menghan Xia, Yong Zhang, Haoxin Chen, Jinbo Xing, Yibo Wang,
    Xintao Wang, Yujiu Yang, Ying Shan
  created_at: '2024-12-23T05:04:51.322550'
  issue_number: 38
  issue_url: https://github.com/dmarx/arxiv-archive/issues/38
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "StyleCrafter: Enhancing Stylized Text-to-Video Generation with Style\n \
    \ Adapter"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2312.00330v2
'2312.07731':
  abstract: 'Recent work proposed a new mechanism to remove protective perturbation
    added

    by Glaze in order to again enable mimicry of art styles from images protected

    by Glaze. Despite promising results shown in the original paper, our own tests

    with the authors'' code demonstrated several limitations of the proposed

    purification approach. The main limitations are 1) purification has a limited

    effect when tested on artists that are not well-known historical artists

    already embedded in original training data, 2) problems in evaluation metrics,

    and 3) collateral damage on mimicry result for clean images. We believe these

    limitations should be carefully considered in order to understand real world

    usability of the purification attack.'
  arxivId: '2312.07731'
  authors: Shawn Shan, Stanley Wu, Haitao Zheng, Ben Y. Zhao
  created_at: '2024-12-23T05:03:33.342927'
  issue_number: 161
  issue_url: https://github.com/dmarx/arxiv-archive/issues/161
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: A Response to Glaze Purification via IMPRESS
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2312.07731v1
'2402.03239':
  abstract: 'Bluesky is a new social network built upon the AT Protocol, a decentralized

    foundation for public social media. It was launched in private beta in February

    2023, and has grown to over 10 million registered users by October 2024. In

    this paper we introduce the architecture of Bluesky and the AT Protocol, and

    explain how the technical design of Bluesky is informed by our goals: to enable

    decentralization by having multiple interoperable providers for every part of

    the system; to make it easy for users to switch providers; to give users agency

    over the content they see; and to provide a simple user experience that does

    not burden users with complexity arising from the system''s decentralized

    nature. The system''s openness allows anybody to contribute to content

    moderation and community management, and we invite the research community to

    use Bluesky as a dataset and testing ground for new approaches in social media

    moderation.'
  arxivId: '2402.03239'
  authors: Martin Kleppmann, Paul Frazee, Jake Gold, Jay Graber, Daniel Holmgren,
    Devin Ivy, Jeromy Johnson, Bryan Newbold, Jaz Volpert
  created_at: '2024-12-23T05:04:18.348075'
  issue_number: 105
  issue_url: https://github.com/dmarx/arxiv-archive/issues/105
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: 'Bluesky and the AT Protocol: Usable Decentralized Social Media'
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2402.03239v2
'2403.14781':
  abstract: 'In this study, we introduce a methodology for human image animation by

    leveraging a 3D human parametric model within a latent diffusion framework to

    enhance shape alignment and motion guidance in curernt human generative

    techniques. The methodology utilizes the SMPL(Skinned Multi-Person Linear)

    model as the 3D human parametric model to establish a unified representation of

    body shape and pose. This facilitates the accurate capture of intricate human

    geometry and motion characteristics from source videos. Specifically, we

    incorporate rendered depth images, normal maps, and semantic maps obtained from

    SMPL sequences, alongside skeleton-based motion guidance, to enrich the

    conditions to the latent diffusion model with comprehensive 3D shape and

    detailed pose attributes. A multi-layer motion fusion module, integrating

    self-attention mechanisms, is employed to fuse the shape and motion latent

    representations in the spatial domain. By representing the 3D human parametric

    model as the motion guidance, we can perform parametric shape alignment of the

    human body between the reference image and the source video motion.

    Experimental evaluations conducted on benchmark datasets demonstrate the

    methodology''s superior ability to generate high-quality human animations that

    accurately capture both pose and shape variations. Furthermore, our approach

    also exhibits superior generalization capabilities on the proposed in-the-wild

    dataset. Project page: https://fudan-generative-vision.github.io/champ.'
  arxivId: '2403.14781'
  authors: Shenhao Zhu, Junming Leo Chen, Zuozhuo Dai, Qingkun Su, Yinghui Xu, Xun
    Cao, Yao Yao, Hao Zhu, Siyu Zhu
  created_at: '2024-12-23T22:12:50.380750'
  issue_number: 197
  issue_url: https://github.com/dmarx/arxiv-archive/issues/197
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "Champ: Controllable and Consistent Human Image Animation with 3D\n  Parametric\
    \ Guidance"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2403.14781v2
'2405.17472':
  abstract: 'Text-to-image diffusion models can be fine-tuned in custom domains to
    adapt

    to specific user preferences, but such adaptability has also been utilized for

    illegal purposes, such as forging public figures'' portraits, duplicating

    copyrighted artworks and generating explicit contents. Existing work focused on

    detecting the illegally generated contents, but cannot prevent or mitigate

    illegal adaptations of diffusion models. Other schemes of model unlearning and

    reinitialization, similarly, cannot prevent users from relearning the knowledge

    of illegal model adaptation with custom data. In this paper, we present

    FreezeAsGuard, a new technique that addresses these limitations and enables

    irreversible mitigation of illegal adaptations of diffusion models. Our

    approach is that the model publisher selectively freezes tensors in pre-trained

    diffusion models that are critical to illegal model adaptations, to mitigate

    the fine-tuned model''s representation power in illegal adaptations, but

    minimize the impact on other legal adaptations. Experiment results in multiple

    text-to-image application domains show that FreezeAsGuard provides 37% stronger

    power in mitigating illegal model adaptations compared to competitive

    baselines, while incurring less than 5% impact on legal model adaptations. The

    source code is available at: https://github.com/pittisl/FreezeAsGuard.'
  arxivId: '2405.17472'
  authors: Kai Huang, Haoming Wang, Wei Gao
  created_at: '2024-12-23T05:03:24.344145'
  issue_number: 167
  issue_url: https://github.com/dmarx/arxiv-archive/issues/167
  labels:
  - paper
  - rating:downvote
  last_read: null
  state: open
  title: "FreezeAsGuard: Mitigating Illegal Adaptation of Diffusion Models via\n \
    \ Selective Tensor Freezing"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2405.17472v2
'2406.06158':
  abstract: 'While the impressive performance of modern neural networks is often

    attributed to their capacity to efficiently extract task-relevant features from

    data, the mechanisms underlying this rich feature learning regime remain

    elusive, with much of our theoretical understanding stemming from the opposing

    lazy regime. In this work, we derive exact solutions to a minimal model that

    transitions between lazy and rich learning, precisely elucidating how

    unbalanced layer-specific initialization variances and learning rates determine

    the degree of feature learning. Our analysis reveals that they conspire to

    influence the learning regime through a set of conserved quantities that

    constrain and modify the geometry of learning trajectories in parameter and

    function space. We extend our analysis to more complex linear models with

    multiple neurons, outputs, and layers and to shallow nonlinear networks with

    piecewise linear activation functions. In linear networks, rapid feature

    learning only occurs from balanced initializations, where all layers learn at

    similar speeds. While in nonlinear networks, unbalanced initializations that

    promote faster learning in earlier layers can accelerate rich learning. Through

    a series of experiments, we provide evidence that this unbalanced rich regime

    drives feature learning in deep finite-width networks, promotes

    interpretability of early layers in CNNs, reduces the sample complexity of

    learning hierarchical data, and decreases the time to grokking in modular

    arithmetic. Our theory motivates further exploration of unbalanced

    initializations to enhance efficient feature learning.'
  arxivId: '2406.06158'
  authors: Daniel Kunin, Allan Raventós, Clémentine Dominé, Feng Chen, David Klindt,
    Andrew Saxe, Surya Ganguli
  created_at: '2024-12-23T05:03:57.560595'
  issue_number: 120
  issue_url: https://github.com/dmarx/arxiv-archive/issues/120
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "Get rich quick: exact solutions reveal how unbalanced initializations\n\
    \  promote rapid feature learning"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2406.06158v2
'2406.19354':
  abstract: 'The model editing problem concerns how language models should learn new
    facts

    about the world over time. While empirical research on model editing has drawn

    widespread attention, the conceptual foundations of model editing remain shaky

    -- perhaps unsurprisingly, since model editing is essentially belief revision,

    a storied problem in philosophy that has eluded succinct solutions for decades.

    Model editing nonetheless demands a solution, since we need to be able to

    control the knowledge within language models. With this goal in mind, this

    paper critiques the standard formulation of the model editing problem and

    proposes a formal testbed for model editing research. We first describe 12 open

    problems with model editing, based on challenges with (1) defining the problem,

    (2) developing benchmarks, and (3) assuming LLMs have editable beliefs in the

    first place. Many of these challenges are extremely difficult to address, e.g.

    determining far-reaching consequences of edits, labeling probabilistic

    entailments between facts, and updating beliefs of agent simulators. Next, we

    introduce a semi-synthetic dataset for model editing based on Wikidata, where

    we can evaluate edits against labels given by an idealized Bayesian agent. This

    enables us to say exactly how belief revision in language models falls short of

    a desirable epistemic standard. We encourage further research exploring

    settings where such a gold standard can be compared against. Our code is

    publicly available at: https://github.com/peterbhase/LLM-belief-revision'
  arxivId: '2406.19354'
  authors: Peter Hase, Thomas Hofweber, Xiang Zhou, Elias Stengel-Eskin, Mohit Bansal
  created_at: '2024-12-23T05:03:42.344002'
  issue_number: 129
  issue_url: https://github.com/dmarx/arxiv-archive/issues/129
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "Fundamental Problems With Model Editing: How Should Rational Belief\n  Revision\
    \ Work in LLMs?"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2406.19354v1
'2408.03314':
  abstract: 'Enabling LLMs to improve their outputs by using more test-time computation
    is

    a critical step towards building generally self-improving agents that can

    operate on open-ended natural language. In this paper, we study the scaling of

    inference-time computation in LLMs, with a focus on answering the question: if

    an LLM is allowed to use a fixed but non-trivial amount of inference-time

    compute, how much can it improve its performance on a challenging prompt?

    Answering this question has implications not only on the achievable performance

    of LLMs, but also on the future of LLM pretraining and how one should tradeoff

    inference-time and pre-training compute. Despite its importance, little

    research attempted to understand the scaling behaviors of various test-time

    inference methods. Moreover, current work largely provides negative results for

    a number of these strategies. In this work, we analyze two primary mechanisms

    to scale test-time computation: (1) searching against dense, process-based

    verifier reward models; and (2) updating the model''s distribution over a

    response adaptively, given the prompt at test time. We find that in both cases,

    the effectiveness of different approaches to scaling test-time compute

    critically varies depending on the difficulty of the prompt. This observation

    motivates applying a "compute-optimal" scaling strategy, which acts to most

    effectively allocate test-time compute adaptively per prompt. Using this

    compute-optimal strategy, we can improve the efficiency of test-time compute

    scaling by more than 4x compared to a best-of-N baseline. Additionally, in a

    FLOPs-matched evaluation, we find that on problems where a smaller base model

    attains somewhat non-trivial success rates, test-time compute can be used to

    outperform a 14x larger model.'
  arxivId: '2408.03314'
  authors: Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar
  created_at: '2024-12-23T05:04:36.319841'
  issue_number: 57
  issue_url: https://github.com/dmarx/arxiv-archive/issues/57
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "Scaling LLM Test-Time Compute Optimally can be More Effective than\n  Scaling\
    \ Model Parameters"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2408.03314v1
'2408.11810':
  abstract: 'Diffusion Models have emerged as powerful generative models for high-quality

    image synthesis, with many subsequent image editing techniques based on them.

    However, the ease of text-based image editing introduces significant risks,

    such as malicious editing for scams or intellectual property infringement.

    Previous works have attempted to safeguard images from diffusion-based editing

    by adding imperceptible perturbations. These methods are costly and

    specifically target prevalent Latent Diffusion Models (LDMs), while

    Pixel-domain Diffusion Models (PDMs) remain largely unexplored and robust

    against such attacks. Our work addresses this gap by proposing a novel

    attacking framework with a feature representation attack loss that exploits

    vulnerabilities in denoising UNets and a latent optimization strategy to

    enhance the naturalness of protected images. Extensive experiments demonstrate

    the effectiveness of our approach in attacking dominant PDM-based editing

    methods (e.g., SDEdit) while maintaining reasonable protection fidelity and

    robustness against common defense methods. Additionally, our framework is

    extensible to LDMs, achieving comparable performance to existing approaches.'
  arxivId: '2408.11810'
  authors: Chun-Yen Shih, Li-Xuan Peng, Jia-Wei Liao, Ernie Chu, Cheng-Fu Chou, Jun-Cheng
    Chen
  created_at: '2024-12-23T05:03:39.332224'
  issue_number: 158
  issue_url: https://github.com/dmarx/arxiv-archive/issues/158
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "Pixel Is Not A Barrier: An Effective Evasion Attack for Pixel-Domain\n \
    \ Diffusion Models"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2408.11810v1
'2410.02423':
  abstract: 'In this paper, we introduce Plug-and-Play (PnP) Flow Matching, an algorithm

    for solving imaging inverse problems. PnP methods leverage the strength of

    pre-trained denoisers, often deep neural networks, by integrating them in

    optimization schemes. While they achieve state-of-the-art performance on

    various inverse problems in imaging, PnP approaches face inherent limitations

    on more generative tasks like inpainting. On the other hand, generative models

    such as Flow Matching pushed the boundary in image sampling yet lack a clear

    method for efficient use in image restoration. We propose to combine the PnP

    framework with Flow Matching (FM) by defining a time-dependent denoiser using
    a

    pre-trained FM model. Our algorithm alternates between gradient descent steps

    on the data-fidelity term, reprojections onto the learned FM path, and

    denoising. Notably, our method is computationally efficient and

    memory-friendly, as it avoids backpropagation through ODEs and trace

    computations. We evaluate its performance on denoising, super-resolution,

    deblurring, and inpainting tasks, demonstrating superior results compared to

    existing PnP algorithms and Flow Matching based state-of-the-art methods.'
  arxivId: '2410.02423'
  authors: Ségolène Martin, Anne Gagneux, Paul Hagemann, Gabriele Steidl
  created_at: '2024-12-23T05:04:03.322383'
  issue_number: 115
  issue_url: https://github.com/dmarx/arxiv-archive/issues/115
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: 'PnP-Flow: Plug-and-Play Image Restoration with Flow Matching'
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2410.02423v1
'2410.11900':
  abstract: 'Modern Question Answering (QA) and Reasoning approaches based on Large

    Language Models (LLMs) commonly use prompting techniques, such as

    Chain-of-Thought (CoT), assuming the resulting generation will have a more

    granular exploration and reasoning over the question space and scope. However,

    such methods struggle with generating outputs that are faithful to the

    intermediate chain of reasoning produced by the model. On the other end of the

    spectrum, neuro-symbolic methods such as Faithful CoT (F-CoT) propose to

    combine LLMs with external symbolic solvers. While such approaches boast a high

    degree of faithfulness, they usually require a model trained for code

    generation and struggle with tasks that are ambiguous or hard to formalise

    strictly. We introduce $\textbf{F}$aithful $\textbf{L}$ogic-$\textbf{A}$ided

    $\textbf{R}$easoning and $\textbf{E}$xploration ($\textbf{FLARE}$), a novel

    interpretable approach for traversing the problem space using task

    decompositions. We use the LLM to plan a solution, soft-formalise the query

    into facts and predicates using a logic programming code and simulate that code

    execution using an exhaustive multi-hop search over the defined space. Our

    method allows us to compute the faithfulness of the reasoning process w.r.t.

    the generated code and analyse the steps of the multi-hop search without

    relying on external solvers. Our methods achieve SOTA results on $\mathbf{7}$

    out of $\mathbf{9}$ diverse reasoning benchmarks. We also show that model

    faithfulness positively correlates with overall performance and further

    demonstrate that $\textbf{FLARE}$ allows pinpointing the decisive factors

    sufficient for and leading to the correct answer with optimal reasoning during

    the multi-hop search.'
  arxivId: '2410.11900'
  authors: Erik Arakelyan, Pasquale Minervini, Pat Verga, Patrick Lewis, Isabelle
    Augenstein
  created_at: '2024-12-23T05:03:54.339632'
  issue_number: 121
  issue_url: https://github.com/dmarx/arxiv-archive/issues/121
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: 'FLARE: Faithful Logic-Aided Reasoning and Exploration'
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2410.11900v2
'2410.15468':
  abstract: 'We consider emergence from the perspective of dynamics: states of a system

    evolving with time. We focus on the role of a decomposition of wholes into

    parts, and attempt to characterize relationships between levels without

    reference to whether higher-level properties are "novel" or "unexpected." We

    offer a classification of different varieties of emergence, with and without

    new ontological elements at higher levels.'
  arxivId: '2410.15468'
  authors: Sean M. Carroll, Achyuth Parola
  created_at: '2024-12-23T05:04:15.336139'
  issue_number: 107
  issue_url: https://github.com/dmarx/arxiv-archive/issues/107
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: What Emergence Can Possibly Mean
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2410.15468v1
'2410.15815':
  abstract: 'We present a method for computing free-energy differences using thermodynamic

    integration with a neural network potential that interpolates between two

    target Hamiltonians. The interpolation is defined at the sample distribution

    level, and the neural network potential is optimized to match the corresponding

    equilibrium potential at every intermediate time-step. Once the interpolating

    potentials and samples are well-aligned, the free-energy difference can be

    estimated using (neural) thermodynamic integration. To target molecular

    systems, we simultaneously couple Lennard-Jones and electrostatic interactions

    and model the rigid-body rotation of molecules. We report accurate results for

    several benchmark systems: a Lennard-Jones particle in a Lennard-Jones fluid,

    as well as the insertion of both water and methane solutes in a water solvent

    at atomistic resolution using a simple three-body neural-network potential.'
  arxivId: '2410.15815'
  authors: Bálint Máté, François Fleuret, Tristan Bereau
  created_at: '2024-12-23T05:03:51.328349'
  issue_number: 123
  issue_url: https://github.com/dmarx/arxiv-archive/issues/123
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: Solvation Free Energies from Neural Thermodynamic Integration
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2410.15815v2
'2410.24054':
  abstract: 'We develop EigenVI, an eigenvalue-based approach for black-box variational

    inference (BBVI). EigenVI constructs its variational approximations from

    orthogonal function expansions. For distributions over $\mathbb{R}^D$, the

    lowest order term in these expansions provides a Gaussian variational

    approximation, while higher-order terms provide a systematic way to model

    non-Gaussianity. These approximations are flexible enough to model complex

    distributions (multimodal, asymmetric), but they are simple enough that one can

    calculate their low-order moments and draw samples from them. EigenVI can also

    model other types of random variables (e.g., nonnegative, bounded) by

    constructing variational approximations from different families of orthogonal

    functions. Within these families, EigenVI computes the variational

    approximation that best matches the score function of the target distribution

    by minimizing a stochastic estimate of the Fisher divergence. Notably, this

    optimization reduces to solving a minimum eigenvalue problem, so that EigenVI

    effectively sidesteps the iterative gradient-based optimizations that are

    required for many other BBVI algorithms. (Gradient-based methods can be

    sensitive to learning rates, termination criteria, and other tunable

    hyperparameters.) We use EigenVI to approximate a variety of target

    distributions, including a benchmark suite of Bayesian models from posteriordb.

    On these distributions, we find that EigenVI is more accurate than existing

    methods for Gaussian BBVI.'
  arxivId: '2410.24054'
  authors: Diana Cai, Chirag Modi, Charles C. Margossian, Robert M. Gower, David M.
    Blei, Lawrence K. Saul
  created_at: '2024-12-23T05:04:12.337036'
  issue_number: 109
  issue_url: https://github.com/dmarx/arxiv-archive/issues/109
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "EigenVI: score-based variational inference with orthogonal function\n  expansions"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2410.24054v1
'2411.04282':
  abstract: 'Large language models (LLMs) have shown impressive capabilities, but
    still

    struggle with complex reasoning tasks requiring multiple steps. While

    prompt-based methods like Chain-of-Thought (CoT) can improve LLM reasoning at

    inference time, optimizing reasoning capabilities during training remains

    challenging. We introduce LaTent Reasoning Optimization (LaTRO), a principled

    framework that formulates reasoning as sampling from a latent distribution and

    optimizes it via variational approaches. LaTRO enables LLMs to concurrently

    improve both their reasoning process and ability to evaluate reasoning quality,

    without requiring external feedback or reward models. We validate LaTRO through

    experiments on GSM8K and ARC-Challenge datasets using multiple model

    architectures. On GSM8K, LaTRO improves zero-shot accuracy by an average of

    12.5% over base models and 9.6% over supervised fine-tuning across

    Phi-3.5-mini, Mistral-7B, and Llama-3.1-8B. Our findings suggest that

    pre-trained LLMs possess latent reasoning capabilities that can be unlocked and

    enhanced through our proposed optimization approach in a self-improvement

    manner. The code of LaTRO is available at

    \url{https://github.com/SalesforceAIResearch/LaTRO}.'
  arxivId: '2411.04282'
  authors: Haolin Chen, Yihao Feng, Zuxin Liu, Weiran Yao, Akshara Prabhakar, Shelby
    Heinecke, Ricky Ho, Phil Mui, Silvio Savarese, Caiming Xiong, Huan Wang
  created_at: '2024-12-23T05:03:21.358851'
  issue_number: 169
  issue_url: https://github.com/dmarx/arxiv-archive/issues/169
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "Language Models are Hidden Reasoners: Unlocking Latent Reasoning\n  Capabilities\
    \ via Self-Rewarding"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2411.04282v2
'2411.19722':
  abstract: 'Removing modeling constraints and unifying architectures across domains
    has

    been a key driver of the recent progress in training large multimodal models.

    However, most of these models still rely on many separately trained components

    such as modality-specific encoders and decoders. In this work, we further

    streamline joint generative modeling of images and text. We propose an

    autoregressive decoder-only transformer - JetFormer - which is trained to

    directly maximize the likelihood of raw data, without relying on any separately

    pretrained components, and can understand and generate both text and images.

    Specifically, we leverage a normalizing flow model to obtain a soft-token image

    representation that is jointly trained with an autoregressive multimodal

    transformer. The normalizing flow model serves as both an image encoder for

    perception tasks and an image decoder for image generation tasks during

    inference. JetFormer achieves text-to-image generation quality competitive with

    recent VQ-VAE- and VAE-based baselines. These baselines rely on pretrained

    image autoencoders, which are trained with a complex mixture of losses,

    including perceptual ones. At the same time, JetFormer demonstrates robust

    image understanding capabilities. To the best of our knowledge, JetFormer is

    the first model that is capable of generating high-fidelity images and

    producing strong log-likelihood bounds.'
  arxivId: '2411.19722'
  authors: Michael Tschannen, André Susano Pinto, Alexander Kolesnikov
  created_at: '2024-12-23T05:04:42.331912'
  issue_number: 40
  issue_url: https://github.com/dmarx/arxiv-archive/issues/40
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: 'JetFormer: An Autoregressive Generative Model of Raw Images and Text'
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2411.19722v1
'2412.04619':
  abstract: 'Language models (LMs), like other neural networks, often favor shortcut

    heuristics based on surface-level patterns. Although LMs behave like n-gram

    models early in training, they must eventually learn hierarchical syntactic

    representations to correctly apply grammatical rules out-of-distribution (OOD).

    In this work, we use case studies of English grammar to explore how complex,

    diverse training data drives models to generalize OOD. We construct a framework

    that unifies our understanding of random variation with training dynamics, rule

    selection with memorization, and data diversity with complexity. We show that

    these factors are nuanced, and that intermediate levels of diversity and

    complexity lead to inconsistent behavior across random seeds and to unstable

    training dynamics. Our findings emphasize the critical role of training data in

    shaping generalization patterns and illuminate how competing model strategies

    lead to inconsistent generalization outcomes across random seeds. Code is

    available at https://github.com/sunnytqin/concept_comp.git.'
  arxivId: '2412.04619'
  authors: Tian Qin, Naomi Saphra, David Alvarez-Melis
  created_at: '2024-12-23T05:03:27.334766'
  issue_number: 164
  issue_url: https://github.com/dmarx/arxiv-archive/issues/164
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: 'Sometimes I am a Tree: Data Drives Unstable Hierarchical Generalization'
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2412.04619v3
'2412.05265':
  abstract: 'This manuscript gives a big-picture, up-to-date overview of the field
    of

    (deep) reinforcement learning and sequential decision making, covering

    value-based RL, policy-gradient methods, model-based methods, and various other

    topics (including a very brief discussion of RL+LLMs).'
  arxivId: '2412.05265'
  authors: Kevin Murphy
  created_at: '2024-12-23T05:03:48.317322'
  issue_number: 125
  issue_url: https://github.com/dmarx/arxiv-archive/issues/125
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: 'Reinforcement Learning: An Overview'
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2412.05265v1
'2412.06264':
  abstract: 'Flow Matching (FM) is a recent framework for generative modeling that
    has

    achieved state-of-the-art performance across various domains, including image,

    video, audio, speech, and biological structures. This guide offers a

    comprehensive and self-contained review of FM, covering its mathematical

    foundations, design choices, and extensions. By also providing a PyTorch

    package featuring relevant examples (e.g., image and text generation), this

    work aims to serve as a resource for both novice and experienced researchers

    interested in understanding, applying and further developing FM.'
  arxivId: '2412.06264'
  authors: Yaron Lipman, Marton Havasi, Peter Holderrieth, Neta Shaul, Matt Le, Brian
    Karrer, Ricky T. Q. Chen, David Lopez-Paz, Heli Ben-Hamu, Itai Gat
  created_at: '2024-12-23T05:04:00.318342'
  issue_number: 117
  issue_url: https://github.com/dmarx/arxiv-archive/issues/117
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: Flow Matching Guide and Code
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2412.06264v1
'2412.09349':
  abstract: 'Controllable human image animation aims to generate videos from reference

    images using driving videos. Due to the limited control signals provided by

    sparse guidance (e.g., skeleton pose), recent works have attempted to introduce

    additional dense conditions (e.g., depth map) to ensure motion alignment.

    However, such strict dense guidance impairs the quality of the generated video

    when the body shape of the reference character differs significantly from that

    of the driving video. In this paper, we present DisPose to mine more

    generalizable and effective control signals without additional dense input,

    which disentangles the sparse skeleton pose in human image animation into

    motion field guidance and keypoint correspondence. Specifically, we generate a

    dense motion field from a sparse motion field and the reference image, which

    provides region-level dense guidance while maintaining the generalization of

    the sparse pose control. We also extract diffusion features corresponding to

    pose keypoints from the reference image, and then these point features are

    transferred to the target pose to provide distinct identity information. To

    seamlessly integrate into existing models, we propose a plug-and-play hybrid

    ControlNet that improves the quality and consistency of generated videos while

    freezing the existing model parameters. Extensive qualitative and quantitative

    experiments demonstrate the superiority of DisPose compared to current methods.

    Code:

    \href{https://github.com/lihxxx/DisPose}{https://github.com/lihxxx/DisPose}.'
  arxivId: '2412.09349'
  authors: Hongxiang Li, Yaowei Li, Yuhang Yang, Junjie Cao, Zhihong Zhu, Xuxin Cheng,
    Long Chen
  created_at: '2024-12-23T22:12:51.130692'
  issue_number: 191
  issue_url: https://github.com/dmarx/arxiv-archive/issues/191
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-23T23:12:55.260431'
  state: open
  title: "DisPose: Disentangling Pose Guidance for Controllable Human Image\n  Animation"
  total_reading_time_seconds: 350
  url: http://arxiv.org/abs/2412.09349v2
'2412.09621':
  abstract: 'Learning to understand dynamic 3D scenes from imagery is crucial for

    applications ranging from robotics to scene reconstruction. Yet, unlike other

    problems where large-scale supervised training has enabled rapid progress,

    directly supervising methods for recovering 3D motion remains challenging due

    to the fundamental difficulty of obtaining ground truth annotations. We present

    a system for mining high-quality 4D reconstructions from internet stereoscopic,

    wide-angle videos. Our system fuses and filters the outputs of camera pose

    estimation, stereo depth estimation, and temporal tracking methods into

    high-quality dynamic 3D reconstructions. We use this method to generate

    large-scale data in the form of world-consistent, pseudo-metric 3D point clouds

    with long-term motion trajectories. We demonstrate the utility of this data by

    training a variant of DUSt3R to predict structure and 3D motion from real-world

    image pairs, showing that training on our reconstructed data enables

    generalization to diverse real-world scenes. Project page:

    https://stereo4d.github.io'
  arxivId: '2412.09621'
  authors: Linyi Jin, Richard Tucker, Zhengqi Li, David Fouhey, Noah Snavely, Aleksander
    Holynski
  created_at: '2024-12-23T05:04:45.332202'
  issue_number: 52
  issue_url: https://github.com/dmarx/arxiv-archive/issues/52
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: 'Stereo4D: Learning How Things Move in 3D from Internet Stereo Videos'
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2412.09621v1
'2412.13145':
  abstract: 'Could an AI have conscious experiences? Any answer to this question should

    conform to Evidentialism - that is, it should be based not on intuition, dogma

    or speculation but on solid scientific evidence. I argue that such evidence is

    hard to come by and that the only justifiable stance on the prospects of

    artificial consciousness is agnosticism. In the current debate, the main

    division is between biological views that are sceptical of artificial

    consciousness and functional views that are sympathetic to it. I argue that

    both camps make the same mistake of over-estimating what the evidence tells us.

    Scientific insights into consciousness have been achieved through the study of

    conscious organisms. Although this has enabled cautious assessments of

    consciousness in various creatures, extending this to AI faces serious

    obstacles. AI thus presents consciousness researchers with a dilemma: either

    reach a verdict on artificial consciousness but violate Evidentialism; or

    respect Evidentialism but offer no verdict on the prospects of artificial

    consciousness. The dominant trend in the literature has been to take the first

    option while purporting to follow the scientific evidence. I argue that if we

    truly follow the evidence, we must take the second option and adopt

    agnosticism.'
  arxivId: '2412.13145'
  authors: Tom McClelland
  created_at: '2024-12-23T05:04:24.317296'
  issue_number: 102
  issue_url: https://github.com/dmarx/arxiv-archive/issues/102
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: Agnosticism About Artificial Consciousness
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2412.13145v1
'2412.13663':
  abstract: 'Encoder-only transformer models such as BERT offer a great performance-size

    tradeoff for retrieval and classification tasks with respect to larger

    decoder-only models. Despite being the workhorse of numerous production

    pipelines, there have been limited Pareto improvements to BERT since its

    release. In this paper, we introduce ModernBERT, bringing modern model

    optimizations to encoder-only models and representing a major Pareto

    improvement over older encoders. Trained on 2 trillion tokens with a native

    8192 sequence length, ModernBERT models exhibit state-of-the-art results on a

    large pool of evaluations encompassing diverse classification tasks and both

    single and multi-vector retrieval on different domains (including code). In

    addition to strong downstream performance, ModernBERT is also the most speed

    and memory efficient encoder and is designed for inference on common GPUs.'
  arxivId: '2412.13663'
  authors: Benjamin Warner, Antoine Chaffin, Benjamin Clavié, Orion Weller, Oskar
    Hallström, Said Taghadouini, Alexis Gallagher, Raja Biswas, Faisal Ladhak, Tom
    Aarsen, Nathan Cooper, Griffin Adams, Jeremy Howard, Iacopo Poli
  created_at: '2024-12-23T05:04:06.324542'
  issue_number: 113
  issue_url: https://github.com/dmarx/arxiv-archive/issues/113
  labels:
  - paper
  - rating:novote
  last_read: null
  state: open
  title: "Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for\n  Fast,\
    \ Memory Efficient, and Long Context Finetuning and Inference"
  total_reading_time_seconds: 0
  url: http://arxiv.org/abs/2412.13663v2
'2412.17799':
  abstract: 'With the recent Nobel Prize awarded for radical advances in protein

    discovery, foundation models (FMs) for exploring large combinatorial spaces

    promise to revolutionize many scientific fields. Artificial Life (ALife) has

    not yet integrated FMs, thus presenting a major opportunity for the field to

    alleviate the historical burden of relying chiefly on manual design and

    trial-and-error to discover the configurations of lifelike simulations. This

    paper presents, for the first time, a successful realization of this

    opportunity using vision-language FMs. The proposed approach, called Automated

    Search for Artificial Life (ASAL), (1) finds simulations that produce target

    phenomena, (2) discovers simulations that generate temporally open-ended

    novelty, and (3) illuminates an entire space of interestingly diverse

    simulations. Because of the generality of FMs, ASAL works effectively across a

    diverse range of ALife substrates including Boids, Particle Life, Game of Life,

    Lenia, and Neural Cellular Automata. A major result highlighting the potential

    of this technique is the discovery of previously unseen Lenia and Boids

    lifeforms, as well as cellular automata that are open-ended like Conway''s Game

    of Life. Additionally, the use of FMs allows for the quantification of

    previously qualitative phenomena in a human-aligned way. This new paradigm

    promises to accelerate ALife research beyond what is possible through human

    ingenuity alone.'
  arxivId: '2412.17799'
  authors: Akarsh Kumar, Chris Lu, Louis Kirsch, Yujin Tang, Kenneth O. Stanley, Phillip
    Isola, David Ha
  created_at: '2024-12-24T05:13:36.805648'
  issue_number: 247
  issue_url: https://github.com/dmarx/arxiv-archive/issues/247
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-24T05:13:36.807235'
  state: open
  title: Automating the Search for Artificial Life with Foundation Models
  total_reading_time_seconds: 8
  url: http://arxiv.org/abs/2412.17799v1
