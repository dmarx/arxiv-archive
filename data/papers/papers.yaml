'1503.03585':
  abstract: 'A central problem in machine learning involves modeling complex data-sets

    using highly flexible families of probability distributions in which learning,

    sampling, inference, and evaluation are still analytically or computationally

    tractable. Here, we develop an approach that simultaneously achieves both

    flexibility and tractability. The essential idea, inspired by non-equilibrium

    statistical physics, is to systematically and slowly destroy structure in a

    data distribution through an iterative forward diffusion process. We then learn

    a reverse diffusion process that restores structure in data, yielding a highly

    flexible and tractable generative model of the data. This approach allows us to

    rapidly learn, sample from, and evaluate probabilities in deep generative

    models with thousands of layers or time steps, as well as to compute

    conditional and posterior probabilities under the learned model. We

    additionally release an open source reference implementation of the algorithm.'
  arxivId: '1503.03585'
  arxiv_tags:
  - cs.LG
  - cond-mat.dis-nn
  - q-bio.NC
  - stat.ML
  authors: Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, Surya Ganguli
  created_at: '2024-12-27T08:36:57.788009'
  issue_number: 253
  issue_url: https://github.com/dmarx/arxiv-archive/issues/253
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:36:57.788841'
  last_visited: '2024-12-24T21:08:52.964Z'
  main_tex_file: null
  published_date: '2015-03-12T04:51:37Z'
  state: open
  title: Deep Unsupervised Learning using Nonequilibrium Thermodynamics
  total_reading_time_seconds: 15
  url: https://arxiv.org/abs/1503.03585
'1804.08838':
  abstract: 'Many recently trained neural networks employ large numbers of parameters
    to

    achieve good performance. One may intuitively use the number of parameters

    required as a rough gauge of the difficulty of a problem. But how accurate are

    such notions? How many parameters are really needed? In this paper we attempt

    to answer this question by training networks not in their native parameter

    space, but instead in a smaller, randomly oriented subspace. We slowly increase

    the dimension of this subspace, note at which dimension solutions first appear,

    and define this to be the intrinsic dimension of the objective landscape. The

    approach is simple to implement, computationally tractable, and produces

    several suggestive conclusions. Many problems have smaller intrinsic dimensions

    than one might suspect, and the intrinsic dimension for a given dataset varies

    little across a family of models with vastly different sizes. This latter

    result has the profound implication that once a parameter space is large enough

    to solve a problem, extra parameters serve directly to increase the

    dimensionality of the solution manifold. Intrinsic dimension allows some

    quantitative comparison of problem difficulty across supervised, reinforcement,

    and other types of learning where we conclude, for example, that solving the

    inverted pendulum problem is 100 times easier than classifying digits from

    MNIST, and playing Atari Pong from pixels is about as hard as classifying

    CIFAR-10. In addition to providing new cartography of the objective landscapes

    wandered by parameterized models, the method is a simple technique for

    constructively obtaining an upper bound on the minimum description length of a

    solution. A byproduct of this construction is a simple approach for compressing

    networks, in some cases by more than 100 times.'
  arxivId: '1804.08838'
  arxiv_tags:
  - cs.LG
  - cs.NE
  - stat.ML
  authors: Chunyuan Li, Heerad Farkhoor, Rosanne Liu, Jason Yosinski
  created_at: '2024-12-27T08:37:30.796183'
  issue_number: 198
  issue_url: https://github.com/dmarx/arxiv-archive/issues/198
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:37:30.797641'
  last_visited: '2024-12-24T02:11:53.179Z'
  main_tex_file: null
  published_date: '2018-04-24T04:29:10Z'
  state: open
  title: Measuring the Intrinsic Dimension of Objective Landscapes
  total_reading_time_seconds: 26
  url: https://arxiv.org/abs/1804.08838
'1810.01588':
  abstract: 'Interpreting the prediction mechanism of complex models is currently
    one of

    the most important tasks in the machine learning field, especially with layered

    neural networks, which have achieved high predictive performance with various

    practical data sets. To reveal the global structure of a trained neural network

    in an interpretable way, a series of clustering methods have been proposed,

    which decompose the units into clusters according to the similarity of their

    inference roles. The main problems in these studies were that (1) we have no

    prior knowledge about the optimal resolution for the decomposition, or the

    appropriate number of clusters, and (2) there was no method with which to

    acquire knowledge about whether the outputs of each cluster have a positive or

    negative correlation with the input and output dimension values. In this paper,

    to solve these problems, we propose a method for obtaining a hierarchical

    modular representation of a layered neural network. The application of a

    hierarchical clustering method to a trained network reveals a tree-structured

    relationship among hidden layer units, based on their feature vectors defined

    by their correlation with the input and output dimension values.'
  arxivId: '1810.01588'
  arxiv_tags:
  - stat.ML
  - cs.LG
  authors: Chihiro Watanabe
  created_at: '2024-12-27T08:37:16.425853'
  issue_number: 230
  issue_url: https://github.com/dmarx/arxiv-archive/issues/230
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:37:16.427681'
  last_visited: '2024-12-24T03:07:38.277Z'
  main_tex_file: null
  published_date: '2018-10-03T05:38:26Z'
  state: open
  title: "Interpreting Layered Neural Networks via Hierarchical Modular\n  Representation"
  total_reading_time_seconds: 6
  url: https://arxiv.org/abs/1810.01588
'1901.10159':
  abstract: 'To understand the dynamics of optimization in deep neural networks, we

    develop a tool to study the evolution of the entire Hessian spectrum throughout

    the optimization process. Using this, we study a number of hypotheses

    concerning smoothness, curvature, and sharpness in the deep learning

    literature. We then thoroughly analyze a crucial structural feature of the

    spectra: in non-batch normalized networks, we observe the rapid appearance of

    large isolated eigenvalues in the spectrum, along with a surprising

    concentration of the gradient in the corresponding eigenspaces. In batch

    normalized networks, these two effects are almost absent. We characterize these

    effects, and explain how they affect optimization speed through both theory and

    experiments. As part of this work, we adapt advanced tools from numerical

    linear algebra that allow scalable and accurate estimation of the entire

    Hessian spectrum of ImageNet-scale neural networks; this technique may be of

    independent interest in other applications.'
  arxivId: '1901.10159'
  arxiv_tags:
  - cs.LG
  - stat.ML
  authors: Behrooz Ghorbani, Shankar Krishnan, Ying Xiao
  created_at: '2024-12-27T08:37:06.795951'
  issue_number: 239
  issue_url: https://github.com/dmarx/arxiv-archive/issues/239
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:37:06.798545'
  last_visited: '2024-12-24T03:33:51.377Z'
  main_tex_file: null
  published_date: '2019-01-29T08:24:10Z'
  state: open
  title: "An Investigation into Neural Net Optimization via Hessian Eigenvalue\n \
    \ Density"
  total_reading_time_seconds: 102
  url: https://arxiv.org/abs/1901.10159
'1906.04358':
  abstract: 'Not all neural network architectures are created equal, some perform
    much

    better than others for certain tasks. But how important are the weight

    parameters of a neural network compared to its architecture? In this work, we

    question to what extent neural network architectures alone, without learning

    any weight parameters, can encode solutions for a given task. We propose a

    search method for neural network architectures that can already perform a task

    without any explicit weight training. To evaluate these networks, we populate

    the connections with a single shared weight parameter sampled from a uniform

    random distribution, and measure the expected performance. We demonstrate that

    our method can find minimal neural network architectures that can perform

    several reinforcement learning tasks without weight training. On a supervised

    learning domain, we find network architectures that achieve much higher than

    chance accuracy on MNIST using random weights. Interactive version of this

    paper at https://weightagnostic.github.io/'
  arxivId: '1906.04358'
  arxiv_tags:
  - cs.LG
  - cs.NE
  - stat.ML
  authors: Adam Gaier, David Ha
  created_at: '2024-12-27T08:37:09.834733'
  issue_number: 235
  issue_url: https://github.com/dmarx/arxiv-archive/issues/235
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:37:09.836754'
  last_visited: '2024-12-24T03:27:56.957Z'
  main_tex_file: null
  published_date: '2019-06-11T02:40:11Z'
  state: open
  title: Weight Agnostic Neural Networks
  total_reading_time_seconds: 20
  url: https://arxiv.org/abs/1906.04358
'1912.02757':
  abstract: 'Deep ensembles have been empirically shown to be a promising approach
    for

    improving accuracy, uncertainty and out-of-distribution robustness of deep

    learning models. While deep ensembles were theoretically motivated by the

    bootstrap, non-bootstrap ensembles trained with just random initialization also

    perform well in practice, which suggests that there could be other explanations

    for why deep ensembles work well. Bayesian neural networks, which learn

    distributions over the parameters of the network, are theoretically

    well-motivated by Bayesian principles, but do not perform as well as deep

    ensembles in practice, particularly under dataset shift. One possible

    explanation for this gap between theory and practice is that popular scalable

    variational Bayesian methods tend to focus on a single mode, whereas deep

    ensembles tend to explore diverse modes in function space. We investigate this

    hypothesis by building on recent work on understanding the loss landscape of

    neural networks and adding our own exploration to measure the similarity of

    functions in the space of predictions. Our results show that random

    initializations explore entirely different modes, while functions along an

    optimization trajectory or sampled from the subspace thereof cluster within a

    single mode predictions-wise, while often deviating significantly in the weight

    space. Developing the concept of the diversity--accuracy plane, we show that

    the decorrelation power of random initializations is unmatched by popular

    subspace sampling methods. Finally, we evaluate the relative effects of

    ensembling, subspace based methods and ensembles of subspace based methods, and

    the experimental results validate our hypothesis.'
  arxivId: '1912.02757'
  arxiv_tags:
  - stat.ML
  - cs.LG
  authors: Stanislav Fort, Huiyi Hu, Balaji Lakshminarayanan
  created_at: '2024-12-27T08:37:18.794896'
  issue_number: 226
  issue_url: https://github.com/dmarx/arxiv-archive/issues/226
  labels:
  - paper
  - rating:novote
  last_read: null
  last_visited: '2024-12-24T03:02:43.131Z'
  main_tex_file: null
  published_date: '2019-12-05T17:48:18Z'
  state: open
  title: 'Deep Ensembles: A Loss Landscape Perspective'
  total_reading_time_seconds: 0
  url: https://arxiv.org/abs/1912.02757
'2001.04063':
  abstract: 'This paper presents a new sequence-to-sequence pre-training model called

    ProphetNet, which introduces a novel self-supervised objective named future

    n-gram prediction and the proposed n-stream self-attention mechanism. Instead

    of optimizing one-step-ahead prediction in the traditional sequence-to-sequence

    model, the ProphetNet is optimized by n-step ahead prediction that predicts the

    next n tokens simultaneously based on previous context tokens at each time

    step. The future n-gram prediction explicitly encourages the model to plan for

    the future tokens and prevent overfitting on strong local correlations. We

    pre-train ProphetNet using a base scale dataset (16GB) and a large-scale

    dataset (160GB), respectively. Then we conduct experiments on CNN/DailyMail,

    Gigaword, and SQuAD 1.1 benchmarks for abstractive summarization and question

    generation tasks. Experimental results show that ProphetNet achieves new

    state-of-the-art results on all these datasets compared to the models using the

    same scale pre-training corpus.'
  arxivId: '2001.04063'
  arxiv_tags:
  - cs.CL
  authors: Weizhen Qi, Yu Yan, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen,
    Ruofei Zhang, Ming Zhou
  created_at: '2024-12-27T08:36:45.863546'
  issue_number: 286
  issue_url: https://github.com/dmarx/arxiv-archive/issues/286
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:36:45.864400'
  last_visited: '2024-12-26T17:17:59.219Z'
  main_tex_file: null
  published_date: '2020-01-13T05:12:38Z'
  state: open
  title: "ProphetNet: Predicting Future N-gram for Sequence-to-Sequence\n  Pre-training"
  total_reading_time_seconds: 3
  url: https://arxiv.org/abs/2001.04063
'2006.11120':
  abstract: 'A basic operation in Convolutional Neural Networks (CNNs) is spatial
    resizing

    of feature maps. This is done either by strided convolution (donwscaling) or

    transposed convolution (upscaling). Such operations are limited to a fixed

    filter moving at predetermined integer steps (strides). Spatial sizes of

    consecutive layers are related by integer scale factors, predetermined at

    architectural design, and remain fixed throughout training and inference time.

    We propose a generalization of the common Conv-layer, from a discrete layer to

    a Continuous Convolution (CC) Layer. CC Layers naturally extend Conv-layers by

    representing the filter as a learned continuous function over sub-pixel

    coordinates. This allows learnable and principled resizing of feature maps, to

    any size, dynamically and consistently across scales. Once trained, the CC

    layer can be used to output any scale/size chosen at inference time. The scale

    can be non-integer and differ between the axes. CC gives rise to new freedoms

    for architectural design, such as dynamic layer shapes at inference time, or

    gradual architectures where the size changes by a small factor at each layer.

    This gives rise to many desired CNN properties, new architectural design

    capabilities, and useful applications. We further show that current Conv-layers

    suffer from inherent misalignments, which are ameliorated by CC layers.'
  arxivId: '2006.11120'
  arxiv_tags:
  - cs.LG
  - cs.CV
  - stat.ML
  authors: Assaf Shocher, Ben Feinstein, Niv Haim, Michal Irani
  created_at: '2024-12-27T08:36:54.792937'
  issue_number: 262
  issue_url: https://github.com/dmarx/arxiv-archive/issues/262
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:36:54.794180'
  last_visited: '2024-12-25T05:28:48.326Z'
  main_tex_file: null
  published_date: '2020-06-19T13:16:06Z'
  state: open
  title: From Discrete to Continuous Convolution Layers
  total_reading_time_seconds: 24
  url: https://arxiv.org/abs/2006.11120
'2010.15110':
  abstract: 'In suitably initialized wide networks, small learning rates transform
    deep

    neural networks (DNNs) into neural tangent kernel (NTK) machines, whose

    training dynamics is well-approximated by a linear weight expansion of the

    network at initialization. Standard training, however, diverges from its

    linearization in ways that are poorly understood. We study the relationship

    between the training dynamics of nonlinear deep networks, the geometry of the

    loss landscape, and the time evolution of a data-dependent NTK. We do so

    through a large-scale phenomenological analysis of training, synthesizing

    diverse measures characterizing loss landscape geometry and NTK dynamics. In

    multiple neural architectures and datasets, we find these diverse measures

    evolve in a highly correlated manner, revealing a universal picture of the deep

    learning process. In this picture, deep network training exhibits a highly

    chaotic rapid initial transient that within 2 to 3 epochs determines the final

    linearly connected basin of low loss containing the end point of training.

    During this chaotic transient, the NTK changes rapidly, learning useful

    features from the training data that enables it to outperform the standard

    initial NTK by a factor of 3 in less than 3 to 4 epochs. After this rapid

    chaotic transient, the NTK changes at constant velocity, and its performance

    matches that of full network training in 15% to 45% of training time. Overall,

    our analysis reveals a striking correlation between a diverse set of metrics

    over training time, governed by a rapid chaotic to stable transition in the

    first few epochs, that together poses challenges and opportunities for the

    development of more accurate theories of deep learning.'
  arxivId: '2010.15110'
  arxiv_tags:
  - cs.LG
  - stat.ML
  authors: Stanislav Fort, Gintare Karolina Dziugaite, Mansheej Paul, Sepideh Kharaghani,
    Daniel M. Roy, Surya Ganguli
  created_at: '2024-12-27T08:37:03.796154'
  issue_number: 245
  issue_url: https://github.com/dmarx/arxiv-archive/issues/245
  labels:
  - paper
  - rating:novote
  last_read: null
  last_visited: '2024-12-24T04:03:01.478Z'
  main_tex_file: null
  published_date: '2020-10-28T17:53:01Z'
  state: open
  title: "Deep learning versus kernel learning: an empirical study of loss\n  landscape\
    \ geometry and the time evolution of the Neural Tangent Kernel"
  total_reading_time_seconds: 0
  url: https://arxiv.org/abs/2010.15110
'2012.13255':
  abstract: 'Although pretrained language models can be fine-tuned to produce

    state-of-the-art results for a very wide range of language understanding tasks,

    the dynamics of this process are not well understood, especially in the low

    data regime. Why can we use relatively vanilla gradient descent algorithms

    (e.g., without strong regularization) to tune a model with hundreds of millions

    of parameters on datasets with only hundreds or thousands of labeled examples?

    In this paper, we argue that analyzing fine-tuning through the lens of

    intrinsic dimension provides us with empirical and theoretical intuitions to

    explain this remarkable phenomenon. We empirically show that common pre-trained

    models have a very low intrinsic dimension; in other words, there exists a low

    dimension reparameterization that is as effective for fine-tuning as the full

    parameter space. For example, by optimizing only 200 trainable parameters

    randomly projected back into the full space, we can tune a RoBERTa model to

    achieve 90\% of the full parameter performance levels on MRPC. Furthermore, we

    empirically show that pre-training implicitly minimizes intrinsic dimension

    and, perhaps surprisingly, larger models tend to have lower intrinsic dimension

    after a fixed number of pre-training updates, at least in part explaining their

    extreme effectiveness. Lastly, we connect intrinsic dimensionality with low

    dimensional task representations and compression based generalization bounds to

    provide intrinsic-dimension-based generalization bounds that are independent of

    the full parameter count.'
  arxivId: '2012.13255'
  arxiv_tags:
  - cs.LG
  - cs.CL
  authors: Armen Aghajanyan, Luke Zettlemoyer, Sonal Gupta
  created_at: '2024-12-27T08:37:21.793523'
  issue_number: 208
  issue_url: https://github.com/dmarx/arxiv-archive/issues/208
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:37:21.794281'
  last_visited: '2024-12-24T02:33:23.234Z'
  main_tex_file: null
  published_date: '2020-12-22T07:42:30Z'
  state: open
  title: "Intrinsic Dimensionality Explains the Effectiveness of Language Model\n\
    \  Fine-Tuning"
  total_reading_time_seconds: 4
  url: https://arxiv.org/abs/2012.13255
'2106.04647':
  abstract: 'Adapting large-scale pretrained language models to downstream tasks via

    fine-tuning is the standard method for achieving state-of-the-art performance

    on NLP benchmarks. However, fine-tuning all weights of models with millions or

    billions of parameters is sample-inefficient, unstable in low-resource

    settings, and wasteful as it requires storing a separate copy of the model for

    each task. Recent work has developed parameter-efficient fine-tuning methods,

    but these approaches either still require a relatively large number of

    parameters or underperform standard fine-tuning. In this work, we propose

    Compacter, a method for fine-tuning large-scale language models with a better

    trade-off between task performance and the number of trainable parameters than

    prior work. Compacter accomplishes this by building on top of ideas from

    adapters, low-rank optimization, and parameterized hypercomplex multiplication

    layers. Specifically, Compacter inserts task-specific weight matrices into a

    pretrained model''s weights, which are computed efficiently as a sum of

    Kronecker products between shared "slow" weights and "fast" rank-one matrices

    defined per Compacter layer. By only training 0.047% of a pretrained model''s

    parameters, Compacter performs on par with standard fine-tuning on GLUE and

    outperforms standard fine-tuning on SuperGLUE and low-resource settings. Our

    code is publicly available at~\url{https://github.com/rabeehk/compacter}.'
  arxivId: '2106.04647'
  arxiv_tags:
  - cs.CL
  authors: Rabeeh Karimi Mahabadi, James Henderson, Sebastian Ruder
  created_at: '2024-12-27T08:37:27.793777'
  issue_number: 202
  issue_url: https://github.com/dmarx/arxiv-archive/issues/202
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:37:27.794917'
  last_visited: '2024-12-24T02:31:09.658Z'
  main_tex_file: null
  published_date: '2021-06-08T19:17:04Z'
  state: open
  title: 'Compacter: Efficient Low-Rank Hypercomplex Adapter Layers'
  total_reading_time_seconds: 3
  url: https://arxiv.org/abs/2106.04647
'2302.05543':
  abstract: 'We present ControlNet, a neural network architecture to add spatial

    conditioning controls to large, pretrained text-to-image diffusion models.

    ControlNet locks the production-ready large diffusion models, and reuses their

    deep and robust encoding layers pretrained with billions of images as a strong

    backbone to learn a diverse set of conditional controls. The neural

    architecture is connected with "zero convolutions" (zero-initialized

    convolution layers) that progressively grow the parameters from zero and ensure

    that no harmful noise could affect the finetuning. We test various conditioning

    controls, eg, edges, depth, segmentation, human pose, etc, with Stable

    Diffusion, using single or multiple conditions, with or without prompts. We

    show that the training of ControlNets is robust with small (<50k) and large

    (>1m) datasets. Extensive results show that ControlNet may facilitate wider

    applications to control image diffusion models.'
  arxivId: '2302.05543'
  arxiv_tags:
  - cs.CV
  - cs.AI
  - cs.GR
  - cs.HC
  - cs.MM
  authors: Lvmin Zhang, Anyi Rao, Maneesh Agrawala
  created_at: '2024-12-27T08:37:24.799283'
  issue_number: 205
  issue_url: https://github.com/dmarx/arxiv-archive/issues/205
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:37:24.800097'
  last_visited: '2024-12-24T02:32:45.904Z'
  main_tex_file: null
  published_date: '2023-02-10T23:12:37Z'
  state: open
  title: Adding Conditional Control to Text-to-Image Diffusion Models
  total_reading_time_seconds: 23
  url: https://arxiv.org/abs/2302.05543
'2302.11529':
  abstract: 'Transfer learning has recently become the dominant paradigm of machine

    learning. Pre-trained models fine-tuned for downstream tasks achieve better

    performance with fewer labelled examples. Nonetheless, it remains unclear how

    to develop models that specialise towards multiple tasks without incurring

    negative interference and that generalise systematically to non-identically

    distributed tasks. Modular deep learning has emerged as a promising solution to

    these challenges. In this framework, units of computation are often implemented

    as autonomous parameter-efficient modules. Information is conditionally routed

    to a subset of modules and subsequently aggregated. These properties enable

    positive transfer and systematic generalisation by separating computation from

    routing and updating modules locally. We offer a survey of modular

    architectures, providing a unified view over several threads of research that

    evolved independently in the scientific literature. Moreover, we explore

    various additional purposes of modularity, including scaling language models,

    causal inference, programme induction, and planning in reinforcement learning.

    Finally, we report various concrete applications where modularity has been

    successfully deployed such as cross-lingual and cross-modal knowledge transfer.

    Related talks and projects to this survey, are available at

    https://www.modulardeeplearning.com/.'
  arxivId: '2302.11529'
  arxiv_tags:
  - cs.LG
  authors: Jonas Pfeiffer, Sebastian Ruder, Ivan Vulić, Edoardo Maria Ponti
  created_at: '2024-12-27T08:37:12.875322'
  issue_number: 227
  issue_url: https://github.com/dmarx/arxiv-archive/issues/227
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:37:16.428802'
  last_visited: '2024-12-24T03:05:18.719Z'
  main_tex_file: null
  published_date: '2023-02-22T18:11:25Z'
  state: open
  title: Modular Deep Learning
  total_reading_time_seconds: 26
  url: https://arxiv.org/abs/2302.11529
'2310.05736':
  abstract: 'Large language models (LLMs) have been applied in various applications
    due to

    their astonishing capabilities. With advancements in technologies such as

    chain-of-thought (CoT) prompting and in-context learning (ICL), the prompts fed

    to LLMs are becoming increasingly lengthy, even exceeding tens of thousands of

    tokens. To accelerate model inference and reduce cost, this paper presents

    LLMLingua, a coarse-to-fine prompt compression method that involves a budget

    controller to maintain semantic integrity under high compression ratios, a

    token-level iterative compression algorithm to better model the interdependence

    between compressed contents, and an instruction tuning based method for

    distribution alignment between language models. We conduct experiments and

    analysis over four datasets from different scenarios, i.e., GSM8K, BBH,

    ShareGPT, and Arxiv-March23; showing that the proposed approach yields

    state-of-the-art performance and allows for up to 20x compression with little

    performance loss. Our code is available at https://aka.ms/LLMLingua.'
  arxivId: '2310.05736'
  arxiv_tags:
  - cs.CL
  - cs.LG
  authors: Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, Lili Qiu
  created_at: '2024-12-27T08:36:39.791647'
  issue_number: 299
  issue_url: https://github.com/dmarx/arxiv-archive/issues/299
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:36:39.794510'
  last_visited: '2024-12-26T22:53:26.354Z'
  main_tex_file: null
  published_date: '2023-10-09T14:10:21Z'
  state: open
  title: "LLMLingua: Compressing Prompts for Accelerated Inference of Large\n  Language\
    \ Models"
  total_reading_time_seconds: 38
  url: https://arxiv.org/abs/2310.05736
'2403.00231':
  abstract: 'Large vision-language models (LVLMs) excel across diverse tasks involving

    concrete images from natural scenes. However, their ability to interpret

    abstract figures, such as geometry shapes and scientific plots, remains limited

    due to a scarcity of training datasets in scientific domains. To fill this gap,

    we introduce Multimodal ArXiv, consisting of ArXivCap and ArXivQA, for

    enhancing LVLMs scientific comprehension. ArXivCap is a figure-caption dataset

    comprising 6.4M images and 3.9M captions, sourced from 572K ArXiv papers

    spanning various scientific domains. Drawing from ArXivCap, we introduce

    ArXivQA, a question-answering dataset generated by prompting GPT-4V based on

    scientific figures. ArXivQA greatly enhances open-sourced LVLMs'' mathematical

    reasoning capabilities, achieving a 10.4\% absolute accuracy gain on a

    multimodal mathematical reasoning benchmark. Furthermore, employing ArXivCap,

    we devise four vision-to-text tasks for benchmarking LVLMs. Evaluation results

    with state-of-the-art LVLMs underscore their struggle with the nuanced

    semantics of academic figures, while domain-specific training yields

    substantial performance gains. Our error analysis uncovers misinterpretations

    of visual context, recognition errors, and the production of overly simplified

    captions by current LVLMs, shedding light on future improvements.'
  arxivId: '2403.00231'
  arxiv_tags:
  - cs.CV
  - cs.CL
  authors: Lei Li, Yuqi Wang, Runxin Xu, Peiyi Wang, Xiachong Feng, Lingpeng Kong,
    Qi Liu
  created_at: '2024-12-27T08:36:34.072876'
  issue_number: 311
  issue_url: https://github.com/dmarx/arxiv-archive/issues/311
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:36:34.074812'
  last_visited: '2024-12-27T05:14:48.788Z'
  main_tex_file: null
  published_date: '2024-03-01T02:21:30Z'
  state: open
  title: "Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of\n\
    \  Large Vision-Language Models"
  total_reading_time_seconds: 8
  url: https://arxiv.org/abs/2403.00231
'2403.14781':
  abstract: 'In this study, we introduce a methodology for human image animation by

    leveraging a 3D human parametric model within a latent diffusion framework to

    enhance shape alignment and motion guidance in curernt human generative

    techniques. The methodology utilizes the SMPL(Skinned Multi-Person Linear)

    model as the 3D human parametric model to establish a unified representation of

    body shape and pose. This facilitates the accurate capture of intricate human

    geometry and motion characteristics from source videos. Specifically, we

    incorporate rendered depth images, normal maps, and semantic maps obtained from

    SMPL sequences, alongside skeleton-based motion guidance, to enrich the

    conditions to the latent diffusion model with comprehensive 3D shape and

    detailed pose attributes. A multi-layer motion fusion module, integrating

    self-attention mechanisms, is employed to fuse the shape and motion latent

    representations in the spatial domain. By representing the 3D human parametric

    model as the motion guidance, we can perform parametric shape alignment of the

    human body between the reference image and the source video motion.

    Experimental evaluations conducted on benchmark datasets demonstrate the

    methodology''s superior ability to generate high-quality human animations that

    accurately capture both pose and shape variations. Furthermore, our approach

    also exhibits superior generalization capabilities on the proposed in-the-wild

    dataset. Project page: https://fudan-generative-vision.github.io/champ.'
  arxivId: '2403.14781'
  arxiv_tags:
  - cs.CV
  authors: Shenhao Zhu, Junming Leo Chen, Zuozhuo Dai, Qingkun Su, Yinghui Xu, Xun
    Cao, Yao Yao, Hao Zhu, Siyu Zhu
  created_at: '2024-12-27T08:37:33.793502'
  issue_number: 197
  issue_url: https://github.com/dmarx/arxiv-archive/issues/197
  labels:
  - paper
  - rating:novote
  last_read: null
  last_visited: '2024-12-23T21:24:01.786Z'
  main_tex_file: null
  published_date: '2024-03-21T18:52:58Z'
  state: open
  title: "Champ: Controllable and Consistent Human Image Animation with 3D\n  Parametric\
    \ Guidance"
  total_reading_time_seconds: 0
  url: https://arxiv.org/abs/2403.14781
'2405.04434':
  abstract: 'We present DeepSeek-V2, a strong Mixture-of-Experts (MoE) language model

    characterized by economical training and efficient inference. It comprises 236B

    total parameters, of which 21B are activated for each token, and supports a

    context length of 128K tokens. DeepSeek-V2 adopts innovative architectures

    including Multi-head Latent Attention (MLA) and DeepSeekMoE. MLA guarantees

    efficient inference through significantly compressing the Key-Value (KV) cache

    into a latent vector, while DeepSeekMoE enables training strong models at an

    economical cost through sparse computation. Compared with DeepSeek 67B,

    DeepSeek-V2 achieves significantly stronger performance, and meanwhile saves

    42.5% of training costs, reduces the KV cache by 93.3%, and boosts the maximum

    generation throughput to 5.76 times. We pretrain DeepSeek-V2 on a high-quality

    and multi-source corpus consisting of 8.1T tokens, and further perform

    Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) to fully unlock

    its potential. Evaluation results show that, even with only 21B activated

    parameters, DeepSeek-V2 and its chat versions still achieve top-tier

    performance among open-source models.'
  arxivId: '2405.04434'
  arxiv_tags:
  - cs.CL
  - cs.AI
  authors: DeepSeek-AI, Aixin Liu, Bei Feng, Bin Wang, Bingxuan Wang, Bo Liu, Chenggang
    Zhao, Chengqi Dengr, Chong Ruan, Damai Dai, Daya Guo, Dejian Yang, Deli Chen,
    Dongjie Ji, Erhang Li, Fangyun Lin, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei
    Li, H. Zhang, Hanwei Xu, Hao Yang, Haowei Zhang, Honghui Ding, Huajian Xin, Huazuo
    Gao, Hui Li, Hui Qu, J. L. Cai, Jian Liang, Jianzhong Guo, Jiaqi Ni, Jiashi Li,
    Jin Chen, Jingyang Yuan, Junjie Qiu, Junxiao Song, Kai Dong, Kaige Gao, Kang Guan,
    Lean Wang, Lecong Zhang, Lei Xu, Leyi Xia, Liang Zhao, Liyue Zhang, Meng Li, Miaojun
    Wang, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Mingming Li, Ning Tian, Panpan
    Huang, Peiyi Wang, Peng Zhang, Qihao Zhu, Qinyu Chen, Qiushi Du, R. J. Chen, R.
    L. Jin, Ruiqi Ge, Ruizhe Pan, Runxin Xu, Ruyi Chen, S. S. Li, Shanghao Lu, Shangyan
    Zhou, Shanhuang Chen, Shaoqing Wu, Shengfeng Ye, Shirong Ma, Shiyu Wang, Shuang
    Zhou, Shuiping Yu, Shunfeng Zhou, Size Zheng, T. Wang, Tian Pei, Tian Yuan, Tianyu
    Sun, W. L. Xiao, Wangding Zeng, Wei An, Wen Liu, Wenfeng Liang, Wenjun Gao, Wentao
    Zhang, X. Q. Li, Xiangyue Jin, Xianzu Wang, Xiao Bi, Xiaodong Liu, Xiaohan Wang,
    Xiaojin Shen, Xiaokang Chen, Xiaosha Chen, Xiaotao Nie, Xiaowen Sun, Xiaoxiang
    Wang, Xin Liu, Xin Xie, Xingkai Yu, Xinnan Song, Xinyi Zhou, Xinyu Yang, Xuan
    Lu, Xuecheng Su, Y. Wu, Y. K. Li, Y. X. Wei, Y. X. Zhu, Yanhong Xu, Yanping Huang,
    Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Li, Yaohui Wang, Yi Zheng, Yichao Zhang,
    Yiliang Xiong, Yilong Zhao, Ying He, Ying Tang, Yishi Piao, Yixin Dong, Yixuan
    Tan, Yiyuan Liu, Yongji Wang, Yongqiang Guo, Yuchen Zhu, Yuduan Wang, Yuheng Zou,
    Yukun Zha, Yunxian Ma, Yuting Yan, Yuxiang You, Yuxuan Liu, Z. Z. Ren, Zehui Ren,
    Zhangli Sha, Zhe Fu, Zhen Huang, Zhen Zhang, Zhenda Xie, Zhewen Hao, Zhihong Shao,
    Zhiniu Wen, Zhipeng Xu, Zhongyu Zhang, Zhuoshu Li, Zihan Wang, Zihui Gu, Zilin
    Li, Ziwei Xie
  created_at: '2024-12-27T08:36:36.875369'
  issue_number: 281
  issue_url: https://github.com/dmarx/arxiv-archive/issues/281
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:36:45.867060'
  last_visited: '2024-12-26T13:01:17.331Z'
  main_tex_file: null
  published_date: '2024-05-07T15:56:43Z'
  state: open
  title: "DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts\n  Language\
    \ Model"
  total_reading_time_seconds: 46
  url: https://arxiv.org/abs/2405.04434
'2405.12399':
  abstract: 'World models constitute a promising approach for training reinforcement

    learning agents in a safe and sample-efficient manner. Recent world models

    predominantly operate on sequences of discrete latent variables to model

    environment dynamics. However, this compression into a compact discrete

    representation may ignore visual details that are important for reinforcement

    learning. Concurrently, diffusion models have become a dominant approach for

    image generation, challenging well-established methods modeling discrete

    latents. Motivated by this paradigm shift, we introduce DIAMOND (DIffusion As
    a

    Model Of eNvironment Dreams), a reinforcement learning agent trained in a

    diffusion world model. We analyze the key design choices that are required to

    make diffusion suitable for world modeling, and demonstrate how improved visual

    details can lead to improved agent performance. DIAMOND achieves a mean human

    normalized score of 1.46 on the competitive Atari 100k benchmark; a new best

    for agents trained entirely within a world model. We further demonstrate that

    DIAMOND''s diffusion world model can stand alone as an interactive neural game

    engine by training on static Counter-Strike: Global Offensive gameplay. To

    foster future research on diffusion for world modeling, we release our code,

    agents, videos and playable world models at https://diamond-wm.github.io.'
  arxivId: '2405.12399'
  arxiv_tags:
  - cs.LG
  - cs.AI
  - cs.CV
  authors: Eloi Alonso, Adam Jelley, Vincent Micheli, Anssi Kanervisto, Amos Storkey,
    Tim Pearce, François Fleuret
  created_at: '2024-12-27T08:36:42.797996'
  issue_number: 296
  issue_url: https://github.com/dmarx/arxiv-archive/issues/296
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:36:42.798867'
  last_visited: '2024-12-26T22:06:50.951Z'
  main_tex_file: null
  published_date: '2024-05-20T22:51:05Z'
  state: open
  title: 'Diffusion for World Modeling: Visual Details Matter in Atari'
  total_reading_time_seconds: 12
  url: https://arxiv.org/abs/2405.12399
'2407.01392':
  abstract: 'This paper presents Diffusion Forcing, a new training paradigm where
    a

    diffusion model is trained to denoise a set of tokens with independent

    per-token noise levels. We apply Diffusion Forcing to sequence generative

    modeling by training a causal next-token prediction model to generate one or

    several future tokens without fully diffusing past ones. Our approach is shown

    to combine the strengths of next-token prediction models, such as

    variable-length generation, with the strengths of full-sequence diffusion

    models, such as the ability to guide sampling to desirable trajectories. Our

    method offers a range of additional capabilities, such as (1) rolling-out

    sequences of continuous tokens, such as video, with lengths past the training

    horizon, where baselines diverge and (2) new sampling and guiding schemes that

    uniquely profit from Diffusion Forcing''s variable-horizon and causal

    architecture, and which lead to marked performance gains in decision-making and

    planning tasks. In addition to its empirical success, our method is proven to

    optimize a variational lower bound on the likelihoods of all subsequences of

    tokens drawn from the true joint distribution. Project website:

    https://boyuan.space/diffusion-forcing'
  arxivId: '2407.01392'
  arxiv_tags:
  - cs.LG
  - cs.CV
  - cs.RO
  authors: Boyuan Chen, Diego Marti Monso, Yilun Du, Max Simchowitz, Russ Tedrake,
    Vincent Sitzmann
  created_at: '2024-12-27T08:36:30.880723'
  issue_number: 295
  issue_url: https://github.com/dmarx/arxiv-archive/issues/295
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:36:30.883756'
  last_visited: '2024-12-26T22:05:31.374Z'
  main_tex_file: null
  published_date: '2024-07-01T15:43:25Z'
  state: open
  title: 'Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion'
  total_reading_time_seconds: 34
  url: https://arxiv.org/abs/2407.01392
'2407.05872':
  abstract: 'Robust and effective scaling of models from small to large width typically

    requires the precise adjustment of many algorithmic and architectural details,

    such as parameterization and optimizer choices. In this work, we propose a new

    perspective on parameterization by investigating a key assumption in prior work

    about the alignment between parameters and data and derive new theoretical

    results under weaker assumptions and a broader set of optimizers. Our extensive

    empirical investigation includes tens of thousands of models trained with all

    combinations of three optimizers, four parameterizations, several alignment

    assumptions, more than a dozen learning rates, and fourteen model sizes up to

    26.8B parameters. We find that the best learning rate scaling prescription

    would often have been excluded by the assumptions in prior work. Our results

    show that all parameterizations, not just maximal update parameterization

    (muP), can achieve hyperparameter transfer; moreover, our novel per-layer

    learning rate prescription for standard parameterization outperforms muP.

    Finally, we demonstrate that an overlooked aspect of parameterization, the

    epsilon parameter in Adam, must be scaled correctly to avoid gradient underflow

    and propose Adam-atan2, a new numerically stable, scale-invariant version of

    Adam that eliminates the epsilon hyperparameter entirely.'
  arxivId: '2407.05872'
  arxiv_tags:
  - cs.LG
  authors: Katie Everett, Lechao Xiao, Mitchell Wortsman, Alexander A. Alemi, Roman
    Novak, Peter J. Liu, Izzeddin Gur, Jascha Sohl-Dickstein, Leslie Pack Kaelbling,
    Jaehoon Lee, Jeffrey Pennington
  created_at: '2024-12-27T08:36:51.877134'
  issue_number: 255
  issue_url: https://github.com/dmarx/arxiv-archive/issues/255
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:36:51.877977'
  last_visited: '2024-12-24T21:09:44.860Z'
  main_tex_file: null
  published_date: '2024-07-08T12:32:51Z'
  state: open
  title: Scaling Exponents Across Parameterizations and Optimizers
  total_reading_time_seconds: 4
  url: https://arxiv.org/abs/2407.05872
'2408.14837':
  abstract: 'We present GameNGen, the first game engine powered entirely by a neural
    model

    that enables real-time interaction with a complex environment over long

    trajectories at high quality. GameNGen can interactively simulate the classic

    game DOOM at over 20 frames per second on a single TPU. Next frame prediction

    achieves a PSNR of 29.4, comparable to lossy JPEG compression. Human raters are

    only slightly better than random chance at distinguishing short clips of the

    game from clips of the simulation. GameNGen is trained in two phases: (1) an

    RL-agent learns to play the game and the training sessions are recorded, and

    (2) a diffusion model is trained to produce the next frame, conditioned on the

    sequence of past frames and actions. Conditioning augmentations enable stable

    auto-regressive generation over long trajectories.'
  arxivId: '2408.14837'
  arxiv_tags:
  - cs.LG
  - cs.AI
  - cs.CV
  authors: Dani Valevski, Yaniv Leviathan, Moab Arar, Shlomi Fruchter
  created_at: '2024-12-27T08:36:28.173575'
  issue_number: 290
  issue_url: https://github.com/dmarx/arxiv-archive/issues/290
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:36:42.801601'
  last_visited: '2024-12-26T21:43:51.081Z'
  main_tex_file: null
  published_date: '2024-08-27T07:46:07Z'
  state: open
  title: Diffusion Models Are Real-Time Game Engines
  total_reading_time_seconds: 14
  url: https://arxiv.org/abs/2408.14837
'2410.01131':
  abstract: 'We propose a novel neural network architecture, the normalized Transformer

    (nGPT) with representation learning on the hypersphere. In nGPT, all vectors

    forming the embeddings, MLP, attention matrices and hidden states are unit norm

    normalized. The input stream of tokens travels on the surface of a hypersphere,

    with each layer contributing a displacement towards the target output

    predictions. These displacements are defined by the MLP and attention blocks,

    whose vector components also reside on the same hypersphere. Experiments show

    that nGPT learns much faster, reducing the number of training steps required to

    achieve the same accuracy by a factor of 4 to 20, depending on the sequence

    length.'
  arxivId: '2410.01131'
  arxiv_tags:
  - cs.LG
  - cs.AI
  authors: Ilya Loshchilov, Cheng-Ping Hsieh, Simeng Sun, Boris Ginsburg
  created_at: '2024-12-27T08:36:48.854357'
  issue_number: 270
  issue_url: https://github.com/dmarx/arxiv-archive/issues/270
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:36:48.856096'
  last_visited: '2024-12-25T20:54:14.596Z'
  main_tex_file: null
  published_date: '2024-10-01T23:50:09Z'
  state: open
  title: "nGPT: Normalized Transformer with Representation Learning on the\n  Hypersphere"
  total_reading_time_seconds: 13
  url: https://arxiv.org/abs/2410.01131
'2412.09349':
  abstract: 'Controllable human image animation aims to generate videos from reference

    images using driving videos. Due to the limited control signals provided by

    sparse guidance (e.g., skeleton pose), recent works have attempted to introduce

    additional dense conditions (e.g., depth map) to ensure motion alignment.

    However, such strict dense guidance impairs the quality of the generated video

    when the body shape of the reference character differs significantly from that

    of the driving video. In this paper, we present DisPose to mine more

    generalizable and effective control signals without additional dense input,

    which disentangles the sparse skeleton pose in human image animation into

    motion field guidance and keypoint correspondence. Specifically, we generate a

    dense motion field from a sparse motion field and the reference image, which

    provides region-level dense guidance while maintaining the generalization of

    the sparse pose control. We also extract diffusion features corresponding to

    pose keypoints from the reference image, and then these point features are

    transferred to the target pose to provide distinct identity information. To

    seamlessly integrate into existing models, we propose a plug-and-play hybrid

    ControlNet that improves the quality and consistency of generated videos while

    freezing the existing model parameters. Extensive qualitative and quantitative

    experiments demonstrate the superiority of DisPose compared to current methods.

    Code:

    \href{https://github.com/lihxxx/DisPose}{https://github.com/lihxxx/DisPose}.'
  arxivId: '2412.09349'
  arxiv_tags:
  - cs.CV
  authors: Hongxiang Li, Yaowei Li, Yuhang Yang, Junjie Cao, Zhihong Zhu, Xuxin Cheng,
    Long Chen
  created_at: '2024-12-27T08:37:36.793096'
  issue_number: 194
  issue_url: https://github.com/dmarx/arxiv-archive/issues/194
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:37:36.795535'
  last_visited: '2024-12-23T21:16:28.682000+00:00'
  main_tex_file: null
  published_date: '2024-12-12T15:15:59Z'
  state: open
  title: "DisPose: Disentangling Pose Guidance for Controllable Human Image\n  Animation"
  total_reading_time_seconds: 339
  url: https://arxiv.org/abs/2412.09349
'2412.17799':
  abstract: 'With the recent Nobel Prize awarded for radical advances in protein

    discovery, foundation models (FMs) for exploring large combinatorial spaces

    promise to revolutionize many scientific fields. Artificial Life (ALife) has

    not yet integrated FMs, thus presenting a major opportunity for the field to

    alleviate the historical burden of relying chiefly on manual design and

    trial-and-error to discover the configurations of lifelike simulations. This

    paper presents, for the first time, a successful realization of this

    opportunity using vision-language FMs. The proposed approach, called Automated

    Search for Artificial Life (ASAL), (1) finds simulations that produce target

    phenomena, (2) discovers simulations that generate temporally open-ended

    novelty, and (3) illuminates an entire space of interestingly diverse

    simulations. Because of the generality of FMs, ASAL works effectively across a

    diverse range of ALife substrates including Boids, Particle Life, Game of Life,

    Lenia, and Neural Cellular Automata. A major result highlighting the potential

    of this technique is the discovery of previously unseen Lenia and Boids

    lifeforms, as well as cellular automata that are open-ended like Conway''s Game

    of Life. Additionally, the use of FMs allows for the quantification of

    previously qualitative phenomena in a human-aligned way. This new paradigm

    promises to accelerate ALife research beyond what is possible through human

    ingenuity alone.'
  arxivId: '2412.17799'
  arxiv_tags:
  - cs.AI
  - cs.NE
  authors: Akarsh Kumar, Chris Lu, Louis Kirsch, Yujin Tang, Kenneth O. Stanley, Phillip
    Isola, David Ha
  created_at: '2024-12-27T08:37:00.881996'
  issue_number: 247
  issue_url: https://github.com/dmarx/arxiv-archive/issues/247
  labels:
  - paper
  - rating:novote
  last_read: '2024-12-27T08:37:00.884084'
  last_visited: '2024-12-24T04:41:56.160Z'
  main_tex_file: null
  published_date: '2024-12-23T18:57:00Z'
  state: open
  title: Automating the Search for Artificial Life with Foundation Models
  total_reading_time_seconds: 11
  url: https://arxiv.org/abs/2412.17799
