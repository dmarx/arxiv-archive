\section{Related Work} \label{sec:relatedwork}


\noindent
\textbf{Knowledge Graph Question Answering (KGQA).}
KGQA aims to answer questions over KG, and previous methods are usually categorized as EM-based, IR-based, SP-based and LLM-based methods.
EM-based methods encode the entities and relations in the embedding space and reason final answer using these structural embeddings~\cite{shi2021transfernet}.
% For instance, QA-GNN~\cite{yasunaga2021qa} utilizes graph neural networks (GNNs) to reason both KG subgraphs and QA contexts jointly.
IR-based KBQA methods propose to retrieve and re-rank answers from KGs given information conveyed in the question~\cite{chen2019uhop,zhang2022subgraph}.
SP-based methods, focus on transforming question into a structural query, such as SPARQL and S-expression, and reason final answers using these executable queries~\cite{liang2017neural,lan2020query}.
Besides, recent attempts have been made to utilize LLM-based methods for KGQA~\cite{jiang2023unikgqa,chenplan}.
For instance, \citet{RoG} presents a planning-retrieval-reasoning pipeline. ToG \cite{TOG} proposes to interactively explore paths and reasoning on KGs using LLM as an agent.
% G-Retriever is a retrieval-augmented method for general textual graphs and it integrates graph neural networks and LLMs via soft prompting~\cite{G-retriever}.
Despite their significant improvements, a substantial challenge persists when handling multi-aspect retrieved data as input, which may introduce irrelevant knowledge.
However, our method is capable of aligning knowledge and implementing adaptive relevance gating with questions, thus addressing this issue.


% \noindent
% \textbf{Parameter-Efficient Fine-Tuning (PEFT).}
% % 参考 G-Retriever， 简单介绍 lora  和 prompt tuning 等方法。
% Fine-tuning (FT) can provide additional knowledge to LLMs and adjust LLMs' input and output to, for example, adapt to the structured data. Various parameter-efficient fine-tuning (PEFT) methods have been proposed to refine LLMs with minimal training costs~\cite{hu2022lora,zhang2023adalora,li2021prefix,lester2021prompttuning}.
% Low-Rank Adaptation (LoRA) reduces the number of trainable parameters by decomposing a large matrix into two smaller low-rank matrices in the attention layers~\cite{hu2022lora}, and AdaLoRA improves on LoRA by adaptively allocating the parameters among different weight matrices and layers according to their importance scores~\cite{zhang2023adalora}.
% Prompt tuning adds task-specific prompts to the tuning data and these prompt parameters are updated during fine-tuning~\cite{lester2021prompttuning}.
% Prefix tuning is proposed to prefix task-specific vectors to the tuning data and only updates these prefix parameters while keeping the LLM's parameters frozen~\cite{li2021prefix}.

% However, PEFT methods, such as LoRA and Prompt tuning, may face difficulties in effectively utilizing the extensive information derived from long texts, which often yield subpar model performance \cite{chen2023longlora}. In contrast, our model designed an adaptive framework for the retrieval information, enabling efficient learning the mapping between knowledge to generate the desired output.


\noindent
\textbf{Large Language Model Reasoning.}
Considering the impressive abilities of LLMs, some previous works focus on facilitating LLMs' reasoning via prompting~\cite{NSM,CBR-KBQA,structgpt,wang2023knowledge,li2024visualization,10.1007/978-981-97-7232-2_18,chen2024tackling}.
% For example, as a neuro-symbolic approach, CBR-KBQA reuses existing cases to improve reasoning on unseen cases~\cite{CBR-KBQA}.
To overcome the unfaithful reasoning of LLMs, ~\citet{structgpt} proposes StructGPT, an iterative reading-then-reasoning framework, to improve reasoning of LLMs when handling structured data.
 % FAME leverages Monte-Carlo planning to generate faithful reasoning steps~\cite{hong2023faithful} and
KD-CoT is designed to formulate chain-of-thought into a multi-round QA format and LLMs can retrieve external knowledge during interaction~\cite{wang2023knowledge}.
% ~\citet{du2024improving} proposes to utilize multiple LLMs and obtain the final answer through discussion and debation among these LLMs, which improves the factual validity of the generated contents.
However, LLMs reasoning is challenging when leveraging information present in lengthy texts \cite{wang2024beyond}. In contrast, our model facilitates efficient selection of information by utilizing prompt embeddings, thereby mitigating the issue of excessive context.

