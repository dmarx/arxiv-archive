\section{Conclusion}
In this work, we propose a novel approach to enhance LLMs reasoning and factual output by retrieving multi-aspect knowledge from KGs. By employing self-alignment and relevance gating modules, \model adaptively enhances and selects relevant information. 
It has proven more effective than simply appending retrieved text to input context, as it minimizes noise interference. Through extensive experiments, \model outperforms 22 baseline models and achieves a new state-of-the-art performance.

\section{Acknowledgment}
This work was supported in part by the grants from National Science and Technology Major Project (No. 2023ZD0121104), and National Natural Science Foundation of China (No.62222213, 62072423).
This research was partially supported by Research Impact Fund (No.R1015-23), APRC - CityU New Research Initiatives (No.9610565, Start-up Grant for New Faculty of CityU), CityU - HKIDS Early Career Research Grant (No.9360163), Hong Kong ITC Innovation and Technology Fund Midstream Research Programme for Universities Project (No.ITS/034/22MS), Hong Kong Environmental and Conservation Fund (No. 88/2022), and SIRG - CityU Strategic Interdisciplinary Research Grant (No.7020046), Tencent (CCF-Tencent Open Fund, Tencent Rhino-Bird Focused Research Program).